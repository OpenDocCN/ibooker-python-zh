- en: Appendix C. Debugging Dask
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 C. 调试 Dask
- en: Depending on your debugging techniques, moving to distributed systems could
    require a new set of techniques. While you can use debuggers in remote mode, it
    often requires more setup work. You can also run Dask locally to use your existing
    debugging tools in many other situations, although—take it from us—a surprising
    number of difficult-to-debug errors don’t show up in local mode. Dask has a special
    hybrid approach. Some errors happen outside Python, making them more difficult
    to debug, like container out-of-memory (OOM) errors, segmentation faults, and
    other native errors.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的调试技术，转向分布式系统可能需要一套新的技术。虽然您可以在远程模式下使用调试器，但通常需要更多的设置工作。您还可以在本地运行 Dask，以在许多其他情况下使用现有的调试工具，尽管——从我们的经验来看——令人惊讶的许多难以调试的错误在本地模式下并不会显现。Dask
    采用了特殊的混合方法。一些错误发生在 Python 之外，使得它们更难以调试，如容器内存不足 (OOM) 错误、段错误和其他本地错误。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Some of this advice is common across distributed systems, including Ray and
    Apache Spark. As such, some elements of this chapter are shared with *High Performance
    Spark*, second edition, and *Scaling Python with Ray*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这些建议中有些适用于分布式系统，包括 Ray 和 Apache Spark。因此，本章的某些部分与 *High Performance Spark*,
    第二版 和 *Scaling Python with Ray* 有共通之处。
- en: Using Debuggers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用调试器
- en: There are a few different options for using debuggers in Dask. PyCharm and PDB
    both support connecting to remote debugger processes, but figuring out where your
    task is running and also setting up the remote debugger can be a challenge. For
    details on PyCharm remote debugging, see the JetBrains article [“Remote Debugging
    with PyCharm”](https://oreil.ly/HGl90). One option is to use epdb and run `import
    epdb; epdb.serve()` inside of an actor. The easiest option, which is not perfect,
    is to have Dask re-run failed tasks locally by running `client.recreate_error_locally`
    on the future that failed.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Dask 中使用调试器有几种不同的选项。PyCharm 和 PDB 都支持连接到远程调试器进程，但是找出任务运行的位置并设置远程调试器可能会有挑战。有关
    PyCharm 远程调试的详细信息，请参阅 JetBrains 文章 [“使用 PyCharm 远程调试”](https://oreil.ly/HGl90)。一种选择是使用
    epdb 并在 actor 中运行 `import epdb; epdb.serve()`。最简单的选项是通过在失败的 future 上运行 `client.recreate_error_locally`
    来让 Dask 在本地重新运行失败的任务，尽管这并非完美解决方案。
- en: General Debugging Tips with Dask
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Dask 的一般调试技巧
- en: 'You likely have your own standard debugging techniques for working with Python
    code, and these are not meant to replace them. Some general techniques that are
    helpful with Dask include the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能有自己的标准 Python 代码调试技术，并且这些技术并非替代它们。一些在 Dask 中有帮助的一般技术包括以下内容：
- en: Break up failing functions into smaller functions; smaller functions make it
    easier to isolate the problem.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将失败的函数分解为更小的函数；更小的函数使问题更容易隔离。
- en: Be careful about referencing variables from outside of a function, which can
    result in unintended scope capture, serializing more data and objects than intended.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要小心引用函数外的变量，可能会导致意外的作用域捕获，序列化更多的数据和对象。
- en: Sample data and try to reproduce locally (local debugging is often easier).
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽样数据并尝试在本地复现（本地调试通常更容易）。
- en: Use [mypy](https://mypy-lang.org) for type checking. While we haven’t included
    types in many of our examples for space, in production code liberal type usage
    can catch tricky errors.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [mypy](https://mypy-lang.org) 进行类型检查。虽然我们的示例中未包含类型信息以节省空间，但在生产代码中，宽松的类型使用可以捕捉到棘手的错误。
- en: Having difficulty tracking down where a task is getting scheduled? Dask actors
    can’t move, so use an actor to keep all invocations on one machine for debugging.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以追踪任务的调度位置？Dask actors 无法移动，因此可以使用 actor 将所有调用保持在一台机器上进行调试。
- en: When the issues do appear, regardless of parallelization, debugging your code
    in local single-threaded mode can make it easier to understand what’s going on.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当问题出现时，无论并行化如何，通过在本地单线程模式下调试您的代码，可以更容易地理解正在发生的事情。
- en: With these tips you will (often) be able to find yourself in a familiar enough
    environment to use your traditional debugging tools, but some types of errors
    are a little bit more complicated.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些提示，通常可以在熟悉的环境中找到自己，以使用传统的调试工具，但某些类型的错误可能会更复杂一些。
- en: Native Errors
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地错误
- en: Native errors and core dumps can be challenging to debug for the same reasons
    as container errors. Since these types of errors often result in the container
    exiting, accessing the debugging information can become challenging. Depending
    on your deployment, there may be a centralized log aggregator that collects all
    of the logs from the containers, although sometimes these can miss the final few
    parts of the log (which you likely care about the most). A quick solution to this
    is to add a `sleep` to the launch script (on failure) so that you can connect
    to the container (e.g., `[dasklaunchcommand] || sleep 100000`) and use native
    debugging tools.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器错误的原因相同，本地错误和核心转储可能很难调试。由于这些类型的错误通常导致容器退出，因此访问调试信息可能变得困难。根据您的部署方式，可能有一个集中式日志聚合器，收集来自容器的所有日志，尽管有时这些日志可能会错过最后几部分（这些部分很可能是您最关心的）。这个问题的一个快速解决方案是在启动脚本中添加一个
    `sleep`（在失败时），以便您可以连接到容器（例如，`[dasklaunchcommand] || sleep 100000`）并使用本地调试工具。
- en: However, accessing the internals of a container can be easier said than done.
    In many production environments, you may not be able to get remote access (e.g.,
    `kubectly exec` on Kubernetes) for security reasons. If that is the case, you
    can (sometimes) add a shutdown script to your container specification that copies
    the core files to a location that persists after the container shuts down (e.g.,
    `s3` or `HDFS` or `NFS`). Your cluster administrator may also have recommended
    tools to help debug (or if not, they may be able to help you create a recommended
    path for your organization).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，访问容器的内部可能并不像说起来那么容易。在许多生产环境中，出于安全原因，您可能无法远程访问（例如，在 Kubernetes 上使用 `kubectl
    exec`）。如果是这种情况，您可以（有时）向容器规范添加一个关闭脚本，将核心文件复制到容器关闭后仍然存在的位置（例如，`s3`、`HDFS` 或 `NFS`）。您的集群管理员可能还推荐了一些工具来帮助调试（如果没有的话，他们可能能够为您的组织创建一个推荐的路径）。
- en: Some Notes on Official Advice for Handling Bad Records
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理坏记录的官方建议的一些注释
- en: Dask’s [official debugging guide](https://oreil.ly/I9wDw) recommends removing
    failed futures manually. When loading data that can be processed in smaller chunks
    rather than entire partitions at a time, returning tuples with successful and
    failed data is better, since removing entire partitions is not conducive to determining
    the root cause. This technique is demonstrated in [Example C-1](#dask-debugging-handle_appC_1686051006707).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的 [官方调试指南](https://oreil.ly/I9wDw) 建议手动移除失败的 futures。当加载可以分块处理而不是一次加载整个分区的数据时，返回具有成功和失败数据的元组更好，因为移除整个分区不利于确定根本原因。这种技术在
    [示例 C-1](#dask-debugging-handle_appC_1686051006707) 中有所示。
- en: Example C-1\. Alternative approach for handling bad data
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 C-1\. 处理错误数据的替代方法
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Bad records here does not exclusively mean records that fail to load or parse;
    they can also be records that are causing your code to fail. By following this
    pattern, you can extract the problematic records for deeper investigation and
    use this to improve your code.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的坏记录不仅仅指加载或解析失败的记录；它们也可能是导致您的代码失败的记录。通过遵循这种模式，您可以提取有问题的记录进行深入调查，并使用它来改进您的代码。
- en: Dask Diagnostics
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dask 诊断
- en: Dask has built-in diagnostic tools for both [distributed](https://oreil.ly/Uin87)
    and [local](https://oreil.ly/JO4qR) schedulers. The local diagnostics are more
    featureful with pretty much every part of debugging. These diagnostics can be
    especially great for debugging situations in which you see a slow degradation
    of performance over time.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 为 [distributed](https://oreil.ly/Uin87) 和 [local](https://oreil.ly/JO4qR)
    调度器都内置了诊断工具。本地诊断工具具有更丰富的功能，几乎涵盖了所有调试的部分。这些诊断工具在您看到性能逐渐下降的调试情况下尤其有用。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It’s really easy to accidentally use Dask’s distributed local backend by mistake
    when making a Dask client, so if you don’t see the diagnostics you expect, make
    sure you are explicit about which backend you are running on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 Dask 客户端时，很容易因错误而意外地使用 Dask 的分布式本地后端，因此，如果您没有看到您期望的诊断结果，请确保明确指定您正在运行的后端。
- en: Conclusion
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You will have a bit more work to get started with your debugging tools in Dask,
    and when possible, Dask’s local mode offers a great alternative to remote debugging.
    Not all errors are created equal, and some errors, like segmentation faults in
    native code, are especially challenging to debug. Good luck finding the bug(s);
    we believe in you.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Dask 中启动调试工具会需要更多工作，而且在可能的情况下，Dask 的本地模式提供了远程调试的绝佳替代方案。并非所有错误都一样，而且一些错误，比如本地代码中的分段错误，尤其难以调试。祝你找到（们）bug
    的好运；我们相信你。
