<html><head></head><body><section data-pdf-bookmark="Chapter 11. Container Technologies: Docker and Docker Compose" data-type="chapter" epub:type="chapter"><div class="chapter" id="containers-docker">&#13;
<h1><span class="label">Chapter 11. </span>Container Technologies: <span class="keep-together">Docker and Docker Compose</span></h1>&#13;
&#13;
&#13;
<p><a data-primary="Docker" data-type="indexterm" id="ix_ch11-asciidoc0"/>Virtualization technologies have been around since the days of the IBM mainframes. Most people have not had a chance to work on a mainframe, but we are sure some readers of this book remember the days when they had to set up or use a bare-metal server from a manufacturer such as HP or Dell. These manufacturers are still around today, and you can still use bare-metal servers hosted in a colocation facility, like in the good old days of the dot-com era.</p>&#13;
&#13;
<p>When most people think of virtualization, however, they do not automatically have a mainframe in mind. Instead, they most likely imagine a virtual machine (VM) running a guest operating system (OS) such as Fedora or Ubuntu on top of a hypervisor such as VMware ESX or Citrix/Xen. The big advantage of VMs over regular bare-metal servers is that by using VMs, you can optimize the server’s resources (CPU, memory, disk) by splitting them across several virtual machines. You can also run several operating systems, each in its own VM, on top of one shared bare-metal server, instead of buying a dedicated server per targeted OS. Cloud computing services such as Amazon EC2 would not have been possible without hypervisors and virtual machines. This type of virtualization can be called kernel-level because each virtual machine runs its own OS kernel.</p>&#13;
&#13;
<p>In the never-ending quest for more bang for their buck, people realized that virtual machines were still wasteful in terms of resources. The next logical step was to isolate an individual application into its own virtual environment. This was achieved by running containers within the same OS kernel. In this case, they were isolated at the file-system level. Linux containers (LXC) and Sun Solaris zones were early examples of such technologies. Their disadvantage was that they were hard to use and were tightly coupled to the OS they were running on. The big breakthrough in container usage came when Docker started to offer an easy way to manage and run filesystem-level containers.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="What Is a Docker Container?" data-type="sect1"><div class="sect1" id="idm46691322595704">&#13;
<h1>What Is a Docker Container?</h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="defining" data-type="indexterm" id="idm46691322594248"/>A Docker container encapsulates an application together with other software packages and libraries it requires to run. People sometimes use the terms Docker container and Docker image interchangeably, but there is a difference. The filesystem-level object that encapsulates the application is called a Docker image. When you run the image, it becomes a Docker container.</p>&#13;
&#13;
<p>You can run many Docker containers, all using the same OS kernel. The only requirement is that you must install a server-side component called the Docker engine or the Docker daemon on the host where you want to run the containers. In this way, the host resources can be split and utilized in a more granular way across the containers, giving you more bang for your buck.</p>&#13;
&#13;
<p>Docker containers provide more isolation and resource control than regular Linux processes, but provide less than full-fledged virtual machines would. To achieve these properties of isolation and resource control, the Docker engine makes use of Linux kernel features such as namespaces, control groups (or cgroups), and Union File Systems (UnionFS).</p>&#13;
&#13;
<p>The main advantage of Docker containers is portability. Once you create a Docker image, you can run it as a Docker container on any host OS where the Docker server-side daemon is available. These days, all the major operating systems run the Docker daemon: Linux, Windows, and macOS.</p>&#13;
&#13;
<p>All this can sound too theoretical, so it is time for some concrete examples.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Creating, Building, Running, and Removing Docker Images and Containers" data-type="sect1"><div class="sect1" id="idm46691322589944">&#13;
<h1>Creating, Building, Running, and Removing Docker Images and Containers</h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="creating/building/running/removing images/containers" data-type="indexterm" id="ix_ch11-asciidoc1"/>Since this is a book on Python and DevOps, we will take the canonical Flask “Hello World” as the first example of an application that runs in a Docker container. The examples shown in this section use the Docker for Mac package. Subsequent sections will show how to install Docker on Linux.</p>&#13;
&#13;
<p>Here is the main file of the Flask application:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">app</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">from</code> <code class="nn">flask</code> <code class="kn">import</code> <code class="n">Flask</code>&#13;
<code class="n">app</code> <code class="o">=</code> <code class="n">Flask</code><code class="p">(</code><code class="nv-Magic">__name__</code><code class="p">)</code>&#13;
&#13;
<code class="nd">@app.route</code><code class="p">(</code><code class="s1">'/'</code><code class="p">)</code>&#13;
<code class="k">def</code> <code class="nf">hello_world</code><code class="p">():</code>&#13;
    <code class="k">return</code> <code class="s1">'Hello, World! (from a Docker container)'</code>&#13;
&#13;
<code class="k">if</code> <code class="nv-Magic">__name__</code> <code class="o">==</code> <code class="s1">'__main__'</code><code class="p">:</code>&#13;
    <code class="n">app</code><code class="o">.</code><code class="n">run</code><code class="p">(</code><code class="n">debug</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">host</code><code class="o">=</code><code class="s1">'0.0.0.0'</code><code class="p">)</code></pre>&#13;
&#13;
<p>We also need a requirements file that specifies the version of the Flask package to be installed with <code>pip</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat requirements.txt&#13;
Flask==1.0.2</pre>&#13;
&#13;
<p>Trying to run the <em>app.py</em> file directly with Python on a macOS laptop without first installing the requirements results in an error:</p>&#13;
&#13;
<pre data-type="programlisting">$ python app.py&#13;
Traceback (most recent call last):&#13;
  File "app.py", line 1, in &lt;module&gt;&#13;
    from flask import Flask&#13;
ImportError: No module named flask</pre>&#13;
&#13;
<p>One obvious way to get past this issue is to install the requirements with <code>pip</code> on your local machine. This would make everything specific to the operating system you are running locally. What if the application needs to be deployed on a server running a different OS? The well-known issue of “works on my machine” could arise, where everything works beautifully on a macOS laptop, but for some mysterious reason, usually related to OS-specific versions of Python libraries, everything breaks on the staging or production servers running other operating systems, such as Ubuntu or Red Hat Linux.</p>&#13;
&#13;
<p>Docker offers an elegant solution to this conundrum. We can still do our development locally, using our beloved editors and toolchains, but we package our application’s dependencies inside a portable Docker container.</p>&#13;
&#13;
<p>Here is the Dockerfile describing the Docker image that is going to be built:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="nv">$ </code>cat Dockerfile&#13;
<code class="k">FROM</code><code class="s"> python:3.7.3-alpine</code>&#13;
&#13;
<code class="k">ENV</code><code class="s"> APP_HOME /app</code>&#13;
<code class="k">WORKDIR</code><code class="s"> $APP_HOME</code>&#13;
&#13;
COPY requirements.txt .&#13;
&#13;
<code class="k">RUN</code> pip install -r requirements.txt&#13;
&#13;
<code class="k">ENTRYPOINT</code><code class="s"> [ "python" ]</code>&#13;
<code class="k">CMD</code><code class="s"> [ "app.py" ]</code></pre>&#13;
&#13;
<p class="pagebreak-before">A few notes about this Dockerfile:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Use a prebuilt Docker image for Python 3.7.3 based on the Alpine distribution that produces slimmer Docker images; this Docker image already contains executables such as <code>python</code> and <code>pip</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Install the required packages with <code>pip</code>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Specify an ENTRYPOINT and a CMD. The difference between the two is that when the Docker container runs the image built from this Dockerfile, the program it runs is the ENTRYPOINT, followed by any arguments specified in CMD; in this case, it will run <code>python app.py</code>.</p>&#13;
</li>&#13;
</ul>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>If you do not specify an ENTRYPOINT in your Dockerfile, the following default will be used: <code>/bin/sh -c</code>.</p>&#13;
</div>&#13;
&#13;
<p>To create the Docker image for this application, run <a data-primary="docker build command" data-type="indexterm" id="idm46691322419528"/><code>docker build</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker build -t hello-world-docker .</pre>&#13;
&#13;
<p>To verify that the Docker image was saved locally, run <a data-primary="docker images command" data-type="indexterm" id="idm46691322410328"/><code>docker images</code> followed by the name of the image:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker images hello-world-docker&#13;
REPOSITORY               TAG       IMAGE ID            CREATED          SIZE&#13;
hello-world-docker       latest    dbd84c229002        2 minutes ago    97.7MB</pre>&#13;
&#13;
<p>To run the Docker image as a Docker container, use the <a data-primary="docker run command" data-type="indexterm" id="idm46691322407864"/><code>docker run</code> command:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker run --rm -d -v `pwd`:/app -p 5000:5000 hello-world-docker&#13;
c879295baa26d9dff1473460bab810cbf6071c53183890232971d1b473910602</pre>&#13;
&#13;
<p>A few notes about the <code>docker run</code> command arguments:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The <code>--rm</code> argument tells the Docker server to remove this container once it stops running. This is useful to prevent old containers from clogging the local <span class="keep-together">filesystem.</span></p>&#13;
</li>&#13;
<li>&#13;
<p>The <code>-d</code> argument tells the Docker server to run this container in the background.</p>&#13;
</li>&#13;
<li>&#13;
<p>The <code>-v</code> argument specifies that the current directory (<em>pwd</em>) is mapped to the <em>/app</em> directory inside the Docker container. This is essential for the local development workflow we want to achieve because it enables us to edit the application files locally and have them be auto-reloaded by the Flask development server running inside the container.</p>&#13;
</li>&#13;
<li>&#13;
<p>The <code>-p 5000:5000</code> argument maps the first port (5000) locally to the second port (5000) inside the container.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>To list running containers, run <code>docker ps</code> and note the container ID because it will be used in other <code>docker</code> commands:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker ps&#13;
CONTAINER ID  IMAGE                      COMMAND         CREATED&#13;
c879295baa26  hello-world-docker:latest  "python app.py" 4 seconds ago&#13;
STATUS          PORTS                    NAMES&#13;
Up 2 seconds    0.0.0.0:5000-&gt;5000/tcp   flamboyant_germain</pre>&#13;
&#13;
<p>To inspect the logs for a given container, run <code>docker logs</code> and specify the container name or ID:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker logs c879295baa26&#13;
 * Serving Flask app "app" (lazy loading)&#13;
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)&#13;
 * Restarting with stat&#13;
 * Debugger is active!&#13;
 * Debugger PIN: 647-161-014</pre>&#13;
&#13;
<p>Hit the endpoint URL with <code>curl</code> to verify that the application works. Because port 5000 of the application running inside the Docker container was mapped to port 5000 on the local machine with the <code>-p</code> command-line flag, you can use the local IP address 127.0.0.1 with port 5000 as the endpoint for the application.</p>&#13;
&#13;
<pre data-type="programlisting">$ curl http://127.0.0.1:5000&#13;
Hello, World! (from a Docker container)%</pre>&#13;
&#13;
<p>Now modify the code in <em>app.py</em> with your favorite editor. Change the greeting text to <em>Hello, World! (from a Docker container with modified code)</em>. Save <em>app.py</em> and notice lines similar to these in the Docker container logs:</p>&#13;
&#13;
<pre data-type="programlisting"> * Detected change in '/app/app.py', reloading&#13;
 * Restarting with stat&#13;
 * Debugger is active!&#13;
 * Debugger PIN: 647-161-014</pre>&#13;
&#13;
<p>This shows that the Flask development server running inside the container has detected the change in <em>app.py</em> and has reloaded the application.</p>&#13;
&#13;
<p>Hitting the application endpoint with <code>curl</code> will show the modified greeting:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl http://127.0.0.1:5000&#13;
Hello, World! (from a Docker container with modified code)%</pre>&#13;
&#13;
<p>To stop a running container, run <a data-primary="docker kill command" data-type="indexterm" id="idm46691322329864"/><a data-primary="docker stop command" data-type="indexterm" id="idm46691322329160"/><code>docker stop</code> or <code>docker kill</code> and specify the container ID as the argument:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker stop c879295baa26&#13;
c879295baa26</pre>&#13;
&#13;
<p>To delete a Docker image from local disk, run <a data-primary="docker rmi command" data-type="indexterm" id="idm46691322326376"/><code>docker rmi</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker rmi hello-world-docker&#13;
Untagged: hello-world-docker:latest&#13;
Deleted:sha256:dbd84c229002950550334224b4b42aba948ce450320a4d8388fa253348126402&#13;
Deleted:sha256:6a8f3db7658520a1654cc6abee8eafb463a72ddc3aa25f35ac0c5b1eccdf75cd&#13;
Deleted:sha256:aee7c3304ef6ff620956850e0b6e6b1a5a5828b58334c1b82b1a1c21afa8651f&#13;
Deleted:sha256:dca8a433d31fa06ab72af63ae23952ff27b702186de8cbea51cdea579f9221e8&#13;
Deleted:sha256:cb9d58c66b63059f39d2e70f05916fe466e5c99af919b425aa602091c943d424&#13;
Deleted:sha256:f0534bdca48bfded3c772c67489f139d1cab72d44a19c5972ed2cd09151564c1</pre>&#13;
&#13;
<p>This output shows the different filesystem layers comprising a Docker image. When the image is removed, the layers are deleted as well. Consult the <a href="https://oreil.ly/wqNve">Docker storage drivers</a> documentation for more details on how Docker uses filesystem layers to build its images.<a data-startref="ix_ch11-asciidoc1" data-type="indexterm" id="idm46691322322632"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Publishing Docker Images to a Docker Registry" data-type="sect1"><div class="sect1" id="idm46691322589000">&#13;
<h1>Publishing Docker Images to a Docker Registry</h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="publishing images to Docker registry" data-type="indexterm" id="idm46691322320792"/><a data-primary="Docker registry, publishing images to" data-type="indexterm" id="idm46691322319752"/>Once you have a Docker image built locally, you can publish it to what is called a Docker registry. There are several public registries to choose from, and for this example we will use Docker Hub. The purpose of these registries is to allow people and organizations to share pre-built Docker images that can be reused across different machines and operating systems.</p>&#13;
&#13;
<p>First, create a free account on <a href="https://hub.docker.com">Docker Hub</a> and then create a repository, either public or private. We created a private repository called <code>flask-hello-world</code> under our <code>griggheo</code> Docker Hub account.</p>&#13;
&#13;
<p>Then, at the command line, run <code>docker login</code> and specify the email and password for your account. At this point, you can interact with Docker Hub via the <code>docker</code> <span class="keep-together">client.</span></p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Before showing you how to publish your locally built Docker image to Docker Hub, we want to point out that best practice is to tag your image with a unique tag. If you don’t tag it specifically, the image will be tagged as <code>latest</code> by default. Pushing a new image version with no tag will move the <code>latest</code> tag to the newest image version. When using a Docker image, if you do not specify the exact tag you need, you will get the <code>latest</code> version of the image, which might contain modifications and updates that might break your dependencies. As always, the principle of least surprise should apply: you should use tags both when pushing images to a registry, and when referring to images in a Dockerfile. That being said, you can also tag your desired version of the image as <code>latest</code> so that people who are interested in the latest and greatest can use it without specifying a tag.</p>&#13;
</div>&#13;
&#13;
<p>When building the Docker image in the previous section, it was automatically tagged as <code>latest</code>, and the repository was set to the name of the image, signifying that the image is local:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker images hello-world-docker&#13;
REPOSITORY               TAG       IMAGE ID            CREATED          SIZE&#13;
hello-world-docker       latest    dbd84c229002        2 minutes ago    97.7MB</pre>&#13;
&#13;
<p>To tag a Docker image, run <code>docker tag</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker tag hello-world-docker hello-world-docker:v1</pre>&#13;
&#13;
<p>Now you can see both tags for the <code>hello-world-docker</code> image:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker images hello-world-docker&#13;
REPOSITORY               TAG      IMAGE ID           CREATED          SIZE&#13;
hello-world-docker       latest   dbd84c229002       2 minutes ago    97.7MB&#13;
hello-world-docker       v1       89bd38cb198f       42 seconds ago   97.7MB</pre>&#13;
&#13;
<p>Before you can publish the <code>hello-world-docker</code> image to Docker Hub, you also need to tag it with the Docker Hub repository name, which contains your username or your organization name. In our case, this repository is <code>griggheo/hello-world-docker</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker tag hello-world-docker:latest griggheo/hello-world-docker:latest&#13;
$ docker tag hello-world-docker:v1 griggheo/hello-world-docker:v1</pre>&#13;
&#13;
<p>Publish both image tags to Docker Hub with <code>docker push</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker push griggheo/hello-world-docker:latest&#13;
$ docker push griggheo/hello-world-docker:v1</pre>&#13;
&#13;
<p>If you followed along, you should now be able to see your Docker image published with both tags to the Docker Hub repository you created under your account.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running a Docker Container with the Same Image on a Different Host" data-type="sect1"><div class="sect1" id="idm46691322321672">&#13;
<h1>Running a Docker Container with the Same Image <span class="keep-together">on a Different Host</span></h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="running container with same image on different host" data-type="indexterm" id="ix_ch11-asciidoc2"/>Now that the Docker image is published to Docker Hub, we are ready to show off the portability of Docker by running a container based on the published image on a different host. The scenario considered here is that of collaborating with a colleague who doesn’t have macOS but likes to develop on a laptop running Fedora. The scenario includes checking out the application code and modifying it.</p>&#13;
&#13;
<p>Launch an EC2 instance in AWS based on the Linux 2 AMI, which is based on RedHat/CentOS/Fedora, and then install the Docker engine. Add the default user on the EC2 Linux AMI, called <code>ec2-user</code>, to the <code>docker</code> group so it can run <code>docker</code> client commands:</p>&#13;
&#13;
<pre data-type="programlisting">$ sudo yum update -y&#13;
$ sudo amazon-linux-extras install docker&#13;
$ sudo service docker start&#13;
$ sudo usermod -a -G docker ec2-user</pre>&#13;
&#13;
<p>Make sure to check out the application code on the remote EC2 instance. In this case, the code consists only of <em>app.py</em> file.</p>&#13;
&#13;
<p>Next, run the Docker container based on the image published to Docker Hub.&#13;
The only difference is that the image used as an argument to the <code>docker run</code> command&#13;
was <code>griggheo/hello-world-docker:v1</code> instead of simply <code>hello-world-docker</code>.</p>&#13;
&#13;
<p>Run <code>docker login</code>, then:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker run --rm -d -v `pwd`:/app -p 5000:5000 griggheo/hello-world-docker:v1&#13;
&#13;
Unable to find image 'griggheo/hello-world-docker:v1' locally&#13;
v1: Pulling from griggheo/hello-world-docker&#13;
921b31ab772b: Already exists&#13;
1a0c422ed526: Already exists&#13;
ec0818a7bbe4: Already exists&#13;
b53197ee35ff: Already exists&#13;
8b25717b4dbf: Already exists&#13;
d997915c3f9c: Pull complete&#13;
f1fd8d3cc5a4: Pull complete&#13;
10b64b1c3b21: Pull complete&#13;
Digest: sha256:af8b74f27a0506a0c4a30255f7ff563c9bf858735baa610fda2a2f638ccfe36d&#13;
Status: Downloaded newer image for griggheo/hello-world-docker:v1&#13;
9d67dc321ffb49e5e73a455bd80c55c5f09febc4f2d57112303d2b27c4c6da6a</pre>&#13;
&#13;
<p>Note that the Docker engine on the EC2 instance recognizes that it does not have the Docker image locally, so it downloads it from Docker Hub, then runs a container based on the newly downloaded image.</p>&#13;
&#13;
<p>At this point, access to port 5000 was granted by adding a rule to the security group associated with the EC2 instance. Visit http://54.187.189.51:5000<sup><a data-type="noteref" href="ch11.html#idm46691322287592" id="idm46691322287592-marker">1</a></sup> (with 54.187.189.51 being the external IP of the EC2 instance) and see the greeting <em>Hello, World! (from a Docker container with modified code)</em>.</p>&#13;
&#13;
<p>When modifying the application code on the remote EC2 instance, the Flask server running inside the Docker container will auto-reload the modified code. Change the greeting to <em>Hello, World! (from a Docker container on an EC2 Linux 2 AMI instance)</em> and notice that the Flask server reloaded the application by inspecting the logs of the Docker container:</p>&#13;
&#13;
<pre data-type="programlisting">[ec2-user@ip-10-0-0-111 hello-world-docker]$ docker ps&#13;
CONTAINER ID  IMAGE                           COMMAND         CREATED&#13;
9d67dc321ffb  griggheo/hello-world-docker:v1  "python app.py" 3 minutes ago&#13;
STATUS        PORTS                    NAMES&#13;
Up 3 minutes  0.0.0.0:5000-&gt;5000/tcp   heuristic_roentgen&#13;
&#13;
[ec2-user@ip-10-0-0-111 hello-world-docker]$ docker logs 9d67dc321ffb&#13;
 * Serving Flask app "app" (lazy loading)&#13;
 * Debug mode: on&#13;
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)&#13;
 * Restarting with stat&#13;
 * Debugger is active!&#13;
 * Debugger PIN: 306-476-204&#13;
72.203.107.13 - - [19/Aug/2019 04:43:34] "GET / HTTP/1.1" 200 -&#13;
72.203.107.13 - - [19/Aug/2019 04:43:35] "GET /favicon.ico HTTP/1.1" 404 -&#13;
 * Detected change in '/app/app.py', reloading&#13;
 * Restarting with stat&#13;
 * Debugger is active!&#13;
 * Debugger PIN: 306-476-204</pre>&#13;
&#13;
<p>Hitting http://54.187.189.51:5000<sup><a data-type="noteref" href="ch11.html#idm46691322283160" id="idm46691322283160-marker">2</a></sup> now shows the new greeting <em>Hello, World! (from a Docker container on an EC2 Linux 2 AMI instance)</em>.</p>&#13;
&#13;
<p>It is worth noting that we did not have to install anything related to Python or Flask to get our application to run. By simply running our application inside a container, we were able to take advantage of the portability of Docker. It is not for nothing that Docker chose the name “container” to popularize its technology—one inspiration was how the shipping container revolutionized the global transportation industry.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Read <a href="https://pythonspeed.com/docker">“Production-ready Docker images”</a> by Itamar Turner-Trauring for an extensive collection of articles on Docker container packaging for Python applications.<a data-startref="ix_ch11-asciidoc2" data-type="indexterm" id="idm46691322279160"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Running Multiple Docker Containers with Docker Compose" data-type="sect1"><div class="sect1" id="idm46691322300056">&#13;
<h1>Running Multiple Docker Containers with <span class="keep-together">Docker Compose</span></h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="running multiple containers with Docker Compose" data-type="indexterm" id="ix_ch11-asciidoc3"/><a data-primary="Docker Compose" data-secondary="running multiple containers" data-type="indexterm" id="ix_ch11-asciidoc4"/>In this section we will use the <a href="https://oreil.ly/prNg7">“Flask By Example”</a> tutorial that describes how to build a Flask application that calculates word-frequency pairs based on the text from a given URL.</p>&#13;
&#13;
<p>Start by cloning the <a href="https://oreil.ly/M-pvc">Flask By Example GitHub repository</a>:</p>&#13;
&#13;
<pre data-type="programlisting">$ git clone https://github.com/realpython/flask-by-example.git</pre>&#13;
&#13;
<p>We will use <code>compose</code> to run multiple Docker containers representing the different parts of the example application. With Compose, you use a YAML file to define and configure the services comprising an application, then you use the <code>docker-compose</code> command-line utility to create, start, and stop these services that will run as Docker containers.</p>&#13;
&#13;
<p>The first dependency to consider for the example application is PostgreSQL, as described in <a href="https://oreil.ly/iobKp">Part 2 of the tutorial</a>.</p>&#13;
&#13;
<p>Here is how to run PostgreSQL in a Docker container inside a <em>docker-compose.yaml</em> file:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat docker-compose.yaml</code>&#13;
<code class="l-Scalar-Plain">version</code><code class="p-Indicator">:</code> <code class="s">"3"</code>&#13;
<code class="nt">services</code><code class="p">:</code>&#13;
  <code class="nt">db</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"postgres:11"</code>&#13;
    <code class="nt">container_name</code><code class="p">:</code> <code class="s">"postgres"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"5432:5432"</code>&#13;
    <code class="nt">volumes</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">dbdata:/var/lib/postgresql/data</code>&#13;
<code class="nt">volumes</code><code class="p">:</code>&#13;
  <code class="nt">dbdata</code><code class="p">:</code></pre>&#13;
&#13;
<p>A few things to note about this file:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Define a service called <code>db</code> based on the <code>postgres:11</code> image published on Docker Hub.</p>&#13;
</li>&#13;
<li>&#13;
<p>Specify a port mapping from local port 5432 to the container port 5432.</p>&#13;
</li>&#13;
<li>&#13;
<p>Specify a Docker volume for the directory where PostgreSQL stores its data, which is <em>/var/lib/postgresql/data</em>. This is so that the data stored in PostgreSQL will persist across restarts of the container.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The <code>docker-compose</code> utility is not part of the Docker engine, so it needs to be installed separately. See the <a href="https://docs.docker.com/compose/install">official documentation</a> for instructions on installing it on various operating systems.</p>&#13;
&#13;
<p>To bring up the <code>db</code> service defined in <em>docker-compose.yaml</em>, run the <a data-primary="docker-compose up -d db command" data-type="indexterm" id="idm46691322235000"/><code>docker-compose up -d db</code> command, which will launch the Docker container for the <code>db</code> service in the background (the <code>-d</code> flag):</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose up -d db&#13;
Creating postgres ... done</pre>&#13;
&#13;
<p>Inspect the logs for the <code>db</code> service with the <code>docker-compose logs db</code> command:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose logs db&#13;
Creating volume "flask-by-example_dbdata" with default driver&#13;
Pulling db (postgres:11)...&#13;
11: Pulling from library/postgres&#13;
Creating postgres ... done&#13;
Attaching to postgres&#13;
postgres | PostgreSQL init process complete; ready for start up.&#13;
postgres |&#13;
postgres | 2019-07-11 21:50:20.987 UTC [1]&#13;
LOG:  listening on IPv4 address "0.0.0.0", port 5432&#13;
postgres | 2019-07-11 21:50:20.987 UTC [1]&#13;
LOG:  listening on IPv6 address "::", port 5432&#13;
postgres | 2019-07-11 21:50:20.993 UTC [1]&#13;
LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"&#13;
postgres | 2019-07-11 21:50:21.009 UTC [51]&#13;
LOG:  database system was shut down at 2019-07-11 21:50:20 UTC&#13;
postgres | 2019-07-11 21:50:21.014 UTC [1]&#13;
LOG:  database system is ready to accept connections</pre>&#13;
&#13;
<p>Running <code>docker ps</code> shows the container running the PostgreSQL database:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker ps&#13;
dCONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
83b54ab10099 postgres:11 "docker-entrypoint.s…"  3 minutes ago  Up 3 minutes&#13;
        0.0.0.0:5432-&gt;5432/tcp   postgres</pre>&#13;
&#13;
<p>Running <code>docker volume ls</code> shows the <code>dbdata</code> Docker volume mounted for the PostgreSQL <em>/var/lib/postgresql/data</em> directory:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker volume ls | grep dbdata&#13;
local               flask-by-example_dbdata</pre>&#13;
&#13;
<p>To connect to the PostgreSQL database running in the Docker container associated with the <code>db</code> service, run the command <a data-primary="docker-compose exec db" data-type="indexterm" id="idm46691322224280"/><code>docker-compose exec db</code> and pass it the command line <code>psql -U postgres</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose exec db psql -U postgres&#13;
psql (11.4 (Debian 11.4-1.pgdg90+1))&#13;
Type "help" for help.&#13;
&#13;
postgres=#</pre>&#13;
&#13;
<p>Following <a href="https://oreil.ly/iobKp">“Flask by Example, Part 2”</a>, create a database called <code>wordcount</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose exec db psql -U postgres&#13;
psql (11.4 (Debian 11.4-1.pgdg90+1))&#13;
Type "help" for help.&#13;
&#13;
postgres=# create database wordcount;&#13;
CREATE DATABASE&#13;
&#13;
postgres=# \l</pre>&#13;
&#13;
<pre class="pagebreak-before less_space" data-type="programlisting">                            List of databases&#13;
     Name  |  Owner | Encoding |  Collate |   Ctype  |   Access privileges&#13;
-----------+--------+----------+----------+----------+--------------------&#13;
 postgres  | postgres | UTF8   | en_US.utf8 | en_US.utf8 |&#13;
 template0 | postgres | UTF8   | en_US.utf8 | en_US.utf8 | =c/postgres +&#13;
           |          |        |            |            |postgres=CTc/postgres&#13;
 template1 | postgres | UTF8   | en_US.utf8 | en_US.utf8 | =c/postgres +&#13;
           |          |        |            |            |postgres=CTc/postgres&#13;
 wordcount| postgres | UTF8| en_US.utf8 | en_US.utf8 |&#13;
(4 rows)&#13;
postgres=# \q</pre>&#13;
&#13;
<p>Connect to the <code>wordcount</code> database and create a role called <code>wordcount_dbadmin</code> that will be used by the Flask application:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose exec db psql -U postgres wordcount&#13;
wordcount=# CREATE ROLE wordcount_dbadmin;&#13;
CREATE ROLE&#13;
wordcount=# ALTER ROLE wordcount_dbadmin LOGIN;&#13;
ALTER ROLE&#13;
wordcount=# ALTER USER wordcount_dbadmin PASSWORD 'MYPASS';&#13;
ALTER ROLE&#13;
postgres=# \q</pre>&#13;
&#13;
<p>The next step is to create a Dockerfile for installing all the prerequisites for the Flask application.</p>&#13;
&#13;
<p>Make the following modifications to the <em>requirements.txt</em> file:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Modify the version of the <code>psycopg2</code> package from <code>2.6.1</code> to <code>2.7</code> so that it supports PostgreSQL 11</p>&#13;
</li>&#13;
<li>&#13;
<p>Modify the version of the <code>redis</code> package from <code>2.10.5</code> to <code>3.2.1</code> for better Python 3.7 support</p>&#13;
</li>&#13;
<li>&#13;
<p>Modify the version of the <code>rq</code> package from <code>0.5.6</code> to <code>1.0</code> for better Python 3.7 support</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Here is the Dockerfile:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="nv">$ </code>cat Dockerfile&#13;
<code class="k">FROM</code><code class="s"> python:3.7.3-alpine</code>&#13;
&#13;
<code class="k">ENV</code><code class="s"> APP_HOME /app</code>&#13;
<code class="k">WORKDIR</code><code class="s"> $APP_HOME</code>&#13;
&#13;
COPY requirements.txt .&#13;
&#13;
<code class="k">RUN</code> <code class="se">\</code>&#13;
 apk add --no-cache postgresql-libs <code class="o">&amp;&amp;</code> <code class="se">\</code>&#13;
 apk add --no-cache --virtual .build-deps gcc musl-dev postgresql-dev <code class="o">&amp;&amp;</code> <code class="se">\</code>&#13;
 python3 -m pip install -r requirements.txt --no-cache-dir <code class="o">&amp;&amp;</code> <code class="se">\</code>&#13;
 apk --purge del .build-deps&#13;
&#13;
COPY . .&#13;
&#13;
<code class="k">ENTRYPOINT</code><code class="s"> [ "python" ]</code>&#13;
<code class="k">CMD</code><code class="s"> ["app.py"]</code></pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>There is an important difference between this Dockerfile and the version used in the first <em>hello-world-docker</em> example. Here the contents of the current directory, which includes the application files, are copied into the Docker image. This is done to illustrate a scenario different from the development workflow shown earlier. In this case, we are more interested in running the application in the most portable way, for example, in a staging or production environment, where we do not want to modify application files via mounted volumes as was done in the development scenario. It is possible and even common to use <code>docker-compose</code> with locally mounted volumes for development purposes, but the focus in this section is on the portability of Docker containers across environments, such as development, staging, and production.</p>&#13;
</div>&#13;
&#13;
<p>Run <code>docker build -t flask-by-example:v1 .</code> to build a local Docker image. The output of this command is not shown because it is quite lengthy.</p>&#13;
&#13;
<p>The next step in the “Flask By Example” tutorial is to run the Flask migrations.</p>&#13;
&#13;
<p>In the <em>docker-compose.yaml</em> file, define a new service called <code>migrations</code>  and specify its <code>image</code>, its <code>command</code>, its <code>environment</code> variables, and the fact that it depends on the <code>db</code> service being up and running:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat docker-compose.yaml</code>&#13;
<code class="l-Scalar-Plain">version</code><code class="p-Indicator">:</code> <code class="s">"3"</code>&#13;
<code class="nt">services</code><code class="p">:</code>&#13;
  <code class="nt">migrations</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"manage.py</code><code class="nv"> </code><code class="s">db</code><code class="nv"> </code><code class="s">upgrade"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
  <code class="nt">db</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"postgres:11"</code>&#13;
    <code class="nt">container_name</code><code class="p">:</code> <code class="s">"postgres"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"5432:5432"</code>&#13;
    <code class="nt">volumes</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">dbdata:/var/lib/postgresql/data</code>&#13;
<code class="nt">volumes</code><code class="p">:</code>&#13;
  <code class="nt">dbdata</code><code class="p">:</code></pre>&#13;
&#13;
<p>The <code>DATABASE_URL</code> variable uses the name <code>db</code> for the PostgreSQL database host. This is because the name <code>db</code> is defined as a service name in the <em>docker-compose.yaml</em> file, and <code>docker-compose</code> knows how to link one service to another by creating an overlay network where all services defined in the <em>docker-compose.yaml</em> file can interact with each other by their names. See the <a href="https://oreil.ly/Io80N">docker-compose networking reference</a> for more details.</p>&#13;
&#13;
<p>The <code>DATABASE_URL</code> variable definition refers to another variable called <code>DBPASS</code>, instead of hardcoding the password for the <code>wordcount_dbadmin</code> user. The <em>docker-compose.yaml</em> file is usually checked into source control, and best practices are not to commit secrets such as database credentials to GitHub. Instead, use an encryption tool such as <a href="https://github.com/mozilla/sops"><code>sops</code></a> to manage a secrets file.</p>&#13;
&#13;
<p>Here is an example of how to create an encrypted file using <code>sops</code> with PGP <span class="keep-together">encryption.</span></p>&#13;
&#13;
<p>First, install <code>gpg</code> on macOS via <code>brew install gpg</code>, then generate a new PGP key with an empty passphrase:</p>&#13;
&#13;
<pre data-type="programlisting">$ gpg --generate-key&#13;
pub   rsa2048 2019-07-12 [SC] [expires: 2021-07-11]&#13;
      E14104A0890994B9AC9C9F6782C1FF5E679EFF32&#13;
uid                      pydevops &lt;my.email@gmail.com&gt;&#13;
sub   rsa2048 2019-07-12 [E] [expires: 2021-07-11]</pre>&#13;
&#13;
<p>Next, download <code>sops</code> from its <a href="https://github.com/mozilla/sops/releases">release page</a>.</p>&#13;
&#13;
<p>To create a new encrypted file called, for example, <em>environment.secrets</em>, run <code>sops</code> with the <code>-pgp</code> flag and give it the fingerprint of the key generated above:</p>&#13;
&#13;
<pre data-type="programlisting">$ sops --pgp BBDE7E57E00B98B3F4FBEAF21A1EEF4263996BD0 environment.secrets</pre>&#13;
&#13;
<p>This will open the default editor and allow for the input of the plain-text secrets. In this example, the contents of the <em>environment.secrets</em> file are:</p>&#13;
&#13;
<pre data-type="programlisting">export DBPASS=MYPASS</pre>&#13;
&#13;
<p>After saving the <em>environment.secrets</em> file, inspect the file to see that it is encrypted, which makes it safe to add to source control:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat environment.secrets&#13;
{&#13;
	"data": "ENC[AES256_GCM,data:qlQ5zc7e8KgGmu5goC9WmE7PP8gueBoSsmM=,&#13;
  iv:xG8BHcRfdfLpH9nUlTijBsYrh4TuSdvDqp5F+2Hqw4I=,&#13;
  tag:0OIVAm9O/UYGljGCzZerTQ==,type:str]",&#13;
	"sops": {&#13;
		"kms": null,&#13;
		"gcp_kms": null,&#13;
		"lastmodified": "2019-07-12T05:03:45Z",&#13;
		"mac": "ENC[AES256_GCM,data:wo+zPVbPbAJt9Nl23nYuWs55f68/DZJWj3pc0&#13;
    l8T2d/SbuRF6YCuOXHSHIKs1ZBpSlsjmIrPyYTqI+M4Wf7it7fnNS8b7FnclwmxJjptBWgL&#13;
    T/A1GzIKT1Vrgw9QgJ+prq+Qcrk5dPzhsOTxOoOhGRPsyN8KjkS4sGuXM=,iv:0VvSMgjF6&#13;
    ypcK+1J54fonRoI7c5whmcu3iNV8xLH02k=,&#13;
    tag:YaI7DXvvllvpJ3Talzl8lg==,&#13;
    type:str]",&#13;
		"pgp": [&#13;
			{&#13;
				"created_at": "2019-07-12T05:02:24Z",&#13;
				"enc": "-----BEGIN PGP MESSAGE-----\n\nhQEMA+3cyc&#13;
        g5b/Hu0OvU5ONr/F0htZM2MZQSXpxoCiO\nWGB5Czc8FTSlRSwu8/cOx0Ch1FwH+IdLwwL+jd&#13;
        oXVe55myuu/3OKUy7H1w/W2R\nPI99Biw1m5u3ir3+9tLXmRpLWkz7+nX7FThl9QnOS25&#13;
        NRUSSxS7hNaZMcYjpXW+w\nM3XeaGStgbJ9OgIp4A8YGigZQVZZFl3fAG3bm2c+TNJcAbl&#13;
        zDpc40fxlR+7LroJI\njuidzyOEe49k0pq3tzqCnph5wPr3HZ1JeQmsIquf//9D509S5xH&#13;
        Sa9lkz3Y7V4KC\nefzBiS8pivm55T0s+zPBPB/GWUVlqGaxRhv1TAU=\n=WA4+&#13;
        \n-----END PGP MESSAGE-----\n",&#13;
				"fp": "E14104A0890994B9AC9C9F6782C1FF5E679EFF32"&#13;
			}&#13;
		],&#13;
		"unencrypted_suffix": "_unencrypted",&#13;
		"version": "3.0.5"&#13;
	}&#13;
}%</pre>&#13;
&#13;
<p>To decrypt the file, run:</p>&#13;
&#13;
<pre data-type="programlisting">$ sops -d environment.secrets&#13;
export DBPASS=MYPASS</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>There is an issue with <code>sops</code> interacting with <code>gpg</code> on a Macintosh. You will need to run the following commands before being able to decrypt the file with <code>sops</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ GPG_TTY=$(tty)&#13;
$ export GPG_TTY</pre>&#13;
</div>&#13;
&#13;
<p>The goal here is to run the <code>migrations</code> service defined previously in the <code>docker-compose.yaml_ file.&#13;
To tie the +sops</code> secret management method into <code>docker-compose</code>, decrypt the <em>environments.secrets</em> file with <code>sops -d</code>, source its contents into the current shell, then invoke <code>docker-compose up -d migrations</code> using one command line that will not expose the secret to the shell history:</p>&#13;
&#13;
<pre data-type="programlisting">$ source &lt;(sops -d environment.secrets); docker-compose up -d migrations&#13;
postgres is up-to-date&#13;
Recreating flask-by-example_migrations_1 ... done</pre>&#13;
&#13;
<p>Verify that the migrations were successfully run by inspecting the database and verifying that two tables were created: <code>alembic_version</code> and <code>results</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose exec db psql -U postgres wordcount&#13;
psql (11.4 (Debian 11.4-1.pgdg90+1))&#13;
Type "help" for help.&#13;
&#13;
wordcount=# \dt</pre>&#13;
&#13;
<pre data-type="programlisting">                  List of relations&#13;
 Schema |      Name       | Type  |       Owner&#13;
--------+-----------------+-------+-------------------&#13;
 public | alembic_version | table | wordcount_dbadmin&#13;
 public | results         | table | wordcount_dbadmin&#13;
(2 rows)&#13;
&#13;
wordcount=# \q</pre>&#13;
&#13;
<p><a href="https://oreil.ly/UY2yw">Part 4</a> in the “Flask By Example” tutorial is to deploy a Python worker process based on Python RQ that talks to an instance of Redis.</p>&#13;
&#13;
<p>First, Redis needs to run. Add it as a service called <code>redis</code> into the <em>docker_compose.yaml</em> file, and make sure that its internal port 6379 is mapped to port 6379 on the local OS:</p>&#13;
&#13;
<pre data-type="programlisting">  redis:&#13;
    image: "redis:alpine"&#13;
    ports:&#13;
      - "6379:6379"</pre>&#13;
&#13;
<p>Start the <code>redis</code> service on its own by specifying it as an argument to <code>docker-compose up -d</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose up -d redis&#13;
Starting flask-by-example_redis_1 ... done</pre>&#13;
&#13;
<p>Run <a data-primary="docker ps" data-type="indexterm" id="idm46691322015288"/><code>docker ps</code> to see a new Docker container running based on the <code>redis:alpine</code> image:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker ps&#13;
CONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
a1555cc372d6   redis:alpine "docker-entrypoint.s…" 3 seconds ago  Up 1 second&#13;
0.0.0.0:6379-&gt;6379/tcp   flask-by-example_redis_1&#13;
83b54ab10099   postgres:11  "docker-entrypoint.s…" 22 hours ago   Up 16 hours&#13;
0.0.0.0:5432-&gt;5432/tcp   postgres</pre>&#13;
&#13;
<p>Use the <a data-primary="docker compose logs command" data-type="indexterm" id="idm46691322012216"/><code>docker-compose logs</code> command to inspect the logs of the <code>redis</code> service:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose logs redis&#13;
Attaching to flask-by-example_redis_1&#13;
1:C 12 Jul 2019 20:17:12.966 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo&#13;
1:C 12 Jul 2019 20:17:12.966 # Redis version=5.0.5, bits=64, commit=00000000,&#13;
modified=0, pid=1, just started&#13;
1:C 12 Jul 2019 20:17:12.966 # Warning: no config file specified, using the&#13;
default config. In order to specify a config file use&#13;
redis-server /path/to/redis.conf&#13;
1:M 12 Jul 2019 20:17:12.967 * Running mode=standalone, port=6379.&#13;
1:M 12 Jul 2019 20:17:12.967 # WARNING: The TCP backlog setting of 511 cannot&#13;
be enforced because /proc/sys/net/core/somaxconn&#13;
is set to the lower value of 128.&#13;
1:M 12 Jul 2019 20:17:12.967 # Server initialized&#13;
1:M 12 Jul 2019 20:17:12.967 * Ready to accept connections</pre>&#13;
&#13;
<p>The next step is to create a service called <code>worker</code> for the Python RQ worker process in <em>docker-compose.yaml</em>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting">  <code class="nt">worker</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"worker.py"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
      <code class="nt">REDISTOGO_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">redis://redis:6379</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">redis</code></pre>&#13;
&#13;
<p>Run the worker service just like the <code>redis</code> service, with <code>docker-compose up -d</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose up -d worker&#13;
flask-by-example_redis_1 is up-to-date&#13;
Starting flask-by-example_worker_1 ... done</pre>&#13;
&#13;
<p>Running <code>docker ps</code> will show the worker container:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker ps&#13;
CONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
72327ab33073  flask-by-example "python worker.py"     8 minutes ago&#13;
Up 14 seconds                             flask-by-example_worker_1&#13;
b11b03a5bcc3  redis:alpine     "docker-entrypoint.s…" 15 minutes ago&#13;
Up About a minute  0.0.0.0:6379-&gt;6379/tc  flask-by-example_redis_1&#13;
83b54ab10099  postgres:11      "docker-entrypoint.s…"  23 hours ago&#13;
Up 17 hours        0.0.0.0:5432-&gt;5432/tcp postgres</pre>&#13;
&#13;
<p>Look at the worker container logs with <code>docker-compose logs</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose logs worker&#13;
Attaching to flask-by-example_worker_1&#13;
20:46:34 RQ worker 'rq:worker:a66ca38275a14cac86c9b353e946a72e' started,&#13;
version 1.0&#13;
20:46:34 *** Listening on default...&#13;
20:46:34 Cleaning registries for queue: default</pre>&#13;
&#13;
<p>Now launch the main Flask application in its own container. Create a new service called <code>app</code> in <em>docker-compose.yaml</em>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting">  <code class="nt">app</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"manage.py</code><code class="nv"> </code><code class="s">runserver</code><code class="nv"> </code><code class="s">--host=0.0.0.0"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"5000:5000"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
      <code class="nt">REDISTOGO_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">redis://redis:6379</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">redis</code></pre>&#13;
&#13;
<p>Map port 5000 from the application container (the default port for a Flask application) to port 5000 on the local machine. Pass the command <code>manage.py runserver --host=0.0.0.0</code> to the application container to ensure that port 5000 is exposed correctly by the Flask application inside the container.</p>&#13;
&#13;
<p>Start up the <code>app</code> service with <code>docker compose up -d</code>, while also running <code>sops -d</code> on the encrypted file containing <code>DBPASS</code>, then sourcing the decrypted file before calling <code>docker-compose</code>:</p>&#13;
&#13;
<pre data-type="programlisting">source &lt;(sops -d environment.secrets); docker-compose up -d app&#13;
postgres is up-to-date&#13;
Recreating flask-by-example_app_1 ... done</pre>&#13;
&#13;
<p>Notice the new Docker container running the application in the list returned by <code>docker ps</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker ps&#13;
CONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
d99168a152f1   flask-by-example "python app.py"  3 seconds ago&#13;
Up 2 seconds    0.0.0.0:5000-&gt;5000/tcp   flask-by-example_app_1&#13;
72327ab33073   flask-by-example "python worker.py" 16 minutes ago&#13;
Up 7 minutes                             flask-by-example_worker_1&#13;
b11b03a5bcc3   redis:alpine     "docker-entrypoint.s…" 23 minutes ago&#13;
Up 9 minutes    0.0.0.0:6379-&gt;6379/tcp   flask-by-example_redis_1&#13;
83b54ab10099   postgres:11      "docker-entrypoint.s…"  23 hours ago&#13;
Up 17 hours     0.0.0.0:5432-&gt;5432/tcp   postgres</pre>&#13;
&#13;
<p>Inspect the logs of the application container with <code>docker-compose logs</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose logs app&#13;
Attaching to flask-by-example_app_1&#13;
app_1         |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</pre>&#13;
&#13;
<p>Running <code>docker-compose logs</code> with no other arguments allows us to inspect the logs of all the services defined in the <em>docker-compose.yaml</em> file:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose logs&#13;
Attaching to flask-by-example_app_1,&#13;
flask-by-example_worker_1,&#13;
flask-by-example_migrations_1,&#13;
flask-by-example_redis_1,&#13;
postgres&#13;
1:C 12 Jul 2019 20:17:12.966 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo&#13;
1:C 12 Jul 2019 20:17:12.966 # Redis version=5.0.5, bits=64, commit=00000000,&#13;
modified=0, pid=1, just started&#13;
1:C 12 Jul 2019 20:17:12.966 # Warning: no config file specified, using the&#13;
default config. In order to specify a config file use&#13;
redis-server /path/to/redis.conf&#13;
1:M 12 Jul 2019 20:17:12.967 * Running mode=standalone, port=6379.&#13;
1:M 12 Jul 2019 20:17:12.967 # WARNING: The TCP backlog setting of 511 cannot&#13;
be enforced because /proc/sys/net/core/somaxconn&#13;
is set to the lower value of 128.&#13;
1:M 12 Jul 2019 20:17:12.967 # Server initialized&#13;
1:M 12 Jul 2019 20:17:12.967 * Ready to accept connections&#13;
app_1         |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)&#13;
postgres      | 2019-07-12 22:15:19.193 UTC [1]&#13;
LOG:  listening on IPv4 address "0.0.0.0", port 5432&#13;
postgres      | 2019-07-12 22:15:19.194 UTC [1]&#13;
LOG:  listening on IPv6 address "::", port 5432&#13;
postgres      | 2019-07-12 22:15:19.199 UTC [1]&#13;
LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"&#13;
postgres      | 2019-07-12 22:15:19.214 UTC [22]&#13;
LOG:  database system was shut down at 2019-07-12 22:15:09 UTC&#13;
postgres      | 2019-07-12 22:15:19.225 UTC [1]&#13;
LOG:  database system is ready to accept connections&#13;
migrations_1  | INFO [alembic.runtime.migration] Context impl PostgresqlImpl.&#13;
migrations_1  | INFO [alembic.runtime.migration] Will assume transactional DDL.&#13;
worker_1      | 22:15:20&#13;
RQ worker 'rq:worker:2edb6a54f30a4aae8a8ca2f4a9850303' started, version 1.0&#13;
worker_1      | 22:15:20 *** Listening on default...&#13;
worker_1      | 22:15:20 Cleaning registries for queue: default</pre>&#13;
&#13;
<p>The final step is to test the application. Visit http://127.0.0.1:5000 and enter <code>python.org</code> in the URL field.&#13;
At that point, the application sends a job to the worker process, asking it to execute the function <code>count_and_save_words</code> against the home page of <code>python.org</code>.&#13;
The application periodically polls the job for the results, and upon completion, it displays the word frequencies&#13;
on the home page.</p>&#13;
&#13;
<p>To make the <em>docker-compose.yaml</em> file more portable, push the <code>flask-by-example</code> Docker image to Docker Hub, and reference the Docker Hub image in the container section for the <code>app</code> and <code>worker</code> services.</p>&#13;
&#13;
<p>Tag the existing local Docker image <code>flask-by-example:v1</code> with a name prefixed by a Docker Hub username, then push the newly tagged image to Docker Hub:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker tag flask-by-example:v1 griggheo/flask-by-example:v1&#13;
$ docker push griggheo/flask-by-example:v1</pre>&#13;
&#13;
<p>Change <em>docker-compose.yaml</em> to reference the new Docker Hub image. Here is the final version of <em>docker-compose.yaml</em>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat docker-compose.yaml</code>&#13;
<code class="l-Scalar-Plain">version</code><code class="p-Indicator">:</code> <code class="s">"3"</code>&#13;
<code class="nt">services</code><code class="p">:</code>&#13;
  <code class="nt">app</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"griggheo/flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"manage.py</code><code class="nv"> </code><code class="s">runserver</code><code class="nv"> </code><code class="s">--host=0.0.0.0"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"5000:5000"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
      <code class="nt">REDISTOGO_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">redis://redis:6379</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">redis</code>&#13;
  <code class="nt">worker</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"griggheo/flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"worker.py"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
      <code class="nt">REDISTOGO_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">redis://redis:6379</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">redis</code>&#13;
  <code class="nt">migrations</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"griggheo/flask-by-example:v1"</code>&#13;
    <code class="nt">command</code><code class="p">:</code> <code class="s">"manage.py</code><code class="nv"> </code><code class="s">db</code><code class="nv"> </code><code class="s">upgrade"</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">APP_SETTINGS</code><code class="p">:</code> <code class="l-Scalar-Plain">config.ProductionConfig</code>&#13;
      <code class="nt">DATABASE_URL</code><code class="p">:</code> <code class="l-Scalar-Plain">postgresql://wordcount_dbadmin:$DBPASS@db/wordcount</code>&#13;
    <code class="nt">depends_on</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">db</code>&#13;
  <code class="nt">db</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"postgres:11"</code>&#13;
    <code class="nt">container_name</code><code class="p">:</code> <code class="s">"postgres"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"5432:5432"</code>&#13;
    <code class="nt">volumes</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="l-Scalar-Plain">dbdata:/var/lib/postgresql/data</code>&#13;
  <code class="nt">redis</code><code class="p">:</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="s">"redis:alpine"</code>&#13;
    <code class="nt">ports</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="s">"6379:6379"</code>&#13;
<code class="nt">volumes</code><code class="p">:</code>&#13;
  <code class="nt">dbdata</code><code class="p">:</code></pre>&#13;
&#13;
<p>To restart the local Docker containers, run <code>docker-compose down</code> followed by <code>docker-compose up -d</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose down&#13;
Stopping flask-by-example_worker_1 ... done&#13;
Stopping flask-by-example_app_1    ... done&#13;
Stopping flask-by-example_redis_1  ... done&#13;
Stopping postgres                  ... done&#13;
Removing flask-by-example_worker_1     ... done&#13;
Removing flask-by-example_app_1        ... done&#13;
Removing flask-by-example_migrations_1 ... done&#13;
Removing flask-by-example_redis_1      ... done&#13;
Removing postgres                      ... done&#13;
Removing network flask-by-example_default&#13;
&#13;
$ source &lt;(sops -d environment.secrets); docker-compose up -d&#13;
Creating network "flask-by-example_default" with the default driver&#13;
Creating flask-by-example_redis_1      ... done&#13;
Creating postgres                 ... done&#13;
Creating flask-by-example_migrations_1 ... done&#13;
Creating flask-by-example_worker_1     ... done&#13;
Creating flask-by-example_app_1        ... done</pre>&#13;
&#13;
<p>Note how easy it is to bring up and down a set of Docker containers with <code>docker-compose</code>.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Even if you want to run a single Docker container, it is still a good idea to include it in a <em>docker-compose.yaml</em> file and launch it with the <code>docker-compose up -d</code> command. It will make your life easier when you want to add a second container into the mix, and it will also serve as a mini Infrastructure as Code example, with the <em>docker-compose.yaml</em> file reflecting the state of your local Docker setup for your application.<a data-startref="ix_ch11-asciidoc4" data-type="indexterm" id="idm46691321681928"/><a data-startref="ix_ch11-asciidoc3" data-type="indexterm" id="idm46691321681224"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Porting the docker-compose Services to a New Host and Operating System" data-type="sect1"><div class="sect1" id="idm46691321869832">&#13;
<h1>Porting the docker-compose Services to a New Host <span class="keep-together">and Operating System</span></h1>&#13;
&#13;
<p><a data-primary="Docker" data-secondary="porting docker-compose services to new host and operating system" data-type="indexterm" id="ix_ch11-asciidoc5"/><a data-primary="Docker Compose" data-secondary="porting to new host and operating system" data-type="indexterm" id="ix_ch11-asciidoc6"/>We will now show how to take the <code>docker-compose</code> setup from the preceding section and port it to a server running Ubuntu 18.04.</p>&#13;
&#13;
<p>Launch an Amazon EC2 instance running Ubuntu 18.04 and install <code>docker-engine</code> and <code>docker-compose</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ sudo apt-get update&#13;
$ sudo apt-get remove docker docker-engine docker.io containerd runc&#13;
$ sudo apt-get install \&#13;
  apt-transport-https \&#13;
  ca-certificates \&#13;
  curl \&#13;
  gnupg-agent \&#13;
  software-properties-common&#13;
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -&#13;
$ sudo add-apt-repository \&#13;
  "deb [arch=amd64] https://download.docker.com/linux/ubuntu \&#13;
  $(lsb_release -cs) \&#13;
  stable"&#13;
$ sudo apt-get update&#13;
$ sudo apt-get install docker-ce docker-ce-cli containerd.io&#13;
$ sudo usermod -a -G docker ubuntu&#13;
&#13;
# download docker-compose&#13;
$ sudo curl -L \&#13;
"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-\&#13;
$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose&#13;
$ sudo chmod +x /usr/local/bin/docker-compose</pre>&#13;
&#13;
<p class="pagebreak-before">Copy the <em>docker-compose.yaml</em> file to the remote EC2 instance and start the <code>db</code> service first, so that the database used by the application can be created:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose up -d db&#13;
Starting postgres ...&#13;
Starting postgres ... done&#13;
&#13;
$ docker ps&#13;
CONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
49fe88efdb45 postgres:11 "docker-entrypoint.s…" 29 seconds ago&#13;
  Up 3 seconds        0.0.0.0:5432-&gt;5432/tcp   postgres</pre>&#13;
&#13;
<p>Use <code>docker exec</code> to run the <a data-primary="psql -U postgres command" data-type="indexterm" id="idm46691321672312"/><code>psql -U postgres</code> command inside the running Docker container for the PostgreSQL database. At the PostgreSQL prompt, create the <code>wordcount</code> database and <code>wordcount_dbadmin</code> role:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose exec db psql -U postgres&#13;
psql (11.4 (Debian 11.4-1.pgdg90+1))&#13;
Type "help" for help.&#13;
&#13;
postgres=# create database wordcount;&#13;
CREATE DATABASE&#13;
postgres=# \q&#13;
&#13;
$ docker exec -it 49fe88efdb45 psql -U postgres wordcount&#13;
psql (11.4 (Debian 11.4-1.pgdg90+1))&#13;
Type "help" for help.&#13;
&#13;
wordcount=# CREATE ROLE wordcount_dbadmin;&#13;
CREATE ROLE&#13;
wordcount=# ALTER ROLE wordcount_dbadmin LOGIN;&#13;
ALTER ROLE&#13;
wordcount=# ALTER USER wordcount_dbadmin PASSWORD 'MYPASS';&#13;
ALTER ROLE&#13;
wordcount=# \q</pre>&#13;
&#13;
<p>Before launching the containers for the services defined in <em>docker-compose.yaml</em>, two things are necessary:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Run <code>docker login</code> to be able to pull the Docker image pushed previously to Docker Hub:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker login</pre>&#13;
</li>&#13;
<li>&#13;
<p>Set the <code>DBPASS</code> environment variable to the correct value in the current shell. The <code>sops</code> method described in the local macOS setup can be used, but for this example, set it directly in the shell:</p>&#13;
&#13;
<pre data-type="programlisting">$ export DOCKER_PASS=MYPASS</pre>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p class="pagebreak-before">Now launch all the services necessary for the application by running <code>docker-compose up -d</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker-compose up -d&#13;
Pulling worker (griggheo/flask-by-example:v1)...&#13;
v1: Pulling from griggheo/flask-by-example&#13;
921b31ab772b: Already exists&#13;
1a0c422ed526: Already exists&#13;
ec0818a7bbe4: Already exists&#13;
b53197ee35ff: Already exists&#13;
8b25717b4dbf: Already exists&#13;
9be5e85cacbb: Pull complete&#13;
bd62f980b08d: Pull complete&#13;
9a89f908ad0a: Pull complete&#13;
d787e00a01aa: Pull complete&#13;
Digest: sha256:4fc554da6157b394b4a012943b649ec66c999b2acccb839562e89e34b7180e3e&#13;
Status: Downloaded newer image for griggheo/flask-by-example:v1&#13;
Creating fbe_redis_1      ... done&#13;
Creating postgres    ... done&#13;
Creating fbe_migrations_1 ... done&#13;
Creating fbe_app_1        ... done&#13;
Creating fbe_worker_1     ... done&#13;
&#13;
$ docker ps&#13;
CONTAINER ID   IMAGE   COMMAND    CREATED   STATUS   PORTS   NAMES&#13;
f65fe9631d44  griggheo/flask-by-example:v1 "python3 manage.py r…" 5 seconds ago&#13;
Up 2 seconds        0.0.0.0:5000-&gt;5000/tcp   fbe_app_1&#13;
71fc0b24bce3  griggheo/flask-by-example:v1 "python3 worker.py"    5 seconds ago&#13;
Up 2 seconds                                 fbe_worker_1&#13;
a66d75a20a2d  redis:alpine     "docker-entrypoint.s…"   7 seconds ago&#13;
Up 5 seconds        0.0.0.0:6379-&gt;6379/tcp   fbe_redis_1&#13;
56ff97067637  postgres:11      "docker-entrypoint.s…"   7 seconds ago&#13;
Up 5 seconds        0.0.0.0:5432-&gt;5432/tcp   postgres</pre>&#13;
&#13;
<p>At this point, after allowing access to port 5000 in the AWS security group associated with our Ubuntu EC2 instance, you can hit the external IP of the instance on port 5000 and use the application.</p>&#13;
&#13;
<p>It’s worth emphasizing one more time how much Docker simplifies the deployment of applications. The portability of Docker containers and images means that you can run your application on any operating system where the Docker engine runs. In the example shown here, none of the prerequisites needed to be installed on the Ubuntu server: not Flask, not PostgreSQL, and not Redis. It was also not necessary to copy the application code over from the local development machine to the Ubuntu server. The only file needed on the Ubuntu server was <em>docker-compose.yaml</em>. Then, the whole set of services comprising the application was launched with just one command:</p>&#13;
&#13;
<p><code>$ docker-compose up -d</code></p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Beware of downloading and using Docker images from public Docker repositories, because many of them include serious security vulnerabilities, the most serious of which can allow an attacker to break through the isolation of a Docker container and take over the host operating system. A good practice here is to start with a trusted, pre-built image, or build your own image from scratch. Stay abreast of the latest security patches and software updates, and rebuild your image whenever any of these patches or updates are available. Another good practice is to scan all of your Docker images with one of the many Docker scanning tools available, among them <a href="https://oreil.ly/OBkkx">Clair</a>, <a href="https://oreil.ly/uRI_1">Anchore</a>, and <a href="https://oreil.ly/QXRg6">Falco</a>. Such scanning can be performed as part of a continuous integration/continuous deployment pipeline, when the Docker images usually get built.</p>&#13;
</div>&#13;
&#13;
<p>Although <code>docker-compose</code> makes it easy to run several containerized services as part of the same application, it is only meant to be run on a single machine, which limits its usefulness in production scenarios. You can really only consider an application deployed with <code>docker-compose</code> to be “production ready” if you are not worried about downtime and you are willing to run everything on a single machine (this being said, Grig has seen hosting providers running Dockerized applications in production with <code>docker-compose</code>). For true “production ready” scenarios, you need a container orchestration engine such as Kubernetes, which will be discussed in the next chapter.<a data-startref="ix_ch11-asciidoc6" data-type="indexterm" id="idm46691321650504"/><a data-startref="ix_ch11-asciidoc5" data-type="indexterm" id="idm46691321649800"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exercises" data-type="sect1"><div class="sect1" id="idm46691322275528">&#13;
<h1>Exercises</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Familiarize yourself with the <a href="https://oreil.ly/kA8ZF">Dockerfile reference</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Familiarize yourself with the <a href="https://oreil.ly/ENMsQ">Docker Compose configuration reference</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Create an AWS KMS key and use it with <code>sops</code> instead of a local <code>PGP</code> key. This allows you to apply AWS IAM permissions to the key, and restrict access to the key to only the developers who need it.</p>&#13;
</li>&#13;
<li>&#13;
<p>Write a shell script that uses <code>docker exec</code> or <code>docker-compose exec</code> to run the PostgreSQL commands necessary for creating a database and a role.</p>&#13;
</li>&#13;
<li>&#13;
<p>Experiment with other container technologies, such as <a href="https://podman.io">Podman</a>.<a data-startref="ix_ch11-asciidoc0" data-type="indexterm" id="idm46691321639192"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm46691322287592"><sup><a href="ch11.html#idm46691322287592-marker">1</a></sup> This is an example URL address—your IP address will be different.</p><p data-type="footnote" id="idm46691322283160"><sup><a href="ch11.html#idm46691322283160-marker">2</a></sup> Again, your IP address will be different.</p></div></div></section></body></html>