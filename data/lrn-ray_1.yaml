- en: Chapter 2\. Getting Started With Ray Core
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 开始使用Ray Core
- en: For a book on distributed Python, it’s not without a certain irony that Python
    on its own is largely ineffective for distributed computing. Its interpreter is
    effectively single threaded which makes it difficult to, for example, leverage
    multiple CPUs on the same machine, let alone a whole cluster of machines, using
    plain Python. That means you need extra tooling, and luckily the Python ecosystem
    has some options for you. For instance, libraries like `multiprocessing` can help
    you distribute work on a single machine, but not beyond.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一本关于分布式Python的书来说，有一定讽刺意味的是，Python本身在分布式计算方面效果并不好。它的解释器实际上是单线程的，这使得在同一台机器上利用多个CPU，甚至整个机群，使用纯Python变得困难。这意味着您需要额外的工具支持，幸运的是，Python生态系统为您提供了一些选择。例如，像`multiprocessing`这样的库可以帮助您在单台机器上分发工作，但不能跨越机器。
- en: In this chapter you’ll understand how Ray core handles distributed computing
    by spinning up a local cluster, and you’ll learn how to use Ray’s lean and powerful
    API to parallelize some interesting computations. For instance, you’ll build an
    example that runs a data-parallel task efficiently and asynchronously on Ray,
    in a convenient way that’s not easily replicable with other tooling. We discuss
    how *tasks* and *actors* work as distributed versions of functions and classes
    in Python. You’ll also learn about all the fundamental concepts underlying Ray
    and what its architecture looks like. In other words, we’ll give you a look under
    the hood of Ray’s engine.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解Ray核心如何通过启动本地集群处理分布式计算，并学习如何使用Ray精简而强大的API来并行化一些有趣的计算任务。例如，您将构建一个示例，以高效异步地在Ray上运行数据并行任务，这种方式方便而且不容易用其他工具复制。我们将讨论*任务*和*actors*如何作为Python中函数和类的分布式版本工作。您还将了解Ray的所有基本概念及其架构的内部工作原理。换句话说，我们将让您深入了解Ray引擎的内部工作。
- en: An Introduction To Ray Core
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ray核心简介
- en: The bulk of this chapter is an extended Ray core example that we’ll build together.
    Many of Ray’s concepts can be explained with a good example, so that’s exactly
    what we’ll do. As before, you can follow this example by typing the code yourself
    (which is highly recommended), or by following the [notebook for this chapter](https://github.com/maxpumperla/learning_ray/blob/main/notebooks/ch_02_ray_core.ipynb).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的大部分内容是一个扩展的Ray核心示例，我们将一起构建。许多Ray的概念可以通过一个良好的示例来解释，这正是我们将要做的。与之前一样，您可以通过自己键入代码（强烈推荐）或者通过跟随本章的[笔记本](https://github.com/maxpumperla/learning_ray/blob/main/notebooks/ch_02_ray_core.ipynb)来跟随这个示例。
- en: In [Chapter 1](ch01.xhtml#chapter_01) we’ve introduced you to the very basics
    of Ray clusters and showed you how start a local cluster simply by typing
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.xhtml#chapter_01)中，我们向您介绍了Ray集群的基础知识，并展示了如何通过简单地键入来启动本地集群
- en: Example 2-1\.
  id: totrans-6
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-1.
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’ll need a running Ray cluster to run the examples in this chapter, so make
    sure you’ve started one before continuing. The goal of this section is to give
    you a quick introduction to the Ray Core API, which we’ll simply refer to as the
    Ray API from now on.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，您需要一个运行中的Ray集群来运行本章的示例。本节的目标是为您快速介绍Ray Core API，从现在起我们将简称为Ray API。
- en: As a Python programmer, the great thing about the Ray API is that it hits so
    close to home. It uses familiar concepts such as decorators, functions and classes
    to provide you with a fast learning experience. The Ray API aims to provide a
    universal programming interface for distributed computing. That’s certainly no
    easy feat, but I think Ray succeeds in this respect, as it provides you with good
    abstractions that are intuitive to learn and use. Ray’s engine does all the heavy
    lifting for you in the background. This design philosophy is what enables Ray
    to be used with existing Python libraries and systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Python程序员，Ray API的一个伟大之处在于它非常贴近我们的生活。它使用熟悉的概念，如装饰器、函数和类，为您提供快速的学习体验。Ray API旨在为分布式计算提供通用的编程接口。这绝非易事，但我认为Ray在这方面取得了成功，因为它为您提供了直观学习和使用的良好抽象。Ray引擎在后台为您处理所有繁重的工作。这种设计理念使得Ray能够与现有的Python库和系统兼容。
- en: A First Example Using the Ray API
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Ray API的第一个示例
- en: To give you an example, take the following function which retrieves and processes
    data from a database. Our dummy `database` is a plain Python list containing the
    words of the title of this book. We act as if retrieving an individual `item`
    from this database and further processing it is expensive by letting Python `sleep`.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，考虑以下从数据库检索和处理数据的函数。我们的虚拟`database`是一个简单的 Python 列表，包含这本书标题的单词。我们假设从这个数据库检索一个单独的`item`并进一步处理它是昂贵的，通过让
    Python `sleep`来模拟这一过程。
- en: Example 2-2\.
  id: totrans-12
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-2\.
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO1-1)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO1-1)'
- en: A dummy database containing string data with the title of this book.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含这本书标题的字符串数据的虚拟数据库。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO1-2)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO1-2)'
- en: We emulate a data-crunching operation that takes a long time.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模拟一个长时间运行的数据处理操作。
- en: 'Our database has eight items, from `database[0]` for “Learning” to `database[7]`
    for “Science”. If we were to retrieve all items sequentially, how long should
    that take? For the item with index `5` we wait for half a second (`5 / 10.`) and
    so on. In total, we can expect a runtime of around `(0+1+2+3+4+5+6+7)/10\. = 2.8`
    seconds. Let’s see if that’s what we actually get:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据库有八个项目，从`database[0]`的“Learning”到`database[7]`的“Science”。如果我们按顺序检索所有项目，那需要多长时间？对于索引为`5`的项目，我们等待半秒（`5
    / 10.`），依此类推。总体而言，我们可以预期大约需要 `(0+1+2+3+4+5+6+7)/10\. = 2.8` 秒的运行时间。让我们看看实际上会得到什么：
- en: Example 2-3\.
  id: totrans-19
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-3\.
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO2-1)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO2-1)'
- en: We use a list comprehension to retrieve all eight items.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用列表推导式来检索所有八个项目。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO2-2)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO2-2)'
- en: Then we unpack the data to print each item on its own line.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们解压数据，每个项目都单独打印在一行上。
- en: 'If you run this code, you should see the following output:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行此代码，您应该看到以下输出：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We cut off the output of the program after one decimal number. There’s a little
    overhead that brings the total closer to `2.82` seconds. On your end this might
    be slightly less, or much more, depending on your computer. The important take-away
    is that our naive Python implementation is not able to run this function in parallel.
    This may not come as a surprise to you, but you could have at least suspected
    that Python list comprehensions are more efficient in that regard. The runtime
    we got is pretty much the worst case scenario, namely the `2.8` seconds we calculated
    prior to running the code. If you think about it, it might even be a bit frustrating
    to see that a program that essentially sleeps most of its runtime is that slow
    overall. Ultimately you can blame the *Global Interpreter Lock* (GIL) for that,
    but it gets enough of it already.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在程序输出后截断小数点后一位数字。还有一点额外的开销使得总时间接近 `2.82` 秒。在您的计算机上可能会略少一些，或者更多，这取决于您的计算机性能。重要的是我们的简单
    Python 实现无法并行运行此函数。也许这对您来说并不奇怪，但您至少可以怀疑 Python 的列表推导在这方面更有效率。我们得到的运行时间几乎是最坏的情况，即我们在运行代码之前计算的
    `2.8` 秒。仔细想想，看到一个基本上大部分时间都在睡眠的程序运行得这么慢甚至有点令人沮丧。最终，您可以归咎于全局解释器锁（GIL），但它已经够受罪了。
- en: Functions and Remote Ray Tasks
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数和远程 Ray 任务
- en: 'It’s reasonable to assume that such a task can benefit from parallelization.
    Perfectly distributed, the runtime should not take much longer than the longest
    subtask, namely `7/10\. = 0.7` seconds. So, let’s see how you can extend this
    example to run on Ray. To do so, you start by using the `@ray.remote` decorator
    as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这样一个任务可以从并行化中受益是合理的。如果完美分布，运行时间不应该比最长的子任务长多少，即`7/10\. = 0.7`秒。因此，让我们看看如何在
    Ray 上扩展这个例子。为此，您可以按照以下步骤使用`@ray.remote`装饰器：
- en: Example 2-4\.
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\.
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO3-1)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO3-1)'
- en: With just this decorator we make any Python function a Ray task.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 只需这个装饰器，我们就可以将任何 Python 函数变成 Ray 任务。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO3-2)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO3-2)'
- en: All else remains unchanged. `retrieve_task` just passes through to `retrieve`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其他一切保持不变。`retrieve_task`只是简单地传递给`retrieve`。
- en: In this way, the function `retrieve_task` becomes a so-called Ray task. That’s
    an extremely convenient design choice, as you can focus on your Python code first,
    and don’t have to completely change your mindset or programming paradigm to use
    Ray. Note that in practice you would have simply added the `@ray.remote` decorator
    to your original `retrieve` function (after all, that’s the intended use of decorators),
    but we didn’t want to touch previous code to keep things as clear as possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，函数`retrieve_task`变成了所谓的Ray任务。这是一个非常方便的设计选择，因为你可以首先专注于你的Python代码，而不必完全改变你的思维方式或编程范式来使用Ray。请注意，在实践中，你只需简单地给你的原始`retrieve`函数添加`@ray.remote`装饰器（毕竟，这就是装饰器的预期用途），但我们为了尽可能清晰地保持事物，不想改动先前的代码。
- en: 'Easy enough, so what do you have to change in the code that retrieves the data
    and measures performance? It turns out, not much. Let’s have a look at how you’d
    do that:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 足够简单，那么在检索数据并测量性能的代码中，你需要改变什么？事实证明，不需要太多改动。让我们看看你会如何做：
- en: Example 2-5\. Measuring performance of your Ray task.
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-5。衡量你的Ray任务的性能。
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO4-1)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO4-1)'
- en: To run `retrieve_task` on your local Ray cluster, you use `.remote()` and pass
    in your data as before. You’ll get a list of object references.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地Ray集群上运行`retrieve_task`，你使用`.remote()`并像以前一样传递你的数据。你会得到一个对象引用的列表。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO4-2)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO4-2)'
- en: To get back data, and not just Ray object references, you use `ray.get`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据，而不仅仅是Ray对象引用，你使用`ray.get`。
- en: Did you spot the differences? You have to execute your Ray task remotely using
    the `remote` function. When tasks get executed remotely, even on your local cluster,
    Ray does so *asynchronously*. The list items in `data_references` in the last
    code snippet do not contain the results directly. In fact, if you check the Python
    type of the first item with `type(data_references[0])` you’ll see that it’s in
    fact an `ObjectRef`. These object references correspond to *futures* which you
    need to ask the result of. This is what the call to `ray.get(...)` is for.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你有发现区别吗？你必须使用`remote`函数远程执行你的Ray任务。当任务在远程执行时，即使在本地集群上，Ray也会*异步*执行。最后一个代码片段中的`data_references`中的列表项并不直接包含结果。实际上，如果你检查第一个项目的Python类型，使用`type(data_references[0])`，你会发现它实际上是一个`ObjectRef`。这些对象引用对应于你需要询问结果的*futures*。这就是调用`ray.get(...)`的用途。
- en: We still want to work more on this example^([2](ch02.xhtml#idm44990033491152)),
    but let’s take a step back here and recap what we did so far. You started with
    a Python function and decorated it with `@ray.remote`. This made your function
    a Ray task. Then, instead of calling the original function in your code straight-up,
    you called `.remote(...)` on the Ray task. The last step was to `.get(...)` the
    results back from your Ray cluster. I think this procedure is so intuitive that
    I’d bet you could already create your own Ray task from another function without
    having to look back at this example. Why don’t you give it a try right now?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然希望在这个例子^([2](ch02.xhtml#idm44990033491152))中进一步努力，但让我们在这里退后一步，总结一下我们到目前为止所做的。你从一个Python函数开始，并使用`@ray.remote`装饰它。这使得你的函数成为一个Ray任务。然后，你不是直接在代码中调用原始函数，而是在Ray任务上调用了`.remote(...)`。最后一步是从Ray集群中`.get(...)`结果。我认为这个过程如此直观，以至于我敢打赌，你现在甚至可以从另一个函数创建自己的Ray任务，而不必回顾这个例子。为什么不现在就试试呢？
- en: Coming back to our example, by using Ray tasks, what did we gain in terms of
    performance? On my machine the runtime clocks in at `0.71` seconds, which is just
    slightly more than the longest subtask, which comes in at `0.7` seconds. That’s
    great and much better than before, but we can further improve our program by leveraging
    more of Ray’s API.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的例子，通过使用Ray任务，我们在性能方面得到了什么？在我的机器上，运行时钟为`0.71`秒，稍微超过最长子任务的`0.7`秒。这非常好，比以前要好得多，但我们可以通过利用Ray的更多API进一步改进我们的程序。
- en: Using the object store with put and get
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用put和get的对象存储
- en: One thing you might have noticed is that in the definition of `retrieve` we
    *directly* accessed items from our `database`. Working on a local Ray cluster
    this is fine, but imagine you’re running on an actual cluster comprising several
    computers. How would all those computers access the same data? Remember from [Chapter 1](ch01.xhtml#chapter_01)
    that in a Ray cluster there is one head node with a driver process (running `ray.init()`)
    and many worker nodes with worker processes executing your tasks. My laptop has
    a total of 8 CPU cores, so Ray will create 8 worker processes on my one-node local
    cluster. Our `database` is currently defined on the driver only, but the workers
    running your tasks need to have access to it to run the `retrieve` task. Luckily,
    Ray provides an easy way to share data between the driver and workers (or between
    workers). You can simply use `put` to place your data into Ray’s *distributed
    object store* and then use `get` on the workers to retrieve it as follows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，在 `retrieve` 的定义中，我们*直接*从我们的 `数据库` 访问了项目。在本地 Ray 集群上运行这没问题，但想象一下你在一个包含多台计算机的实际集群上运行。所有这些计算机如何访问相同的数据？请记住，在
    Ray 集群中，有一个带有驱动程序进程（运行 `ray.init()`）的头节点，以及许多带有执行任务的工作程序进程的工作节点。我的笔记本电脑有总共8个 CPU
    核心，因此 Ray 将在我的单节点本地集群上创建8个工作进程。我们的 `数据库` 目前仅在驱动程序上定义，但运行任务的工作程序需要访问它来运行 `retrieve`
    任务。幸运的是，Ray 提供了一种简单的方法来在驱动程序和工作程序（或工作程序之间）之间共享数据。您可以简单地使用 `put` 将您的数据放入 Ray 的*分布式对象存储*中，然后在工作程序上使用
    `get` 来检索它，如下所示。
- en: Example 2-6\.
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-6。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO5-1)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO5-1)'
- en: '`put` your `database` into the object store and receive a reference to it.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`put` 将你的 `数据库` 放入对象存储并接收到它的引用。'
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO5-2)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO5-2)'
- en: This allows your workers to `get` the data, no matter where they are located
    in the cluster.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得您的工作程序可以在集群中的任何位置 `get` 到数据。
- en: By using the object store this way, you can let Ray handle data access across
    the whole cluster. We’ll talk about how exactly data is passed between nodes and
    within workers when talking about Ray’s infrastructure. While the interaction
    with the object store requires some overhead, Ray is really smart about storing
    the data, which gives you performance gains when working with larger, more realistic
    datasets. For now, the important part is that this step is essential in a truly
    distributed setting. If you like, try to re-run [Example 2-5](#code_duration_remote)
    with this new `retrieve_task` function and confirm that it still runs, as expected.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式使用对象存储，您可以让 Ray 处理整个集群中的数据访问。我们将在讨论 Ray 的基础设施时详细讨论数据在节点之间和工作程序内部如何传递。虽然与对象存储的交互需要一些开销，但
    Ray 在存储数据方面非常聪明，这在处理更大、更真实的数据集时可以提供性能收益。目前，重要的部分是在真正分布式设置中这一步骤是必不可少的。如果愿意，尝试使用这个新的
    `retrieve_task` 函数重新运行 [示例 2-5](#code_duration_remote)，并确认它仍然如预期般运行。
- en: Using Ray’s wait function for non-blocking calls
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Ray 的等待函数进行非阻塞调用。
- en: 'Note how in [Example 2-5](#code_duration_remote) we used `ray.get(data_references)`
    to access results. This call is *blocking*, which means that our driver has to
    wait for all the results to be available. That’s not a big deal in our case, the
    program now finishes in under a second. But imagine processing of each data item
    would take several minutes. In that case you would want to free up the driver
    process for other tasks, instead of sitting idly by. Also, it would be great to
    process results as they come in (some finish much quicker than others), rather
    than waiting for all data to be processed. One more question to keep in mind is
    what happens if one of the data items can’t be retrieved as expected? Let’s say
    there’s a deadlock somewhere in the database connection. In that case, the driver
    will simply hang and never retrieve all items. For that reason it’s a good idea
    to work with reasonable timeouts. In our scenario, we should not wait longer than
    10 times the longest data retrieval task before stopping the task. Here’s how
    you can do that with Ray by using `wait`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意在[示例 2-5](#code_duration_remote)中如何使用`ray.get(data_references)`来访问结果。这个调用是*阻塞的*，这意味着我们的驱动程序必须等待所有结果可用。在我们的情况下这并不是什么大问题，程序现在在不到一秒内完成。但想象一下，如果每个数据项的处理需要几分钟，那该怎么办？在那种情况下，你可能希望释放驱动程序来处理其他任务，而不是闲坐着。此外，最好能够在结果可用时即时处理它们（某些结果比其他的更快完成）。还有一个需要记住的问题是，如果一个数据项无法按预期获取会发生什么情况？假设数据库连接中某处发生死锁。在这种情况下，驱动程序将会挂起并永远无法检索所有项。因此，明智的做法是使用合理的超时。在我们的场景中，在停止任务之前，我们不应等待超过最长数据检索任务的10倍时间。这里是如何通过使用`wait`在Ray中实现的：
- en: Example 2-7\.
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-7\.
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO6-1)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO6-1)'
- en: Instead of blocking, we loop through unfinished `data_references`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 不阻塞，我们循环处理未完成的`data_references`。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO6-2)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO6-2)'
- en: We asynchronously `wait` for finished data with a reasonable `timeout`. `data_references`
    gets overridden here, to prevent an infinite loop.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用合理的`timeout`异步`wait`等待完成的数据。在这里，`data_references`被覆盖，以防止无限循环。
- en: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO6-3)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO6-3)'
- en: We print results as they come in, namely in blocks of two.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当结果到达时，我们按两个数据块打印它们。
- en: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO6-4)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO6-4)'
- en: Then we `append` new `data` to the `all_data` until finished.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，直到完成，我们将新的`data`追加到`all_data`中。
- en: 'As you can see `ray.wait` returns two arguments, namely finished data and futures
    that still need to be processed. We use the `num_returns` argument, which defaults
    to `1`, to let `wait` return whenever a new pair of data items is available. On
    my laptop this results in the following output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`ray.wait`返回两个参数，即已完成的数据和仍需要处理的未来数据。我们使用`num_returns`参数，默认为`1`，让`wait`在新的一对数据项可用时返回。在我的笔记本电脑上，这导致以下输出：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note how in the `while` loop, instead of just printing results, we could have
    done many other things, like starting entirely new tasks on other workers with
    the data already retrieved up to this point.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`while`循环中，与其仅仅打印结果，我们可以做许多其他事情，比如使用已检索到的数据启动其他工作节点上的全新任务。
- en: Handling task dependencies
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理任务依赖关系
- en: So far our example program has been fairly easy on a conceptual level. It consists
    of a single step, namely retrieving a bunch of data. Now, imagine that once your
    data is loaded you want to run a follow-up processing task on it. To be more concrete,
    let’s say we want to use the result of our first retrieve task to query other,
    related data (pretend that you’re querying data from a different table in the
    same database). The following code sets up such a task and runs both our `retrieve_task`
    and `follow_up_task` consecutively.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的示例程序在概念上相当简单。它只包括一个步骤，即检索一堆数据。现在，想象一下，一旦加载了数据，您希望对其运行后续处理任务。更具体地说，假设我们希望使用第一个检索任务的结果查询其他相关数据（假装您正在从同一数据库中的不同表中查询数据）。以下代码设置了这样一个任务，并依次运行我们的`retrieve_task`和`follow_up_task`。
- en: Example 2-8\. Running a follow-up task that depends on another Ray task
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-8\. 运行依赖另一个Ray任务的后续任务
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO7-1)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO7-1)'
- en: Using the result of `retrieve_task` we compute another Ray task on top of it.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`retrieve_task`的结果，我们在其基础上计算另一个Ray任务。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO7-2)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO7-2)'
- en: Leveraging the `original_item` from the first task, we `retrieve` more data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 利用第一个任务中的`original_item`，我们`retrieve`更多的数据。
- en: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO7-3)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO7-3)'
- en: Then we return both the original and the follow-up data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们返回原始数据和后续数据。
- en: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO7-4)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO7-4)'
- en: We pass the object references from the first task into the second task.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一个任务中的对象引用传递给第二个任务。
- en: Running this code results in the following output.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码将产生以下输出。
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you don’t have a lot of experience with asynchronous programming, you might
    not be impressed by [Example 2-8](#code_task_dependency). But I hope to convince
    you that it’s at least a bit surprising^([3](ch02.xhtml#idm44990033068688)) that
    this code snippet runs at all. So, what’s the big deal? After all, the code reads
    like regular Python - a function definition and a few list comprehensions. The
    point is that the function body of `follow_up_task` expects a Python `tuple` for
    its input argument `retrieve_result`, which we unpack in the first line of the
    function definition.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在异步编程方面没有太多经验，您可能对[示例 2-8](#code_task_dependency)不感兴趣。但我希望说服您，这段代码至少有些令人惊讶^([3](ch02.xhtml#idm44990033068688))，因为这段代码片段实际上是可以运行的。那么，有什么了不起的地方呢？毕竟，这段代码看起来像是普通的Python代码
    - 一个函数定义和几个列表推导式。关键在于，`follow_up_task`函数体期望其输入参数`retrieve_result`是一个Python `tuple`，我们在函数定义的第一行对其进行解包。
- en: But by invoking `[follow_up_task.remote(ref) for ref in retrieve_refs]` we do
    *not* pass in tuples to the follow-up task at all. Instead, we pass in Ray *object
    references* with `retrieve_refs`. What happens under the hood is that Ray knows
    that `follow_up_task` requires actual values, so internally in this task it will
    call `ray.get` to resolve the futures. Ray builds a dependency graph for all tasks
    and executes them in an order that respects the dependencies. You do not have
    to tell Ray explicitly when to wait for a previous task to finish, it will infer
    that information for you.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但通过调用`[follow_up_task.remote(ref) for ref in retrieve_refs]`，我们根本没有向后续任务传递元组。相反，我们使用`retrieve_refs`传递了Ray的*对象引用*。在幕后发生的是，Ray知道`follow_up_task`需要实际的值，因此在该任务内部，它将调用`ray.get`来解析这些future对象。Ray为所有任务构建依赖图，并按照依赖关系的顺序执行它们。您不必显式告诉Ray何时等待先前的任务完成，它会自动推断这些信息。
- en: The follow-up tasks will only be scheduled, once the individual retrieve tasks
    have finished. If you ask me, that’s an incredible feature. In fact, if I had
    called `retrieve_refs` something like `retrieve_result`, you may not even have
    noticed this important detail. That’s by design. Ray wants you to focus on your
    work, not on the details of cluster computing. In figure [Figure 2-1](#fig_task_dependency)
    you can see the dependency graph for the two tasks visualized.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 仅当单个检索任务完成时，后续任务才会被调度。如果问我，这是一个令人难以置信的特性。实际上，如果我像`retrieve_refs`那样称呼它为`retrieve_result`，您甚至可能没有注意到这个重要细节。这是有意设计的。Ray希望您专注于工作，而不是集群计算的细节。在图 [Figure 2-1](#fig_task_dependency)中，您可以看到可视化的两个任务的依赖图。
- en: '![Task Dependency](assets/task_dependency.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![任务依赖](assets/task_dependency.png)'
- en: Figure 2-1\. Running two dependent tasks asynchronously and in parallel with
    Ray
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. 使用Ray异步并行运行两个依赖任务
- en: If you feel like it, try to rewrite [Example 2-8](#code_task_dependency) so
    that it explicitly uses `get` on the first task before passing values into the
    follow-up task. That does not only introduce more boilerplate code, but it’s also
    a bit less intuitive to write and understand.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您愿意，可以尝试重写[示例 2-8](#code_task_dependency)，以便在将值传递给后续任务之前明确使用`get`。这不仅会引入更多样板代码，而且写起来和理解起来也没有那么直观。
- en: From classes to actors
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从类到actors
- en: Before wrapping up this example, let’s discuss one more important concept of
    Ray Core. Notice how in our example everything is essentially a function. We just
    used the `ray.remote` decorator to make some of them remote functions, and other
    than that simply used plain Python. Let’s say we wanted to track how often our
    `database` has been queried? Sure, we could simply count the results of our retrieve
    tasks, but is there a better way to do this? We want to track this in a “distributed”
    way that will scale. For that, Ray has the concept of *actors*. Actors allow you
    to run *stateful* computations on your cluster. They can also communicate between
    each other^([4](ch02.xhtml#idm44990033053088)). Much like Ray tasks were simply
    decorated functions, Ray actors are decorated Python classes. Let’s write a simple
    counter to track our database calls.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这个示例之前，让我们讨论Ray Core的另一个重要概念。注意在我们的示例中，一切本质上都是一个函数。我们只是使用`ray.remote`装饰器使其中一些成为远程函数，除此之外只是使用普通的Python。假设我们想追踪我们的`database`被查询的频率？当然，我们可以简单地计算我们的检索任务的结果，但是有没有更好的方法？我们想以一种“分布式”的方式进行跟踪，这样就能扩展。为此，Ray有*actors*的概念。actors允许您在集群上运行*有状态*的计算。它们还可以相互通信^([4](ch02.xhtml#idm44990033053088))。就像Ray任务只是被装饰的函数一样，Ray
    actors是被装饰的Python类。让我们编写一个简单的计数器来跟踪我们的数据库调用。
- en: Example 2-9\.
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-9。
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO8-1)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO8-1)'
- en: We can make any Python class a Ray actor by using the same `ray.remote` decorator
    as before.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用与之前相同的`ray.remote`装饰器使任何Python类成为Ray actor。
- en: This `DataTracker` class is already an actor, since we equipped it with the
    `ray.remote` decorator. This actor can track state, here just a simple counter,
    and its methods are Ray tasks that get invoked precisely like we did with functions
    before, namely using `.remote()`. Let’s see how we can modify our existing `retrieve_task`
    to incorporate this new actor.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`DataTracker`类已经是一个actor，因为我们给它装饰了`ray.remote`。这个actor可以追踪状态，这里只是一个简单的计数器，并且它的方法是Ray任务，可以像我们之前使用函数一样精确地调用，即使用`.remote()`。让我们看看如何修改我们现有的`retrieve_task`以包含这个新的actor。
- en: Example 2-10\.
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-10。
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO9-1)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_getting_started_with_ray_core_CO9-1)'
- en: We pass in the `tracker` actor into this task.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`tracker` actor传递给这个任务。
- en: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO9-2)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_getting_started_with_ray_core_CO9-2)'
- en: The `tracker` receives an `increment` for each call.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`tracker`每次调用都会收到一个`increment`。'
- en: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO9-3)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_getting_started_with_ray_core_CO9-3)'
- en: We instantiate our `DataTracker` actor by calling `.remote()` on the class.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在类上调用`.remote()`来实例化我们的`DataTracker` actor。
- en: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO9-4)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_getting_started_with_ray_core_CO9-4)'
- en: The actor gets passed into the retrieve task.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这个actor被传递到检索任务中。
- en: '[![5](assets/5.png)](#co_getting_started_with_ray_core_CO9-5)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_getting_started_with_ray_core_CO9-5)'
- en: Afterwards we can get the `counts` state from our `tracker` from another remote
    invocation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以从另一个远程调用中获取我们的`tracker`的`counts`状态。
- en: Unsurprisingly, the result of this computation is in fact `8`. We didn’t need
    actors to compute this, but I hope you can see how useful it can be to have a
    mechanism to track state across the cluster, potentially spanning multiple tasks.
    In fact, we could pass our actor into any dependent task, or even pass it into
    the constructor of yet another actor. There is no limitation to what you can do,
    and it’s this flexibility that makes the Ray API so powerful. It’s also worth
    mentioning that it’s not very common for distributed Python tools to allow for
    stateful computations like this. This feature can come in very handy, especially
    when running complex distributed algorithms, for instance when using reinforcement
    learning. This completes our extensive first Ray API example. Let’s see if we
    can concisely summarize the Ray API next.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，这个计算的结果实际上是`8`。我们不需要actor来计算这个，但我希望你能看出它可以多么有用，可以跨集群跟踪状态，潜在地覆盖多个任务。事实上，我们可以将我们的actor传递给任何依赖任务，甚至将其传递给另一个actor的构造函数。你可以做任何事情，没有限制，正是这种灵活性使Ray
    API如此强大。值得一提的是，分布式Python工具很少允许进行这种有状态的计算。这个特性非常有用，特别是在运行复杂的分布式算法时，例如使用强化学习时。这完成了我们广泛的第一个Ray
    API示例。接下来让我们看看是否可以简洁地总结Ray API。
- en: An Overview of the Ray Core API
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ray核心API概述
- en: If you recall what exactly we did in the previous example, you’ll notice that
    we used a total of just six API methods^([5](ch02.xhtml#idm44990032795376)). You
    used `ray.init()` to start the cluster and `@ray.remote` to turn functions and
    classes into tasks and actors. Then we used `ray.put()` to pass data into Ray’s
    object store and `ray.get()` to retrieve data from the cluster. Finally, we used
    `.remote()` on actor methods or tasks to run code on our cluster, and `ray.wait`
    to avoid blocking calls.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回想一下我们在前面的例子中做过的事情，你会注意到我们只使用了总共六种 API 方法^([5](ch02.xhtml#idm44990032795376))。你使用
    `ray.init()` 来启动集群，使用 `@ray.remote` 将函数和类转换为任务和 actor。然后我们使用 `ray.put()` 将数据传入
    Ray 的对象存储，使用 `ray.get()` 从集群中检索数据。最后，我们在 actor 方法或任务上使用 `.remote()` 在我们的集群上运行代码，并使用
    `ray.wait` 避免阻塞调用。
- en: While six API methods might not seem like much, those are the only ones you’ll
    likely ever care about when using the Ray API^([6](ch02.xhtml#idm44990032790816)).
    Let’s briefly summarize them in a table, so you can easily reference them in the
    future.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Ray API 中有六种方法看起来可能不多，但这些方法在你使用 Ray API^([6](ch02.xhtml#idm44990032790816))
    时很可能是你唯一关心的。让我们简要总结它们在表格中，这样你以后可以轻松地参考。
- en: Table 2-1\. The six major API methods of Ray Core
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. Ray 核心的六个主要 API 方法
- en: '| API call | Description |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| API 调用 | 描述 |'
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `ray.init()` | Initializes your Ray cluster. Pass in an `address` to connect
    to an existing cluster. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `ray.init()` | 初始化你的 Ray 集群。传入一个 `address` 来连接到现有的集群。 |'
- en: '| `@ray.remote` | Turns functions into tasks and classes into actors. |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `@ray.remote` | 将函数转换为任务，类转换为 actor。 |'
- en: '| `ray.put()` | Puts data into Ray’s object store. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `ray.put()` | 将数据放入 Ray 的对象存储中。 |'
- en: '| `ray.get()` | Gets data from the object store. Returns data you’ve `put`
    there or that was computed by a task or actor. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `ray.get()` | 从对象存储中获取数据。返回你在那里 `put` 的数据或由任务或 actor 计算的数据。 |'
- en: '| `.remote()` | Runs actor methods or tasks on your Ray cluster and is used
    to instantiate actors. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `.remote()` | 在你的 Ray 集群上运行 actor 方法或任务，并用于实例化 actors。 |'
- en: '| `ray.wait()` | Returns two lists of object references, one with finished
    tasks we’re waiting for and one with unfinished tasks. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `ray.wait()` | 返回两个对象引用列表，一个是我们正在等待的已完成任务，另一个是未完成的任务。 |'
- en: Now that you’ve seen the Ray API in action, let’s quickly discuss Ray’s design
    philosophy, before moving on to discussing its system architecture.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了 Ray API 的实际应用，让我们快速讨论一下 Ray 的设计哲学，然后再讨论其系统架构。
- en: Design Principles
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计原则
- en: Ray is built with several design principles in mind, most of which you’ve got
    a taste of already. Its API is designed for simplicity and generality. Its compute
    model banks on flexibility. And its system architecture is designed for performance
    and scalability. Let’s look at each of these in more detail.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 是根据几个设计原则构建的，你已经对大多数原则有所了解。它的 API 设计简单且通用。其计算模型依赖于灵活性。其系统架构设计用于性能和可伸缩性。让我们更详细地看看每一个。
- en: Simplicity and abstraction
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单和抽象
- en: As you’ve seen, Ray’s API does not only bank on simplicity, it’s also intuitive
    to pick up. It doesn’t matter whether you just want to use all the CPU cores on
    your laptop or leverage all the machines in your cluster. You might have to change
    a line of code or two, but the Ray code you use stays essentially the same. And
    as with any good distributed system, Ray manages task distribution and coordination
    under the hood. That’s great, because you’re not bogged down by reasoning about
    the mechanics of distributed computing. A good abstraction layer allows you to
    focus on your work, and I think Ray has done a great job of giving you one.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，Ray 的 API 不仅简单易懂，而且易于掌握。无论你只想使用笔记本电脑上的所有 CPU 核心还是利用集群中的所有机器，都无关紧要。你可能需要改变一两行代码，但你使用的
    Ray 代码基本保持不变。正如任何好的分布式系统一样，Ray 在幕后管理任务分发和协调。这很棒，因为你不必为分布式计算的机制而烦恼。一个好的抽象层让你专注于工作，我认为
    Ray 在这方面做得很好。
- en: Since Ray’s API is so generally applicable and pythonic, it’s easy to integrate
    with other tools. For instance, Ray actors can call into or be called by existing
    distributed Python workloads. In that sense Ray makes for good “glue code” for
    distributed workloads, too, as its performant and flexible enough to communicate
    between different systems and frameworks.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Ray 的 API 如此通用且符合 Python 风格，它很容易与其他工具集成。例如，Ray actor 可以调用或被现有的分布式 Python
    工作负载调用。从这个意义上说，Ray 也适用于分布工作负载的“胶水代码”，因为它足够高效和灵活，可以在不同系统和框架之间进行通信。
- en: Flexibility
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 灵活性
- en: For AI workloads, in particular when dealing with paradigms like reinforcement
    learning, you need a flexible programming model. Ray’s API is designed to make
    it easy to write flexible and composable code. Simply put, if you can express
    your workload in Python, you can distribute it with Ray. Of course, you still
    need to make sure you have enough resources available and be mindful of what you
    want to distribute. But Ray doesn’t limit you in what you can do with it.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI工作负载，特别是在处理强化学习等范式时，您需要一个灵活的编程模型。射线的API旨在使编写灵活且可组合的代码变得容易。简而言之，如果您可以用Python表达您的工作负载，那么您可以用射线分发它。当然，您仍然需要确保您有足够的资源可用，并且要谨慎考虑您想要分发的内容。但射线不会限制您所能做的事情。
- en: Ray is also flexible when it comes to *heterogenity* of computations. For instance,
    let’s say you work on a complex simulation. Simulations can usually be decomposed
    into several tasks or steps. Some of these steps might take hours to run, others
    just a few milliseconds, but they always need to be scheduled and executed quickly.
    Sometimes a single task in a simulation can take a long time, but other, smaller
    tasks should be able to run in parallel without blocking it. Also, subsequent
    tasks may depend on the outcome of an upstream task, so you need a framework to
    allow for *dynamic execution* that deals well with task dependencies. In the example
    we discussed in this chapter you’ve seen that Ray’s API is built for that.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 射线在计算异构性方面也很灵活。例如，假设您正在进行复杂的模拟。模拟通常可以分解为多个任务或步骤。其中一些步骤可能需要几小时才能运行，而其他一些步骤只需要几毫秒，但总是需要快速调度和执行。有时，模拟中的单个任务可能需要很长时间，但其他较小的任务应该能够并行运行而不会阻塞它。此外，后续任务可能依赖于上游任务的结果，因此您需要一个允许良好处理任务依赖性的*动态执行*框架。在本章中我们讨论的示例中，您已经看到射线的API是为此而构建的。
- en: You also need to ensure you are flexible in your resource usage. For instance,
    some tasks might have to run on a GPU, while others run best on a couple of CPU
    cores. Ray provides you with that flexibility.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要确保您在资源使用方面具有灵活性。例如，某些任务可能必须在GPU上运行，而其他任务最适合在几个CPU核心上运行。射线为您提供了这种灵活性。
- en: Speed and scalability
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 速度和可伸缩性
- en: Another of Ray’s design principles is the speed at which Ray executes its heterogeneous
    tasks. It can handle millions of tasks per second. What’s more is that you only
    incur very low latencies with Ray. It’s build to execute its tasks with just milliseconds
    of latency.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 射线的另一个设计原则是射线执行其异构任务的速度。它可以处理数百万个任务每秒。更重要的是，使用射线只会产生非常低的延迟。它被设计为在毫秒级的延迟下执行任务。
- en: For a distributed system to be fast, it also needs to scale well. Ray is efficient
    at distributing and scheduling your tasks across your compute cluster. And it
    does so in a fault tolerant way, too. In distributed systems it’s not a question
    of if, but when things go wrong. A machine might have an outage, abort a task
    or simply go up in flames.^([7](ch02.xhtml#idm44990032763840)) In any case, Ray
    is built to recover quickly from failures, which contributes to its overall speed.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要使分布式系统快速，它还需要具有良好的可扩展性。射线在您的计算集群中有效地分发和调度任务。它也以容错的方式进行，因为在分布式系统中，问题不在于是否，而在于何时出现问题。一台机器可能会出现故障，中止任务，或者干脆起火。[^7]
    在任何情况下，射线都建立在快速从故障中恢复的基础上，这有助于其整体速度。
- en: Understanding Ray System Components
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解射线系统组件
- en: You’ve seen how the Ray API can be used and understand the design philosophy
    behind Ray. Now it’s time to get a better understanding of the underlying system
    components. In other words, how does Ray work and how does it achieve what it
    does?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经了解了射线API的使用方式，并理解了射线背后的设计哲学。现在是时候更好地了解底层系统组件了。换句话说，射线是如何工作的，以及它如何实现其功能的？
- en: Scheduling and Executing Work on a Node
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在节点上调度和执行工作
- en: You know that Ray clusters consist of nodes. We’ll first look at what happens
    on individual nodes, before we zoom out and discuss how the whole cluster interoperates.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您知道射线集群由节点组成。我们将首先查看单个节点上发生的情况，然后再放大讨论整个集群的互操作性。
- en: As we’ve already discussed, a worker node consists of several worker processes
    or simply workers. Each worker has a unique ID, an IP address and a port by which
    they can be referenced. Workers are called as they are for a reason, they’re components
    that blindly execute the work you give them. But who tells them what to do and
    when? A worker might be busy already, it may not have the proper resources to
    run a task (e.g. access to a GPU), and it might not even have the data it needs
    to run a given task. On top of that, workers have no knowledge of what happens
    before or after they’ve executed their workload, there’s no coordination.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经讨论过的，一个工作节点由多个工作进程或简单地说是工作组成。每个工作进程都有一个唯一的ID、一个IP地址和一个端口，通过这些可以引用它们。工作进程之所以被称为工作进程，是有原因的，它们是盲目执行您给予它们的工作的组件。但是是谁告诉它们什么时候做什么的呢？一个工作进程可能已经很忙了，它可能没有适当的资源来运行一个任务（例如访问GPU），甚至可能没有运行给定任务所需的数据。除此之外，工作进程对其执行的工作之前或之后发生的事情一无所知，没有协调。
- en: To address these issues, each worker node has a component called *Raylet*. Think
    of Raylets as the smart components of a node, which manage the worker processes.
    Raylets are shared between jobs and consist of two components, namely a task scheduler
    and an object store.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，每个工作节点都有一个称为*Raylet*的组件。把Raylets想象成节点的智能组件，负责管理工作进程。Raylets在作业之间共享，并由两个组件组成，即任务调度器和对象存储。
- en: Let’s talk about object stores first. In the running example in this chapter
    we’ve already used the concept of an object store loosely, without really specifying
    it. Each node of a Ray cluster is equipped with an object store, within that node’s
    Raylet, and all object stored collectively form the distributed object store of
    a cluster. An object store has *shared memory* across the node, so that each worker
    process has easy access to it. The object store is implemented in [Plasma](https://arrow.apache.org/docs/python/plasma.xhtml),
    which now belongs to the Apache Arrow project. Functionally, the object store
    takes care of memory management and ultimately makes sure workers have access
    to the data they need.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们谈谈对象存储。在本章的运行示例中，我们已经在不明确指定的情况下宽泛地使用了对象存储的概念。Ray集群的每个节点都配备有一个对象存储，位于该节点的Raylet内部，并且所有存储的对象共同形成了集群的分布式对象存储。对象存储在节点之间具有*共享内存*，因此每个工作进程都可以轻松访问它。对象存储是在[Plasma](https://arrow.apache.org/docs/python/plasma.xhtml)中实现的，现在它归属于Apache
    Arrow项目。功能上，对象存储负责内存管理，并最终确保工作进程可以访问它们所需的数据。
- en: The second component of a Raylet is its scheduler. The scheduler takes care
    of resource management, among other things. For instance, if a task requires access
    to 4 CPUs, the scheduler needs to make sure it can find a free worker process
    that it can *grant access* to said resources. By default, the scheduler knows
    about and acquires information about the number of CPUs and GPUs and the amount
    of memory available on its node, but you can register custom resources, if you
    want to. If it can’t provide the required resources, it can’t schedule execution
    of a task.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Raylet的第二个组件是其调度器。调度器负责资源管理等多项工作。例如，如果一个任务需要访问4个CPU，调度器需要确保它可以找到一个空闲的工作进程，可以*授权访问*这些资源。默认情况下，调度器了解并获取其节点上可用的CPU数、GPU数以及内存量的信息，但如果需要，您可以注册自定义资源。如果它无法提供所需的资源，则无法调度任务的执行。
- en: Apart from resources, the other requirement the scheduler takes care of is *dependency
    resolution*. That means it needs to ensure that each worker has all the input
    data it needs to execute a task. For that to work, the scheduler will first resolve
    local dependencies by looking up data in its object store. If the required data
    is not available on this node’s object store, the scheduler will have to communicate
    with other nodes (we’ll tell you how in a bit) and pull in remote dependencies.
    Once the scheduler has ensured enough resources for a task, resolved all needed
    dependencies, and found a worker for a task, it can schedule said task for execution.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 除了资源外，调度器需要处理的另一个要求是*依赖解析*。这意味着它需要确保每个工作节点具备执行任务所需的所有输入数据。为此，调度器将首先通过查找对象存储中的数据来解析本地依赖关系。如果所需数据在该节点的对象存储中不可用，调度器将不得不与其他节点通信（稍后我们会告诉您如何），并拉取远程依赖项。一旦调度器确保了任务的足够资源，解析了所有所需的依赖关系，并为任务找到了一个工作节点，它就可以将该任务安排到执行队列中。
- en: Task scheduling is a very difficult topic, even if we’re only talking about
    single nodes. I think you can easily imagine scenarios in which an incorrectly
    or naively planned task execution can “block” downstream tasks because there are
    not enough resources left. Especially in a distributed context assigning work
    like this can be become very tricky very quickly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 任务调度是一个非常复杂的话题，即使我们只讨论单个节点。我想你可以轻松想象出一些情况，即由于资源不足，错误或天真地规划任务执行可能会“阻塞”下游任务。特别是在分布式环境中，分配这样的工作可能会很快变得非常棘手。
- en: Now that you know about Raylets, let’s briefly come back to worker processes,
    so that we can wrap up the discussion around worker nodes. An important concept
    that contributed to the performance or Ray overall is that of *ownership*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了 Raylet，让我们简要回到工作进程，以便我们可以结束对工作节点的讨论。对于 Ray 整体性能做出贡献的一个重要概念是*拥有权*。
- en: Ownership means that a process that runs something is responsible for it. This
    makes for a decentralized overall design, since individual tasks have a unique
    owner. In concrete terms this means that each worker process owns the tasks it
    submits, which includes proper execution and availability of results (i.e., correct
    resolution of object references). Also, anything that gets registered through
    `ray.put()` is owned by the caller. You should understand ownership in contrast
    to dependency, which we’ve already covered by example when discussing task dependencies.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有权（Ownership）意味着运行某个进程的过程对其负责。这样一来，整体设计就是去中心化的，因为各个任务都有唯一的所有者。具体来说，这意味着每个工作进程拥有它提交的任务，包括正确执行和结果可用性（即正确解析对象引用）。此外，通过
    `ray.put()` 注册的任何东西都由调用者拥有。你应该理解拥有权与依赖性的对比，我们在讨论任务依赖性时已经通过示例进行了解释。
- en: 'To give you a concrete example, let’s say we have a program that starts a `task`
    which takes an input value `val` and internally calls another task. That could
    look as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 举个具体的例子，假设我们有一个程序启动了一个名为 `task` 的任务，它接受一个名为 `val` 的输入值，并在内部调用另一个任务。具体代码如下：
- en: Example 2-11\.
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例子 2-11。
- en: '[PRE13]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: From this point on we won’t mention it again, but this example assumes that
    you have a running Ray cluster started with `ray.init()`. Let’s quickly analyse
    ownership and dependency for this example. We defined two tasks in `task` and
    `task_owned`, and we have three variables in total, namely `val`, `res` and `rew_owned`.
    Our main program defines both `val` (which puts `"value"` into the object store)
    and `res`, the final result of th whole program, and it also calls `task`. In
    other words, the driver *owns* `task`, `val` and `res` according to Ray’s ownership
    definition. In contrast, `res` depends on `task`, but there’s no ownership relationship
    between the two. When `task` gets called, it takes `val` as a dependency. It then
    calls `task_owned` and assigns `res_owned`, and hence owns them both. Lastly,
    `task_owned` itself does not own anything, but certainly `rew_owned` depends on
    it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，我们不再提及它，但是这个例子假设你已经启动了一个带有 `ray.init()` 的运行中的 Ray 集群。让我们快速分析一下这个例子中的拥有权和依赖关系。我们定义了两个任务
    `task` 和 `task_owned`，总共有三个变量，即 `val`、`res` 和 `res_owned`。我们的主程序定义了 `val`（将 `"value"`
    放入对象存储）和 `res`（程序的最终结果），并调用了 `task`。换句话说，根据 Ray 的拥有权定义，驱动程序拥有 `task`、`val` 和 `res`。相比之下，`res`
    依赖于 `task`，但它们之间没有拥有关系。当调用 `task` 时，它以 `val` 作为依赖项。然后调用 `task_owned` 并赋值 `res_owned`，因此它同时拥有这两者。最后，`task_owned`
    本身并不拥有任何东西，但显然 `res_owned` 依赖于它。
- en: Ownership is important to know about, but it’s not a concept you encounter all
    that often when working with Ray. The reason we brought it up in this context
    is that worker processes need to track what they own. In fact, they possess a
    so-called *ownership table* exactly for that reason. If a task fails and needs
    to be recomputed, the worker already owns all the information it needs to do so.
    On top of that, workers also have an in-process store for small objects, which
    has a default limit of 100KB. Workers have that store so that small data can be
    directly accessed and stored without incurring communication overhead with the
    Raylet object store, which is reserved for large objects.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Ray 的工作来说，了解拥有权是重要的，但在实际使用中并不经常遇到。我们在这个背景下提到它的原因是工作进程需要追踪它们所拥有的内容。事实上，它们有一个所谓的*拥有权表*来确保这一点。如果一个任务失败并需要重新计算，工作进程已经拥有完成此操作所需的所有信息。此外，工作进程还有一个用于小对象的进程内存储，其默认限制为
    100KB。工作进程拥有这个存储空间，可以直接访问和存储小数据，而不必与 Raylet 对象存储产生通信开销，后者主要用于大对象。
- en: To sum up this discussion about worker nodes, figure [Figure 2-2](#fig_workers)
    gives you an overview of all involved components.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 总结关于工作节点的讨论，图 [图 2-2](#fig_workers) 给出了所有涉及组件的概述。
- en: '![Worker](assets/worker_node.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![Worker](assets/worker_node.png)'
- en: Figure 2-2\. The system components comprising a Ray worker node
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 组成 Ray 工作节点的系统组件
- en: The Head Node
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 头节点
- en: We’ve already indicated in [Chapter 1](ch01.xhtml#chapter_01) that each Ray
    cluster has one special node called head node. So far you know that this is the
    node that has the driver process^([8](ch02.xhtml#idm44990032658080)). Drivers
    can submit tasks themselves, but can’t execute them. You also know that the head
    node can have some worker processes, which is important to be able to run local
    clusters constisting of a single node. In other words, the head node has everything
    a worker node has (including a Raylet), but it also has a driver process.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.xhtml#chapter_01)已经指出，每个 Ray 集群都有一个特殊节点称为头节点。到目前为止，您知道这个节点有驱动程序进程^([8](ch02.xhtml#idm44990032658080))。驱动程序可以自己提交任务，但不能执行它们。您还知道头节点可以有一些工作进程，这对于能够运行由单个节点组成的本地集群是很重要的。换句话说，头节点具有工作节点拥有的一切（包括一个
    Raylet），但它还有一个驱动进程。
- en: Additionally, the head node comes with a component called *Global Control Store*
    (GCS). The GCS is a key-value store currently implemented in Redis. It’s an important
    component that carries global information about the cluster, such as system-level
    metadata. For instance, it has a table with heart beat signals for each Raylet,
    to ensure they are still reachable. Raylets, in turn, send heart beat signals
    to the GCS to indicate that they are alive. The GCS also stores the locations
    of Ray actors and large objects in respective tables, and knows about the dependencies
    between objects.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，头节点配备了一个称为*全局控制存储*（GCS）的组件。GCS 是一个键值存储，目前在Redis中实现。它是一个重要的组件，负责携带关于集群的全局信息，例如系统级元数据。例如，它有一个包含每个Raylet心跳信号的表，以确保它们仍然可达。反过来，Raylet
    发送心跳信号到 GCS 表示它们仍然存活。GCS 还在各自的表中存储 Ray actor 和大对象的位置，并知道对象之间的依赖关系。
- en: Distributed Scheduling and Execution
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式调度和执行
- en: Let’s briefly talk about cluster orchestration and how nodes manage, plan and
    execute tasks. When talking about worker nodes, we’ve indicated that there are
    several components to distributing workloads with Ray. Here’s an overview of the
    steps and intricacies involved in this process.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要讨论集群编排以及节点如何管理、计划和执行任务。在谈论工作节点时，我们已经指出，使用 Ray 分发工作负载涉及多个组件。以下是这个过程中涉及的步骤和复杂性的概述。
- en: 'Distributed memory: The object stores of individual Raylets share their memory
    on a node. But sometimes data needs to be transferred between nodes, which is
    called *distributed object transfer*. This is needed for remote dependency resolution,
    so that workers have the data they need to run tasks.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存：单个 Raylet 的对象存储在节点上共享它们的内存。但有时需要在节点之间传输数据，这称为*分布式对象传输*。这对于远程依赖解析是必要的，以便工作节点具有运行任务所需的数据。
- en: Communication
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通信
- en: Most of the communication in a Ray cluster, such as object transfer, takes place
    via the [*gRPC*](https://grpc.io/) protocol.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 集群中大部分通信（例如对象传输）都通过[*gRPC*](https://grpc.io/)协议进行。
- en: Resource management and fulfillment
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理和满足
- en: On a node, Raylets are responsible to grant resources and *lease* worker processes
    to task owners. All schedulers across nodes form the distributed scheduler. Through
    communication with the GCS, local schedulers know about other nodes’ resources.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个节点上，Raylet 负责为任务所有者分配资源并*租赁*工作进程。所有节点上的调度器形成分布式调度器。通过与 GCS 的通信，本地调度器了解其他节点的资源。
- en: Task execution
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 任务执行
- en: Once a task has been submitted for execution, all its dependencies (local and
    remote data) need to be resolved, e.g. by retrieving large data from the object
    store, before execution can begin.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦任务被提交执行，所有依赖项（本地和远程数据）都需要解析，例如通过从对象存储中检索大数据，然后执行才能开始。
- en: If the last few sections seem a bit involved technically, that’s because they
    are. In my view it’s important to understand the basic patterns and ideas of the
    software you’re using, but I’ll admit that the details of Ray’s architecture can
    be a bit tough to wrap your head around in the beginning. In fact, it’s one of
    Ray’s design principles to trade-off usability for architectural complexity. If
    you want to delve deeper into Ray’s architecture, a good place to start is [their
    architecture white paper](https://docs.google.com/document/d/1lAy0Owi-vPz2jEqBSaHNQcy2IBSDEHyXNOQZlGuj93c/preview).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最近几节内容在技术上显得有些复杂，那是因为确实如此。在我看来，理解你正在使用的软件的基本模式和思想非常重要，但我承认，在一开始理解 Ray 的架构细节可能会有些困难。事实上，Ray
    的设计原则之一就是在可用性和架构复杂性之间做出权衡。如果你想更深入地了解 Ray 的架构，一个好的起点是阅读[它们的架构白皮书](https://docs.google.com/document/d/1lAy0Owi-vPz2jEqBSaHNQcy2IBSDEHyXNOQZlGuj93c/preview)。
- en: 'To wrap things up, let’s summarize all we know in a concise architecture overview
    with figure [Figure 2-3](#fig_architecture):'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，让我们通过图 [Figure 2-3](#fig_architecture) 的简明架构概述来总结我们所知道的所有内容：
- en: '![Architecture](assets/architecture.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![架构](assets/architecture.png)'
- en: Figure 2-3\. An overview of Ray’s architectural components
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. Ray 架构组件概述
- en: Summary
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: You’ve seen the basics of the Ray API in action in this chapter. You know how
    to `put` data to the object store, and how to `get` it back. Also, you’re familiar
    with declaring Python functions as Ray tasks with the `@ray.remote` decorator,
    and you know how to run them on a Ray cluster with the `.remote()` call. In much
    the same way, you understand how to declare a Ray actor from a Python class, how
    to instantiate it and leverage it for stateful, distributed computations.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在本章看到了 Ray API 的基本操作。你知道如何将数据 `put` 到对象存储中，并如何 `get` 回来。此外，你还熟悉了使用 `@ray.remote`
    装饰器将 Python 函数声明为 Ray 任务，并且知道如何使用 `.remote()` 在 Ray 集群上运行它们。同样地，你理解了如何从 Python
    类声明 Ray actor，如何实例化它，并利用它进行有状态的分布式计算。
- en: On top of that, you also know the basics of Ray clusters. After starting them
    with `ray.init(...)` you know that you can submit jobs consisting of tasks to
    your cluster. The driver process, sitting on the head node, will then distribute
    the tasks to the worker nodes. Raylets on each node will schedule the tasks and
    worker processes will execute them. This quick tour through Ray core should get
    you started with writing your own distributed programs, and in the next chapter
    we’ll test your knowledge by implementing a basic machine learning application
    together.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还了解了 Ray 集群的基本知识。在使用 `ray.init(...)` 启动它们后，你知道可以向集群提交由任务组成的作业。驻留在主节点上的驱动进程将任务分发给工作节点。每个节点上的
    Raylet 将调度任务，并且工作进程将执行它们。这次快速的 Ray 核心之旅应该能让你开始编写自己的分布式程序，而在下一章中，我们将通过共同实现一个基本的机器学习应用程序来测试你的知识。
- en: ^([1](ch02.xhtml#idm44990033684416-marker)) I still don’t know how to pronounce
    this acronym, but I get the feeling that the same people who pronounce GIF like
    “giraffe” also say GIL like “guitar”. Just pick one, or spell it out, if you feel
    insecure.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.xhtml#idm44990033684416-marker)) 我依然不知道如何正确发音这个缩写词，但我觉得那些把 GIF 发音成“长颈鹿”的人也会把
    GIL 发音成“吉他”。随便选一个，或者拼写出来，如果你不确定的话。
- en: ^([2](ch02.xhtml#idm44990033491152-marker)) This example has been adapted from
    Dean Wampler’s fantastic report [“What is Ray?”](https://www.oreilly.com/library/view/what-is-ray/9781492085768/).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.xhtml#idm44990033491152-marker)) 这个例子改编自迪恩·沃姆普勒的精彩报告 [“什么是 Ray？”](https://www.oreilly.com/library/view/what-is-ray/9781492085768/)。
- en: ^([3](ch02.xhtml#idm44990033068688-marker)) According to [Clarke’s third law](https://en.wikipedia.org/wiki/Clarke%27s_three_laws)
    any sufficiently advanced technology is indistinguishable from magic. For me,
    this example has a bit of magic to it.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch02.xhtml#idm44990033068688-marker)) 根据[克拉克的第三定律](https://en.wikipedia.org/wiki/Clarke%27s_three_laws)，任何足够先进的技术都无法与魔法区分开来。对我来说，这个例子确实有些神奇的成分。
- en: ^([4](ch02.xhtml#idm44990033053088-marker)) The actor model is an established
    concept in computer science, which you can find implemented e.g. in Akka or Erlang.
    However, the history and specifics of actors are not relevant to our discussion.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch02.xhtml#idm44990033053088-marker)) 演员模型是计算机科学中一个已经确立的概念，例如在 Akka 或
    Erlang 中可以找到它的实现。然而，演员的历史和具体细节并不适用于我们的讨论。
- en: ^([5](ch02.xhtml#idm44990032795376-marker)) To paraphrase [Alan Kay](https://www.youtube.com/watch?v=NdSD07U5uBs),
    to get simplicity, you need to find slightly more sophisticated building blocks.
    In my eyes, the Ray API does just that for distributed Python.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch02.xhtml#idm44990032795376-marker)) 引用[艾伦·凯](https://www.youtube.com/watch?v=NdSD07U5uBs)的话来说，为了实现简单，你需要找到稍微复杂一点的构建块。在我看来，Ray
    API 正是为Python分布式计算而设计的。
- en: ^([6](ch02.xhtml#idm44990032790816-marker)) You can check out the [API reference](https://docs.ray.io/en/latest/package-ref.xhtml)
    to see that there are in fact quite a bit more methods available. At some point
    you should invest in understanding the arguments of `init`, but all other methods
    likely won’t be of interest to you, if you’re not an administrator of your Ray
    cluster.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch02.xhtml#idm44990032790816-marker)) 你可以查看[API 参考文档](https://docs.ray.io/en/latest/package-ref.xhtml)，会发现其实有相当多的可用方法。在某个时候，你应该投入时间去理解`init`的参数，但其他所有方法如果你不是Ray集群的管理员，可能对你没什么兴趣。
- en: ^([7](ch02.xhtml#idm44990032763840-marker)) This might sound drastic, but it’s
    not a joke. To name just one example, in March 2021 a French data center powering
    millions of websites burnt down completely, which you can read about [in this
    article](https://www.reuters.com/article/us-france-ovh-fire-idUSKBN2B20NU). If
    your whole cluster burns down, I’m afraid Ray can’t help you.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch02.xhtml#idm44990032763840-marker)) 这听起来可能很激烈，但并非玩笑。举一个例子，在2021年3月，一家法国数据中心完全被烧毁，这件事你可以在[这篇文章](https://www.reuters.com/article/us-france-ovh-fire-idUSKBN2B20NU)中了解到。如果你的整个集群被烧毁了，恐怕Ray也无能为力。
- en: ^([8](ch02.xhtml#idm44990032658080-marker)) In fact, it could have multiple
    drivers, but this is inessential for our discussion.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch02.xhtml#idm44990032658080-marker)) 实际上，它可能有多个驱动程序，但这对我们的讨论来说并不重要。
