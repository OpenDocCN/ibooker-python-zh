# 附录 A. Dask 用户的关键系统概念

在本书中，我们根据需要简要介绍了一些分布式系统概念，但是当你准备独立进行工作时，复习一些 Dask 构建在其上的核心概念是一个好主意。在这个附录中，你将更多地了解 Dask 中使用的关键原则，以及它们如何影响你在 Dask 之上编写的代码。

# 测试

测试通常是数据科学和数据工程中经常被忽视的一部分。我们的一些工具，如 SQL 和 Jupyter 笔记本，不鼓励测试或者使得测试变得容易——但这并不免除我们测试代码的责任。数据隐私问题可能会增加另一层挑战，我们不希望为测试而存储用户数据，这就要求我们努力创建“虚假”数据进行测试，或者将我们的代码分解为可测试的组件，这些组件不需要用户数据。

## 手动测试

我们在编写软件或数据工具时经常进行某种形式的手动测试。这可以包括简单地运行工具并眼睛观察结果，看看它们是否合理。手动测试很耗时，而且不会自动重复，所以虽然在开发过程中很棒，但对于长期项目来说是不够的。

## 单元测试

单元测试指的是测试单个代码单元，而不是整个系统一起测试。这要求你的代码被组织成不同的单元，如模块或函数。虽然在笔记本上这种做法较少见，但我们认为为了可测试性而结构化你的代码是一个好的实践。

为笔记本编写单元测试可能会很有挑战；文档测试在笔记本中稍微更容易内联。如果你想使用传统的单元测试库，[ipython-unittest magics](https://oreil.ly/yUxXy)可以让你在笔记本中内联你的单元测试。

## 集成测试

集成测试指的是测试系统的不同部分如何一起工作。它通常更接近于代码的实际使用情况，但也可能更复杂，因为它涉及设置其他系统来进行测试。你可以在一定程度上使用一些相同的库进行集成测试，但这些测试往往需要更多的设置和拆卸工作。¹ 集成测试也更容易出现“不稳定”，因为在开始测试之前确保你的软件需要的所有不同组件在测试环境中都存在是具有挑战性的。

## 测试驱动开发

测试驱动开发涉及根据代码的需求或期望编写测试，然后再编写代码。对于数据科学管道来说，这通常可以通过创建样本输入（有时称为黄金集）来完成，并写出你期望的输出。测试驱动开发可能会很复杂，特别是当集成多个数据源时。

虽然您不需要使用测试驱动开发，但我们认为在开发数据流水线的同时进行测试非常重要。事后添加的测试总比没有测试好，但根据我们的经验，在开发过程中您拥有的上下文帮助您更好地创建测试（并且尽早验证您的假设）。

## 属性测试

属性测试可能是应对数据测试挑战的一个潜在的很好的解决方案，该解决方案涵盖了您的代码可能会出错的所有边缘情况的测试数据。与编写传统的“对于输入 A，预期结果 B”的方法不同，您可以指定属性，比如“如果我们有 0 个顾客，我们应该有 0 笔销售”或者“所有（有效的）顾客在此流水线后应该有欺诈评分”。

[Hypothesis](https://oreil.ly/zQhnh) 是 Python 中最流行的属性测试库。

## 使用笔记本

测试笔记本是令人痛苦的，尽管它们极其受欢迎。一般来说，您可以选择在笔记本外进行测试，这样可以使用现有的 Python 测试库，或者尝试将测试放在笔记本内部。

## 外部笔记本测试

除了忽略测试之外，传统选项是将您想要测试的代码部分重构为单独的常规 Python 文件，并使用正常的测试库对其进行测试。虽然部分重构可能会很痛苦，但将代码重写为更易测试的组件也可以带来调试的好处。

[testbook 项目](https://oreil.ly/3_YsK) 是重构的一种替代方法，采用了一种有趣的方法，允许您在笔记本外编写测试，而无需放弃笔记本。相反，您可以使用库装饰器来注释测试，例如，`@testbook('untitled_7.ipynb', execute=True)` 将在执行测试之前导入和执行笔记本。您还可以控制执行笔记本的哪些部分，但是这种部分执行可能在更新时很脆弱并容易中断。

## 笔记本内测试：内联断言

有些人喜欢在笔记本中使用内联断言作为测试的一种形式。在这种情况下，如果某些断言失败（例如，断言应该有一些顾客），那么笔记本的其余部分将不会运行。虽然我们认为使用内联断言很棒，但我们不认为它能替代传统的测试方法。

# 数据和输出验证

虽然良好的测试可以捕捉到许多问题，但有时现实世界比我们想象的更有创造力，我们的代码仍然会失败。在许多情况下，最糟糕的情况是我们的程序失败并生成一个我们不知道是错误的不正确输出，然后我们（或其他人）根据其结果采取行动。验证试图在我们的作业失败时通知我们，以便我们在其他人之前采取行动。在许多方面，这就像在提交学期论文之前运行拼写检查一样——如果有几个错误，那么好，但如果一切都是红色，最好再检查一遍。根据您的工作内容，验证它的方法会有所不同。

有许多不同的工具可以用来验证您的 Dask 作业的输出，当然包括 Dask 本身。一些工具，如 [TFX 的数据验证](https://oreil.ly/Vfb1Z)，尝试比较先前版本的统计相似性和模式更改[²]。[Pydantic](https://oreil.ly/RN8aI) 相对较新，但它具有 Dask 集成并且进行了出色的类型和模式验证。您还可以使用其假设组件进行更复杂的统计断言（这与 Python 的假设不同）。

机器学习模型在不影响用户的情况下更难验证，但统计技术仍然可以帮助（增量部署也可以）。由于机器学习模型是由数据生成的，验证数据是一个良好（部分）的步骤。

想想你的管道失败可能会带来什么影响是有用的。例如，你可能希望花更多时间验证一个管道，该管道决定临床试验中药物剂量，而不是预测哪个广告版本最成功[³]。

# Peer-to-Peer Versus Centralized Distributed

即使在分布式系统内部，也存在各种级别的“分布式”。Dask 是一个集中式分布式系统，其中有一个静态领导节点负责各种任务和协调工作人员之间的工作。在更分布式的系统中，没有静态领导节点，如果主节点消失，剩余的对等节点可以选举一个新的主节点，就像使用 ZooKeeper 一样。在更分布式的系统中，没有主节点的区别，集群中的所有节点在软件上（硬件可能不同）都是同等能力的。

集中式分布式系统倾向于更快，但在扩展方面遇到早期限制，并且在集中组件失败的挑战方面也有所挑战。

# 并行方法

有很多不同的方法来分解我们的工作，在本书中，我们主要讨论了任务并行和数据并行。

## 任务并行

`dask.delayed` 和 Python 的多进程都代表了任务并行。通过任务并行，您不受限于执行相同的代码。任务并行提供了最大的灵活性，但需要更多的代码更改来充分利用它。

## 数据并行

数据并行指的是对不同数据块（或分区）上的相同操作进行并行运行。这是一种在 DataFrame 和数组上操作的优秀技术。数据并行依赖于分区来分割工作。我们在第四章详细介绍了分区。

### 洗牌和窄与宽转换

*窄* 转换（或没有任何聚合或洗牌的数据并行）通常比*宽* 转换快得多，后者涉及洗牌或聚合。虽然这个术语借用自 Spark 社区，但区分（及其对容错性的影响）同样适用于 Dask 的数据并行操作。

### 限制

数据并行不太适合各种不同类型的工作。即使在处理数据问题时，也不适合执行多种不同的操作（非均匀计算）。数据并行通常不适合处理少量数据的计算，例如模型服务，可能需要逐个评估单个请求。

## 负载均衡

负载均衡是并行性的另一种视角，系统（或系统）将请求（或任务）路由到不同的服务器。负载均衡的范围从基本的轮询到“智能”负载均衡，利用关于相对负载、资源和工作服务器/服务器上数据的信息来调度任务。负载均衡越复杂，负载平衡器的工作量就越大。在 Dask 中，所有这些负载均衡都由中心处理，这要求主节点相对完整地查看大多数工作节点的状态以智能地分配任务。

另一个极端是“简单”的负载均衡，例如某些系统，如基于 DNS 轮询的负载均衡（Dask 未使用），没有任何关于系统负载的信息，只是选择“下一个”节点。当任务（或请求）在复杂性上大致相等时，基于轮询的负载均衡可以很好地工作。这种技术最常用于处理 Web 请求或外部 API 请求，其中您无法完全控制进行请求的客户端。您最有可能在模型服务中看到这一点，例如翻译文本或预测欺诈交易。

# 网络容错和 CAP 定理

如果您搜索“分布式计算概念”，您可能会遇到 CAP 定理。CAP 定理对于分布式数据存储最为相关，但无论如何理解它都是有用的。该定理指出，我们无法构建一个既一致（Consistent）、可用（Available）、又分区容忍（Partition-tolerant）的分布式系统。分区可能由硬件故障或更常见的是由于过载的网络链路引起。

Dask 本身已经做出了不支持容错分区的折衷；网络分区的任一一侧拥有“领导者”，则该侧将继续运行，而另一侧则无法进展。

了解这如何应用于您从 Dask 访问的资源是很重要的。例如，您可能会发现自己处于一种情况中，即网络分区意味着 Dask 无法写入其输出。或者更糟糕的是，在我们看来，它可能导致您从 Dask 存储的数据被丢弃。⁴

由 Kyle Kingsbury 创建的[Jepsen 项目](https://jepsen.io)是我们所知的用于测试分布式存储和查询系统的最佳项目之一。

# 递归（尾递归和其他）

递归是指调用自身的函数（直接或间接）。当它是间接的时候，被称为*co-recursion*，而返回最终值的递归函数被称为*tail-recursive*。⁵ 尾递归函数类似于循环，有时语言可以将尾递归调用转换为循环或映射。

有时会避免在无法优化递归的语言中使用递归函数，因为调用函数会有开销。相反，用户会尝试使用循环表达递归逻辑。

过度的非优化递归可能导致堆栈溢出错误。在 C、Java、C++等语言中，堆栈内存与主内存（也称为堆内存）分开分配。在 Python 中，递归的数量由`set​recur⁠sionlimit`控制。Python 提供了一个[tail-recursive annotation](https://oreil.ly/QTHYz)，您可以使用它来帮助优化这些递归调用。

在 Dask 中，虽然递归调用没有完全相同的堆栈问题，但过度递归可能是头节点负载的原因之一。这是因为调度递归调用必须经过头节点，并且过多的递归函数会导致 Dask 的调度器在遇到任何堆栈大小问题之前变慢。

# 版本控制和分支：代码和数据

版本控制是一个重要的计算机科学概念，它可以应用于代码和数据。理想情况下，版本控制使得很容易撤销错误并返回到早期版本或同时探索多个方向。我们生产的许多物品都是我们的代码和数据的结合；为了真正实现快速回滚和支持实验的目标，您将希望对代码和数据都进行版本控制。

源代码的版本控制工具已经存在很长时间。对于代码来说，[Git](https://git-scm.com)已经成为使用最广泛的开源版本控制系统，超过了诸如 Subversion、Concurrent Version Systems 等工具。

尽管深入理解 Git 可能非常复杂，⁶ 但对于常见用法，有几个 [核心命令](https://oreil.ly/ZYBJM) 经常能帮助你解决问题。本附录不涵盖 Git 的教学内容，但有许多资源可供参考，包括 Raju Gandhi（O'Reilly）的 [*Head First Git*](https://learning.oreilly.com/library/view/head-first-git/9781492092506/) 和 Julia Evans 的 *Oh Shit, Git!*，还有免费的在线资源。

不幸的是，软件版本控制工具目前的笔记本集成体验并不是最佳的，通常需要额外的工具，比如 [ReviewNB](https://www.reviewnb.com)，以便更好地理解变更。

现在，一个自然的问题是，你能否使用相同的工具对数据进行版本控制，就像你对软件做的那样？有时候可以——只要你的数据足够小并且不包含任何个人信息，使用源代码控制对数据进行管理是可以接受的。然而，软件通常存储在文本中，通常比你的数据要小，并且在文件开始超过几十 MB 后，许多源代码控制工具的效果并不理想。

相反，像 [LakeFS](https://lakefs.io) 这样的工具在现有的外部数据存储（例如 S3、HDFS、Iceberg、Delta）之上添加了类似 Git 的版本控制语义。⁷ 另一种选择是手动复制你的表格，但我们发现这会导致命名笔记本和 Word 文档时常见的“-final2-really-final”问题。

# 隔离和噪音邻居

到目前为止，我们已经讨论了能够拥有自己的 Python 包的隔离性，但还有更多种类的隔离。一些其他层次的隔离包括 CPU、GPU、内存和网络。⁸ 许多集群管理器并未提供完整的隔离性——这意味着如果你的任务被安排在错误的节点上，它们可能会表现出差劲的性能。解决这个问题的常见方法是按照整个节点的资源量请求资源，以避免在你自己的任务旁边安排其他任务。

严格的隔离也可能存在缺点，特别是如果隔离框架不支持突发性需求。严格的隔离如果没有突发性需求支持，可能会导致资源浪费，但对于关键任务工作流来说，这通常是一种权衡。

# 机器容错

容错是分布式计算中的一个关键概念，因为你增加的计算机数量越多，每台计算机发生故障的概率就越高。在一些较小的 Dask 部署中，机器容错并不那么重要，因此，如果你仅在本地模式下或在两三台桌子底下的计算机上运行 Dask，你可能可以跳过本节内容。⁹

Dask 的核心容错方法是重新计算丢失的数据。这是许多现代数据并行系统选择的方法，因为故障并不是很常见，因此使没有故障的情况下快速恢复是首要任务。¹⁰

考虑 Dask 的容错性时，重要的是考虑 Dask 连接到的各个组件的故障条件可能性。虽然重新计算是分布式计算的一种良好方法，但分布式存储有不同的权衡。

Dask 对于在失败后重新计算的方法意味着用于计算的数据仍然存在以便需要时重新加载。在大多数系统中，这将是情况，但在某些流式系统中，您可能需要配置更长的 TTL 或者在顶部有一个缓冲区，以提供 Dask 所需的可靠性。另外，如果您正在部署自己的存储层（例如 MinIO），重要的是以一种方式部署它，以最小化数据丢失。

Dask 的容错性不包括领导节点。解决这个问题的部分方案通常称为高可用性，即 Dask 外部的系统监控并重启您的 Dask 领导节点。

在缩减规模时常常也会使用容错技术，因为容错和缩减规模都涉及节点的丢失。

# 可伸缩性（上升和下降）

可伸缩性指的是分布式系统处理更大问题并在需要减少时（例如研究生睡觉后）缩小的能力。在计算机科学中，我们通常将可伸缩性分类为*水平*或*垂直*。水平扩展是指添加更多计算机，而垂直扩展是指使用更大的计算机。

另一个重要的考虑因素是自动扩展与手动扩展。在自动扩展中，执行引擎（在我们的情况下是 Dask）将为我们扩展资源。Dask 的自动扩展器将通过在需要时添加工作节点来进行水平扩展（前提是部署支持）。要进行垂直扩展，您可以向 Dask 的自动扩展器添加较大的实例类型，并在作业中请求这些资源。

###### 注意

从某种意义上说，Dask 的任务“窃取”可以看作是一种自动垂直扩展的形式。如果一个节点无法（或特别慢）处理一个任务，那么另一个 Dask 工作节点可以“窃取”这个任务。在实践中，除非您安排了一个请求这些资源的任务，否则自动扩展器不会分配更高资源节点。

# 缓存、内存、磁盘和网络：性能变化的影响

Dask 作业通常数据密集，将数据传输到 CPU（或 GPU）对性能影响很大。CPU 缓存通常比从内存读取快一个数量级以上。从 SSD 读取数据大约比从内存慢 4 倍，在数据中心内部发送数据可能慢约 10 倍。¹¹ CPU 缓存通常只能包含几个元素。

将数据从 RAM（甚至更糟的是从磁盘/网络）转移可能导致 CPU 停顿或无法执行任何有用的工作。这使得链式操作尤为重要。

[计算机速度很快网站](https://oreil.ly/Iyzds) 通过真实代码很好地说明了这些性能影响。

# 哈希

哈希算法不仅在 Dask 中很重要，在计算机科学中也是如此。Dask 使用哈希算法将复杂的数据类型转换为整数，以便将数据分配给正确的分区。哈希通常是一个“单向”的操作，它将较大的键空间嵌入到较小的键空间中。对于许多操作，比如将数据分配给正确的分区，你希望哈希算法快速执行。然而，对于像假名化和密码这样的任务，你故意选择较慢的哈希算法，并经常增加更多迭代次数，以使其难以逆转。选择正确的哈希算法以匹配你的目的非常重要，因为不同的行为可能在一个用例中是一个特性，但在另一个用例中是一个错误。

# 数据局部性

对于简单的计算，数据传输成本可能会迅速超过数据计算成本。在可能的情况下，在已经具有数据的节点上安排任务通常会快得多，因为任务必须在某处安排（例如，无论如何都要支付复制任务的网络成本），但如果将任务放在正确的位置，则可以避免移动数据。网络复制通常也比磁盘慢。

在 `client.submit` 中，Dask 允许你指定一个期望的工作节点，通过 `workers=`。此外，如果你有数据将在各处访问，而不是进行常规的 scatter，你可以通过添加 `broadcast=True` 来广播它，以便所有工作节点都有集合的完整副本。

# 一次性执行与至少一次执行

在大多数软件开发中，“一次性执行”这个概念是如此的普遍，以至于我们甚至不将其视为一个要求。例如，对银行账户的重复应用借记或贷记可能会是灾难性的。在 Dask 中实现一次性执行需要使用外部系统，因为 Dask 的容错方法。一个常见的方法是使用数据库（分布式或非分布式）以及事务来确保一次性执行。

并非所有的分布式系统都有这个挑战。输入和输出受控制，并通过冗余写入实现容错的系统在执行上一次时更容易。一些使用失败后重新计算的系统仍能通过集成分布式锁提供一次性执行。

# 结论

分布式系统很有趣，但正如你从分布式系统的概念中看到的那样，它们增加了大量的开销。如果你不需要分布式系统，那么在本地模式下使用 Dask 并使用本地数据存储可以极大地简化你的生活。无论你选择本地模式还是分布式模式，对一般系统概念的了解都将帮助你构建更好的 Dask 流水线。

¹ 这可以包括创建数据库，填充数据，启动集群服务等。

² 我们不建议在新环境中使用 TFX，因为可能很难启动。

³ 我们承认社会通常不是这样构建的。

⁴ 这不是数据库最常见的容错方式，但一些常见数据库的默认配置可能导致这种情况。

⁵ *间接*在这里意味着在两个函数之间;例如，“A 调用 B，B 调用 A”是共递归的一个例子。

⁶ 一部经典的[XKCD 漫画](https://oreil.ly/9zAmg)出人意料地接近捕捉我们在 Git 早期经历中的经验。

⁷ 利益冲突披露：Holden 已从 LakeFS 项目获得 T 恤衫和贴纸。一些替代方案包括专注于 Iceberg 表的 Nessie 项目。

⁸ 例如，同一个节点上的两个 ML 任务可能都会尝试使用所有的 CPU 资源。

⁹ 我们在这里选择了三个，因为没有驱动程序的工作节点失败的概率仅为驱动程序的两倍（我们无法恢复），并且随着添加更多机器，这种比例呈线性增长。

¹⁰ 您可以缓存中间步骤以减少重新计算的成本，但前提是缓存位置未失败，并且需要清理任何缓存。

¹¹ 精确的性能数字取决于您的硬件。
