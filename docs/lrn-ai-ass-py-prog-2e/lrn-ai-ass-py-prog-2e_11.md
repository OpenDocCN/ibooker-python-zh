# 第十二章：12 未来发展方向

### 本章内容包括

+   使用提示模式编写和解释代码

+   生成式 AI 工具的当前局限性与未来发展方向

在本章的最后，我们想给你一个 glimpse（瞥见）目前人们使用生成式 AI 工具（如 GitHub Copilot 和 ChatGPT）的一些创造性方法的机会。例如，现在可以让 Copilot Chat 问你问题，而不是你去问它。而且，可以让 Copilot 采取不同的人物角色，以便更好地帮助你完成当前的编程任务。我们会简短地介绍这些内容，虽然目前还不清楚其中有多少会成为标准实践，但我们希望借此机会展示如何通过创造性地使用这些新工具来发挥它们的强大功能。我们还将讨论生成式 AI 工具的当前局限性（你已经在本书中看到过其中的一些！），并提出我们对未来的看法。

## 12.1 提示模式

在本书中，我们传达了为什么直接用 Python 编程与使用 Copilot 编程是非常不同的体验。我们的重点不再是编写代码，而是编写提示语，并与生成的代码进行交互，以确定其是否正确，然后在需要时进行修正。但与这些差异相伴的，还有一些令人惊讶的相似之处，既有不使用 Copilot 时的编程方式，也有使用 Copilot 时的编程方式。

当程序员编写代码时，他们并不是每次编写新程序时都从零开始。研究人员和程序员们创建了设计的*模式*，即组织程序的通用方法，使得编写、调试和扩展程序变得更加容易。最著名的这种模式目录是一本名为《*设计模式：可重用面向对象软件的元素*》的书[1]，也被称为“四人帮书”，因为它是由四位作者共同编写的。它要求熟悉面向对象编程，而我们在本书中并未教授这一内容，因此我们不建议你现在就去读这本书。只要知道，成千上万的程序员通过使用这本书中的模式，节省了成千上万个小时的时间，而不是重复发明轮子。

作为设计模式的一个例子，假设你正在编写一个电脑游戏，其中玩家与计算机对战。你希望实现多个具有不同难度（例如：初级、中级、高级和专家级）的 AI 对手，为人类玩家提供不同的对战技能水平。每个 AI 对手将拥有自己的代码来决定其行为。可以使用`if`条件来确定 AI 对手应该做什么：

```py
if ai_opponent == 'beginner':
    # make decision consistent with beginner AI opponent
elif ai_opponent == 'intermediate':
    # make decision consistent with intermediate AI opponent
…
```

然而，这种方式的缺点是组织上的。我们会将所有 AI 对手的 AI 代码放在同一个地方。从本书所学，我们知道像这样的庞大函数并不容易设计和测试。

组织这种程序的简洁方式是使用一种名为*策略模式*的模式。我们在这里不会详细讨论该模式，但重要的是，人们已经为他人记录了这一模式[1]。该模式的文档告诉你它的意图（目的）、使用它的动机、实现它所需的代码结构以及示例代码。

研究人员开始对可以与生成式人工智能工具（如 GitHub Copilot 和 ChatGPT）一起使用的模式进行编目[2]。这些模式被称为*提示模式*，类似于设计模式，它们告诉你如何构建提示，以实现期望的目标。每个模式的文档类似于设计模式的文档，但与示例代码不同，我们得到的是可以使用的示例提示。

在本书中，我们大部分时间集中在两种类型的 AI 回应：生成代码（通过在 VS Code 中按 Tab 键）和解释代码（通过使用 Copilot Chat）。正在出现的新提示模式可以帮助生成式 AI 工具超越这些，协助其他与代码相关的任务。

为了让你了解提示模式的最新进展，我们将在这里展示其中一些样本。更多的模式，请参考我们所使用的提示模式目录[2]。不过要注意，我们推荐的是一篇学术论文，而不是初学者指南，因为目前我们没有看到任何初学者指南（这仍然是新兴的内容）。

##### Copilot Chat 可能不会参与这些提示模式

在撰写本文时，Copilot Chat 拒绝参与一些已编目的提示模式，声称它们与编程辅助无关。虽然其中一些可能与编程的关系不那么具体，但它们都旨在帮助程序员。与 ChatGPT 不同，Copilot 被设计成尽量始终专注于编程主题。如果你决定进一步探索这些多样的模式，可能希望在与 Copilot 的互动不太有效时，使用 ChatGPT 进行尝试。

### 12.1.1 翻转互动模式

到目前为止，我们一直是请求代码并提问，而 Copilot 则是回答。但有可能翻转剧本，让 Copilot 来提问，我们来回答。这被称为*翻转互动模式*。

这个模式的目的是帮助我们与人工智能互动，尤其是在我们不知道它需要什么信息来执行任务时。其动机是，人工智能可能比我们提供不完整或无效信息时，知道应该向我们提问什么，以便更快速地达到目标。我们的提示结构将如下所示：

我希望你向我提问，以实现 X。你应该继续提问，直到我们实现这个目标，其中 X 是我们希望实现的目标。

这个结构并不是为了精确规定我们应该使用的提示词。相反，它提醒我们需要在提示中传达的关键想法。例如，这里的关键想法是我们希望 Copilot 提问，并且希望它在我们达成目标之前不要停止。

在第三章中，我们编写了一个函数，不断要求用户输入密码，直到他们输入一个强密码。假设我们不确定如何设计这个函数。我们可以请求 Copilot 为我们设计它，通过提供代码提示，但那样可能会做出我们不同意的决定。相反，我们可以让 Copilot 问我们问题。我们来使用 Copilot Chat 来实现这一点。

LPHuman 我希望有一个 Python 函数，不断要求用户输入密码，直到他们提供一个强密码。请每次问我一个问题，直到你能编写出这个 Python 函数。

![chatGpt](img/chatGpt.png)GitHub Copilot 当然，我很乐意帮助你编写一个 Python 函数，不断要求用户输入强密码！以下是一些问题，供你开始：

1.  你认为什么是强密码？

1.  这个函数应该有任何输入参数吗？

1.  这个函数应该返回什么？

1.  这个函数应该有任何副作用，比如向控制台打印信息吗？

1.  这个函数应该有任何错误处理机制吗，比如处理来自用户的无效输入？

Copilot 没有按照我们的指示“每次问我一个问题”来操作。我们来提醒它一下。

LPHuman 每次问我一个问题。

![chatGpt](img/chatGpt.png)GitHub Copilot 好的，让我们从第一个问题开始：

1.  你认为什么是强密码？

现在我们可以开始回答问题了。Copilot 将根据这些答案为我们编写代码。

LPHuman 密码必须至少包含一个大写字母、一个数字和一个标点符号。

![chatGpt](img/chatGpt.png)GitHub Copilot 太好了，感谢你告诉我！这是下一个问题：

1.  2\. 这个函数应该有任何输入参数吗？

LPHuman 我不知道。它们会被用来做什么？

![chatGpt](img/chatGpt.png)GitHub Copilot 输入参数用于将数据传递到函数中，以便函数对这些数据执行某些操作。例如，如果我们想编写一个将两个数字相加的函数，我们需要将这两个数字作为输入参数传递给函数。

在我们的密码函数中，我们可能希望传入一些参数来定义强密码的要求。例如，我们可能希望传入密码的最小长度、要求的大写字母数量、要求的数字数量以及要求的标点符号数量。

或者，我们也可以将这些要求硬编码到函数中，但使用输入参数会使函数更加灵活和可重用。

LPHumanPlease 硬编码它们。

![chatGpt](img/chatGpt.png)GitHub Copilot 当然，我们可以将密码要求硬编码到函数本身。接下来是下一个问题：

1.  3\. 该函数应该返回什么？

LPHuman 它应该返回用户的强密码。

![chatGpt](img/chatGpt.png)GitHub Copilot 太好了，谢谢你告诉我！接下来是下一个问题：

1.  4\. 该函数是否应该有副作用，例如向控制台打印消息？

我们到此为止，因为我们认为阅读完整的交互过程并不有趣。我们继续与 Copilot 对话并回答了问题 4 和 5，Copilot 获取了所需的信息，能够编写我们想要的代码。最终我们收到的代码，在回答完所有五个问题后，显示在以下列表中。

##### 列表 12.1 通过反转交互模式设计的函数

```py
import string

def get_strong_password():
    '''
    Keep asking the user to enter a password until they provide 
    a strong password.
    A strong password has at least one uppercase character, one 
    number, and one punctuation character.
    '''
    # Print the password requirements
    print("Your password must contain at least:")
    print("- One uppercase letter")
    print("- One number")
    print("- One punctuation character")

    # Keep asking for a password until a strong one is provided
    while True:                                          #1
        password = input("Enter a password: ")

        # Check if the password meets the requirements
        if not any(c.isupper() for c in password):        #2
            print("Password does not contain an uppercase letter.")
        elif not any(c.isdigit() for c in password):        #3
            print("Password does not contain a number.")
        elif not any(c in string.punctuation      #4
                     for c in password):          #4
            print("Password does not contain a punctuation character.") #4
        else: #4
            print("Password is strong!") #4
            return password                     #5
```

#1 这个 True 条件永远无法变为 False！

#2 如果密码中没有大写字母

#3 如果密码中没有数字字符

#4 如果密码中没有标点符号

#5 这就是我们退出“while True”循环的方法。

在我们到目前为止的`while`循环中，我们总是使用一个我们希望最终变为`False`的循环条件（否则我们将遇到无限循环）。例如，我们可以想象有一个循环，实际上是“当密码无效时”。但在这里，代码使用的是`while True`，而`True`是一个永远不会变为`False`的条件。必须有其他方式可以退出循环——确实有！当密码有效时，我们通过`return`语句退出循环。也就是说，这里的逻辑是“循环永远进行；如果密码有效，则停止循环。”`while True`形式的`while`循环是我们在本书中看到的一种常见替代结构。

这段代码很好地实现了我们的任务。它首先通过一些`print`调用告诉用户强密码的规则。如果密码不够强，它还会告诉用户密码的错误之处。它会一直循环，直到用户输入一个强密码。当用户最终输入强密码时，我们就返回它。

现在，鉴于我们在第三章中的工作，我们已经知道如何编写这个函数。到目前为止，你的 Python 知识已经足够强大，你可以直接切入正题，写出函数签名，让 Copilot 按照我们在本书中一直做的方式编写代码。但对于一些你不太熟悉的任务，并且可能不知道从哪里开始的情况，这种反转交互模式可能会有所帮助。

### 12.1.2 人物模式

这种模式的目的是让 AI 扮演特定的角色或观点。为什么我们会有动机这么做呢？举个例子：假设你是一个初学 Python 编程课程的学生。你的老师在课程中使用 Copilot，但他们禁止了一些他们认为会影响学习初级 Python 的 Python 功能。你可以要求 Copilot 扮演这位教师的角色，然后帮助你检查代码，找出并在必要时移除任何不允许使用的 Python 功能。我们提示的结构看起来会是这样的：

从现在开始，扮演角色 X。提供角色 X 会创建的输出。

我们将用一个特定的人物角色来填充 X。让我们尝试使用我们介绍性编程教师的角色。我们将要求 Copilot 扮演这个角色，同时禁止一些更高级的 Python 概念。（即使你从未听说过这些概念，也不用担心！）

LPHuman 从现在开始，扮演一名初级 Python 编程课程的教师。在你教授的课程中，以下 Python 特性是不允许的：列表推导式、生成器、`lambda` 以及 `any` 函数。我将提供代码，你将检查这些代码，找出任何不允许使用的 Python 功能，并建议如何重写代码以不使用这些功能。

![chatGpt](img/chatGpt.png)GitHub Copilot 好的，我可以做到！请提供你希望我审查的代码。

让我们输入上一节的 `get_strong_password` 函数。它使用了 `any` 函数，而根据我们的角色规则，这个函数是不允许的。以下是我们原始的代码和 Copilot 做出的响应。

**LPHuman**

```py
*`*def get_strong_password():*`*
 *`*'''*`*
 *`*Keep asking the user to enter a password until they provide*`* 
 *`*a strong password.*`*
 *`*A strong password has at least one uppercase character, one*`* 
 *`*number, and one punctuation character.*`*
 *`*'''*`*
 *`*# Print the password requirements*`*
 *`*print("Your password must contain at least:")*`*
 *`*print("- One uppercase letter")*`*
 *`*print("- One number")*`*
 *`*print("- One punctuation character")*`*

 *`*# Keep asking for a password until a strong one is provided*`*
 *`*while True:*`*
 *`*password = input("Enter a password: ")*`*

 *`*# Check if the password meets the requirements*`*
 *`*if not any(c.isupper() for c in password):*`*
 *`*print("Password does not contain an uppercase letter.")*`*
 *`*elif not any(c.isdigit() for c in password):*`*
 *`*print("Password does not contain a number.")*`*
 *`*elif not any(c in string.punctuation for c in password):*`*
 *`*print("Password does not contain a punctuation character.")*`*
 *`*else:*`*
 *`*print("Password is strong!")*`*
 *`*return password*`*
```

![chatGpt](img/chatGpt.png)GitHub Copilot `get_strong_password` 函数使用了 `any` 函数，而你的课程中不允许使用该函数。以下是一个不使用 `any` 函数的修改版本：

```py
*`*import string*`*

*`*def get_strong_password():*`*
 *`*'''*`*
 *`*Keep asking the user to enter a password until they provide*`*
 *`*a strong password.*`*
 *`*A strong password has at least one uppercase character, one*`* 
 *`*number, and one punctuation character.*`*
 *`*'''*`*
 *`*# Print the password requirements*`*
 *`*print("Your password must contain at least:")*`*
 *`*print("- One uppercase letter")*`*
 *`*print("- One number")*`*
 *`*print("- One punctuation character")*`*

 *`*# Keep asking for a password until a strong one is provided*`*
 *`*while True:*`*
 *`*password = input("Enter a password: ")*`*

 *`*# Check if the password meets the requirements*`*
 *`*has_uppercase = False*`*
 *`*has_number = False*`*
 *`*has_punctuation = False*`*
 *for c in password:* #1
 *`*if c.isupper():*`*
 *`*has_uppercase = True*`*
 *`*elif c.isdigit():*`*
 *`*has_number = True*`*
 *`*elif c in string.punctuation:*`*
 *`*has_punctuation = True*`*
 *`*if not has_uppercase:*`*
 *`*print("Password does not contain an uppercase letter.")*`*
 *`*elif not has_number:*`*
 *`*print("Password does not contain a number.")*`*
 *`*elif not has_punctuation:*`*
 *`*print("Password does not contain a punctuation character.")*`*
 *`*else:*`*
 *`*print("Password is strong!")*`*
 *`*return password*`*
```

#1 替换“any”的循环

这个版本的函数使用 `for` 循环遍历密码中的每个字符，检查它是否符合要求。这个方法比使用 `any` 函数更冗长，但它没有使用被禁止的 Python 功能。

正如 Copilot Chat 所指出的，这个程序没有使用 `any` 函数。Copilot 已经重写了程序，避免了使用该函数，从而遵守了我们 Python 编程角色设定的规则。

`any` 函数会返回 `True`，如果它的参数中有一个或多个值为真；如果所有的值都为假，则返回 `False`。在幕后，`any` 必须查看每个值以检查它是对还是错。这听起来像是一个循环，对吧？事实上，Copilot 正是用循环来替代 `any` 函数调用的。

## 12.2 限制与未来方向

在我们与 Copilot（以及学生）合作的经验中，并阅读了在我们编写本书期间发布的研究文献时，我们观察到了一些生成式 AI 模型的局限性和未来可能性，我们希望分享这些观察。

### 12.2.1 Copilot（当前）面临的挑战

我们发现 Copilot 在三种不同的场景中遇到了困难：人为设计的问题、不明确的问题和大型任务。

#### 人为设计的问题

在 ChatGPT 和 GitHub Copilot 横扫全球后不久，编程教师们疯狂地寻找这些工具无法做好的任务类型。一项早期提议是使用人为设计的任务：通过使任务变得模糊和复杂，试图引导像 Copilot 这样的工具生成错误的代码。对我们来说，这些任务完全没有趣味，并且对学生不公平，它们的使用似乎是在试图坚持之前的编程课程风格，而没有意识到像 Copilot 这样的工具所带来的颠覆性变化。我们的感觉是，随着 Copilot 模型的不断改进，这些人为设计的任务最终会被 Copilot 解决，但即使没有解决，这些问题通常也不是必须要解决的。

#### 不明确的问题

一个不明确的问题是指一个没有被精确描述的问题，这意味着我们并不完全知道或尚未决定在所有情况下应该做什么。例如，要求 Copilot 编写一个函数来判断密码是否强大，这就是一个不明确的问题，直到我们定义“强密码”是什么意思为止。你可能首先认为 Copilot 不可能在解决这类问题上变得更好。毕竟，如果我们很难精确定义我们想要的行为，怎么能把所需的行为传达给 Copilot 呢？不明确的问题对于 Copilot 确实是一个挑战，但并不是不可能解决的。还记得我们在本章早些时候讨论的反转交互提示模式吗？也许，不久的将来，当 Copilot 没有足够的精确信息来解决问题时，它会自动切换到这种模式。

#### 大型任务

本书中我们花了很多时间教你如何设计小功能，以及如何通过自顶向下的设计将这些功能组织起来，以解决大型问题。我们这么做是因为当面对一个整体性的任务时，Copilot 很难解决。这个问题是类似 Copilot 的工具固有的局限性，还是人工智能能够克服它？我们不知道。现在，Copilot 在问题分解方面很挣扎，即便它能够做到这一点，概率也不在它的一边。具体来说，它写代码越多，出错的概率就越高。例如，如果它需要写 20 个函数来解决一个任务，每个函数平均 10 行代码，它几乎肯定会在某个地方出错。但与这些系统对抗也是愚蠢的。随着 Copilot 学习方式的进步，也许这一点并不遥远。

### 12.2.2 Copilot 是一种新的编程语言吗？

当我们用像 Python 这样的语言编写计算机代码时，背后有一个编译器将 Python 代码转换为计算机能够理解的汇编代码或机器代码。曾经有一段时间，程序员用像 Fortran 或 C 这样的旧计算机语言编写代码，运行编译器生成汇编语言代码，然后检查汇编代码确保它是正确的。那时候我们还没出现过，可能也不会发生太多这样的情况，但我们能理解为什么当时程序员不信任编译器。编译器是一项新技术，而且需要时间来解决其中的错误。此外，编译器输出的代码相对于手写的汇编代码来说，可能效率较低。但经过几十年的改进，无论是在正确性还是效率方面（编译器优化对于任何好奇的人来说都是一个非常激动人心和有趣的主题！），现在很少有程序员会查看编译器的输出。是否可能会有这样的一天，人类只是将大型语言模型（LLMs）作为与计算机交互的主要接口，而不花太多时间检查它们生成的代码？让我们考虑一下这个问题的两种可能答案。

#### 为什么 LLMs 可能不会取代编程语言

有理由认为 LLMs 不会成为人类编程计算机的主要接口。最主要的原因是，LLMs 不是一种严格的编程语言。我们信任编译器，因为每种编程语言都有其语言规范，并且每行代码都有指定的、精确的预期行为。而 LLMs 并没有这些。它只是有人用英语或其他自然语言向 LLMs 输入内容。LLMs 并不一定按照某种特定的方式来解释自然语言。它不需要基于任何严格的规范输出答案。而且，由于随机性和非确定性，它给出的答案可能会有所不同或错误！编译器是确定性的，而且现在已经是一个成熟、值得信赖的技术。它们没有这些问题。

#### 为什么 LLMs 可能会取代编程语言

也有理由相信，像编译器一样，大型语言模型（LLMs）将变得更好，并成为我们主要的编程接口。事实上，在数据科学领域，这已经开始发生了。

正如我们在本书中所学到的，与 Copilot 合作的一个关键挑战是判断生成的代码是否正确。从某种意义上说，这对非程序员是不公平的：我们给 Copilot 提供自然语言（我们的偏好），而它给我们回馈的代码却不是自然语言（计算机的偏好）。如果我们可以“跳过代码”，不仅用自然语言与 Copilot 沟通，还能直接得到我们的答案，那就太好了。

研究人员开始在计算机用户关注的受限领域探索这一可能性。举个例子，考虑数据科学。数据科学家通过探索数据、可视化数据以及利用数据进行预测来理解数据。他们所做的许多工作涉及以受限且广为人知的方式操作数据，例如合并电子表格、清理特定数据列，或进行聚类分析将数据划分为有意义的类别，或者简化数据以专注于其核心结构。使用 Python 的数据显示科学家通常会使用许多库来处理数据，但一个极为流行的库叫做 pandas。

研究人员成功地在使用 pandas 进行数据科学的过程中“跳过了代码”[3]。它是如何运作的呢：

1.  用户用自然语言表达他们的意图，例如英语。

1.  AI 生成 Python 代码并运行它，获取用户的结果（例如，分析结果表或新的电子表格）。重要的是，用户看不到这些 Python 代码。

1.  AI 将代码转换回自然语言，并将其（而不是 Python 代码！）呈现给用户。用户收到的自然语言是以一致的格式呈现的，AI 可以可靠地理解。研究人员这样描述 AI 回应的目的：“这就是你应该告诉系统做你刚才要求它做的事情的方式。” 这个回应帮助用户理解 AI 的能力以及哪些查询是有效的。

1.  如果自然语言从第三步返回的内容不正确，用户可以进行编辑。如果用户做出修改，他们可以提交新的提示，从而重复整个周期。

研究人员提供的一个例子阐明了这个过程[3]。假设我们有一份每行代表一个宇航员的电子表格。每一行有三列相关数据：宇航员的名字、他们在太空的总时长以及他们参与的任务的逗号分隔列表。我们想要计算每个宇航员的平均任务时长。

在第一步中，用户写下类似“计算平均任务时长”的提示。在第二步中，AI 生成与该提示相对应的代码。它运行该代码，并将包含平均任务时长的新列添加到用户的电子表格中。在第三步中，AI 将代码转换为自然语言的任务列表，如下所示：

1.  创建列“任务时长”。

1.  列“太空飞行（小时）”除以（列“任务”中的逗号数 + 1）。

在第 4 步中，用户可以编辑第 3 步中的自然语言，并将更新后的任务重新提交给 AI。我们是否能够在更广泛的“Python 编程”领域中“跳过代码”，而不是局限于“使用 pandas 进行数据科学”的更狭窄场景呢？现在还为时过早。数据处理的优势在于它能够以可视化的方式呈现，通过电子表格和图表直接展示给用户，用户可能能判断分析是否正确，或者是否需要进一步的提示工程。这样的可视化表示对于通用编程而言并不容易显现。

尽管如此，我们仍然能想象一个新时代，在这个时代里，人类继续执行重要任务，如问题分解、指定程序行为、编写测试、设计算法等等，而程序的编写完全由 LLM 来完成。人类向 AI 工具说明程序需要做什么，并提供测试用例，AI 则生成代码。然后，人类可以检查程序是否正常工作，而无需查看代码。

关于 LLM 是否会取代编程语言的另一种看法，我们推荐由编程和编译专家 Chris Lattner 所写的博客文章[4]。Lattner 认为，至少在短期内，甚至可能更长时间内，编程语言不会消失，因为 LLM 生成的代码可能会存在细微的错误。所以，如果编程语言在一段时间内还会存在，那么问题就变成了：我们应该使用哪种编程语言？Lattner 表示：“最适合 LLM 的语言是那种对人类来说易于使用和阅读，但其实现能够扩展到许多不同的用例和应用场景的语言”[4]。现有的语言能达到这一目标吗？我们能否通过设计一种比 Python 更易读的编程语言来做得更好？敬请期待！

好吧，也许编程语言会消失，也许它们不会消失；也许它们会改变。不管怎样，我们是否需要担心程序员的工作？我们认为不需要。任何在软件公司工作过的人都会告诉你，编写代码并不是程序员用来打发时间的唯一，甚至是主要的工作。程序员还需要与客户会面，确定他们的需求。他们会指定程序的功能以及它们如何协同工作。他们检查系统的性能和安全问题。他们与其他团队合作，协调设计大型软件项目。如果编写代码的步骤变得更简单，也许我们只是得到了更有用的软件。这就像我们当初拥有了高级语言一样。没人会用汇编语言来编写下一个杀手级应用程序！编译器提高了我们制作软件的效率。我们认为，LLM 如果被谨慎使用，也能达到这一目标。

#### 激动人心的未来

尽管我们对未来仍然有些不确定，但显然 LLM 将会极大地改变编程的未来。也许现在它们只是帮助软件工程师编写更好代码的辅助工具。然而，或许五年后，大多数软件将由 LLM 编写，只有一小部分软件工程师会从零开始编写代码。无论哪种结果最终成真，变化正在迅速到来，它们可能会让更多人能够编写符合自己需求的软件。

截至目前，我们已经对这些工具的使用方式有了一些见解。在一项调查中，92%的软件开发人员报告称定期使用这些工具[5]。最近的研究发现，使用这些工具的开发人员比没有使用工具时更具生产力[6]。在一项特别有趣的研究中，UC 圣地亚哥的研究人员发现，专业开发人员使用这些工具有两种方式：加速和探索[7]。在加速阶段，开发人员使用这些工具来帮助他们比自己手写代码更快地生成代码。在探索阶段，开发人员使用这些工具来帮助他们找到可能有用的库，或者理解现有的代码库。这些发现与我们在本书中所学的一致，我们期待未来的研究。

最重要的是，我们希望你现在能够做出自己的、明智的决定，关于如何使用 LLM（大语言模型）进行编程，以及 LLM 可能对编程的未来意味着什么。在这样的时刻，一些人热烈宣称：“编程已经结束！”而另一些人则同样热烈地宣称：“编程几乎不会发生太大变化！”[8]，对我们来说，能够自己权衡这些论点以及这种变化如何影响我们和其他人非常重要。这些工具能帮助我们吗？我们认为可以。因此，我们应该使用它们，但要负责任地使用它们。有担忧吗？同样，我们认为是有的，正如我们在书中所讨论的。我们应该采取措施，如测试和调试，来减轻这些担忧。

本书中我们采用的编程教学方法是全新的。像我们这样的教师和教授才刚刚开始将类似 Copilot 的工具纳入编程课程[9]，尽管我们仍在努力平衡何时让学习者使用 Copilot 以及何时不使用这些工具。无论程序员选择什么样的方式来学习编程，我们都希望强调你已经学到了每个人在编写优秀软件时都需要掌握的至关重要的技能，无论你是在工作中偶尔编写代码以自动化繁琐的任务，还是计划成为一名专业的软件工程师。你已经打下了坚实的基础，无论你的道路将带你走向何方。

## 12.3 练习

1.  解释如何使用**人物角色模式**来强制执行公司的编码标准。例如，公司可能要求员工始终使用驼峰命名法（例如：xVal，ZValOut）。提供一个示例提示，说明如何让 GitHub Copilot 充当管理者来执行特定的编码标准。

1.  你需要创建一个 Python 函数，根据用户的首选用户名和全名来生成一个用户名。该函数应遵循以下规则：

    1.  如果首选用户名可用（即尚未被占用），则使用该用户名。

    1.  如果首选用户名已被占用，通过在用户名后附加一个数字（例如 1、2、3……）生成一个新的用户名。

    1.  如果生成的用户名已被占用，使用用户的全名，通过组合其名字和姓氏的一部分来生成用户名。

    1.  如果生成的用户名已被占用，函数应继续请求新的首选用户名。

你会使用哪种交互模式（**反转交互模式**或**人物角色模式**）来设计这个函数，并借助 GitHub Copilot？请说明你的选择，并概述你如何开始这个交互。

## 摘要

+   提示模式是一个模板，帮助我们构建一个能够实现特定目标的提示。

+   **反转交互模式**（flipped interaction pattern）改变了规则：与其向 LLM 提问，不如让 LLM 向我们提问。

+   **反转交互模式**在我们不知道如何有效地向 LLM 提出提示时非常有用。

+   **人物角色模式**用于让 AI 扮演特定的人物角色，例如“初级编程讲师”或某个特定的视角。

+   当我们希望大型语言模型（LLM）从某个特定角度进行回应时，**人物角色模式**（persona pattern）非常有用。

+   Copilot 当前在处理那些人为设计、定义不清或规模较大的任务时表现较差。

+   有些人认为，LLM 将取代编程语言；而另一些人则认为编程语言将继续存在。

+   大型语言模型正在帮助人们完成数据科学任务，而这些人甚至没有接触到底层的编程语言代码。

+   可能编程语言本身不会被取代，但领先的编程语言将会发展得比今天的语言更具可读性。
