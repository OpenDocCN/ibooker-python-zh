<html><head></head><body><div id="sbo-rt-content" class="calibre2"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Matrix and Vector Computation" class="calibre3"><div class="preface" id="matrix_computation">
<h1 class="calibre23"><span class="publishername">Chapter 6. </span>Matrix and Vector Computation</h1>

<aside data-type="sidebar" epub:type="sidebar" class="calibre40"><div class="sidebar" id="idm46122422929336">
<h5 class="calibre41">Questions You’ll Be Able to Answer After This Chapter</h5>
<ul class="printings">
<li class="calibre21">
<p class="calibre42">What are the bottlenecks in vector calculations?</p>
</li>
<li class="calibre21">
<p class="calibre42">What tools can I use to see how efficiently the CPU is doing my calculations?</p>
</li>
<li class="calibre21">
<p class="calibre42">Why is <code class="calibre26">numpy</code> better at numerical calculations than pure Python?</p>
</li>
<li class="calibre21">
<p class="calibre42">What are <code class="calibre26">cache-miss</code>es and <code class="calibre26">page-fault</code>s?</p>
</li>
<li class="calibre21">
<p class="calibre42">How can I track the memory allocations in my code?</p>
</li>
</ul>
</div></aside>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="about" id="idm46122422921672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="about" id="idm46122422920632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Regardless of what problem you are trying to solve on a computer, you will
encounter vector computation at some point.  Vector calculations are integral to
how a computer works and how it tries to speed up runtimes of programs down at
the silicon level—the only thing the computer knows how to do is operate on
numbers, and knowing how to do several of those calculations at once will speed
up your program.</p>

<p class="author1">In this chapter we try to unwrap some of the complexities of this problem by
focusing on a relatively simple mathematical problem, solving the diffusion
equation, and understanding what is happening at the CPU level.  By
understanding how different Python code affects the CPU and how to effectively
probe these things, we can learn how to understand other problems as well.</p>

<p class="author1">We will start by introducing the problem and coming up with a quick solution
using <a data-type="indexterm" data-primary="pure Python mode" id="idm46122422917928" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>pure Python.  After identifying some memory issues and trying to fix them
using pure Python, we will introduce <a data-type="indexterm" data-primary="numpy" data-secondary="about" id="idm46122422916968" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">numpy</code> and identify how and why it
speeds up our code.  Then we will start doing some algorithmic changes and
specialize our code to solve the problem at hand.  By removing some of the
generality of the libraries we are using, we will yet again be able to gain more
speed.  Next, we introduce some extra modules that will help facilitate this
sort of process out in the field, and also explore a cautionary tale about
optimizing before profiling.</p>

<p class="author1">Finally, we’ll take a look at the Pandas library, which builds upon <code class="calibre26">numpy</code> by
taking columns of homogeneous data and storing them in a table of heterogeneous
types. Pandas has grown beyond using pure <code class="calibre26">numpy</code> types and now can mix its own
missing-data-aware types with <code class="calibre26">numpy</code> datatypes. While Pandas is incredibly
popular with scientific developers and data scientists, there’s a lot of
misinformation about ways to make it run quickly; we address some of these
issues and give you tips for writing performant and supportable analysis code.</p>






<section data-type="sect1" data-pdf-bookmark="Introduction to the Problem" class="calibre3"><div class="preface" id="matrix_intro">
<h1 class="calibre25">Introduction to the Problem</h1>

<p class="author1"><a data-type="indexterm" data-primary="diffusion equation" id="de_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="diffusion equation" id="mvc_de" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="diffusion equation" id="vmc_de" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>To explore matrix and vector computation in this chapter, we will
repeatedly use the example of diffusion in fluids.  Diffusion is one of the
mechanisms that moves fluids and tries to make them uniformly mixed.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">This section is meant to give a deeper understanding of the equations we will be
solving throughout the chapter.  It is not strictly necessary that you understand this
section in order to approach the rest of the chapter.  If you wish to skip this
section, make sure to at least look at the algorithm in Examples <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06_split_000.xhtml#matrix_algo1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-1</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch06_split_000.xhtml#matrix_algo2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-2</a> to understand the code we
will be optimizing.</p>

<p class="author1">On the other hand, if you read this section and want even more explanation, read
Chapter 17 of <a href="https://oreil.ly/sSz8s" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">Numerical Recipes</em></a>, 3rd Edition, by William Press et al.
(Cambridge University Press).</p>
</div>

<p class="author1">In this section we will explore the mathematics behind the diffusion equation.
This may seem complicated, but don’t worry!  We will quickly simplify this to
make it more understandable.  Also, it is important to note that while having a
basic understanding of the final equation we are solving will be useful while
reading this chapter, it is not completely necessary; the subsequent chapters
will focus mainly on various formulations of the code, not the equation.
However, having an understanding of the equations will help you gain intuition
about ways of optimizing your code.  This is true in general—understanding the
motivation behind your code and the intricacies of the algorithm will give you
deeper insight about possible methods of optimization.</p>

<p class="author1">One simple example of diffusion is dye in water: if you put several drops of dye
into water at room temperature, the dye will slowly move out until it fully mixes
with the water.  Since we are not stirring the water, nor is it warm enough to
create convection currents, diffusion will be the main process mixing the two
liquids.  When solving these equations numerically, we pick what we want the
initial condition to look like and are able to evolve the initial condition
forward in time to see what it will look like at a later time (see
<a data-type="xref" href="ch06_split_000.xhtml#matrix_diffusion_image" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-2</a>).</p>

<p class="author1">All this being said, the most important thing to know about diffusion for our
purposes is its formulation.  Stated as a partial differential equation in one
dimension (1D), the diffusion equation is written as follows:</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <mfrac><mi>∂</mi> <mrow><mi>∂</mi><mi>t</mi></mrow></mfrac>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mi>D</mi>
    <mo>·</mo>
    <mfrac><msup><mi>∂</mi> <mn>2</mn> </msup> <mrow><mi>∂</mi><msup><mi>x</mi> <mn>2</mn> </msup></mrow></mfrac>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
  </mrow>
</math>
</div>

<p class="author1">In this formulation, <code class="calibre26">u</code> is the vector representing the quantities we are
diffusing.  For example, we could have a vector with values of <code class="calibre26">0</code> where there
is only water, and of <code class="calibre26">1</code> where there is only dye (and values in between where there
is mixing).  In general, this will be a 2D or 3D matrix representing an actual
area or volume of fluid.  In this way, we could have <code class="calibre26">u</code> be a 3D matrix
representing the fluid in a glass, and instead of simply doing the second
derivative along the <code class="calibre26">x</code> direction, we’d have to take it over all axes.  In
addition, <code class="calibre26">D</code> is a physical value that represents properties of the fluid we are
simulating.  A large value of <code class="calibre26">D</code> represents a fluid that can diffuse very
easily.  For simplicity, we will set <code class="calibre26">D = 1</code> for our code but still include it
in the calculations.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">The diffusion equation is also called the <em class="hyperlink">heat equation</em>.  In this case, <code class="calibre26">u</code>
represents the temperature of a region, and <code class="calibre26">D</code> describes how well the material
conducts heat. Solving the equation tells us how the heat is being transferred.
So instead of solving for how a couple of drops of dye diffuse through water, we
might be solving for how the heat generated by a CPU diffuses into a heat sink.</p>
</div>

<p class="author1">What we will do is take the diffusion equation, which is continuous in space and
time, and approximate it using discrete volumes and discrete times.  We will do
so using <a data-type="indexterm" data-primary="Euler's approximation" id="idm46122422800392" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Euler’s method.  <em class="hyperlink">Euler’s method</em> simply takes the derivative and writes
it as a difference, such that</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <mfrac><mi>∂</mi> <mrow><mi>∂</mi><mi>t</mi></mrow></mfrac>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>≈</mo>
    <mfrac><mrow><mi>u</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>+</mo><mi>d</mi><mi>t</mi><mo>)</mo><mo>–</mo><mi>u</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow> <mrow><mi>d</mi><mi>t</mi></mrow></mfrac>
  </mrow>
</math>
</div>

<p class="author1">where <code class="calibre26">dt</code> is now a fixed number.  This fixed number represents the time step,
or the resolution in time for which we wish to solve this equation.  It can be
thought of as the frame rate of the movie we are trying to make.  As the frame
rate goes up (or <code class="calibre26">dt</code> goes down), we get a clearer picture of what happens.  In
fact, as <code class="calibre26">dt</code> approaches zero, Euler’s approximation becomes exact (note,
however, that this exactness can be achieved only theoretically, since there is
only finite precision on a computer and numerical errors will quickly dominate
any results).  We can thus rewrite this 
<span class="publishername">equation</span> to figure out what <code class="calibre26">u(x, t + dt)</code>
is, given <code class="calibre26">u(x,t)</code>.  What this means for us is that we can start with some
initial state (<code class="calibre26">u(x,0)</code>, representing the glass of water just as we add a drop
of dye into it) and churn through the mechanisms we’ve outlined to “evolve” that
initial state and see what it will look like at future times (<code class="calibre26">u(x,dt)</code>).  This
type of problem is called an<a data-type="indexterm" data-primary="initial value problem" id="idm46122422780584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cauchy problem" id="idm46122422779880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">initial value problem</em> or <em class="hyperlink">Cauchy problem</em>.
<a data-type="indexterm" data-primary="" data-startref="de_ab" id="idm46122422778216" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mvc_de" id="idm46122422777208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_de" id="idm46122422776264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
Doing a similar trick for the derivative in <code class="calibre26">x</code> using the finite differences
approximation, we arrive at the final equation:</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>+</mo>
      <mi>d</mi>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>+</mo>
    <mi>d</mi>
    <mi>t</mi>
    <mo>*</mo>
    <mi>D</mi>
    <mo>*</mo>
    <mfrac><mrow><mi>u</mi><mo>(</mo><mi>x</mi><mo>+</mo><mi>d</mi><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo><mo>+</mo><mi>u</mi><mo>(</mo><mi>x</mi><mo>–</mo><mi>d</mi><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo><mo>–</mo><mn>2</mn><mo>·</mo><mi>u</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow> <mrow><mi>d</mi><msup><mi>x</mi> <mn>2</mn> </msup></mrow></mfrac>
  </mrow>
</math>
</div>

<p class="author1">Here, similar to how <code class="calibre26">dt</code> represents the frame rate, <code class="calibre26">dx</code> represents the
resolution of the images—the smaller <code class="calibre26">dx</code> is, the smaller a region every cell
in our matrix represents.  For simplicity, we will set <code class="calibre26">D = 1</code> and <code class="calibre26">dx =
1</code>.  These two values become very important when doing proper physical
simulations; however, since we are solving the diffusion equation for
illustrative purposes, they are not important to us.</p>

<p class="author1">Using this equation, we can solve almost any diffusion problem.  However, there
are some considerations regarding this equation.  First, we said before that
the spatial index in <code class="calibre26">u</code> (i.e., the <code class="calibre26">x</code> parameter) will be represented as the
indices into a matrix.  What happens when we try to find the value at <code class="calibre26">x – dx</code>
when <code class="calibre26">x</code> is at the beginning of the matrix?  This problem is called the<a data-type="indexterm" data-primary="boundary conditions" id="idm46122422746104" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<em class="hyperlink">boundary condition</em>.  You can have fixed boundary conditions that say “any
value out of the bounds of my matrix will be set to <em class="hyperlink">0</em>” (or any other
value).  Alternatively, you can have periodic boundary conditions that say that
the values will wrap around. (That is, if one of the dimensions of your matrix has
length <code class="calibre26">N</code>, the value in that dimension at index <code class="calibre26">-1</code> is the same as at
<code class="calibre26">N – 1</code>, and the value at <code class="calibre26">N</code> is the same as at index <code class="calibre26">0</code>.  In other words,
if you are trying to access the value at index <code class="calibre26">i</code>, you will get the value at
index <code class="calibre26">(i%N)</code>.)</p>

<p class="author1">Another consideration is how we are going to store the multiple time components
of <code class="calibre26">u</code>.  We could have one matrix for every time value we do our calculation
for.  At minimum, it seems that we will need two matrices: one for the
current state of the fluid and one for the next state of the fluid.  As we’ll
see, there are very drastic performance considerations for this particular
question.</p>

<p class="author1">So what does it look like to solve this problem in practice?  <a data-type="xref" href="ch06_split_000.xhtml#matrix_algo1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-1</a>
contains some pseudocode to illustrate the way we can use our equation to solve
the problem.<a data-type="indexterm" data-primary="1D diffusion" id="idm46122422738536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="diffusion equation" data-secondary="1D diffusion" id="idm46122422737864" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="1D diffusion" data-primary-sortas="one" id="idm46122422736920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<div id="matrix_algo1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-1. </span>Pseudocode for 1D diffusion</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c"># Create the initial conditions</code>
<code class="n">u</code> <code class="o">=</code> <code class="n">vector</code> <code class="n">of</code> <code class="n">length</code> <code class="n">N</code>
<code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
    <code class="n">u</code> <code class="o">=</code> <code class="mi">0</code> <code class="kn">if</code> <code class="n">there</code> <code class="ow">is</code> <code class="n">water</code><code class="p">,</code> <code class="mi">1</code> <code class="kn">if</code> <code class="n">there</code> <code class="ow">is</code> <code class="n">dye</code>

<code class="c"># Evolve the initial conditions</code>
<code class="n">D</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">t</code> <code class="o">=</code> <code class="mi">0</code>
<code class="n">dt</code> <code class="o">=</code> <code class="mi">0.0001</code>
<code class="kn">while</code> <code class="nb">True</code><code class="p">:</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"Current time is: {t}"</code><code class="p">)</code>
    <code class="n">unew</code> <code class="o">=</code> <code class="n">vector</code> <code class="n">of</code> <code class="n">size</code> <code class="n">N</code>

    <code class="c"># Update step for every cell</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
        <code class="n">unew</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="n">dt</code> <code class="o">*</code> <code class="p">(</code><code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[(</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="o">%</code><code class="n">N</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">])</code>
    <code class="c"># Move the updated solution into u</code>
    <code class="n">u</code> <code class="o">=</code> <code class="n">unew</code>

    <code class="n">visualize</code><code class="p">(</code><code class="n">u</code><code class="p">)</code></pre></div>

<p class="author1">This code will take an initial condition of the dye in water and tell us what
the system looks like at every 0.0001-second interval in the future.  The
results can be seen in <a data-type="xref" href="ch06_split_000.xhtml#matrix_diffusion_1d_image" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-1</a>, where we evolve
our very concentrated drop of dye (represented by the top-hat function) into the
future.  We can see how, far into the future, the dye becomes well mixed, to the
point where everywhere has a similar concentration of the dye.</p>

<figure class="calibre46"><div id="matrix_diffusion_1d_image" class="figure">
<img src="Images/hpp2_0601.png" alt="Example of 1D diffusion" class="calibre81"/>
<h6 class="calibre47"><span class="publishername">Figure 6-1. </span>Example of 1D diffusion</h6>
</div></figure>

<p class="author1"><a data-type="indexterm" data-primary="2D diffusion" id="idm46122422645016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="diffusion equation" data-secondary="2D diffusion" id="idm46122422644312" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="2D diffusion" data-primary-sortas="two" id="idm46122422643368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>For the purposes of this chapter, we will be solving the 2D version of the
preceding equation.  All this means is that instead of operating over a vector
(or in other words, a matrix with one index), we will be operating over a 2D
matrix.  The only change to the equation (and thus to the subsequent code) is that
we must now also take the second derivative in the <code class="calibre26">y</code> direction.  This simply
means that the original equation we were working with becomes the following:</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <mfrac><mi>∂</mi> <mrow><mi>∂</mi><mi>t</mi></mrow></mfrac>
    <mi>u</mi>
    <mrow>
      <mo>(</mo>
      <mi>x</mi>
      <mo>,</mo>
      <mi>y</mi>
      <mo>,</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mi>D</mi>
    <mo>·</mo>
    <mfenced separators="" open="(" close=")">
      <mfrac><msup><mi>∂</mi> <mn>2</mn> </msup> <mrow><mi>∂</mi><msup><mi>x</mi> <mn>2</mn> </msup></mrow></mfrac>
      <mi>u</mi>
      <mrow>
        <mo>(</mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo>,</mo>
        <mi>t</mi>
        <mo>)</mo>
      </mrow>
      <mo>+</mo>
      <mfrac><msup><mi>∂</mi> <mn>2</mn> </msup> <mrow><mi>∂</mi><msup><mi>y</mi> <mn>2</mn> </msup></mrow></mfrac>
      <mi>u</mi>
      <mrow>
        <mo>(</mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo>,</mo>
        <mi>t</mi>
        <mo>)</mo>
      </mrow>
    </mfenced>
  </mrow>
</math>
</div>

<p class="author1">This numerical diffusion equation in 2D translates to the pseudocode in <a data-type="xref" href="ch06_split_000.xhtml#matrix_algo2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-2</a>, using the same methods we used
before.</p>
<div id="matrix_algo2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-2. </span>Algorithm for calculating 2D diffusion</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">N</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">M</code><code class="p">):</code>
        <code class="n">unew</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">dt</code> <code class="o">*</code> <code class="p">(</code>
            <code class="p">(</code><code class="n">u</code><code class="p">[(</code><code class="n">i</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">N</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[(</code><code class="n">i</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">N</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">])</code> <code class="o">+</code> <code class="c"># d^2 u / dx^2</code>
            <code class="p">(</code><code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">M</code><code class="p">]</code> <code class="o">+</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">M</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">u</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">])</code>   <code class="c"># d^2 u / dy^2</code>
        <code class="p">)</code></pre></div>

<p class="author1">We can now put all of this together and write the full Python 2D diffusion code
that we will use as the basis for our benchmarks for the rest of this chapter.
While the code looks more complicated, the results are similar to that of the 1D
diffusion (as can be seen in <a data-type="xref" href="ch06_split_000.xhtml#matrix_diffusion_image" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-2</a>).</p>

<p class="author1">If you’d like to do some additional reading on the topics in this section, check
out the <a href="http://bit.ly/diffusion_eq" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Wikipedia page on the diffusion equation</a> and
<a href="http://bit.ly/Gurevich" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a> of <em class="hyperlink">Numerical Methods for Complex Systems</em> by
S. V. Gurevich.</p>

<figure class="calibre46"><div id="matrix_diffusion_image" class="figure">
<img src="Images/hpp2_0602.png" alt="Example of 2D diffusion for two sets of initial conditions" class="calibre82"/>
<h6 class="calibre47"><span class="publishername">Figure 6-2. </span>Example of 2D diffusion for two sets of initial conditions</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Aren’t Python Lists Good Enough?" class="calibre3"><div class="preface" id="arent_python_lists_good_enough">
<h1 class="calibre25">Aren’t Python Lists Good Enough?</h1>

<p class="author1">Let’s take our pseudocode from <a data-type="xref" href="ch06_split_000.xhtml#matrix_algo1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-1</a> and formalize it so we can
better analyze its runtime performance.  The first step is to write out the
<a data-type="indexterm" data-primary="evolve function" id="idm46122422440104" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="diffusion equation" data-secondary="evolution function" id="idm46122422439432" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>evolution function that takes in the matrix and returns its evolved state. This
is shown in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-3</a>.</p>
<div id="matrix_pure_python" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-3. </span>Pure Python 2D diffusion</h5>

<pre data-type="programlisting" class="calibre59">grid_shape = (640, 640)


def evolve(grid, dt, D=1.0):
    xmax, ymax = grid_shape
    new_grid = [[0.0] * ymax for x in range(xmax)]
    for i in range(xmax):
        for j in range(ymax):
            grid_xx = (
                grid[(i + 1) % xmax][j] + grid[(i - 1) % xmax][j] - 2.0 * grid[i][j]
            )
            grid_yy = (
                grid[i][(j + 1) % ymax] + grid[i][(j - 1) % ymax] - 2.0 * grid[i][j]
            )
            new_grid[i][j] = grid[i][j] + D * (grid_xx + grid_yy) * dt
    return new_grid</pre></div>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Instead of preallocating the <code class="calibre26">new_grid</code> list, we could have built it up in the
<code class="calibre26">for</code> loop by using <code class="calibre26">append</code>s.  While this would have been noticeably faster than what we have
written, the conclusions we draw are still applicable.  We chose this method
because it is more <span class="publishername">illustrative</span>.</p>
</div>

<p class="author1">The global variable <code class="calibre26">grid_shape</code> designates how big a region we will simulate;
and, as explained in <a data-type="xref" href="ch06_split_000.xhtml#matrix_intro" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Introduction to the Problem”</a>, we are using periodic <a data-type="indexterm" data-primary="boundary conditions" id="idm46122422429640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>boundary conditions
(which is why we use modulo for the indices).  To actually use this
code, we must initialize a grid and call <code class="calibre26">evolve</code> on it.  The code in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_run" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-4</a> is a very generic<a data-type="indexterm" data-primary="diffusion equation" data-secondary="initialization" id="idm46122422427448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> initialization procedure that will
be reused throughout the chapter (its performance characteristics will not be
analyzed since it must run only once, as opposed to the<a data-type="indexterm" data-primary="evolve function" id="idm46122422426152" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">evolve</code> function, which
is called repeatedly).</p>
<div id="matrix_pure_python_run" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-4. </span>Pure Python 2D diffusion initialization</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code><code class="calibre26"> </code><code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># Setting up initial conditions </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO1-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO1-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">xmax</code><code class="p">,</code><code class="calibre26"> </code><code class="n">ymax</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid_shape</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">[</code><code class="p">[</code><code class="mi">0.0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">ymax</code><code class="calibre26"> </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">x</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">)</code><code class="p">]</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># These initial conditions are simulating a drop of dye in the middle of our</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># simulated region</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_low</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.4</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_high</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.5</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code><code class="calibre26"> </code><code class="n">block_high</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">j</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code><code class="calibre26"> </code><code class="n">block_high</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">            </code><code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">[</code><code class="n">j</code><code class="p">]</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0.005</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># Evolve the initial conditions</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">start</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0.1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code class="calibre26"> </code><code class="o">-</code><code class="calibre26"> </code><code class="n">start</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO1-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO1-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">The initial conditions used here are the same as in the square example in <a data-type="xref" href="ch06_split_000.xhtml#matrix_diffusion_image" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-2</a>.</p></dd>
</dl></div>

<p class="author1">The values for <code class="calibre26">dt</code> and grid elements have been chosen to be sufficiently small
that the algorithm is stable.  See<a data-type="indexterm" data-primary="Numerical Recipes, 3rd Edition (Press)" id="idm46122422187448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Press, William" data-secondary="Numerical Recipes, 3rd Edition" id="idm46122422186728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/O8Seo" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">Numerical Recipes</em></a> for a more in-depth
treatment of this algorithm’s convergence characteristics.</p>








<section data-type="sect2" data-pdf-bookmark="Problems with Allocating Too Much" class="calibre3"><div class="preface" id="idm46122422184664">
<h2 class="calibre43">Problems with Allocating Too Much</h2>

<p class="author1"><a data-type="indexterm" data-primary="diffusion equation" data-secondary="profiling" id="de_pro" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="line_profiler" id="li_pro" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="memory allocation problems" id="mvc_map" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory allocations" id="ma_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="diffusion equations" id="pro_de" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="memory allocation problems" id="vmc_map" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>By using <code class="calibre26">line_profiler</code> on the pure Python evolution function, we can start to
unravel what is contributing to a possibly slow runtime.  Looking at the
profiler output in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_lineprof" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-5</a>, we see that most of the time
in the function is spent doing the derivative calculation and updating the
grid.<sup class="calibre44"><a data-type="noteref" id="idm46122422174440-marker" href="ch06_split_001.xhtml#idm46122422174440" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup>  This is what we want, since this is a purely
CPU-bound problem—any time not spent on solving the CPU-bound problem is an obvious
place for optimization.</p>
<div id="matrix_pure_python_lineprof" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-5. </span>Pure Python 2D diffusion profiling</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="err">$</code><code class="calibre26"> </code><code class="n">kernprof</code><code class="calibre26"> </code><code class="o">-</code><code class="n">lv</code><code class="calibre26"> </code><code class="n">diffusion_python</code><code class="o">.</code><code class="n">py</code><code class="calibre26">
</code><code class="n">Wrote</code><code class="calibre26"> </code><code class="n">profile</code><code class="calibre26"> </code><code class="n">results</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="n">diffusion_python</code><code class="o">.</code><code class="n">py</code><code class="o">.</code><code class="n">lprof</code><code class="calibre26">
</code><code class="n">Timer</code><code class="calibre26"> </code><code class="n">unit</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">1e-06</code><code class="calibre26"> </code><code class="n">s</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">Total</code><code class="calibre26"> </code><code class="n">time</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">787.161</code><code class="calibre26"> </code><code class="n">s</code><code class="calibre26">
</code><code class="n">File</code><code class="p">:</code><code class="calibre26"> </code><code class="n">diffusion_python</code><code class="o">.</code><code class="n">py</code><code class="calibre26">
</code><code class="n">Function</code><code class="p">:</code><code class="calibre26"> </code><code class="n">evolve</code><code class="calibre26"> </code><code class="n">at</code><code class="calibre26"> </code><code class="n">line</code><code class="calibre26"> </code><code class="mi">12</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">Line</code><code class="calibre26"> </code><code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code><code class="calibre26">
</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">12</code><code class="calibre26">                                           </code><code class="nd">@profile</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">13</code><code class="calibre26">                                           </code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1.0</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">14</code><code class="calibre26">       </code><code class="mi">500</code><code class="calibre26">        </code><code class="mi">843.0</code><code class="calibre26">      </code><code class="mi">1.7</code><code class="calibre26">      </code><code class="mi">0.0</code><code class="calibre26">      </code><code class="n">xmax</code><code class="p">,</code><code class="calibre26"> </code><code class="n">ymax</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid_shape</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO2-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO2-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">15</code><code class="calibre26">       </code><code class="mi">500</code><code class="calibre26">   </code><code class="mi">24764794.0</code><code class="calibre26">  </code><code class="mi">49529.6</code><code class="calibre26">      </code><code class="mi">3.1</code><code class="calibre26">      </code><code class="n">new_grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">[</code><code class="p">[</code><code class="mi">0.0</code><code class="calibre26"> </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">x</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">16</code><code class="calibre26">    </code><code class="mi">320500</code><code class="calibre26">     </code><code class="mi">208683.0</code><code class="calibre26">      </code><code class="mi">0.7</code><code class="calibre26">      </code><code class="mi">0.0</code><code class="calibre26">      </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">)</code><code class="p">:</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO2-2" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO2-2"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">17</code><code class="calibre26"> </code><code class="mi">205120000</code><code class="calibre26">  </code><code class="mi">128928913.0</code><code class="calibre26">      </code><code class="mi">0.6</code><code class="calibre26">     </code><code class="mi">16.4</code><code class="calibre26">          </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">j</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">ymax</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">18</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">222422192.0</code><code class="calibre26">      </code><code class="mi">1.1</code><code class="calibre26">     </code><code class="mi">28.3</code><code class="calibre26">              </code><code class="n">grid_xx</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">19</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">228660607.0</code><code class="calibre26">      </code><code class="mi">1.1</code><code class="calibre26">     </code><code class="mi">29.0</code><code class="calibre26">              </code><code class="n">grid_yy</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">20</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">182174957.0</code><code class="calibre26">      </code><code class="mi">0.9</code><code class="calibre26">     </code><code class="mi">23.1</code><code class="calibre26">              </code><code class="n">new_grid</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">[</code><code class="n">j</code><code class="p">]</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">21</code><code class="calibre26">       </code><code class="mi">500</code><code class="calibre26">        </code><code class="mi">331.0</code><code class="calibre26">      </code><code class="mi">0.7</code><code class="calibre26">      </code><code class="mi">0.0</code><code class="calibre26">      </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">new_grid</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO2-3" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO2-3"><img src="Images/3.png" alt="3" class="calibre74"/></a></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO2-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO2-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This statement takes such a long time per hit because <code class="calibre26">grid_shape</code> must be retrieved from the local namespace (see <a data-type="xref" href="ch04.xhtml#dict_namespace" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Dictionaries and Namespaces”</a> for more information).</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO2-2" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO2-2"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This line has 320,500 hits associated with it, because the grid we operated over had <code class="calibre26">xmax = 640</code> and the we ran the function 500 times. The calculation is <code class="calibre26">(640 + 1) * 500</code>, where the extra one evaluation is from the termination of the loop.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO2-3" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO2-3"><img src="Images/3.png" alt="3" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This line has 500 hits associated with it, which informs us that the function was profiled over 500 runs.</p></dd>
</dl></div>

<p class="author1">It’s interesting to see the big difference in the <code class="calibre26">Per Hit</code> and <code class="calibre26">%
Time</code> fields for line 15, where we allocate the new grid. This difference occurs because, while
the line itself is quite slow (the <code class="calibre26">Per Hit</code> field shows that each run takes
0.0495 seconds, much slower than all other lines), it isn’t called as often as
other lines inside the loop. If we were to reduce the size of the grid and do
more iterations (i.e., reduce the number of iterations of the loop but increase
the number of times we call the function), we would see the <code class="calibre26">% Time</code> of this
line increase and quickly dominate the runtime.</p>

<p class="author1">This is a waste, because the properties of <code class="calibre26">new_grid</code> do not change—no matter
what values we send to <code class="calibre26">evolve</code>, the <code class="calibre26">new_grid</code> list will always be the same
shape and size and contain the same values.  A simple optimization would be to
allocate this list once and simply reuse it.  This way, we need to run this
code only once, no matter the size of the grid or the number of iterations.
This sort of optimization is similar to moving repetitive code outside a fast
loop:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code><code class="calibre26"> </code><code class="nn">math</code><code class="calibre26"> </code><code class="kn">import</code><code class="calibre26"> </code><code class="n">sin</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">loop_slow</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; %timeit loop_slow(int(1e4))
    1.68 ms ± 61.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">result</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">result</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">sin</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO3-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO3-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">result</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">loop_fast</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; %timeit loop_fast(int(1e4))
    551 µs ± 23.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">result</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">factor</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">sin</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">result</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">result</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">factor</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO3-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO3-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">The value of <code class="calibre26">sin(num_iterations)</code> doesn’t change throughout the loop, so there is no use recalculating it every time.</p></dd>
</dl>

<p class="author1">We can do a similar transformation to our diffusion code, as illustrated in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a>.  In this case, we would want to instantiate
<code class="calibre26">new_grid</code> in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_run" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-4</a> and send it in to our <code class="calibre26">evolve</code>
function.  That function will do the same as it did before: read the <code class="calibre26">grid</code> list
and write to the <code class="calibre26">new_grid</code> list.  Then we can simply swap <code class="calibre26">new_grid</code> with
<code class="calibre26">grid</code> and continue again.</p>
<div id="matrix_pure_python_memory" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-6. </span>Pure Python 2D diffusion after reducing memory allocations</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1.0</code><code class="p">):</code>
    <code class="n">xmax</code><code class="p">,</code> <code class="n">ymax</code> <code class="o">=</code> <code class="n">grid_shape</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">):</code>
        <code class="kn">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">ymax</code><code class="p">):</code>
            <code class="n">grid_xx</code> <code class="o">=</code> <code class="p">(</code>
                <code class="n">grid</code><code class="p">[(</code><code class="n">i</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[(</code><code class="n">i</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">xmax</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="p">)</code>
            <code class="n">grid_yy</code> <code class="o">=</code> <code class="p">(</code>
                <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">ymax</code><code class="p">]</code> <code class="o">+</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][(</code><code class="n">j</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code> <code class="o">%</code> <code class="n">ymax</code><code class="p">]</code> <code class="o">-</code> <code class="mi">2.0</code> <code class="o">*</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code>
            <code class="p">)</code>
            <code class="n">out</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="p">(</code><code class="n">grid_xx</code> <code class="o">+</code> <code class="n">grid_yy</code><code class="p">)</code> <code class="o">*</code> <code class="n">dt</code>


<code class="kn">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="c"># Setting up initial conditions</code>
    <code class="n">xmax</code><code class="p">,</code> <code class="n">ymax</code> <code class="o">=</code> <code class="n">grid_shape</code>
    <code class="n">next_grid</code> <code class="o">=</code> <code class="p">[[</code><code class="mi">0.0</code><code class="p">]</code> <code class="o">*</code> <code class="n">ymax</code> <code class="kn">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">)]</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="p">[[</code><code class="mi">0.0</code><code class="p">]</code> <code class="o">*</code> <code class="n">ymax</code> <code class="kn">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">)]</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="mi">0.4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="mi">0.5</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
        <code class="kn">for</code> <code class="n">j</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">block_low</code><code class="p">,</code> <code class="n">block_high</code><code class="p">):</code>
            <code class="n">grid</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="mi">0.005</code>

    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="c"># evolve modifies grid and next_grid in-place</code>
        <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mi">0.1</code><code class="p">,</code> <code class="n">next_grid</code><code class="p">)</code>
        <code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code> <code class="o">=</code> <code class="n">next_grid</code><code class="p">,</code> <code class="n">grid</code>
    <code class="kn">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre></div>

<p class="author1">We can see from the line profile of the modified version of the code in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_mem_lineprof" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-7</a> that this small change has given us a 31.25% speedup.<sup class="calibre44"><a data-type="noteref" id="idm46122422123864-marker" href="ch06_split_001.xhtml#idm46122422123864" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> This leads us to a
conclusion similar to the one made during our discussion of <code class="calibre26">append</code>
operations on lists (see <a data-type="xref" href="ch03.xhtml#list_as_dynamic_arrays" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Lists as Dynamic Arrays”</a>): memory allocations are not
cheap.  Every time we request memory to store a variable or a list,
Python must take its time to talk to the operating system in order to allocate
the new space, and then we must iterate over the newly allocated space to
initialize it to some value.</p>

<p class="author1">Whenever possible, reusing space that has already
been allocated will give performance speedups.  However, be careful when
implementing these changes.  While the speedups can be substantial, as always
you should profile to make sure you are achieving the results you want and are
not simply polluting your code base.<a data-type="indexterm" data-primary="" data-startref="de_pro" id="idm46122421430184" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="li_pro" id="idm46122421429240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mvc_map" id="idm46122421428296" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ma_ab" id="idm46122421427352" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_de" id="idm46122421426408" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_map" id="idm46122421425464" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<div data-type="example" id="matrix_pure_python_mem_lineprof" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-7. </span>Line profiling Python diffusion after reducing allocations</h5>
<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="err">$</code><code class="calibre26"> </code><strong class="calibre83"><code class="n1">kernprof</code><code class="calibre33"> </code><code class="o1">-</code><code class="n1">lv</code><code class="calibre33"> </code><code class="n1">diffusion_python_memory</code><code class="o1">.</code><code class="n1">py</code></strong><code class="calibre26">
</code><code class="n">Wrote</code><code class="calibre26"> </code><code class="n">profile</code><code class="calibre26"> </code><code class="n">results</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="n">diffusion_python_memory</code><code class="o">.</code><code class="n">py</code><code class="o">.</code><code class="n">lprof</code><code class="calibre26">
</code><code class="n">Timer</code><code class="calibre26"> </code><code class="n">unit</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">1e-06</code><code class="calibre26"> </code><code class="n">s</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">Total</code><code class="calibre26"> </code><code class="n">time</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">541.138</code><code class="calibre26"> </code><code class="n">s</code><code class="calibre26">
</code><code class="n">File</code><code class="p">:</code><code class="calibre26"> </code><code class="n">diffusion_python_memory</code><code class="o">.</code><code class="n">py</code><code class="calibre26">
</code><code class="n">Function</code><code class="p">:</code><code class="calibre26"> </code><code class="n">evolve</code><code class="calibre26"> </code><code class="n">at</code><code class="calibre26"> </code><code class="n">line</code><code class="calibre26"> </code><code class="mi">12</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">Line</code><code class="calibre26"> </code><code class="c">#      Hits         Time  Per Hit   % Time  Line Contents</code><code class="calibre26">
</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">12</code><code class="calibre26">                                           </code><code class="nd">@profile</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">13</code><code class="calibre26">                                           </code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1.0</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">14</code><code class="calibre26">       </code><code class="mi">500</code><code class="calibre26">        </code><code class="mi">503.0</code><code class="calibre26">      </code><code class="mi">1.0</code><code class="calibre26">      </code><code class="mi">0.0</code><code class="calibre26">      </code><code class="n">xmax</code><code class="p">,</code><code class="calibre26"> </code><code class="n">ymax</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid_shape</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">15</code><code class="calibre26">    </code><code class="mi">320500</code><code class="calibre26">     </code><code class="mi">131498.0</code><code class="calibre26">      </code><code class="mi">0.4</code><code class="calibre26">      </code><code class="mi">0.0</code><code class="calibre26">      </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">xmax</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">16</code><code class="calibre26"> </code><code class="mi">205120000</code><code class="calibre26">   </code><code class="mi">81105090.0</code><code class="calibre26">      </code><code class="mi">0.4</code><code class="calibre26">     </code><code class="mi">15.0</code><code class="calibre26">          </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">j</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">ymax</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">17</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">166271837.0</code><code class="calibre26">      </code><code class="mi">0.8</code><code class="calibre26">     </code><code class="mi">30.7</code><code class="calibre26">              </code><code class="n">grid_xx</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">18</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">169216352.0</code><code class="calibre26">      </code><code class="mi">0.8</code><code class="calibre26">     </code><code class="mi">31.3</code><code class="calibre26">              </code><code class="n">grid_yy</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="mi">19</code><code class="calibre26"> </code><code class="mi">204800000</code><code class="calibre26">  </code><code class="mi">124412452.0</code><code class="calibre26">      </code><code class="mi">0.6</code><code class="calibre26">     </code><code class="mi">23.0</code><code class="calibre26">              </code><code class="n">out</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">[</code><code class="n">j</code><code class="p">]</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code class="calibre26">
</code></pre>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Memory Fragmentation" class="calibre3"><div class="preface" id="matrix_memory_fragmentation">
<h1 class="calibre25">Memory Fragmentation</h1>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="memory fragmentation" id="mvc_mf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory copies" data-secondary="memory fragmentation" id="mc_mf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="memory fragmentation" id="vmc_mf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The Python code we wrote in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a> still has a problem
that is at the heart of using Python for these sorts of vectorized operations:
Python doesn’t natively support vectorization.  There are two reasons for this:
Python lists store <a data-type="indexterm" data-primary="pointers" id="idm46122420850632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>pointers to the actual data, and Python bytecode is not
optimized for vectorization, so <code class="calibre26">for</code> loops cannot predict when using
vectorization would be beneficial.</p>

<p class="author1">The fact that Python lists store <em class="hyperlink">pointers</em> means that, instead of actually
holding the data we care about, lists store locations where that data can be
found.  For most uses, this is good because it allows us to store whatever type
of data we like inside a list.  However, when it comes to vector and matrix
operations, this is a source of a lot of performance degradation.</p>

<p class="author1">The degradation occurs because every time we want to fetch an element from the
<code class="calibre26">grid</code> matrix, we must do multiple lookups. For example, doing <code class="calibre26">grid[5][2]</code>
requires us to first do a list lookup for index <code class="calibre26">5</code> on the list <code class="calibre26">grid</code>. This
will return a pointer to where the data at that location is stored. Then we
need to do another list lookup on this returned object, for the element at index
<code class="calibre26">2</code>. Once we have this reference, we have the location where the actual data
is stored.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Rather than creating a grid as a list-of-lists (<code class="calibre26">grid[x][y]</code>), how would you create a grid indexed by a tuple (<code class="calibre26">grid[(x, y)]</code>)? How would this affect
the performance of the code?</p>
</div>

<p class="author1">The overhead for one such lookup is not big and can be, in most cases,
disregarded. However, if the data we wanted was located in one contiguous block
in memory, we could move <em class="hyperlink">all</em> of the data in one operation instead of needing
two operations for each element. This is one of the major points with data
fragmentation: when your data is fragmented, you must move each piece over
individually instead of moving the entire block over. This means you are
invoking more memory transfer overhead, and you are forcing the CPU to wait
while data is being transferred. We will see with <code class="calibre26">perf</code> just how important
this is when looking at the <code class="calibre26">cache-misses</code>.</p>

<p class="author1">This problem of getting the right data to the CPU when it is needed is related
to the <a data-type="indexterm" data-primary="bottlenecks" id="idm46122420840664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Von Neumann bottleneck" id="idm46122420839960" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">von Neumann bottleneck</em>. This refers to the limited bandwidth that exists between the memory and the CPU as a result of the tiered
memory architecture that modern computers use. If we could move data infinitely
fast, we would not need any cache, since the CPU could retrieve any data it
needed instantly. This would be a state in which the bottleneck is nonexistent.</p>

<p class="author1">Since we can’t move data infinitely fast, we must prefetch data from RAM and
store it in smaller but faster CPU caches so that, hopefully, when the CPU needs
a piece of data, it will be in a location that can be read from quickly.
While this is a severely idealized way of looking at the architecture, we can
still see some of the problems with it—how do we know what data will be needed
in the future?  The CPU does a good job with mechanisms called<a data-type="indexterm" data-primary="branch prediction" id="idm46122420837512" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="pipelining" id="idm46122420836808" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">branch
prediction</em> and <em class="hyperlink">pipelining</em>, which try to predict the next instruction and
load the relevant portions of memory into the cache while still working on the
current instruction.  However, the best way to minimize the effects of the
bottleneck is to be smart about how we allocate our memory and how we do our
calculations over our data.</p>

<p class="author1">Probing how well memory is being moved to the CPU can be quite hard; however, in
Linux the<a data-type="indexterm" data-primary="Linux, perf tool" id="idm46122420834072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">perf</code> tool can be used to get amazing amounts of insight into how the
CPU is dealing with the program being run.<sup class="calibre44"><a data-type="noteref" id="idm46122420832696-marker" href="ch06_split_001.xhtml#idm46122420832696" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup>  For example, we can run <code class="calibre26">perf</code> on
the pure Python code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a> and see just how
efficiently the CPU is running our code.</p>

<p class="author1">The results are shown in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-8</a>. Note that the output in this example and the following
<code class="calibre26">perf</code> examples has been truncated to fit within the margins of the page. The
removed data included variances for each measurement, indicating how much the
values changed throughout multiple benchmarks. This is useful for seeing how
much a measured value is dependent on the actual performance characteristics of
the program versus other system properties, such as other running programs using
system resources.</p>
<div id="matrix_perf_python_memory" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-8. </span>Performance counters for pure Python 2D diffusion with reduced memory allocations (grid size: 640 × 640, 500 iterations)</h5>

<pre data-type="programlisting" class="calibre59">$ perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_python_memory.py


 Performance counter stats for 'python diffusion_python_memory.py':

   415,864,974,126      cycles                    #    2.889 GHz
 1,210,522,769,388      instructions              #    2.91  insn per cycle
       656,345,027      cache-references          #    4.560 M/sec
       349,562,390      cache-misses              #   53.259 % of all cache refs
   251,537,944,600      branches                  # 1747.583 M/sec
     1,970,031,461      branch-misses             #    0.78% of all branches
     143934.730837      task-clock (msec)         #    1.000 CPUs utilized
            12,791      faults                    #    0.089 K/sec
            12,791      minor-faults              #    0.089 K/sec
               117      cs                        #    0.001 K/sec
                 6      migrations                #    0.000 K/sec

     143.935522122 seconds time elapsed</pre></div>








<section data-type="sect2" data-pdf-bookmark="Understanding perf" class="calibre3"><div class="preface" id="understanding_perf">
<h2 class="calibre43">Understanding perf</h2>

<p class="author1"><a data-type="indexterm" data-primary="memory copies" data-secondary="perf and" id="mc_p" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="perf tool" id="pt_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Let’s
take a second to understand the various performance metrics that <code class="calibre26">perf</code> is
giving us and their connection to our code.  The<a data-type="indexterm" data-primary="task-clock metric" id="idm46122421137464" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">task-clock</code> metric tells us
how many clock cycles our task took.  This is different from the total runtime,
because if our program took one second to run but used two CPUs, then the
task-clock would be <code class="calibre26">2000</code> (<code class="calibre26">task-clock</code> is generally in milliseconds).
Conveniently, <code class="calibre26">perf</code> does the calculation for us and tells us, next to this
metric, how many CPUs were utilized (where it says “XXXX CPUs utilized”).  This
number wouldn’t be exactly <code class="calibre26">2</code> even when two CPUs are
being used, though, because the process sometimes relied on other
subsystems to do instructions for it (for example, when memory was allocated).</p>

<p class="author1">On the other hand,<a data-type="indexterm" data-primary="instructions" id="idm46122421133640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">instructions</code> tells us how many CPU instructions our code
issued, and <code class="calibre26">cycles</code> tells us how many CPU cycles it took to run all of these
instructions. The difference between these two numbers gives us an indication of
how well our code is vectorizing and pipelining.  With pipelining, the CPU is
able to run the current operation while fetching and preparing the next one.</p>

<p class="author1"><a data-type="indexterm" data-primary="context switches" id="idm46122421131352" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="CPU-migrations" id="idm46122421130424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">cs</code> (representing “context switches”) and <code class="calibre26">CPU-migrations</code> tell us about how
the program is halted in order to wait for a <a data-type="indexterm" data-primary="Kernel" id="idm46122421128952" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>kernel operation to finish (such as
I/O), to let other applications run, or to move execution to another CPU core.
When a <code class="calibre26">context-switch</code> happens, the program’s execution is halted and another
program is allowed to run instead.  This is a <em class="hyperlink">very</em> time-intensive task and is
something we would like to minimize as much as possible, but we don’t have too
much control over when this happens.  The kernel delegates when programs are
allowed to be switched out; however, we can do things to disincentivize the
kernel from moving <em class="hyperlink">our</em> program.  In general, the kernel suspends a program
when it is doing I/O (such as reading from memory, disk, or the network).  As
you’ll see in later chapters, we can use asynchronous routines to make sure that
our program still uses the CPU even when waiting for I/O, which will let us keep
running without being context-switched.  In addition, we could set the <code class="calibre26">nice</code>
value of our program to give our program priority and stop the kernel
from context-switching it.<sup class="calibre44"><a data-type="noteref" id="idm46122421125416-marker" href="ch06_split_001.xhtml#idm46122421125416" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup>
Similarly, <code class="calibre26">CPU-migrations</code> happen when the program is halted and resumed on a
different CPU than the one it was on before, in order to have all CPUs have the
same level of utilization.  This can be seen as an especially bad context
switch, as not only is our program being temporarily halted, but we also lose
whatever data we had in the L1 cache (recall that each CPU has its own L1
cache).</p>

<p class="author1">A <a data-type="indexterm" data-primary="page-fault" id="idm46122421121704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">page-fault</code> (or just
<code class="calibre26">fault</code>) is part of the modern Unix memory allocation scheme.  When memory is
allocated, the kernel doesn’t do much except give the program a reference to
memory.  Later, however, when the memory is first used, the operating system
throws a minor page fault interrupt, which pauses the program that is being run
and properly allocates the memory.  This is called a<a data-type="indexterm" data-primary="lazy allocation system" id="idm46122421119768" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">lazy allocation system</em>.
While this method is an optimization over previous memory allocation
systems, minor page faults are quite an expensive operation since most of the
operations are done outside the scope of the program you are running.  There is
also a major page fault, which happens when the program requests data from a
device (disk, network, etc.) that hasn’t been read yet.  These are even more
expensive operations: not only do they interrupt your program, but they
also involve reading from whichever device the data lives on.  This sort of page
fault does not generally affect CPU-bound work; however, it will be a source of
pain for any program that does disk or network reads/writes.<sup class="calibre44"><a data-type="noteref" id="idm46122421117832-marker" href="ch06_split_001.xhtml#idm46122421117832" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">5</a></sup></p>

<p class="author1">Once we have data in memory and we reference it, the data makes its way through
the various tiers of memory (L1/L2/L3 memory—see
<a data-type="xref" href="ch01_split_000.xhtml#understanding_pp_communication" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Communications Layers”</a> for a discussion of this).  Whenever we
reference data that is in our cache, the <a data-type="indexterm" data-primary="cache-references" id="idm46122421114552" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">cache-references</code> metric increases.
If we do not already have this data in the cache and need to fetch it from RAM,
this counts as a<a data-type="indexterm" data-primary="cache-miss" id="idm46122421113368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">cache-miss</code>.  We won’t get a cache miss if we are reading data
we have read recently (that data will still be in the cache) or data that is
located <em class="hyperlink">near</em> data we have recently read (data is sent from RAM into the cache in
chunks).  Cache misses can be a source of slowdowns when it comes to CPU-bound
work, since we need to wait to fetch the data from RAM <em class="hyperlink">and</em> we
interrupt the flow of our execution pipeline (more on this in a second). As a
result, reading through an array in order will give many <code class="calibre26">cache-references</code>
but not many <code class="calibre26">cache-misses</code> since if we read element <code class="calibre26">i</code>, element <code class="calibre26">i + 1</code> will
already be in cache. If, however, we read randomly through an array or
otherwise don’t lay out our data in memory well, every read will require access
to data that couldn’t possibly already be in cache. Later in this chapter we will discuss how to
reduce this effect by optimizing the layout of data in memory.</p>

<p class="author1">A <code class="calibre26">branch</code> is a time in the code where the execution flow changes.  Think of an
<code class="calibre26">if...then</code> statement—depending on the result of the conditional, we will be executing either
one section of code or another.  This is essentially a branch in
the execution of the code—the next instruction in the program could be one of
two things.  To optimize this, especially with regard to the pipeline,
the CPU tries to guess which direction the branch will take and preload the
relevant instructions.  When this prediction is incorrect, we will get a
<code class="calibre26">branch-miss</code>. Branch misses can be quite confusing and can result in many strange
effects (for example, some loops will run substantially faster on sorted lists
than on unsorted lists simply because there will be fewer branch <span class="publishername">misses)</span>.<sup class="calibre44"><a data-type="noteref" id="idm46122421106008-marker" href="ch06_split_001.xhtml#idm46122421106008" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">6</a></sup></p>

<p class="author1">There are a lot more metrics that <code class="calibre26">perf</code> can keep track of, many of which are
very specific to the CPU you are running the code on. You can run <code class="calibre26">perf list</code> to
get the list of currently supported metrics on your system. For example, in the
previous edition of this book, we ran on a machine that also supported
<code class="calibre26">stalled-cycles-frontend</code> and <code class="calibre26">stalled-cycles-backend</code>, which tell us how many
cycles our program was waiting for the frontend or backend of the pipeline to be
filled.  This can happen because of a cache miss, a mispredicted branch, or a
resource conflict. The frontend of the pipeline is responsible for fetching the
next instruction from memory and decoding it into a valid operation, while the
backend is responsible for actually running the operation. These sorts of
metrics can help tune the performance of a code to the
optimizations and architecture choices of a particular CPU; however, unless you
are always running on the same chip-set, it may be excessive to worry too much
about them.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">If you would like a more thorough explanation of what is going on at the CPU
level with the various performance metrics, check out <a data-type="indexterm" data-primary="Prabhu, Gurpur M." id="idm46122421100536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="&quot;Computer Architecture Tutorial&quot; (Prabhu)" data-primary-sortas="computer" id="idm46122421099832" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Gurpur M. Prabhu’s
fantastic <a href="http://bit.ly/ca_tutorial" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Computer Architecture Tutorial.”</a> It deals
with the problems at a very low level, which will give you a good understanding of
what is going on under the hood when you run your code.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Making Decisions with perf’s Output" class="calibre3"><div class="preface" id="idm46122421141864">
<h2 class="calibre43">Making Decisions with perf’s Output</h2>

<p class="author1">With all this in mind, the performance metrics in <a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-8</a>
are telling us that while running our code, the CPU had to reference the L1/L2
cache 656,345,027 times.  Of those references, 349,562,390 (or 53.3%) were
requests for data that wasn’t in memory at the time and had to be retrieved.  In
addition, we can see that in each CPU cycle we are able to perform an average of
2.91 instructions, which tells us the total speed boost from pipelining,
out-of-order execution, and hyperthreading (or any other CPU feature that lets
you run more than one instruction per clock cycle).</p>

<p class="author1">Fragmentation increases the number of memory transfers to the CPU. Additionally,
since you don’t have multiple pieces of data ready in the CPU cache when a
calculation is requested, you cannot vectorize the calculations.  As
explained in <a data-type="xref" href="ch01_split_000.xhtml#understanding_pp_communication" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Communications Layers”</a>, vectorization of computations
(or having the CPU do <span class="publishername">multiple</span>
computations at a time) can occur only if we can fill the CPU cache with all the
relevant data.  Since the bus can only move contiguous chunks of memory, this is
possible only if the grid data is stored sequentially in RAM.  Since a list
stores pointers to data instead of the actual data, the actual values in the
grid are scattered throughout memory and cannot be copied all at
once.</p>

<p class="author1">We can alleviate this problem by using the <a data-type="indexterm" data-primary="array module" id="idm46122421092040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory copies" data-secondary="array module and" id="idm46122421091064" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">array</code> module instead of lists.
These objects store data sequentially in memory, so that a slice of the <code class="calibre26">array</code>
actually represents a continuous range in memory.  However, this doesn’t
completely fix the 
<span class="publishername">problem</span>—now we have data that is stored sequentially in
memory, but Python still does not know how to vectorize our loops.  What we
would like is for any loop that does arithmetic on our array one element at a
time to work on chunks of data, but as mentioned previously, there is no such
bytecode optimization in Python (partly because of the extremely dynamic nature of
the language).</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Why doesn’t having the data we want stored sequentially in memory automatically
give us <a data-type="indexterm" data-primary="vectorization" id="idm46122421086888" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>vectorization?  If we look at the raw machine code that the CPU is
running, vectorized operations (such as multiplying two arrays) use a different
part of the CPU and different instructions than nonvectorized operations.
For Python to use these special instructions, we must have a module that
was created to use them. We will soon see how <code class="calibre26">numpy</code> gives us access to these
specialized instructions.</p>
</div>

<p class="author1">Furthermore, because of implementation details, using the <code class="calibre26">array</code> type when
creating lists of data that must be iterated on is actually <em class="hyperlink">slower</em> than simply
creating a <code class="calibre26">list</code>.  This is because the <code class="calibre26">array</code> object stores a very low-level
representation of the numbers it stores, and this must be converted into a
Python-compatible version before being returned to the user.  This extra
overhead happens every time you index an <code class="calibre26">array</code> type.  That implementation
decision has made the <code class="calibre26">array</code> object less suitable for math and more suitable
for storing fixed-type data more efficiently in memory.<a data-type="indexterm" data-primary="" data-startref="mvc_mf" id="idm46122421081656" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mc_mf" id="idm46122421080680" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_mf" id="idm46122421079736" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mc_p" id="idm46122421078792" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pt_ab" id="idm46122421077848" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Enter numpy" class="calibre3"><div class="preface" id="enter-numpy">
<h2 class="calibre43">Enter numpy</h2>

<p class="author1"><a data-type="indexterm" data-primary="numpy" id="nu_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>To deal with the
fragmentation we found using <code class="calibre26">perf</code>, we must find a package that can
efficiently vectorize operations. Luckily, <code class="calibre26">numpy</code> has all of the features we
need—it stores data in contiguous chunks of memory and supports vectorized
operations on its data.  As a result, any arithmetic we do on <code class="calibre26">numpy</code> arrays
happens in chunks without us having to explicitly loop over each
element.<sup class="calibre44"><a data-type="noteref" id="idm46122421072568-marker" href="ch06_split_001.xhtml#idm46122421072568" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">7</a></sup>  Not only is it much easier to do matrix arithmetic this
way, but it is also faster. Let’s look at an example:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code><code class="calibre26"> </code><code class="nn">array</code><code class="calibre26"> </code><code class="kn">import</code><code class="calibre26"> </code><code class="n">array</code><code class="calibre26">
</code><code class="kn">import</code><code class="calibre26"> </code><code class="nn">numpy</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">norm_square_list</code><code class="p">(</code><code class="n">vector</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; vector = list(range(1_000_000))
    &gt;&gt;&gt; %timeit norm_square_list(vector)
    85.5 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">norm</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="n">vector</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">norm</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">norm</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">norm_square_list_comprehension</code><code class="p">(</code><code class="n">vector</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; vector = list(range(1_000_000))
    &gt;&gt;&gt; %timeit norm_square_list_comprehension(vector)
    80.3 ms ± 1.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="nb">sum</code><code class="p">(</code><code class="p">[</code><code class="n">v</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="n">vector</code><code class="p">]</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">norm_square_array</code><code class="p">(</code><code class="n">vector</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; vector_array = array('l', range(1_000_000))
    &gt;&gt;&gt; %timeit norm_square_array(vector_array)
    101 ms ± 4.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">norm</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="n">vector</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">norm</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">v</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">norm</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">norm_square_numpy</code><code class="p">(</code><code class="n">vector</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; vector_np = numpy.arange(1_000_000)
    &gt;&gt;&gt; %timeit norm_square_numpy(vector_np)
    3.22 ms ± 136 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">numpy</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">vector</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">vector</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO4-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO4-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">norm_square_numpy_dot</code><code class="p">(</code><code class="n">vector</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="sd">"""
    &gt;&gt;&gt; vector_np = numpy.arange(1_000_000)
    &gt;&gt;&gt; %timeit norm_square_numpy_dot(vector_np)
    960 µs ± 41.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
    """</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">numpy</code><code class="o">.</code><code class="n">dot</code><code class="p">(</code><code class="n">vector</code><code class="p">,</code><code class="calibre26"> </code><code class="n">vector</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO4-2" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO4-2"><img src="Images/2.png" alt="2" class="calibre74"/></a></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO4-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO4-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This creates two implied loops over <code class="calibre26">vector</code>, one to do the multiplication and one to do the sum.  These loops are similar to the loops from <code class="calibre26">norm_square_list_comprehension</code>, but they are executed using <code class="calibre26">numpy</code>’s optimized numerical code.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO4-2" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO4-2"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This is the preferred way of doing vector norms in <code class="calibre26">numpy</code> by using the vectorized <code class="calibre26">numpy.dot</code> operation.  The less efficient <code class="calibre26">norm_square_numpy</code> code is provided for illustration.</p></dd>
</dl>

<p class="author1">The simpler <code class="calibre26">numpy</code> code runs 89× faster than <code class="calibre26">norm_square_list</code> and 83.65×
faster than the “optimized” Python list comprehension.  The difference in speed
between the pure Python looping method and the list comprehension method shows
the benefit of doing more calculation behind the scenes rather than explicitly
in your Python code.  By performing calculations using Python’s
already-built machinery, we get the speed of the native C code that Python is
built on.  This is also partly the same reasoning behind why we have such a
drastic speedup in the <code class="calibre26">numpy</code> code: instead of using the generalized
list structure, we have a finely tuned and specially built object for
dealing with arrays of numbers.</p>

<p class="author1">In addition to more lightweight and specialized machinery, the <code class="calibre26">numpy</code> object
gives us memory locality and vectorized operations, which are incredibly
important when dealing with numerical computations.  The CPU is exceedingly
fast, and most of the time simply getting it the data it needs faster is the
best way to optimize code quickly.  Running each function using the <code class="calibre26">perf</code> tool
we looked at earlier shows that the <a data-type="indexterm" data-primary="array module" id="idm46122420390088" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">array</code> and pure Python functions take
about 10<sup class="calibre44">12</sup> instructions, while the <code class="calibre26">numpy</code> version takes about 10<sup class="calibre44">9</sup>
instructions.  In addition, the <code class="calibre26">array</code> and pure Python versions have around 53%
cache misses, while <code class="calibre26">numpy</code> has around 20%.</p>

<p class="author1">In our <code class="calibre26">norm_square_numpy</code> code, when doing <code class="calibre26">vector * vector</code>, there is an
<em class="hyperlink">implied</em> loop that <code class="calibre26">numpy</code> will take care of.  The implied loop is the same loop
we have explicitly written out in the other examples: loop over all items in
<code class="calibre26">vector</code>, multiplying each item by itself.  However, since we tell <code class="calibre26">numpy</code> to do
this instead of explicitly writing it out in Python code, <code class="calibre26">numpy</code> can take advantage
of all the optimizations it wants.  In the background, <code class="calibre26">numpy</code> has very
optimized C code that has been made specifically to take advantage of any
vectorization the CPU has enabled.  In addition, <code class="calibre26">numpy</code> arrays are represented
sequentially in memory as low-level numerical types, which gives them the same
space requirements as <code class="calibre26">array</code> objects (from the <code class="calibre26">array</code> module).</p>

<p class="author1">As an added bonus, we can reformulate the problem as a dot product, which
<code class="calibre26">numpy</code> supports.  This gives us a single operation to calculate the value we
want, as opposed to first taking the product of the two vectors and then summing
them.  As you can see in <a data-type="xref" href="ch06_split_000.xhtml#matrix_norm_squared_figure" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-3</a>, this operation,
<code class="calibre26">norm_numpy_dot</code>, outperforms all the others by quite a substantial margin—this
is thanks to the specialization of the function, and because we don’t need to
store the intermediate value of <code class="calibre26">vector * vector</code> as we did in <code class="calibre26">norm_numpy</code>.<a data-type="indexterm" data-primary="" data-startref="nu_ab" id="idm46122420377624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<figure class="calibre46"><div id="matrix_norm_squared_figure" class="figure">
<img src="Images/hpp2_0603.png" alt="Runtimes for the various norm-square routines with vectors of different lenghts" class="calibre84"/>
<h6 class="calibre47"><span class="publishername">Figure 6-3. </span>Runtimes for the various norm squared routines with vectors of different length</h6>
</div></figure>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Applying numpy to the Diffusion Problem" class="calibre3"><div class="preface" id="idm46122420433944">
<h1 class="calibre25">Applying numpy to the Diffusion Problem</h1>

<p class="author1"><a data-type="indexterm" data-primary="numpy" data-secondary="performance improvement with" id="nu_pi" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Using
what we’ve learned about <code class="calibre26">numpy</code>, we can easily adapt our pure Python code to
be vectorized.  The only new functionality we must introduce is <code class="calibre26">numpy</code>’s
<a data-type="indexterm" data-primary="roll function" id="idm46122421058648" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="roll function" id="idm46122421057912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">roll</code> function.  This function does the same thing as our modulo-index trick,
but it does so for an entire <code class="calibre26">numpy</code> array.  In essence, it vectorizes this
reindexing:</p>

<pre data-type="programlisting" data-code-language="pycon" class="calibre50"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">([</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">,</code><code class="mi">4</code><code class="p">],</code> <code class="mi">1</code><code class="p">)</code>
<code class="go">array([4, 1, 2, 3])</code>

<code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">([[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">],[</code><code class="mi">4</code><code class="p">,</code><code class="mi">5</code><code class="p">,</code><code class="mi">6</code><code class="p">]],</code> <code class="mi">1</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="go">array([[3, 1, 2],</code>
<code class="go">       [6, 4, 5]])</code></pre>

<p class="author1">The <code class="calibre26">roll</code> function creates a new <code class="calibre26">numpy</code> array, which can be thought of as
both good and bad.  The downside is that we are taking time to allocate new
space, which then needs to be filled with the appropriate data.  On the other
hand, once we have created this new rolled array, we will be able to vectorize
operations on it quite quickly without suffering from cache misses from the CPU
cache.  This can substantially affect the speed of the actual calculation we
must do on the grid.  Later in this chapter we will rewrite this so that we get
the same benefit without having to constantly allocate more memory.</p>

<p class="author1">With this additional function we can rewrite the Python diffusion code from
<a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a> using simpler, and vectorized, <code class="calibre26">numpy</code> arrays.
<a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-9</a> shows our initial <code class="calibre26">numpy</code> diffusion code.</p>
<div id="matrix_numpy_naive" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-9. </span>Initial <code class="calibre26">numpy</code> diffusion</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">numpy</code> <code class="kn">import</code> <code class="p">(</code><code class="n">zeros</code><code class="p">,</code> <code class="n">roll</code><code class="p">)</code>

<code class="n">grid_shape</code> <code class="o">=</code> <code class="p">(</code><code class="mi">640</code><code class="p">,</code> <code class="mi">640</code><code class="p">)</code>


<code class="kn">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">):</code>
    <code class="kn">return</code> <code class="p">(</code>
        <code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code> <code class="o">+</code>
        <code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code> <code class="o">+</code>
        <code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="o">+</code>
        <code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="o">-</code>
        <code class="mi">4</code> <code class="o">*</code> <code class="n">grid</code>
    <code class="p">)</code>


<code class="kn">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="kn">return</code> <code class="n">grid</code> <code class="o">+</code> <code class="n">dt</code> <code class="o">*</code> <code class="n">D</code> <code class="o">*</code> <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">)</code>


<code class="kn">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code>

    <code class="n">block_low</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="mi">0.4</code><code class="p">)</code>
    <code class="n">block_high</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="mi">0.5</code><code class="p">)</code>
    <code class="n">grid</code><code class="p">[</code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">,</code> <code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">]</code> <code class="o">=</code> <code class="mi">0.005</code>

    <code class="n">start</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">grid</code> <code class="o">=</code> <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mi">0.1</code><code class="p">)</code>
    <code class="kn">return</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code></pre></div>

<p class="author1">Immediately we see that this code is much shorter.  This is sometimes a good
indication of performance: we are doing a lot of the heavy lifting outside
the Python interpreter, and hopefully inside a module specially built for
performance and for solving a particular problem (however, this should always be
tested!).  One of the assumptions here is that <code class="calibre26">numpy</code> is using better memory
management to give the CPU the data it needs more quickly.  However, since
whether this happens or not relies on the actual implementation of <code class="calibre26">numpy</code>,
let’s profile our code to see whether our hypothesis is correct.
<a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-10</a> shows the results.</p>
<div id="matrix_perf_numpy" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-10. </span>Performance counters for <code class="calibre26">numpy</code> 2D diffusion (grid size: 640 × 640, 500 iterations)</h5>

<pre data-type="programlisting" class="calibre59">$ perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_numpy.py


 Performance counter stats for 'python diffusion_numpy.py':

     8,432,416,866      cycles                    #    2.886 GHz
     7,114,758,602      instructions              #    0.84  insn per cycle
     1,040,831,469      cache-references          #  356.176 M/sec
       216,490,683      cache-misses              #   20.800 % of all cache refs
     1,252,928,847      branches                  #  428.756 M/sec
         8,174,531      branch-misses             #    0.65% of all branches
       2922.239426      task-clock (msec)         #    1.285 CPUs utilized
           403,282      faults                    #    0.138 M/sec
           403,282      minor-faults              #    0.138 M/sec
                96      cs                        #    0.033 K/sec
                 5      migrations                #    0.002 K/sec

       2.274377105 seconds time elapsed</pre></div>

<p class="author1">This shows that the simple change to <code class="calibre26">numpy</code> has given us a 63.3× speedup over
the pure Python implementation with reduced memory allocations
(<a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-8</a>).  How was this achieved?</p>

<p class="author1">First of all, we can thank the vectorization that <code class="calibre26">numpy</code> gives.  Although the
<code class="calibre26">numpy</code> version seems to be running fewer instructions per cycle, each
instruction does much more work.  That is to say, one vectorized
instruction can multiply four (or more) numbers in an array together instead of
requiring four independent multiplication instructions.  Overall, this results in
fewer total instructions being necessary to solve the same problem.</p>

<p class="author1">Several other factors contribute to the <code class="calibre26">numpy</code> version
requiring a lower absolute number of instructions to solve the diffusion
problem.  One of them has to do with the full Python API being available when
running the pure Python version, but not necessarily for the <code class="calibre26">numpy</code> version—for
example, the pure Python grids can be appended to in pure Python but not in
<code class="calibre26">numpy</code>.  Even though we aren’t explicitly using this (or other)
functionality, there is overhead in providing a system where it <em class="hyperlink">could</em> be
available.  Since <code class="calibre26">numpy</code> can make the assumption that the data being stored is
always going to be numbers, everything regarding the arrays can be optimized for
operations over numbers.  We will continue on the track of removing necessary
functionality in favor of performance when we talk about Cython (see
<a data-type="xref" href="ch07.xhtml#compiling-cython" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Cython”</a>), where it is even possible to remove list bounds checking
to speed up list lookups.</p>

<p class="author1">Normally, the number of instructions doesn’t necessarily correlate with
performance—the program with fewer instructions may not issue them efficiently,
or they may be slow instructions.  However, we see that in addition to reducing
the number of instructions, the <code class="calibre26">numpy</code> version has also reduced a large
inefficiency: cache misses (20.8% cache misses instead of 53.3%).  As
explained in <a data-type="xref" href="ch06_split_000.xhtml#matrix_memory_fragmentation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Memory Fragmentation”</a>, cache misses slow down
computations because the CPU must wait for data to be retrieved from slower
memory instead of having the data immediately available in its cache.  In fact, memory
fragmentation is such a dominant factor in performance that if we disable
vectorization in <code class="calibre26">numpy</code> but keep
everything else the same,<sup class="calibre44"><a data-type="noteref" id="idm46122420993032-marker" href="ch06_split_001.xhtml#idm46122420993032" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">8</a></sup> we still see a sizable speed increase compared to the
pure Python version (<a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_numpy_novec" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-11</a>).</p>
<div id="matrix_perf_numpy_novec" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-11. </span>Performance counters for <code class="calibre26">numpy</code> 2D diffusion without vectorization (grid size: 640 × 640, 500 iterations)</h5>

<pre data-type="programlisting" class="calibre59">$ perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_numpy.py


 Performance counter stats for 'python diffusion_numpy.py':

    50,086,999,350      cycles                    #    2.888 GHz
    53,611,608,977      instructions              #    1.07  insn per cycle
     1,131,742,674      cache-references          #   65.266 M/sec
       322,483,897      cache-misses              #   28.494 % of all cache refs
     4,001,923,035      branches                  #  230.785 M/sec
         6,211,101      branch-misses             #    0.16% of all branches
      17340.464580      task-clock (msec)         #    1.000 CPUs utilized
           403,193      faults                    #    0.023 M/sec
           403,193      minor-faults              #    0.023 M/sec
                74      cs                        #    0.004 K/sec
                 6      migrations                #    0.000 K/sec

      17.339656586 seconds time elapsed</pre></div>

<p class="author1">This shows us that the dominant factor in our 63.3× speedup when introducing
<code class="calibre26">numpy</code> is not the vectorized instruction set but rather the memory locality
and reduced memory fragmentation.  In fact, we can see from the preceding
experiment that vectorization accounts for only about 13% of that 63.3×
speedup.<sup class="calibre44"><a data-type="noteref" id="idm46122420742936-marker" href="ch06_split_001.xhtml#idm46122420742936" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">9</a></sup></p>

<p class="author1">This realization that memory issues are the dominant factor in slowing down our
code doesn’t come as too much of a shock.  Computers are very well designed to
do exactly the calculations we are requesting them to do with this
problem—multiplying and adding numbers together.  The <a data-type="indexterm" data-primary="bottlenecks" id="idm46122420741624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>bottleneck is in getting
those numbers to the CPU fast enough to see it do the calculations as fast as it
can.<a data-type="indexterm" data-primary="" data-startref="nu_pi" id="idm46122420740664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>








<section data-type="sect2" data-pdf-bookmark="Memory Allocations and In-Place Operations" class="calibre3"><div class="preface" id="SEC-numpy-inplace">
<h2 class="calibre43">Memory Allocations and In-Place Operations</h2>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="memory allocations and in-place operations" id="mvc_mai" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory allocations" id="ma_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="memory allocations and in-place operations" id="nu_mai" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="memory allocations and in-place operations" id="vmc_mai" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="in-place operations" id="ipo_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>To optimize the memory-dominated effects, let’s try using the same
method we used in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a> to reduce the number of
allocations we make in our <code class="calibre26">numpy</code> code.  Allocations are quite a bit worse than
the cache misses we discussed previously.  Instead of simply having to find the
right data in RAM when it is not found in the cache, an allocation also must
make a request to the operating system for an available chunk of data and then
reserve it.  The request to the operating system generates quite a lot more
overhead than simply filling a cache—while filling a cache miss is a hardware
routine that is optimized on the motherboard, allocating memory  requires
talking to another process, the kernel, in order to complete.</p>

<p class="author1">To remove the allocations in <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-9</a>, we will
preallocate some scratch space at the beginning of the code and then use only
in-place operations. In-place operations (such as <code class="calibre26">+=</code>, <code class="calibre26">*=</code>, etc.) reuse one
of the inputs as their output.  This means that we don’t need to allocate space
to store the result of the calculation.</p>

<p class="author1">To show this explicitly, we will look at how the <code class="calibre26">id</code> of a <a data-type="indexterm" data-primary="numpy" data-secondary="arrays in" id="idm46122420726648" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">numpy</code> array changes
as we perform operations on it (<a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_inplace_example1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-12</a>).  The <code class="calibre26">id</code> is
a good way of tracking this for <code class="calibre26">numpy</code> arrays, since the <code class="calibre26">id</code> indicates which
section of memory is being referenced. If two <code class="calibre26">numpy</code> arrays have the same <code class="calibre26">id</code>, they are referencing the same section of memory.<sup class="calibre44"><a data-type="noteref" id="idm46122420722136-marker" href="ch06_split_001.xhtml#idm46122420722136" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">10</a></sup></p>
<div data-type="example" id="matrix_numpy_inplace_example1" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-12. </span>In-place operations reducing memory allocations</h5>
<pre data-type="programlisting" data-code-language="pycon" class="calibre59"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code><code class="calibre26"> </code><code class="nn">numpy</code><code class="calibre26"> </code><code class="kn">as</code><code class="calibre26"> </code><code class="nn">np</code><code class="calibre26">
</code><code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">)</code><code class="p">)</code><code class="calibre26">
</code><code class="gp">&gt;&gt;&gt; </code><code class="n">array2</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">10</code><code class="p">)</code><code class="p">)</code><code class="calibre26">
</code><code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code><code class="calibre26">
</code><code class="go">140199765947424  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-1a" href="ch06_split_000.xhtml#CO9-1a_list"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code><code class="calibre26">
</code><code class="go">140199765947424  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-2a" href="ch06_split_000.xhtml#CO9-2a_list"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="gp">&gt;&gt;&gt; </code><code class="nb">id</code><code class="p">(</code><code class="n">array1</code><code class="p">)</code><code class="calibre26">
</code><code class="go">140199765969792  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-3a" href="ch06_split_000.xhtml#CO9-3a_list"><img src="Images/3.png" alt="1" class="calibre74"/></a></pre>
</div>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-1a_list" href="ch06_split_000.xhtml#CO9-1a"><img src="Images/1.png" alt="1" class="calibre74"/></a>, <a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-2a_list" href="ch06_split_000.xhtml#CO9-2a"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">    These two <code class="calibre26">id</code>s are the same, since we are doing an in-place operation.  This means that the memory address of <code class="calibre26">array1</code> does not change; we are simply changing the data contained within it.</p>
</dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="CO9-3a_list" href="ch06_split_000.xhtml#CO9-3a"><img src="Images/3.png" alt="3" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">Here, the memory address has changed.  When doing <code class="calibre26">array1 + array2</code>, a new memory address is allocated and filled with the result of the computation.  This does have benefits, however, for when the original data needs to be preserved (i.e., <code class="calibre26">array3 = array1 + array2</code> allows you to keep using <code class="calibre26">array1</code> and <code class="calibre26">array2</code>, while in-place operations destroy some of the original data).</p>
</dd>
</dl>

<p class="author1">Furthermore, we can see an expected slowdown from the non-in-place operation. In
<a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_inplace_benchmark" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-13</a>, we see that using in-place operations gives
us a 27% speedup for an array of 100 × 100 elements. This margin will become
larger as the arrays grow, since the memory allocations become more strenuous.
However, it is important to note that this effect happens only when the array
sizes are bigger than the CPU cache! When the arrays are smaller and the two
inputs and the output can all fit into cache, the out-of-place operation is
faster because it can benefit from vectorization.</p>
<div id="matrix_numpy_inplace_benchmark" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-13. </span>Runtime differences between in-place and out-of-place operations</h5>

<pre data-type="programlisting" data-code-language="pycon" class="calibre59"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code><code class="calibre26"> </code><code class="nn">numpy</code><code class="calibre26"> </code><code class="kn">as</code><code class="calibre26"> </code><code class="nn">np</code><code class="calibre26">
</code><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="o">%</code><code class="n">timeit</code><code class="calibre26"> </code><code class="n">array1</code><code class="p">,</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">100</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO5-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO5-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26"> </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO5-2" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO5-3"><img src="Images/3.png" alt="3" class="calibre74"/></a><code class="calibre26">
</code><code class="gp">... </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="go">6.45 µs ± 53.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
</code><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="o">%</code><code class="n">timeit</code><code class="calibre26"> </code><code class="n">array1</code><code class="p">,</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">100</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO5-3" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO5-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="gp">... </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="go">5.06 µs ± 78.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
</code><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="o">%</code><code class="n">timeit</code><code class="calibre26"> </code><code class="n">array1</code><code class="p">,</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">)</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO5-4" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO5-2"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="gp">... </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="go">518 ns ± 4.88 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
</code><code class="go">
</code><code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="o">%</code><code class="n">timeit</code><code class="calibre26"> </code><code class="n">array1</code><code class="p">,</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">random</code><code class="p">(</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">)</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO5-5" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO5-2"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="gp">... </code><code class="n">array1</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">array2</code><code class="calibre26">
</code><code class="go">1.18 µs ± 6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO5-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO5-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">These arrays are too big to fit into the CPU cache, and the in-place operation is faster because of fewer allocations and cache misses.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO5-2" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO5-4"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">These arrays easily fit into cache, and we see the out-of-place operations as faster.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO5-3" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO5-2"><img src="Images/3.png" alt="3" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">Note that we use <code class="calibre26">%%timeit</code> instead of <code class="calibre26">%timeit</code>, which allows us to specify code to set up the experiment that doesn’t get timed.</p></dd>
</dl></div>

<p class="author1">The downside is that while rewriting our code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-9</a> to use
in-place operations is not very complicated, it does make the resulting code
a bit harder to read.  In <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>, we can see the results of
this refactoring.  We instantiate <code class="calibre26">grid</code> and <code class="calibre26">next_grid</code> vectors, and we constantly
swap them with each other.  <code class="calibre26">grid</code> is the current information we know about the
system, and after running <code class="calibre26">evolve</code>, <code class="calibre26">next_grid</code> contains the updated information.</p>
<div id="matrix_numpy_memory1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-14. </span>Making most <code class="calibre26">numpy</code> operations in-place</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code><code class="calibre26"> </code><code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">np</code><code class="o">.</code><code class="n">copyto</code><code class="p">(</code><code class="n">out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">grid</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">*</code><code class="o">=</code><code class="calibre26"> </code><code class="o">-</code><code class="mi">4</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">+</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">-</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">+</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">-</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">*</code><code class="o">=</code><code class="calibre26"> </code><code class="n">D</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">dt</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">out</code><code class="calibre26"> </code><code class="o">+</code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">next_grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_low</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.4</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_high</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.5</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="p">[</code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">,</code><code class="calibre26"> </code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">]</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0.005</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">start</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0.1</code><code class="p">,</code><code class="calibre26"> </code><code class="n">next_grid</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">next_grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">next_grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">grid</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_matrix_and_vector_computation_CO6-1" href="ch06_split_000.xhtml#callout_matrix_and_vector_computation_CO6-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code class="calibre26"> </code><code class="o">-</code><code class="calibre26"> </code><code class="n">start</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_matrix_and_vector_computation_CO6-1" href="ch06_split_000.xhtml#co_matrix_and_vector_computation_CO6-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">Since the output of <code class="calibre26">evolve</code> gets stored in the output vector <code class="calibre26">next_grid</code>, we must swap these two variables so that, for the next iteration of the loop, <code class="calibre26">grid</code> has the most up-to-date information.  This swap operation is quite cheap because only the references to the data are changed, not the data itself.</p></dd>
</dl></div>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">It is important to remember that since we want each operation to be in-place,
whenever we do a vector operation, we must put it on its own line.  This can
make something as simple as <code class="calibre26">A = A * B + C</code> become quite convoluted.  Since
Python has a heavy emphasis on readability, we should make sure that the changes
we have made give us sufficient speedups to be justified.</p>
</div>

<p class="author1">Comparing the performance metrics from Examples <a href="ch06_split_001.xhtml#matrix_numpy_memory1_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-15</a> and
<a href="ch06_split_000.xhtml#matrix_perf_numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-10</a>, we see that <span class="publishername">removing</span> the spurious allocations sped up our code
by 30.9%.  This speedup comes partly from a reduction in the number of cache misses but
mostly from a reduction in minor faults. This comes from reducing the number of
memory allocations necessary in the code by reusing already allocated space.</p>

<p class="author1">Minor faults are caused when a program accesses newly allocated space in memory.
Since memory addresses are lazily allocated by the kernel, when you first access
newly allocated data, the kernel pauses your execution while it
makes sure that the required space exists and creates references to it for the
program to use. This added machinery is quite expensive to run and can slow a
program down substantially. On top of those additional operations that need
to be run, we also lose any state that we had in cache and any possibility of doing
instruction pipelining. In essence, we have to drop everything we’re doing,
including all associated optimizations, in order to go out and allocate some
memory.<a data-type="indexterm" data-primary="" data-startref="ipo_ab" id="idm46122419767096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mvc_mai" id="idm46122419766120" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ma_abt" id="idm46122419765176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="nu_mai" id="idm46122419764232" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_mai" id="idm46122419763288" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Matrix and Vector Computation" class="calibre3">
<div class="preface" id="matrix_computation">
<section data-type="sect1" data-pdf-bookmark="Applying numpy to the Diffusion Problem" class="calibre3">
<div class="preface" id="idm46122420433944">
<section data-type="sect2" data-pdf-bookmark="Memory Allocations and In-Place Operations" class="calibre3">
<div class="preface" id="SEC-numpy-inplace">
<div data-type="example" id="matrix_numpy_memory1_perf" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-15. </span>Performance metrics for <code class="calibre26">numpy</code> with in-place memory operations (grid size: 640 × 640, 500 iterations)</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_numpy_memory.py</strong>


 Performance counter stats for 'python diffusion_numpy_memory.py':

     6,880,906,446      cycles                    #    2.886 GHz
     5,848,134,537      instructions              #    0.85  insn per cycle
     1,077,550,720      cache-references          #  452.000 M/sec
       217,974,413      cache-misses              #   20.229 % of all cache refs
     1,028,769,315      branches                  #  431.538 M/sec
         7,492,245      branch-misses             #    0.73% of all branches
       2383.962679      task-clock (msec)         #    1.373 CPUs utilized
            13,521      faults                    #    0.006 M/sec
            13,521      minor-faults              #    0.006 M/sec
               100      cs                        #    0.042 K/sec
                 8      migrations                #    0.003 K/sec

       1.736322099 seconds time elapsed

</pre>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Selective Optimizations: Finding What Needs to Be Fixed" class="calibre3"><div class="preface" id="matrix_selective_optimizations">
<h2 class="calibre43">Selective Optimizations: Finding What Needs to Be Fixed</h2>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="selective optimization" id="mvc_so" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="selective optimization" id="nu_so" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="selective optimization" id="so_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="selective optimization" id="vmc_so" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Looking at the code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>, it
seems like we have addressed most of the issues at hand: we have reduced the CPU
burden by using <code class="calibre26">numpy</code>, and we have reduced the number of allocations necessary
to solve the problem.  However, there is always more investigation to be done.
If we do a line profile on that code (<a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_memory_lineprof" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-16</a>), we see
that the majority of our work is done within the<a data-type="indexterm" data-primary="laplacian function" id="idm46122419749016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">laplacian</code> function.  In fact,
84% of the time that <code class="calibre26">evolve</code> takes to run is spent in <code class="calibre26">laplacian</code>.</p>
<div id="matrix_numpy_memory_lineprof" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-16. </span>Line profiling shows that <code class="calibre26">laplacian</code> is taking too much time</h5>

<pre data-type="programlisting" class="calibre59">Wrote profile results to diffusion_numpy_memory.py.lprof
Timer unit: 1e-06 s

Total time: 1.58502 s
File: diffusion_numpy_memory.py
Function: evolve at line 21

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    21                                           @profile
    22                                           def evolve(grid, dt, out, D=1):
    23       500    1327910.0   2655.8     83.8      laplacian(grid, out)
    24       500     100733.0    201.5      6.4      out *= D * dt
    25       500     156377.0    312.8      9.9      out += grid</pre></div>

<p class="author1">There could be many reasons <code class="calibre26">laplacian</code> is so slow. However, there are two
main high-level issues to consider.  First, it looks like the calls to <code class="calibre26">np.roll</code>
are allocating new vectors (we can verify this by looking at the documentation
for the function).  This means that even though we removed seven memory
allocations in our previous refactoring, four outstanding
allocations remain.  Furthermore, <code class="calibre26">np.roll</code> is a very generalized function that has a
lot of code to deal with special cases.  Since we know exactly what we want to
do (move just the first column of data to be the last in every dimension), we
can rewrite this function to eliminate most of the spurious code.  We could even
merge the <code class="calibre26">np.roll</code> logic with the add operation that happens with the <span class="publishername">rolled</span>
data to make a very specialized <code class="calibre26">roll_add</code> function that does exactly what we
want with the fewest number of allocations and the least extra logic.</p>

<p class="author1"><a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_memory2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-17</a> shows what this refactoring would look like.  All we
need to do is create our new <code class="calibre26">roll_add</code> function and have <code class="calibre26">laplacian</code> use it.
Since <code class="calibre26">numpy</code> supports fancy indexing, implementing such a function is just a
matter of not jumbling up the indices.  However, as stated earlier, while this
code may be more performant, it is much less readable.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">Notice the extra work that has gone into having an informative docstring for the
function, in addition to full tests.  When you are taking a route similar to this
one, it is important to maintain the readability of the code, and these steps go
a long way toward making sure that your code is always doing what it was intended to do
and that future programmers can modify your code and know what things do and
when things are not working.<a data-type="indexterm" data-primary="roll function" id="idm46122419735944" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="roll function" id="idm46122419735240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
<div id="matrix_numpy_memory2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-17. </span>Creating our own <code class="calibre26">roll</code> function</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>


<code class="kn">def</code> <code class="nf">roll_add</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    Given a matrix, a rollee, and an output matrix, out, this function will</code>
<code class="sd">    perform the calculation:</code>

<code class="sd">        &gt;&gt;&gt; out += np.roll(rollee, shift, axis=axis)</code>

<code class="sd">    This is done with the following assumptions:</code>
<code class="sd">        * rollee is 2D</code>
<code class="sd">        * shift will only ever be +1 or -1</code>
<code class="sd">        * axis will only ever be 0 or 1 (also implied by the first assumption)</code>

<code class="sd">    Using these assumptions, we are able to speed up this function by avoiding</code>
<code class="sd">    extra machinery that numpy uses to generalize the roll function and also</code>
<code class="sd">    by making this operation intrinsically in-place.</code>
<code class="sd">    """</code>
    <code class="kn">if</code> <code class="n">shift</code> <code class="o">==</code> <code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[</code><code class="mi">1</code><code class="p">:,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code>
        <code class="n">out</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code>
    <code class="kn">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="o">-</code><code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="mi">1</code><code class="p">:,</code> <code class="p">:]</code>
        <code class="n">out</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="p">:]</code>
    <code class="kn">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">:]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="o">-</code><code class="mi">1</code><code class="p">]</code>
    <code class="kn">elif</code> <code class="n">shift</code> <code class="o">==</code> <code class="o">-</code><code class="mi">1</code> <code class="ow">and</code> <code class="n">axis</code> <code class="o">==</code> <code class="mi">1</code><code class="p">:</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">:]</code>
        <code class="n">out</code><code class="p">[:,</code> <code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">+=</code> <code class="n">rollee</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">]</code>


<code class="kn">def</code> <code class="nf">test_roll_add</code><code class="p">():</code>
    <code class="n">rollee</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">asarray</code><code class="p">([[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">],</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">]])</code>
    <code class="kn">for</code> <code class="n">shift</code> <code class="ow">in</code> <code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">):</code>
        <code class="kn">for</code> <code class="n">axis</code> <code class="ow">in</code> <code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">):</code>
            <code class="n">out</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">asarray</code><code class="p">([[</code><code class="mi">6</code><code class="p">,</code> <code class="mi">3</code><code class="p">],</code> <code class="p">[</code><code class="mi">9</code><code class="p">,</code> <code class="mi">2</code><code class="p">]])</code>
            <code class="n">expected_result</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">roll</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="n">axis</code><code class="p">)</code> <code class="o">+</code> <code class="n">out</code>
            <code class="n">roll_add</code><code class="p">(</code><code class="n">rollee</code><code class="p">,</code> <code class="n">shift</code><code class="p">,</code> <code class="n">axis</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
            <code class="kn">assert</code> <code class="n">np</code><code class="o">.</code><code class="n">all</code><code class="p">(</code><code class="n">expected_result</code> <code class="o">==</code> <code class="n">out</code><code class="p">)</code>


<code class="kn">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="n">np</code><code class="o">.</code><code class="n">copyto</code><code class="p">(</code><code class="n">out</code><code class="p">,</code> <code class="n">grid</code><code class="p">)</code>
    <code class="n">out</code> <code class="o">*=</code> <code class="o">-</code><code class="mi">4</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">+</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code>
    <code class="n">roll_add</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">out</code><code class="p">)</code></pre></div>

<p class="author1">If we look at the performance counters in <a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_memory2_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-18</a> for this
rewrite, we see that while it is 22% faster than <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>, most
of the counters are about the same.  The major difference again is
<code class="calibre26">cache-misses</code>, which is down 7×. This change also seems to have affected the
throughput of instructions to the CPU, increasing the instructions per cycle
from 0.85 to 0.99 (a 14% gain). Similarly, the faults went down 12.85%. This seems
to be a result of first doing the rolls in place as well as reducing the
amount of <code class="calibre26">numpy</code> machinery that needs to be in-place to do all of our desired
computation. Instead of first rolling our array, doing other computation
required by <code class="calibre26">numpy</code> in order to do bounds checking and error handling, and then adding
the result, we are doing it all in one shot and not requiring the computer to
refill the cache every time.  This theme of trimming out unnecessary machinery
in both <code class="calibre26">numpy</code> and Python in general will continue in
<a data-type="xref" href="ch07.xhtml#compiling-cython" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Cython”</a>.</p>
<div data-type="example" id="matrix_numpy_memory2_perf" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-18. </span>Performance metrics for <code class="calibre26">numpy</code> with in-place memory operations and custom
<code class="calibre26">laplacian</code> function (grid size: 640 × 640, 500 iterations)</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_numpy_memory2.py</strong>


 Performance counter stats for 'python diffusion_numpy_memory2.py':

     5,971,464,515      cycles                    #    2.888 GHz
     5,893,131,049      instructions              #    0.99  insn per cycle
     1,001,582,133      cache-references          #  484.398 M/sec
        30,840,612      cache-misses              #    3.079 % of all cache refs
     1,038,649,694      branches                  #  502.325 M/sec
         7,562,009      branch-misses             #    0.73% of all branches
       2067.685884      task-clock (msec)         #    1.456 CPUs utilized
            11,981      faults                    #    0.006 M/sec
            11,981      minor-faults              #    0.006 M/sec
                95      cs                        #    0.046 K/sec
                 3      migrations                #    0.001 K/sec

       1.419869071 seconds time elapsed

</pre>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="numexpr: Making In-Place Operations Faster and Easier" class="calibre3"><div class="preface" id="matrix_vector_numexpr">
<h1 class="calibre25">numexpr: Making In-Place Operations Faster and Easier</h1>

<p class="author1"><a data-type="indexterm" data-primary="in-place operations" id="ipo_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="memory allocations and in-place operations" id="mvc_maio" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory allocations" id="ma_about" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="NumExpr" id="nume_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="memory allocations and in-place operations" id="vmc_maio" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>One downfall of <code class="calibre26">numpy</code>’s
optimization of vector operations is that it occurs on only one operation at a
time.  That is to say, when we are doing the operation <code class="calibre26">A * B + C</code> with
<code class="calibre26">numpy</code> vectors, first the entire <code class="calibre26">A * B</code> operation completes, and the data is
stored in a temporary vector; then this new vector is added with <code class="calibre26">C</code>.  The
in-place version of the diffusion code in <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a> shows this
quite explicitly.</p>

<p class="author1">However, many modules can help with this. <code class="calibre26">numexpr</code> is a module
that can take an entire vector expression and compile it into very efficient
code that is optimized to minimize cache misses and temporary space used.  In
addition, the expressions can utilize multiple CPU cores (see
<a data-type="xref" href="ch09_split_000.xhtml#multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 9</a> for more information) and take advantage of the specialized
instructions your CPU may support in order to get even greater speedups. It even
supports OpenMP, which parallels out operations across multiple cores on your
machine.</p>

<p class="author1">It is very easy to change code to use <code class="calibre26">numexpr</code>: all that’s required is to
rewrite the expressions as strings with references to local variables.  The
expressions are compiled behind the scenes (and cached so that calls to the same
expression don’t incur the same cost of compilation) and run using optimized
code.  <a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_numexpr" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-19</a> shows the simplicity of changing the <code class="calibre26">evolve</code>
function to use <code class="calibre26">numexpr</code>.  In this case, we chose to use the <code class="calibre26">out</code> parameter of
the <code class="calibre26">evaluate</code> function so that <code class="calibre26">numexpr</code> doesn’t allocate a new vector to which
to return the result of the calculation.</p>
<div id="matrix_numpy_numexpr" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-19. </span>Using <code class="calibre26">numexpr</code> to further optimize large matrix operations</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">numexpr</code> <code class="kn">import</code> <code class="n">evaluate</code>

<code class="kn">def</code> <code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">next_grid</code><code class="p">,</code> <code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code><code class="p">)</code>
    <code class="n">evaluate</code><code class="p">(</code><code class="s">"next_grid * D * dt + grid"</code><code class="p">,</code> <code class="n">out</code><code class="o">=</code><code class="n">next_grid</code><code class="p">)</code></pre></div>

<p class="author1">An important feature of <code class="calibre26">numexpr</code> is its consideration of CPU caches.  It
specifically moves data around so that the various CPU caches have the correct
data in order to minimize cache misses.  When we run <code class="calibre26">perf</code> on the updated code
(<a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_numexpr_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-20</a>), we see a speedup.  However, if we look at the
performance on a smaller, 256 × 256 grid, we see a decrease in speed (see
<a data-type="xref" href="ch06_split_001.xhtml#matrix_table_speedup_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Table 6-2</a>).  Why is this?</p>
<div data-type="example" id="matrix_numpy_numexpr_perf" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-20. </span>Performance metrics for <code class="calibre26">numpy</code> with in-place memory operations, custom
<code class="calibre26">laplacian</code> function, and <code class="calibre26">numexpr</code> (grid size: 640 × 640, 500 iterations)</h5>
<pre data-type="programlisting" class="calibre59">$ perf <strong class="calibre83">stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_numpy_memory2_numexpr.py</strong>


 Performance counter stats for 'python diffusion_numpy_memory2_numexpr.py':

     8,856,947,179      cycles                    #    2.872 GHz
     9,354,357,453      instructions              #    1.06  insn per cycle
     1,077,518,384      cache-references          #  349.423 M/sec
        59,407,830      cache-misses              #    5.513 % of all cache refs
     1,018,525,317      branches                  #  330.292 M/sec
        11,941,430      branch-misses             #    1.17% of all branches
       3083.709890      task-clock (msec)         #    1.991 CPUs utilized
            15,820      faults                    #    0.005 M/sec
            15,820      minor-faults              #    0.005 M/sec
             8,671      cs                        #    0.003 M/sec
             2,096      migrations                #    0.680 K/sec

       1.548924090 seconds time elapsed

</pre>
</div>

<p class="author1">Much of the extra machinery we are bringing into our program with <code class="calibre26">numexpr</code>
deals with cache considerations.  When our grid size is small and all the data
we need for our calculations fits in the cache, this extra machinery simply adds
more instructions that don’t help performance.  In addition, compiling the
vector operation that we encoded as a string adds a large overhead.  When the
total runtime of the program is small, this overhead can be quite noticeable.
However, as we increase the grid size, we should expect to see <code class="calibre26">numexpr</code>
utilize our cache better than native <code class="calibre26">numpy</code> does.  In addition, <code class="calibre26">numexpr</code>
utilizes multiple cores to do its calculation and tries to saturate each of the
cores’ caches.  When the size of the grid is small, the extra overhead of
managing the multiple cores overwhelms any possible increase in speed.</p>

<p class="author1">The particular computer we are running the code on has a 8,192 KB cache
(Intel Core i7-7820HQ).  Since we are operating on two arrays, one for
input and one for output, we can easily do the calculation for the size of the
grid that will fill up our cache.  The number of grid elements we can store in
total is 8,192 KB / 64 bit = 1,024,000.  Since we have two grids, this number is
split between two objects (so each one can be at most 1,024,000 / 2 = 512,000
elements).  Finally, taking the square root of this number gives us the size of
the grid that uses that many grid elements.  All in all, this means that
approximately two 2D arrays of size 715 × 715 would fill up the cache
(<math alttext="StartRoot 8192 upper K upper B slash 64 b i t slash 2 EndRoot equals 715.5">
  <mrow>
    <msqrt>
      <mrow>
        <mn>8192</mn>
        <mi>K</mi>
        <mi>B</mi>
        <mo>/</mo>
        <mn>64</mn>
        <mi>b</mi>
        <mi>i</mi>
        <mi>t</mi>
        <mo>/</mo>
        <mn>2</mn>
      </mrow>
    </msqrt>
    <mo>=</mo>
    <mn>715</mn>
    <mo>.</mo>
    <mn>5</mn>
  </mrow>
</math>).  In practice, however, we
do not get to fill up the cache ourselves (other programs will fill up parts of
the cache), so realistically we can probably fit two 640 × 640 arrays.
Looking at Tables <a href="ch06_split_001.xhtml#matrix_table_runtime_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-1</a> and
<a href="ch06_split_001.xhtml#matrix_table_speedup_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-2</a>, we see that when the grid size jumps from 512
× 512 to 1,024 × 1,024, the <code class="calibre26">numexpr</code> code starts to outperform pure<a data-type="indexterm" data-primary="" data-startref="ipo_abt" id="idm46122419219912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mvc_maio" id="idm46122419218936" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ma_about" id="idm46122419217992" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="nume_ab" id="idm46122419217048" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_maio" id="idm46122419216104" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<code class="calibre26">numpy</code>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="A Cautionary Tale: Verify “Optimizations” (scipy)" class="calibre3"><div class="preface" id="idm46122419368392">
<h1 class="calibre25">A Cautionary Tale: Verify “Optimizations” (scipy)</h1>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="verifying optimizations" id="idm46122419321144" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="verifying optimizations" id="idm46122419320200" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>An important
thing to take away from this chapter is the approach we took to every
optimization: profile the code to get a sense of what is going on, come up with
a possible solution to fix slow parts, and then profile to make sure the fix
actually worked.  Although this sounds straightforward, things can get
complicated quickly, as we saw in how the performance of <code class="calibre26">numexpr</code> depended
greatly on the size of the grid we were considering.</p>

<p class="author1">Of course, our proposed solutions don’t always work as expected.  While writing
the code for this chapter, we saw that the<a data-type="indexterm" data-primary="laplacian function" id="idm46122419317784" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">laplacian</code> function was the
slowest routine and hypothesized that the <a data-type="indexterm" data-primary="SciPy" id="idm46122419316536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">scipy</code> routine would be considerably
faster.  This thinking came from the fact that Laplacians are a common operation
in image analysis and probably have a very optimized library to speed up the
calls.  <code class="calibre26">scipy</code> has an image submodule, so we must be in luck!</p>

<p class="author1">The implementation was quite simple (<a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_scipy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-21</a>) and required little
thought about the intricacies of implementing the periodic boundary conditions
(or “wrap” condition, as <code class="calibre26">scipy</code> calls it).</p>
<div id="matrix_numpy_scipy" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-21. </span>Using <code class="calibre26">scipy</code>’s <code class="calibre26">laplace</code> filter</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">scipy.ndimage.filters</code> <code class="kn">import</code> <code class="n">laplace</code>

<code class="kn">def</code> <code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">):</code>
    <code class="n">laplace</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">out</code><code class="p">,</code> <code class="n">mode</code><code class="o">=</code><code class="s">"wrap"</code><code class="p">)</code></pre></div>

<p class="author1">Ease of implementation is quite important and definitely won this method some
points before we considered performance.  However, once we benchmarked the
<code class="calibre26">scipy</code> code (<a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_scipy_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-22</a>), we had a revelation: this method
offers no substantial speedup compared to the code it is based on
(<a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>).  In fact, as we increase the grid size, this method
starts performing worse (see <a data-type="xref" href="ch06_split_001.xhtml#matrix_figure_all_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-4</a> at the end of the
chapter).</p>
<div data-type="example" id="matrix_numpy_scipy_perf" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-22. </span>Performance metrics for diffusion with <code class="calibre26">scipy</code>’s <code class="calibre26">laplace</code> function (grid size: 640 × 640, 500 iterations)</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">perf stat -e cycles,instructions,\
    cache-references,cache-misses,branches,branch-misses,task-clock,faults,\
    minor-faults,cs,migrations python diffusion_scipy.py</strong>


 Performance counter stats for 'python diffusion_scipy.py':

    10,051,801,725      cycles                    #    2.886 GHz
    16,536,981,020      instructions              #    1.65  insn per cycle
     1,554,557,564      cache-references          #  446.405 M/sec
       126,627,735      cache-misses              #    8.146 % of all cache refs
     2,673,416,633      branches                  #  767.696 M/sec
         9,626,762      branch-misses             #    0.36% of all branches
       3482.391211      task-clock (msec)         #    1.228 CPUs utilized
            14,013      faults                    #    0.004 M/sec
            14,013      minor-faults              #    0.004 M/sec
                95      cs                        #    0.027 K/sec
                 5      migrations                #    0.001 K/sec

       2.835263796 seconds time elapsed

</pre>
</div>

<p class="author1">Comparing the performance metrics of the <code class="calibre26">scipy</code> version of the code with those
of our custom <code class="calibre26">laplacian</code> function (<a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_memory2_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-18</a>), we can start
to get some indication as to why we aren’t getting the speedup we were expecting
from this rewrite.</p>

<p class="author1">The metric that stands out the most is <code class="calibre26">instructions</code>. This shows us that the
<code class="calibre26">scipy</code> code is requesting that the CPU do more than double the amount of work as our
custom <code class="calibre26">laplacian</code> code.  Even though these instructions are more numerically
optimized (as we can see with the higher <code class="calibre26">insn per cycle</code> count, which says how
many instructions the CPU can do in one clock cycle), the extra optimization
doesn’t win out over the sheer number of added instructions.</p>

<p class="author1">This could be in part because the <code class="calibre26">scipy</code> code is written very
generally so that it can process all sorts of inputs with different boundary
conditions (which requires extra code and thus more instructions).  We can see
this, in fact, by the high number of <code class="calibre26">branches</code> that the <code class="calibre26">scipy</code> code requires.
When code has many branches, it means that we run commands based on a
condition (like having code inside an <code class="calibre26">if</code> statement). The problem
is that we don’t know whether we can evaluate an expression until we check the
conditional, so vectorizing or pipelining isn’t possible. The machinery of
branch prediction helps with this, but it isn’t perfect. This speaks more to the
point of the speed of specialized code: if you don’t need to constantly check
what you need to do and instead know the specific problem at hand, you can solve
it much more 
<span class="publishername">efficiently</span>.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Lessons from Matrix Optimizations" class="calibre3"><div class="preface" id="idm46122419322120">
<h1 class="calibre25">Lessons from Matrix Optimizations</h1>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="lessons from" id="mvc_lf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="lessons from" id="vmc_lf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Looking back on our optimizations, we seem to have taken
two main routes: reducing the time taken to get data to the CPU and reducing the
amount of work that the CPU had to do. Tables <a href="ch06_split_001.xhtml#matrix_table_runtime_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-1</a> and
<a href="ch06_split_001.xhtml#matrix_table_speedup_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">6-2</a> compare of the results achieved by our various optimization efforts, for
various dataset sizes, in relation to the original pure Python <span class="publishername">implementation</span>.</p>

<p class="author1"><a data-type="xref" href="ch06_split_001.xhtml#matrix_figure_all_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-4</a> shows graphically how all these methods compared to
one another. We can see three bands of performance that correspond to these two
methods:  the band along the bottom shows the small improvement made in relation
to our pure Python implementation by our first effort at reducing memory
allocations; the middle band shows what happened when we used <code class="calibre26">numpy</code> and
further reduced allocations; and the upper band illustrates the results achieved
by reducing the work done by our process.</p>
<table id="matrix_table_runtime_perf" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 6-1. </span>Total runtime of all schemes for various grid sizes and 500 iterations of the <code class="calibre86">evolve</code> function</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89">Method</th>
<th class="calibre89">256 x 256</th>
<th class="calibre89">512 x 512</th>
<th class="calibre89">1024 x 1024</th>
<th class="calibre89">2048 x 2048</th>
<th class="calibre89">4096 x 4096</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_pure_python_run" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Python</a></p></td>
<td class="calibre16"><p class="calibre17">2.40s</p></td>
<td class="calibre16"><p class="calibre17">10.43s</p></td>
<td class="calibre16"><p class="calibre17">41.75s</p></td>
<td class="calibre16"><p class="calibre17">168.82s</p></td>
<td class="calibre16"><p class="calibre17">679.16s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Python + memory</a></p></td>
<td class="calibre16"><p class="calibre17">2.26s</p></td>
<td class="calibre16"><p class="calibre17">9.76s</p></td>
<td class="calibre16"><p class="calibre17">38.85s</p></td>
<td class="calibre16"><p class="calibre17">157.25s</p></td>
<td class="calibre16"><p class="calibre17">632.76s</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy</a></p></td>
<td class="calibre16"><p class="calibre17">0.01s</p></td>
<td class="calibre16"><p class="calibre17">0.09s</p></td>
<td class="calibre16"><p class="calibre17">0.69s</p></td>
<td class="calibre16"><p class="calibre17">3.77s</p></td>
<td class="calibre16"><p class="calibre17">14.83s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory</a></p></td>
<td class="calibre16"><p class="calibre17">0.01s</p></td>
<td class="calibre16"><p class="calibre17">0.07s</p></td>
<td class="calibre16"><p class="calibre17">0.60s</p></td>
<td class="calibre16"><p class="calibre17">3.80s</p></td>
<td class="calibre16"><p class="calibre17">14.97s</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_memory2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + laplacian</a></p></td>
<td class="calibre16"><p class="calibre17">0.01s</p></td>
<td class="calibre16"><p class="calibre17">0.05s</p></td>
<td class="calibre16"><p class="calibre17">0.48s</p></td>
<td class="calibre16"><p class="calibre17">1.86s</p></td>
<td class="calibre16"><p class="calibre17">7.50s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_numexpr" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + laplacian + numexpr</a></p></td>
<td class="calibre16"><p class="calibre17">0.02s</p></td>
<td class="calibre16"><p class="calibre17">0.06s</p></td>
<td class="calibre16"><p class="calibre17">0.41s</p></td>
<td class="calibre16"><p class="calibre17">1.60s</p></td>
<td class="calibre16"><p class="calibre17">6.45s</p></td>
</tr>
<tr class="calibre19">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_scipy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + scipy</a></p></td>
<td class="calibre16"><p class="calibre17">0.05s</p></td>
<td class="calibre16"><p class="calibre17">0.25s</p></td>
<td class="calibre16"><p class="calibre17">1.15s</p></td>
<td class="calibre16"><p class="calibre17">6.83s</p></td>
<td class="calibre16"><p class="calibre17">91.43s</p></td>
</tr>
</tbody>
</table>
<table id="matrix_table_speedup_perf" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 6-2. </span>Speedup compared to naive Python (<a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-3</a>) for all schemes and various grid sizes over 500 iterations of the <code class="calibre86">evolve</code> function</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89">Method</th>
<th class="calibre89">256 x 256</th>
<th class="calibre89">512 x 512</th>
<th class="calibre89">1024 x 1024</th>
<th class="calibre89">2048 x 2048</th>
<th class="calibre89">4096 x 4096</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_pure_python_run" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Python</a></p></td>
<td class="calibre16"><p class="calibre17">1.00x</p></td>
<td class="calibre16"><p class="calibre17">1.00x</p></td>
<td class="calibre16"><p class="calibre17">1.00x</p></td>
<td class="calibre16"><p class="calibre17">1.00x</p></td>
<td class="calibre16"><p class="calibre17">1.00x</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Python + memory</a></p></td>
<td class="calibre16"><p class="calibre17">1.06x</p></td>
<td class="calibre16"><p class="calibre17">1.07x</p></td>
<td class="calibre16"><p class="calibre17">1.07x</p></td>
<td class="calibre16"><p class="calibre17">1.07x</p></td>
<td class="calibre16"><p class="calibre17">1.07x</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy</a></p></td>
<td class="calibre16"><p class="calibre17">170.59x</p></td>
<td class="calibre16"><p class="calibre17">116.16x</p></td>
<td class="calibre16"><p class="calibre17">60.49x</p></td>
<td class="calibre16"><p class="calibre17">44.80x</p></td>
<td class="calibre16"><p class="calibre17">45.80x</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory</a></p></td>
<td class="calibre16"><p class="calibre17">185.97x</p></td>
<td class="calibre16"><p class="calibre17">140.10x</p></td>
<td class="calibre16"><p class="calibre17">69.67x</p></td>
<td class="calibre16"><p class="calibre17">44.43x</p></td>
<td class="calibre16"><p class="calibre17">45.36x</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_memory2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + laplacian</a></p></td>
<td class="calibre16"><p class="calibre17">203.66x</p></td>
<td class="calibre16"><p class="calibre17">208.15x</p></td>
<td class="calibre16"><p class="calibre17">86.41x</p></td>
<td class="calibre16"><p class="calibre17">90.91x</p></td>
<td class="calibre16"><p class="calibre17">90.53x</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_numexpr" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + laplacian + numexpr</a></p></td>
<td class="calibre16"><p class="calibre17">97.41x</p></td>
<td class="calibre16"><p class="calibre17">167.49x</p></td>
<td class="calibre16"><p class="calibre17">102.38x</p></td>
<td class="calibre16"><p class="calibre17">105.69x</p></td>
<td class="calibre16"><p class="calibre17">105.25x</p></td>
</tr>
<tr class="calibre19">
<td class="calibre16"><p class="calibre17"><a href="ch06_split_001.xhtml#matrix_numpy_scipy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">numpy + memory + scipy</a></p></td>
<td class="calibre16"><p class="calibre17">52.27x</p></td>
<td class="calibre16"><p class="calibre17">42.00x</p></td>
<td class="calibre16"><p class="calibre17">36.44x</p></td>
<td class="calibre16"><p class="calibre17">24.70x</p></td>
<td class="calibre16"><p class="calibre17">7.43x</p></td>
</tr>
</tbody>
</table>

<p class="author1">One important lesson to take away from this is that you should always take care
of any administrative things the code must do during initialization.  This may
include allocating memory, or reading configuration from a file, or even
precomputing values that will be needed throughout the lifetime of the
program.  This is important for two reasons. First, you are reducing the total
number of times these tasks must be done by doing them once up front, and you
know that you will be able to use those resources without too much penalty in
the future.  Second, you are not disrupting the flow of the program; this
allows it to pipeline more efficiently and keep the caches filled with more
pertinent data.</p>

<p class="author1">You also learned more about the importance of<a data-type="indexterm" data-primary="data locality" id="idm46122419890040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> data locality and how important
simply getting data to the CPU is.  CPU caches can be quite complicated, and
often it is best to allow the various mechanisms designed to optimize them
take care of the issue.  However, understanding what is happening and doing all
that is possible to optimize the way memory is handled can make all the
difference.  For example, by understanding how caches work, we are able to
understand that the decrease in performance that leads to a saturated speedup no
matter the grid size in <a data-type="xref" href="ch06_split_001.xhtml#matrix_figure_all_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-4</a> can probably be attributed to
the L3 cache being filled up by our grid.  When this happens, we stop
benefiting from the tiered memory approach to solving the <a data-type="indexterm" data-primary="Von Neumann bottleneck" id="idm46122419887704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>von Neumann
bottleneck.</p>

<figure class="calibre46"><div id="matrix_figure_all_perf" class="figure">
<img src="Images/hpp2_0604.png" alt="Summary of speedups from the methods attempted in this chapter" class="calibre90"/>
<h6 class="calibre47"><span class="publishername">Figure 6-4. </span>Summary of speedups from the methods attempted in this chapter</h6>
</div></figure>

<p class="author1">Another important lesson concerns the use of<a data-type="indexterm" data-primary="external libraries" id="idm46122419884488" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> external libraries.  Python is
fantastic for its ease of use and readability, which allow you to write and
debug code fast. However, tuning performance down to the external libraries is
essential.  These external libraries can be extremely fast, because they can be
written in lower-level languages—but since they interface with Python, you can
also still write code that uses them quickly.</p>

<p class="author1">Finally, we learned the importance of <a data-type="indexterm" data-primary="benchmarks" id="idm46122419882856" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>benchmarking everything and forming
<a data-type="indexterm" data-primary="hypotheses" id="idm46122419881976" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>hypotheses about performance before running the experiment.  By forming a
hypothesis before running the benchmark, we are able to form conditions to tell
us whether our optimization actually worked.  Was this change able to speed up
runtime?  Did it reduce the number of allocations?  Is the number of cache
misses lower?  Optimization can be an art at times because of the vast
complexity of computer systems, and having a quantitative probe into what is
actually happening can help enormously.</p>

<p class="author1">One last point about optimization is that a lot of care must be taken to make
sure that the optimizations you make generalize to different computers (the
assumptions you make and the results of benchmarks you do may be dependent on
the architecture of the computer you are running on, how the modules you are
using were compiled, etc.).  In addition, when making these optimizations, it is
incredibly important to consider other developers and how the changes will
affect the readability of your code.  For example, we realized that the solution
we implemented in <a data-type="xref" href="ch06_split_001.xhtml#matrix_numpy_memory2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-17</a> was potentially vague, so care was
taken to make sure that the code was fully documented and tested to help not
only us but also other people on the team.</p>

<p class="author1">Sometimes, however, your numerical algorithms also require quite a lot of data
wrangling and manipulation that aren’t just clear-cut mathematical operations. In
these cases, Pandas is a very popular solution, and it has its own performance
characteristics. We’ll now do a deep dive into Pandas and understand how to
better use it to write performant numerical code.<a data-type="indexterm" data-primary="" data-startref="mvc_lf" id="idm46122419877928" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_lf" id="idm46122419876952" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Pandas" class="calibre3"><div class="preface" id="pandas-ols">
<h1 class="calibre25">Pandas</h1>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="Pandas" id="mvc_pa" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="Pandas" id="vmc_pa" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Pandas" data-secondary="about" id="idm46122419871784" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">Pandas</em> is the de facto data manipulation tool in the scientific Python ecosystem
for tabular data. It enables easy manipulation with Excel-like tables of
heterogeneous datatypes, known as <a data-type="indexterm" data-primary="DataFrames" data-secondary="about" id="idm46122419870264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>DataFrames, and has strong support for
time-series operations. Both the public interface and the internal machinery
have evolved a lot since 2008, and there’s a lot of conflicting information in
public forums on “fast ways to solve problems.” In this section, we’ll fix some
misconceptions about common use cases of Pandas.</p>

<p class="author1">We’ll review the internal model for Pandas, find out how to apply a function
efficiently across a DataFrame, see why concatenating to a DataFrame repeatedly
is a poor way to build up a result, and look at faster ways of handling strings.</p>








<section data-type="sect2" data-pdf-bookmark="Pandas’s Internal Model" class="calibre3"><div class="preface" id="idm46122419868040">
<h2 class="calibre43">Pandas’s Internal Model</h2>

<p class="author1"><a data-type="indexterm" data-primary="Pandas" data-secondary="internal model" id="pa_im" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Pandas uses an in-memory, 2D, table-like data structure—if you have in mind an
Excel sheet, you have a good initial mental model. Originally, Pandas focused
on NumPy’s <code class="calibre26">dtype</code> objects such as signed and unsigned numbers for each column.
As the library evolved, it expanded beyond NumPy types and can now handle both Python
strings and extension types (including nullable <code class="calibre26">Int64</code> objects—note the
capital “I”—and IP addresses).</p>

<p class="author1">Operations on a DataFrame apply to all cells in a column (or all cells in a row
if the <code class="calibre26">axis=1</code> parameter is used), all operations are executed eagerly, and
there’s no support for query planning. Operations on columns often generate
temporary intermediate arrays, which consume RAM. The general advice is to expect
a temporary memory usage envelope of up to three to five times your current usage when you’re

<span class="publishername">manipulating</span> your DataFrames. Typically, Pandas works well for datasets under
10 GB in size, assuming you have sufficient RAM for temporary results.</p>

<p class="author1">Operations can be single-threaded and may be limited by <a data-type="indexterm" data-primary="GIL (global interpreter lock)" id="idm46122419861464" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="global interpreter lock (GIL)" id="idm46122419860696" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Python’s global interpreter lock (GIL).
Increasingly, improved internal implementations are allowing the GIL to be
disabled automatically, enabling parallelized operations. We’ll explore an
approach to parallelization with Dask in <a data-type="xref" href="ch10.xhtml#clustering-dask" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Parallel Pandas with Dask”</a>.</p>

<p class="author1">Behind the scenes, columns of the same <code class="calibre26">dtype</code> are grouped together by a
<code class="calibre26">BlockManager</code>. This piece of hidden machinery works to make row-wise operations
on columns of the same datatype faster. It is one of the many hidden technical details
that make the Pandas code base complex but
make the high-level user-facing operations faster.<sup class="calibre44"><a data-type="noteref" id="idm46122419857272-marker" href="ch06_split_001.xhtml#idm46122419857272" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">11</a></sup></p>

<p class="author1">Performing operations on a subset of data from a single common block typically
generates a view, while taking a slice of rows that cross blocks of different
<code class="calibre26">dtypes</code> can cause a copy, which may be slower. One consequence is that while
numeric columns directly reference their NumPy data, string columns reference a
list of Python strings, and these individual strings are scattered in memory—this
can lead to unexpected speed differences for numeric and string operations.</p>

<p class="author1">Behind the scenes, Pandas uses a mix of NumPy datatypes and its own extension
datatypes. Examples from NumPy include<a data-type="indexterm" data-primary="int type" id="idm46122419853720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">int8</code> (1 byte), <code class="calibre26">int64</code> (8 bytes—and note
the lowercase “i”),<a data-type="indexterm" data-primary="float type" id="idm46122419852024" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">float16</code> (2 bytes), <code class="calibre26">float64</code> (8 bytes), and<a data-type="indexterm" data-primary="bool datatype" id="idm46122419850328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">bool</code> (1 byte).
Additional types provided by Pandas include <code class="calibre26">categorical</code> and <code class="calibre26">datetimetz</code>.
Externally, they appear to work similarly, but behind the scenes in the Pandas
code base they cause a lot of type-specific Pandas code and duplication.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Whilst Pandas originally used only<a data-type="indexterm" data-primary="numpy" data-secondary="datatypes in" id="idm46122419847176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">numpy</code> datatypes, it has evolved its own set
of additional Pandas datatypes that understand missing data (NaN) behavior
with three-valued logic. You must distinguish the <code class="calibre26">numpy</code> <code class="calibre26">int64</code>, which is not
NaN-aware, from the Pandas <code class="calibre26">Int64</code>, which uses two columns of data behind the
scenes for the integers and for the NaN bit mask. Note that the <code class="calibre26">numpy</code>
<code class="calibre26">float64</code> is naturally NaN-aware.</p>
</div>

<p class="author1">One side effect of using NumPy’s datatypes has been that, while a <code class="calibre26">float</code> has a
NaN (missing value) state, the same is not true for <code class="calibre26">int</code> and <code class="calibre26">bool</code> objects. If
you introduce a NaN value into an <code class="calibre26">int</code> or <code class="calibre26">bool</code> Series in Pandas, your Series
will be promoted to a <code class="calibre26">float</code>. Promoting <code class="calibre26">int</code> types to a <code class="calibre26">float</code> may reduce the
numeric accuracy that can be represented in the same bits, and the smallest
<code class="calibre26">float</code> is <code class="calibre26">float16</code>, which takes twice as many bytes as a <code class="calibre26">bool</code>.</p>

<p class="author1">The nullable <code class="calibre26">Int64</code> (note the capitalized “I”) was introduced in version 0.24
as an extension type in Pandas. Internally, it uses a NumPy <code class="calibre26">int64</code> and a second
Boolean array as a NaN-mask. Equivalents exist for <code class="calibre26">Int32</code> and <code class="calibre26">Int8</code>. As of
Pandas version 1.0, there is also an equivalent nullable Boolean (with <code class="calibre26">dtype</code>
<code class="calibre26">boolean</code> as opposed to the <code class="calibre26">numpy</code> <code class="calibre26">bool</code>, which isn’t NaN-aware). A
<code class="calibre26">StringDType</code> has been introduced that may in the future offer higher
performance and less memory usage than the standard Python <code class="calibre26">str</code>, which is stored
in a column of <code class="calibre26">object</code> <code class="calibre26">dtype</code>.<a data-type="indexterm" data-primary="" data-startref="pa_im" id="idm46122419831128" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Applying a Function to Many Rows of Data" class="calibre3"><div class="preface" id="idm46122419867544">
<h2 class="calibre43">Applying a Function to Many Rows of Data</h2>

<p class="author1"><a data-type="indexterm" data-primary="Pandas" data-secondary="applying functions to rows of data" id="idm46122419828776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="data" data-secondary="applying functions to rows of" id="idm46122419827832" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="functions, applying to rows of data" data-seealso="specific functions" id="idm46122419826872" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>It is very common to apply functions to rows of data in Pandas. There’s a
selection of approaches, and the idiomatic Python approaches using loops are
generally the slowest. We’ll work through an example based on a real-world
challenge, showing different ways of solving this problem and ending with a
reflection on the trade-off between speed and maintainability.</p>

<p class="author1"><a data-type="indexterm" data-primary="OLS (Ordinary Least Squares)" id="idm46122419825144" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Ordinary Least Squares (OLS)" id="idm46122419824424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">Ordinary Least Squares</em> (OLS) is a bread-and-butter method in data science for fitting
a line to data.  It solves for the slope and intercept in the
<code class="calibre26">m * x + c</code> equation, given some data. This can be incredibly useful when trying to
understand the trend of the data: is it generally increasing, or is it
decreasing?</p>

<p class="author1">An example of its use from our work is a research project for a
telecommunications company where we want to analyze a set of potential
user-behavior signals (e.g., marketing campaigns, demographics, and geographic
behavior). The company has the number of hours a person spends on
their cell phone every day, and its question is: is this person increasing or
decreasing their usage, and how does this change over time?</p>

<p class="author1">One way to approach this problem is to take the company’s large dataset of millions of
users over years of data and break it into smaller windows of data (each
window, for example, representing 14 days out of the years of data). For
each window, we model the users’ use through OLS and record whether they
are increasing or decreasing their usage.</p>

<p class="author1">In the end, we have a sequence for each user showing
whether, for a given 14-day period, their use was generally increasing or
decreasing. However, to get there, we have to run OLS a massive number of
times!</p>

<p class="author1">For one million users and two years of data, we might have 730 windows,<sup class="calibre44"><a data-type="noteref" id="idm46122419819656-marker" href="ch06_split_001.xhtml#idm46122419819656" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">12</a></sup> and thus 730,000,000 calls to OLS! To
solve this problem practically, our OLS implementation should be fairly well tuned.</p>

<p class="author1">In order to understand the performance of various OLS implementations, we will
generate some smaller but representative synthetic data to give us
good indications of what to expect on the larger dataset.  We’ll generate data
for 100,000 rows, each representing a synthetic user, and each containing 14
columns representing “hours used per day” for 14 days, as a continuous
variable.</p>

<p class="author1">We’ll draw from a<a data-type="indexterm" data-primary="Poisson distribution" id="idm46122418918536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> Poisson distribution (with <code class="calibre26">lambda==60</code> as minutes) and divide
by 60 to give us simulated hours of usage as continuous values. The true nature
of the random data doesn’t matter for this experiment; it is convenient to use a
distribution that has a minimum value of 0 as this represents the real-world
minimum. You can see a sample in <a data-type="xref" href="ch06_split_001.xhtml#pandas_ols_data_snippet" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-23</a>.</p>
<div id="pandas_ols_data_snippet" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-23. </span>A snippet of our data</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59">         <code class="mi">0</code>         <code class="mi">1</code>         <code class="mi">2</code>  <code class="o">...</code>       <code class="mi">12</code>        <code class="mi">13</code>
<code class="mi">0</code>  <code class="mi">1.016667</code>  <code class="mi">0.883333</code>  <code class="mi">1.033333</code> <code class="o">...</code>  <code class="mi">1.016667</code>  <code class="mi">0.833333</code>
<code class="mi">1</code>  <code class="mi">1.033333</code>  <code class="mi">1.016667</code>  <code class="mi">0.833333</code> <code class="o">...</code>  <code class="mi">1.133333</code>  <code class="mi">0.883333</code>
<code class="mi">2</code>  <code class="mi">0.966667</code>  <code class="mi">1.083333</code>  <code class="mi">1.183333</code> <code class="o">...</code>  <code class="mi">1.000000</code>  <code class="mi">0.950000</code></pre></div>

<p class="author1">In <a data-type="xref" href="ch06_split_001.xhtml#pandas_random_hours_mobile_phone_usage_3_people" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-5</a>, we see three rows of 14 days
of synthetic data.</p>

<figure class="calibre46"><div id="pandas_random_hours_mobile_phone_usage_3_people" class="figure">
<img src="Images/hpp2_0605.png" alt="Pandas memory grouped into dtype-specific blocks" class="calibre91"/>
<h6 class="calibre47"><span class="publishername">Figure 6-5. </span>Synthetic data for the first three simulated users showing 14 days of cell phone usage</h6>
</div></figure>

<p class="author1">A bonus of generating 100,000 rows of data is that some rows will, by random
variation alone, exhibit “increasing counts,” and some will exhibit “decreasing
counts.” Note that there is no signal behind this in our synthetic data since
the points are drawn independently; simply because we generate many rows of data,
we’re going to see a variance in the ultimate slopes of the lines we calculate.</p>

<p class="author1">This is convenient, as we can identify the “most growing” and “most declining”
lines and draw them as a validation that we’re identifying the sort of signal we
hope to export on the real-world problem.
<a data-type="xref" href="ch06_split_001.xhtml#pandas_random_hours_mobile_min_max_slopes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 6-6</a> shows two of our random traces
with maximal and minimal slopes (<code class="calibre26">m</code>).</p>

<figure class="calibre46"><div id="pandas_random_hours_mobile_min_max_slopes" class="figure">
<img src="Images/hpp2_0606.png" alt="Pandas memory grouped into dtype-specific blocks" class="calibre92"/>
<h6 class="calibre47"><span class="publishername">Figure 6-6. </span>The “most increasing” and “most decreasing” usage in our randomly generated dataset</h6>
</div></figure>

<p class="author1">We’ll start with scikit-learn’s <a data-type="indexterm" data-primary="LinearRegression estimator" id="idm46122418879816" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">LinearRegression</code> estimator to calculate each <code class="calibre26">m</code>. While this method is correct, we’ll see
in the following section that it incurs a surprising overhead against another approach.</p>










<section data-type="sect3" data-pdf-bookmark="Which OLS implementation should we use?" class="calibre3"><div class="preface" id="idm46122418878072">
<h3 class="calibre51">Which OLS implementation should we use?</h3>

<p class="author1"><a data-type="xref" href="ch06_split_001.xhtml#pandas_ols_functions" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-24</a> shows three implementations that we’d like to try.
We’ll evaluate the scikit-learn implementation against the direct linear algebra
implementation using NumPy. Both methods ultimately perform the same job and
calculate the slopes (<code class="calibre26">m</code>) and intercept (<code class="calibre26">c</code>) of the target data from each
Pandas row given an increasing <code class="calibre26">x</code> range (with values [0, 1, …, 13]).</p>

<p class="author1">scikit-learn will be a default choice for many machine learning practitioners, while
a linear algebra solution may be preferred by those coming from other
disciplines.</p>
<div id="pandas_ols_functions" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-24. </span>Solving Ordinary Least Squares with NumPy and scikit-learn</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">ols_sklearn</code><code class="p">(</code><code class="n">row</code><code class="p">):</code>
    <code class="sd">"""Solve OLS using scikit-learn's LinearRegression"""</code>
    <code class="n">est</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
    <code class="n">X</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="c"># shape (14, 1)</code>
    <code class="c"># note that the intercept is built inside LinearRegression</code>
    <code class="n">est</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">row</code><code class="o">.</code><code class="n">values</code><code class="p">)</code>
    <code class="n">m</code> <code class="o">=</code> <code class="n">est</code><code class="o">.</code><code class="n">coef_</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="c"># note c is in est.intercept_</code>
    <code class="kn">return</code> <code class="n">m</code>

<code class="kn">def</code> <code class="nf">ols_lstsq</code><code class="p">(</code><code class="n">row</code><code class="p">):</code>
    <code class="sd">"""Solve OLS using numpy.linalg.lstsq"""</code>
    <code class="c"># build X values for [0, 13]</code>
    <code class="n">X</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code> <code class="c"># shape (14,)</code>
    <code class="n">ones</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code> <code class="c"># constant used to build intercept</code>
    <code class="n">A</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">vstack</code><code class="p">((</code><code class="n">X</code><code class="p">,</code> <code class="n">ones</code><code class="p">))</code><code class="o">.</code><code class="n">T</code> <code class="c"># shape(14, 2)</code>
    <code class="c"># lstsq returns the coefficient and intercept as the first result</code>
    <code class="c"># followed by the residuals and other items</code>
    <code class="n">m</code><code class="p">,</code> <code class="n">c</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">lstsq</code><code class="p">(</code><code class="n">A</code><code class="p">,</code> <code class="n">row</code><code class="o">.</code><code class="n">values</code><code class="p">,</code> <code class="n">rcond</code><code class="o">=-</code><code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>
    <code class="kn">return</code> <code class="n">m</code>

<code class="kn">def</code> <code class="nf">ols_lstsq_raw</code><code class="p">(</code><code class="n">row</code><code class="p">):</code>
    <code class="sd">"""Variant of `ols_lstsq` where row is a numpy array (not a Series)"""</code>
    <code class="n">X</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
    <code class="n">ones</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
    <code class="n">A</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">vstack</code><code class="p">((</code><code class="n">X</code><code class="p">,</code> <code class="n">ones</code><code class="p">))</code><code class="o">.</code><code class="n">T</code>
    <code class="n">m</code><code class="p">,</code> <code class="n">c</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">lstsq</code><code class="p">(</code><code class="n">A</code><code class="p">,</code> <code class="n">row</code><code class="p">,</code> <code class="n">rcond</code><code class="o">=-</code><code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>
    <code class="kn">return</code> <code class="n">m</code></pre></div>

<p class="author1">Surprisingly, if we call <code class="calibre26">ols_sklearn</code> 10,000 times with the <a data-type="indexterm" data-primary="timeit module" id="idm46122418827416" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">timeit</code> module, we
find that it takes at least 0.483 microseconds to execute, while <code class="calibre26">ols_lstsq</code> on
the same data takes 0.182 microseconds. The popular scikit-learn solution takes
more than twice as long as the terse NumPy variant!</p>

<p class="author1">Building on the profiling from <a data-type="xref" href="ch02.xhtml#profiling-line-profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using line_profiler for Line-by-Line Measurements”</a>, we can use the object
interface (rather than the command line or Jupyter magic interfaces) to learn
<em class="hyperlink">why</em> the scikit-learn implementation is slower. In
<a data-type="xref" href="ch06_split_001.xhtml#pandas_profiling_sklearn_ols" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-25</a>, we tell LineProfiler to profile <code class="calibre26">est.fit</code>
(that’s the scikit-learn <code class="calibre26">fit</code> method on our <code class="calibre26">LinearRegression</code> estimator) and
then call <code class="calibre26">run</code> with arguments based on the DataFrame we used before.</p>

<p class="author1">We see a couple of surprises. The very last line of <code class="calibre26">fit</code> calls the same
<code class="calibre26">linalg.lstsq</code> that we’ve called in <code class="calibre26">ols_lstsq</code>—so what else is going on to
cause our slowdown? <code class="calibre26">LineProfiler</code> reveals that scikit-learn is calling two
other expensive methods, namely <code class="calibre26">check_X_y</code> and <code class="calibre26">_preprocess_data</code>.</p>

<p class="author1">Both of these are designed to help us avoid making mistakes—indeed, your author
Ian has been saved repeatedly from passing in inappropriate data such as a
wrongly <span class="publishername">shaped</span> array or one containing NaNs to scikit-learn estimators. A
consequence of this checking is that it takes more time—more safety makes
things run slower! We’re trading developer time (and sanity) against execution
time.</p>
<div id="pandas_profiling_sklearn_ols" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-25. </span>Digging into scikit-learn’s <code class="calibre26">LinearRegression.fit</code> call</h5>

<pre data-type="programlisting" class="calibre59">...
lp = LineProfiler(est.fit)
print("Run on a single row")
lp.run("est.fit(X, row.values)")
lp.print_stats()


Line #   % Time  Line Contents
==============================
   438               def fit(self, X, y, sample_weight=None):
...
   462      0.3          X, y = check_X_y(X, y,
                                          accept_sparse=['csr', 'csc', 'coo'],
   463     35.0                           y_numeric=True, multi_output=True)
...
   468      0.3          X, y, X_offset, y_offset, X_scale = \
                                 self._preprocess_data(
   469      0.3                       X, y,
                                      fit_intercept=self.fit_intercept,
                                      normalize=self.normalize,
   470      0.2                       copy=self.copy_X,
                                      sample_weight=sample_weight,
   471     29.3                       return_mean=True)
...
   502                       self.coef_, self._residues,
                                      self.rank_, self.singular_ = \
   503     29.2                  linalg.lstsq(X, y)</pre></div>

<p class="author1">Behind the scenes, these two methods are performing various checks, including these:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Checking for appropriate sparse NumPy arrays (even though we’re using dense arrays in this example)</p>
</li>
<li class="calibre21">
<p class="calibre27">Offsetting the input array to a mean of 0 to improve numerical stability on wider data ranges than we’re using</p>
</li>
<li class="calibre21">
<p class="calibre27">Checking that we’re providing a 2D X array</p>
</li>
<li class="calibre21">
<p class="calibre27">Checking that we’re not providing NaN or Inf values</p>
</li>
<li class="calibre21">
<p class="calibre27">Checking that we’re providing non-empty arrays of data</p>
</li>
</ul>

<p class="author1">Generally, we prefer to have all of these checks enabled—they’re here to help
us avoid painful debugging sessions, which kill developer productivity. If we
know that our data is of the correct form for our chosen algorithm, these
checks will add a penalty. It is up to you to decide when the safety of these
methods is hurting your overall productivity.</p>

<p class="author1">As a general rule—stay with the safer implementations (scikit-learn, in this
case) <em class="hyperlink">unless</em> you’re confident that your data is in the right form and you’re
optimizing for performance. We’re after increased performance, so we’ll continue
with the <code class="calibre26">ols_lstsq</code> approach.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Applying lstsq to our rows of data" class="calibre3"><div class="preface" id="idm46122418877448">
<h3 class="calibre51">Applying lstsq to our rows of data</h3>

<p class="author1"><a data-type="indexterm" data-primary="lstsq" id="idm46122418632072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>We’ll start with an approach that many Python developers who come from other
programming languages may try. This is <em class="hyperlink">not</em> idiomatic Python, nor is it common
or even efficient for Pandas. It does have the advantage of being very easy to
understand. In <a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_iloc" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-26</a>, we’ll iterate over the index of the
DataFrame from row 0 to row 99,999; on each iteration we’ll use <code class="calibre26">iloc</code> to
retrieve a row, and then we’ll calculate OLS on that row.</p>

<p class="author1">The calculation is common to each of the following methods—what’s different is
how we iterate over the rows. This method takes 18.6 seconds; it is by far the
slowest approach (by a factor of 3) among the options we’re evaluating.</p>

<p class="author1">Behind the scenes, each dereference is expensive—<code class="calibre26">iloc</code> does a lot of work to
get to the row using a fresh <code class="calibre26">row_idx</code>, which is then converted into a new Series
object, which is returned and assigned to <code class="calibre26">row</code>.</p>
<div id="pandas_calc_ols_iloc" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-26. </span>Our worst implementation—counting and fetching rows one at a time with <code class="calibre26">iloc</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">ms</code> <code class="o">=</code> <code class="p">[]</code>
<code class="kn">for</code> <code class="n">row_idx</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">df</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]):</code>
    <code class="n">row</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">row_idx</code><code class="p">]</code>
    <code class="n">m</code> <code class="o">=</code> <code class="n">ols_lstsq</code><code class="p">(</code><code class="n">row</code><code class="p">)</code>
    <code class="n">ms</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">m</code><code class="p">)</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">ms</code><code class="p">)</code></pre></div>

<p class="author1">Next, we’ll take a more idiomatic Python approach: in
<a data-type="xref" href="ch06_split_001.xhtml#pandas_cals_ols_iterrows" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-27</a>, we iterate over the rows using<a data-type="indexterm" data-primary="iterrows" id="idm46122418588904" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">iterrows</code>, which
looks similar to how we might iterate over a Python iterable (e.g., a <code class="calibre26">list</code> or
<code class="calibre26">set</code>) with a <code class="calibre26">for</code> loop. This method looks sensible and is a little faster—it
takes 12.4 seconds.</p>

<p class="author1">This is more efficient, as we don’t have to do so many lookups—<code class="calibre26">iterrows</code> can
walk along the rows without doing lots of sequential lookups. <code class="calibre26">row</code> is still
created as a fresh Series on each iteration of the loop.</p>
<div id="pandas_cals_ols_iterrows" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-27. </span><code class="calibre26">iterrows</code> for more efficient and “Python-like” row operations</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">ms</code> <code class="o">=</code> <code class="p">[]</code>
<code class="kn">for</code> <code class="n">row_idx</code><code class="p">,</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">df</code><code class="o">.</code><code class="n">iterrows</code><code class="p">():</code>
    <code class="n">m</code> <code class="o">=</code> <code class="n">ols_lstsq</code><code class="p">(</code><code class="n">row</code><code class="p">)</code>
    <code class="n">ms</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">m</code><code class="p">)</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">ms</code><code class="p">)</code></pre></div>

<p class="author1"><a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_apply" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-28</a> skips a lot of the Pandas machinery, so a lot of
overhead is avoided. <code class="calibre26">apply</code> passes the function <a data-type="indexterm" data-primary="ols_lstsq function" id="idm46122418549448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">ols_lstsq</code> a new row of data
directly (again, a fresh Series is constructed behind the scenes for each row)
without creating Python intermediate references. This costs 6.8 seconds—this
is a significant improvement, and the code is more compact and readable!</p>
<div id="pandas_calc_ols_apply" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-28. </span><code class="calibre26">apply</code> for idiomatic Pandas function application</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">ms</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">ols_lstsq</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">ms</code><code class="p">)</code></pre></div>

<p class="author1">Our final variant in <a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_apply_raw" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-29</a> uses the same <code class="calibre26">apply</code> call
with an additional <code class="calibre26">raw=True</code> argument. Using <code class="calibre26">raw=True</code> stops the creation of an intermediate
Series object. As we don’t have a Series object, we have to use our third OLS function, <code class="calibre26">ols_lstsq_raw</code>; this variant has direct access to the underlying NumPy array.</p>

<p class="author1">By avoiding the creation and dereferencing of an intermediate Series
object, we shave our execution time a little more, down to 5.3 seconds.</p>
<div id="pandas_calc_ols_apply_raw" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-29. </span>Avoiding intermediate Series creation using <code class="calibre26">raw=True</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">ms</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">ols_lstsq_raw</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">raw</code><code class="o">=</code><code class="nb">True</code><code class="p">)</code>
<code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">ms</code><code class="p">)</code></pre></div>

<p class="author1">The use of <code class="calibre26">raw=True</code> gives us the option to compile with <a data-type="indexterm" data-primary="Numba" data-secondary="compiling with" id="idm46122418326264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Numba
(<a data-type="xref" href="ch07.xhtml#compiling-numba-for-pandas" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Numba to Compile NumPy for Pandas”</a>) or with <a data-type="indexterm" data-primary="Cython" data-secondary="Pandas and" id="idm46122418324456" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Cython as it removes the complication
of compiling Pandas layers that currently aren’t supported.</p>

<p class="author1">We’ll summarize the execution times in <a data-type="xref" href="ch06_split_001.xhtml#pandas_table_iteration_costs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Table 6-3</a> for
100,000 rows of data on a single window of 14 columns of simulated data. New Pandas users often use
<code class="calibre26">iloc</code> and <code class="calibre26">iterrows</code> (or the similar <code class="calibre26">itertuples</code>) when <code class="calibre26">apply</code> would be preferred.</p>

<p class="author1">By performing our analysis and considering our potential need to perform OLS on
1,000,000 rows by up to 730 windows of data, we can see that a first naive
approach combining <code class="calibre26">iloc</code> with <code class="calibre26">ols_sklearn</code> might cost 10 (our larger dataset
factor) * 730 * 18 seconds * 2 (our slowdown factor against <code class="calibre26">ols_lstsq</code>) ==  73
hours.</p>

<p class="author1">If we used <code class="calibre26">ols_lstsq_raw</code> and our fastest approach, the same calculations might take 10 * 730 * 5.3 seconds == 10 hours. This is a significant saving for a task that represents what might be a suite of similar operations. We’ll see even faster solutions if we compile and run on multiple cores.</p>
<table id="pandas_table_iteration_costs" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 6-3. </span>Cost for using <code class="calibre86">lstsq</code> with various Pandas row-wise approaches</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89">Method</th>
<th class="calibre89">Time in seconds</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">iloc</p></td>
<td class="calibre16"><p class="calibre17">18.6</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">iterrows</p></td>
<td class="calibre16"><p class="calibre17">12.4</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">apply</p></td>
<td class="calibre16"><p class="calibre17">6.8</p></td>
</tr>
<tr class="calibre78">
<td class="calibre16"><p class="calibre17">apply raw=True</p></td>
<td class="calibre16"><p class="calibre17">5.3</p></td>
</tr>
</tbody>
</table>

<p class="author1">Earlier we discovered that the scikit-learn approach adds significant overhead
to our execution time by covering our data with a safety net of checks. We can
remove this safety net but with a potential cost on developer debugging time.
Your authors strongly urge you to consider adding unit-tests to your code that
would verify that a well-known and well-debugged method is used to test any
optimized method you settle on. If you added a unit test to compare the
scikit-learn <a data-type="indexterm" data-primary="LinearRegression estimator" id="idm46122418305720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">LinearRegression</code> approach against <code class="calibre26">ols_lstsq</code>, you’d be giving
yourself and other colleagues a future hint about why you developed a less
obvious solution to what appeared to be a standard problem.</p>

<p class="author1">Having experimented, you may also conclude that the heavily tested scikit-learn approach is more than fast enough for your application and that you’re more comfortable using a library that is well known by other developers. This could be a very sane conclusion.</p>

<p class="author1">Later in <a data-type="xref" href="ch10.xhtml#clustering-dask" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Parallel Pandas with Dask”</a>, we’ll look at running Pandas operations across
multiple cores by dividing data into groups of rows using <a data-type="indexterm" data-primary="Dask" id="idm46122418301720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Swifter" id="idm46122418301048" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Dask and Swifter. In
<a data-type="xref" href="ch07.xhtml#compiling-numba-for-pandas" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Numba to Compile NumPy for Pandas”</a>, we look at <a data-type="indexterm" data-primary="compiling" id="idm46122418299448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>compiling the <code class="calibre26">raw=True</code> variant of
<code class="calibre26">apply</code> to achieve an order of magnitude speedup. Compilation and
<a data-type="indexterm" data-primary="parallelization" id="idm46122418274904" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>parallelization can be combined for a really significant final speedup, dropping
our expected runtime from around 10 hours to just 30 minutes.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Building DataFrames and Series from Partial Results Rather than Concatenating" class="calibre3"><div class="preface" id="idm46122419829656">
<h2 class="calibre43">Building DataFrames and Series from Partial Results Rather than Concatenating</h2>

<p class="author1"><a data-type="indexterm" data-primary="series, building" id="idm46122418273176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Pandas" data-secondary="building DataFrames/Series" id="idm46122418272472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="DataFrames" data-secondary="building" id="idm46122418271560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="concatenation" id="idm46122418270616" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>You may have wondered in <a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_iloc" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-26</a> why we built up a list of
partial results that we then turned into a Series, rather than incrementally
building up the Series as we went. Our earlier approach required building up a
list (which has a memory overhead) and then building a <em class="hyperlink">second</em> structure for
the Series, giving us two objects in memory. This brings us to another
common mistake when using Pandas and NumPy.</p>

<p class="author1">As a general rule, you should avoid repeated calls to <code class="calibre26">concat</code> in Pandas (and to
the equivalent <code class="calibre26">concatenate</code> in NumPy). In <a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_many_concatenates" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-30</a>,
we see a similar solution to the preceding one but without the intermediate <code class="calibre26">ms</code>
list. This solution takes 56 seconds, as opposed to the solution using a list at
18.6 seconds!</p>
<div id="pandas_calc_ols_many_concatenates" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-30. </span>Concatenating each result incurs a significant overhead—avoid this!</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">results</code> <code class="o">=</code> <code class="nb">None</code>
<code class="kn">for</code> <code class="n">row_idx</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">df</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]):</code>
    <code class="n">row</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">row_idx</code><code class="p">]</code>
    <code class="n">m</code> <code class="o">=</code> <code class="n">ols_lstsq</code><code class="p">(</code><code class="n">row</code><code class="p">)</code>
    <code class="kn">if</code> <code class="n">results</code> <code class="ow">is</code> <code class="nb">None</code><code class="p">:</code>
        <code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">([</code><code class="n">m</code><code class="p">])</code>
    <code class="kn">else</code><code class="p">:</code>
        <code class="n">results</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">((</code><code class="n">results</code><code class="p">,</code> <code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">([</code><code class="n">m</code><code class="p">])))</code></pre></div>

<p class="author1">Each concatenation creates an entirely <em class="hyperlink">new</em> Series object in a new section of
memory that is one row longer than the previous item. In addition, we have to
make a temporary Series object for each new <code class="calibre26">m</code> on each iteration. We strongly
recommend building up lists of intermediate results and then constructing a Series
or DataFrame from this list, rather than concatenating to an existing object.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="There’s More Than One (and Possibly a Faster) Way to Do a Job" class="calibre3"><div class="preface" id="idm46122418215928">
<h2 class="calibre43">There’s More Than One (and Possibly a Faster) Way to Do a Job</h2>

<p class="author1">Because of the evolution of Pandas, there are typically a couple of approaches to
solving the same task, some of which incur more overhead than others. Let’s take the OLS
DataFrame and convert one column into a string; we’ll then time some string
operations. With string-based columns containing names, product identifiers, or
codes, it is common to have to preprocess the data to turn it into something we
can analyze.</p>

<p class="author1">Let’s say that we need to find the location, if it exists, of the number
9 in the digits from one of the columns. While this operation serves no real
purpose, it is very similar to checking for the presence of a code-bearing symbol
in an identifier’s sequence or checking for an honorific in a name. Typically
for these operations, we’d use <code class="calibre26">strip</code> to remove extraneous whitespace, <code class="calibre26">lower</code>
and <code class="calibre26">replace</code> to normalize the string, and <code class="calibre26">find</code> to locate something of
interest.</p>

<p class="author1">In <a data-type="xref" href="ch06_split_001.xhtml#pandas_calc_ols_str_operations" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-31</a>, we first build a new Series named
<code class="calibre26">0_as_str</code>, which is the zeroth Series of random numbers converted into a printable
string form. We’ll then run two variants of string manipulation code—both
will remove the leading digit and decimal point and then use Python’s <code class="calibre26">find</code> to
locate the first <code class="calibre26">9</code> if it exists, returning –1 
<span class="publishername">otherwise</span>.</p>
<div id="pandas_calc_ols_str_operations" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 6-31. </span><code class="calibre26">str</code> Series operations versus <code class="calibre26">apply</code> for string processing</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">In</code> <code class="p">[</code><code class="mi">10</code><code class="p">]:</code> <code class="n">df</code><code class="p">[</code><code class="s">'0_as_str'</code><code class="p">]</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="kn">lambda</code> <code class="n">v</code><code class="p">:</code> <code class="nb">str</code><code class="p">(</code><code class="n">v</code><code class="p">))</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">10</code><code class="p">]:</code>
              <code class="mi">0</code>            <code class="mi">0</code><code class="n">_as_str</code>
<code class="mi">0</code>      <code class="mi">1.016667</code>  <code class="mi">1.0166666666666666</code>
<code class="mi">1</code>      <code class="mi">1.033333</code>  <code class="mi">1.0333333333333334</code>
<code class="mi">2</code>      <code class="mi">0.966667</code>  <code class="mi">0.9666666666666667</code>
<code class="o">...</code>


<code class="kn">def</code> <code class="nf">find_9</code><code class="p">(</code><code class="n">s</code><code class="p">):</code>
    <code class="sd">"""Return -1 if '9' not found else its location at position &gt;= 0"""</code>
    <code class="kn">return</code> <code class="n">s</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s">'.'</code><code class="p">)[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s">'9'</code><code class="p">)</code>


<code class="n">In</code> <code class="p">[</code><code class="mi">11</code><code class="p">]:</code> <code class="n">df</code><code class="p">[</code><code class="s">'0_as_str'</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s">'.'</code><code class="p">,</code> <code class="n">expand</code><code class="o">=</code><code class="nb">True</code><code class="p">)[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s">'9'</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">11</code><code class="p">]:</code>
<code class="mi">0</code>       <code class="o">-</code><code class="mi">1</code>
<code class="mi">1</code>       <code class="o">-</code><code class="mi">1</code>
<code class="mi">2</code>        <code class="mi">0</code>


<code class="n">In</code> <code class="p">[</code><code class="mi">12</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">df</code><code class="p">[</code><code class="s">'0_as_str'</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s">'.'</code><code class="p">,</code> <code class="n">expand</code><code class="o">=</code><code class="nb">True</code><code class="p">)[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">str</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s">'9'</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">12</code><code class="p">]:</code> <code class="mi">183</code> <code class="n">ms</code> <code class="err">±</code> <code class="mi">4.62</code> <code class="n">ms</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">10</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">13</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">df</code><code class="p">[</code><code class="s">'0_as_str'</code><code class="p">]</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">find_9</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">13</code><code class="p">]:</code> <code class="mi">51</code> <code class="n">ms</code> <code class="err">±</code> <code class="mi">987</code> <code class="err">µ</code><code class="n">s</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">10</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code></pre></div>

<p class="author1">The one-line approach uses Pandas’s <code class="calibre26">str</code> operations to access Python’s string
methods for a Series. For <a data-type="indexterm" data-primary="split" id="idm46122418200968" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">split</code>, we expand the returned result into two columns
(the first column contains the leading digit, and the second contains everything after the
decimal place), and we select column 1. We then apply <code class="calibre26">find</code> to locate the digit
9. The second approach uses <code class="calibre26">apply</code> and the function <code class="calibre26">find_9</code>, which reads like a
regular Python string-processing function.</p>

<p class="author1">We can use <a data-type="indexterm" data-primary="%timeit function" data-primary-sortas="timeit" id="idm46122417957224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="%timeit function" id="idm46122417956216" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">%timeit</code> to check the runtime—this shows us that there’s a 3.5× speed difference between the two methods, even though they both produce the same result! In the former one-line case, Pandas has to make several new intermediate Series objects, which adds overhead; in the <code class="calibre26">find_9</code> case, all of the string-processing work occurs one line at a time without creating new intermediate Pandas objects.</p>

<p class="author1">Further benefits of the <code class="calibre26">apply</code> approach are that we could parallelize this
operation (see <a data-type="xref" href="ch10.xhtml#clustering-dask" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Parallel Pandas with Dask”</a> for an example with Dask
and Swifter), and we can write a unit test that succinctly confirms the
operations performed by <code class="calibre26">find_9</code>, which will aid in readability and maintenance.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Advice for Effective Pandas Development" class="calibre3"><div class="preface" id="idm46122417951944">
<h2 class="calibre43">Advice for Effective Pandas Development</h2>

<p class="author1"><a data-type="indexterm" data-primary="Pandas" data-secondary="effective development for" id="idm46122417950376" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Install the optional dependencies<a data-type="indexterm" data-primary="NumExpr" id="idm46122417949096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">numexpr</code> and <a data-type="indexterm" data-primary="bottlenecks" id="idm46122417947880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">bottleneck</code> for additional
performance improvements. These don’t get installed by default, and you won’t be
told if they’re missing. <code class="calibre26">bottleneck</code> is rarely used in the code base; <code class="calibre26">numexpr</code>,
however, will give significant speedups in some situations when you use <code class="calibre26">exec</code>.
You can test for the presence of both in your environment with <code class="calibre26">import
bottleneck</code> and <code class="calibre26">import numexpr</code>.</p>

<p class="author1">Don’t write your code too tersely; remember to make your code easy to read and
debug to help your future self. While the “method chaining” style is supported,
your authors would caution against chaining too many rows of Pandas operations
in sequence. It typically becomes difficult to figure out which line has
problems when debugging, and then you have to split up the lines—you’re better
off chaining only a couple of operations together at most to simplify your
maintenance.</p>

<p class="author1">Avoid doing more work than necessary: it is preferable to filter your data
before calculating on the remaining rows rather than filtering after
calculating, if possible. For high performance in general, we want to ask the
machine to do as little computation as possible; if you can filter out or mask
away portions of your data, you’re probably winning. If you’re consuming from a
SQL source and later joining or filtering in Pandas, you might want to try to
filter first at the SQL level, to avoid pulling more data than necessary into
Pandas. You may <em class="hyperlink">not</em> want to do this at first if you’re investigating data
quality, as having a simplified view on the variety of datatypes you have might
be more beneficial.</p>

<p class="author1">Check the schema of your DataFrames as they evolve; with a tool like <code class="calibre26">bulwark</code>,
you guarantee at runtime that your schema is being met, and you can visually
confirm when you’re reviewing code that your expectations are being met.  Keep
renaming your columns as you generate new results so that your DataFrame’s
contents make sense to you; sometimes <code class="calibre26">groupby</code> and other operations give you
silly default names, which can later be confusing. Drop columns that you no
longer need with <code class="calibre26">.drop()</code> to reduce bloat and memory usage.</p>

<p class="author1">For large Series containing strings with low cardinality (“yes” and “no,” for example, or
“type_a,” “type_b,” and “type_c”), try converting the Series to a Category <code class="calibre26">dtype</code>
with <code class="calibre26">df['series_of_strings'].astype('category')</code>; you may find that operations like
<code class="calibre26">value_counts</code> and <code class="calibre26">groupby</code> run faster, and the Series is likely to consume less
RAM.</p>

<p class="author1">Similarly, you may want to convert 8-byte<a data-type="indexterm" data-primary="float type" id="idm46122417936888" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">float64</code> and <code class="calibre26">int64</code> columns to
smaller datatypes—perhaps the 2-byte <code class="calibre26">float16</code> or 1-byte <a data-type="indexterm" data-primary="int type" id="idm46122417934712" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">int8</code> if you need a
smaller range to further save RAM.</p>

<p class="author1">As you <a data-type="indexterm" data-primary="DataFrames" data-secondary="evolving" id="idm46122417933240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>evolve DataFrames and generate new copies, remember that you can use the
<code class="calibre26">del</code> keyword to delete earlier references and clear them from memory, if they’re
large and wasting space. You can also use the Pandas <code class="calibre26">drop</code> method to delete
unused 
<span class="publishername">columns</span>.</p>

<p class="author1">If you’re manipulating large DataFrames while you prepare your data for
processing, it may make sense to do these operations once in a function or a
separate script and then persist the prepared version to disk by using
<code class="calibre26">to_pickle</code>. You can subsequently work on the prepared DataFrame without having
to process it each time.</p>

<p class="author1">Avoid the <code class="calibre26">inplace=True</code> operator—in-place operations are scheduled to be
removed from the library over time.</p>

<p class="author1">Finally, always add unit tests to any processing code, as it will quickly become
more complex and harder to debug. Developing your tests up front guarantees that
your code meets your expectations and helps you to avoid silly mistakes
creeping in later that cost developer time to debug.</p>

<p class="author1">Existing tools for making Pandas go faster include<a data-type="indexterm" data-primary="Modin" id="idm46122417927144" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<a href="https://pypi.org/project/modin" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Modin</a> and the GPU-focused<a data-type="indexterm" data-primary="cuDF" id="idm46122417925560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<a href="https://pypi.org/project/cudf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">cuDF</a>. Modin and cuDF take different
approaches to parallelizing common data operations on a Pandas DataFrame–like
object.</p>

<p class="author1">We’d like to also give an honorable mention to the new<a data-type="indexterm" data-primary="Vaex" id="idm46122417923448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://github.com/vaexio/vaex" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Vaex library</a>.
Vaex is designed to work on very
large datasets that exceed RAM by using lazy evaluation while retaining a similar
interface to that of Pandas. In addition, Vaex offers a slew of built-in visualization
functions. One design goal is to use as many CPUs as possible, offering
parallelism for free where possible.</p>

<p class="author1">Vaex specializes in both larger datasets and string-heavy operations; the
authors have rewritten many of the string operations to avoid the standard
Python functions and instead use faster Vaex implementations in <code class="calibre26">C++</code>. Note that
Vaex is not guaranteed to work in the same way as Pandas, so it is possible that
you’ll find edge cases with different behavior—as ever, back your code with
unit tests to gain confidence if you’re trying both Pandas and Vaex to process
the same data.<a data-type="indexterm" data-primary="" data-startref="mvc_pa" id="idm46122417920232" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_pa" id="idm46122417919256" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Wrap-Up" class="calibre3"><div class="preface" id="idm46122417951320">
<h1 class="calibre25">Wrap-Up</h1>

<p class="author1">In the next chapter, we will talk about how to create your own external modules
that can be finely tuned to solve specific problems with much greater
efficiencies.  This allows us to follow the rapid prototyping method of making
our programs—first solve the problem with slow code, then identify the elements
that are slow, and finally, find ways to make those elements faster.  By
profiling often and trying to optimize only the sections of code we <em class="hyperlink">know</em> are slow,
we can save ourselves time while still making our programs run as fast as
possible.</p>
</div></section>







<div data-type="footnotes" class="calibre52"><p data-type="footnote" id="idm46122422174440" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122422174440-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> This is the code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-3</a>, truncated to fit within the page margins. Recall that<a data-type="indexterm" data-primary="kernprof" id="idm46122422172808" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">kernprof</code> requires functions to be decorated with <code class="calibre26">@profile</code> in order to be profiled (see <a data-type="xref" href="ch02.xhtml#profiling-line-profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using line_profiler for Line-by-Line Measurements”</a>).</p><p data-type="footnote" id="idm46122422123864" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122422123864-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> The code profiled in <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_mem_lineprof" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-7</a> is the code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_pure_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-6</a>; it has been truncated to fit within the page margins.</p><p data-type="footnote" id="idm46122420832696" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122420832696-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup> On macOS you can get similar metrics by using Google’s<a data-type="indexterm" data-primary="gperftools" id="idm46122420832136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/MCCVv" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">gperftools</code></a> and the provided <code class="calibre26">Instruments</code> app. For Windows, we are told Visual Studio Profiler works well; however, we don’t have experience with it.</p><p data-type="footnote" id="idm46122421125416" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122421125416-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup> This can be done by running the Python process through the <code class="calibre26">nice</code> utility (<code class="calibre26">nice -n –20 python</code> <span class="publishername"><code class="calibre26">program.py</code></span>). A nice value of -20 will make sure it yields execution as little as possible.</p><p data-type="footnote" id="idm46122421117832" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122421117832-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">5</a></sup> A good survey of the various faults can be found at <a href="https://oreil.ly/12Beq" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">https://oreil.ly/12Beq</em></a>.</p><p data-type="footnote" id="idm46122421106008" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122421106008-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">6</a></sup> This effect is beautifully explained in this <a href="https://stackoverflow.com/a/11227902" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Stack Overflow response</a>.</p><p data-type="footnote" id="idm46122421072568" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122421072568-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">7</a></sup> For an in-depth look at <code class="calibre26">numpy</code> over a variety of problems, check out <a href="https://oreil.ly/KHdg_" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">From Python to Numpy</em></a> by Nicolas P. Rougier.</p><p data-type="footnote" id="idm46122420993032" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122420993032-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">8</a></sup> We do this by compiling <code class="calibre26">numpy</code> with the <code class="calibre26">-fno-tree-vectorize</code> flag.  For this experiment, we built <code class="calibre26">numpy</code> 1.17.3 with the following command: <code class="calibre26">$ OPT='-fno-tree-vectorize' FOPT='-fno-tree-vectorize'
BLAS=None LAPACK=None ATLAS=None python setup.py build</code>.</p><p data-type="footnote" id="idm46122420742936" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122420742936-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">9</a></sup> This is contingent on what CPU is being used.</p><p data-type="footnote" id="idm46122420722136" class="calibre53"><sup class="calibre54"><a href="ch06_split_000.xhtml#idm46122420722136-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">10</a></sup> This is not strictly true, since two <code class="calibre26">numpy</code> arrays can reference the same section of memory but use different striding information to represent the same data in different ways. These two <code class="calibre26">numpy</code> arrays will have different <code class="calibre26">id</code>s. There are many subtleties to the <code class="calibre26">id</code> structure of <code class="calibre26">numpy</code> arrays that are outside the scope of this discussion.</p><p data-type="footnote" id="idm46122419857272" class="calibre53"><sup class="calibre54"><a href="ch06_split_001.xhtml#idm46122419857272-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">11</a></sup> See the DataQuest blog post <a href="https://oreil.ly/frZrr" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Tutorial: Using Pandas with Large Data Sets in Python”</a> for more details.</p><p data-type="footnote" id="idm46122419819656" class="calibre53"><sup class="calibre54"><a href="ch06_split_001.xhtml#idm46122419819656-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">12</a></sup> If we’re going to use a sliding window, it might be possible to apply rolling window optimized functions such as <code class="calibre26">RollingOLS</code> from <code class="calibre26">statsmodels</code>.</p></div></div></section></div>



  </body></html>