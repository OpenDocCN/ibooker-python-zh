- en: Chapter 13\. Serverless Technologies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章。无服务器技术
- en: '*Serverless* is a term that generates a lot of buzz in the IT industry these
    days. As often happens with these kinds of terms, people have different opinions
    about what they actually mean. At face value, *serverless* implies a world where
    you do not need to worry about managing servers anymore. To some extent, this
    is true, but only for the developers who are using the functionality offered by
    *serverless* technologies. This chapter shows there is a *lot* of work that needs
    to happen behind the scenes for this magical world of no servers to come into
    being.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*无服务器*是当今IT行业中引起很多关注的一个词汇。像这样的词汇经常会导致人们对它们的实际含义有不同的看法。表面上看，*无服务器*意味着一个你不再需要担心管理服务器的世界。在某种程度上，这是正确的，但只适用于使用*无服务器*技术提供的功能的开发人员。本章展示了在幕后需要发生很多工作才能实现这个无服务器的神奇世界。'
- en: Many people equate the term *serverless* with Function as a Service (FaaS).
    This is partially true, and it mostly came about when AWS launched the Lambda
    service in 2015\. AWS Lambdas are functions that can be run in the cloud without
    deploying a traditional server to host the functions. Hence the word *serverless*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人将术语*无服务器*等同于函数即服务（FaaS）。这在某种程度上是正确的，这主要是因为AWS在2015年推出了Lambda服务。AWS Lambdas是可以在云中运行的函数，而无需部署传统服务器来托管这些函数。因此，*无服务器*这个词就诞生了。
- en: However, FaaS is not the only service that can be dubbed serverless. These days
    the Big Three public cloud providers (Amazon, Microsoft, and Google) all offer
    Containers as a Service (CaaS), which allows you to deploy full-blown Docker containers
    to their clouds without provisioning servers to host those containers. These services
    can also be called serverless. Examples of such services are AWS Fargate, Microsoft
    Azure Container Instances, and Google Cloud Run.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，FaaS并不是唯一可以称为无服务器的服务。如今，三大公共云提供商（亚马逊、微软和谷歌）都提供容器即服务（CaaS），允许您在它们的云中部署完整的Docker容器，而无需提供托管这些容器的服务器。这些服务也可以称为无服务器。这些服务的示例包括AWS
    Fargate、Microsoft Azure容器实例和Google Cloud Run。
- en: 'What are some use cases for serverless technologies? For FaaS technologies
    such as AWS Lambda, especially due to the event-driven manner in which Lambda
    functions can be triggered by other cloud services, use cases include:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器技术的一些用例是什么？对于像AWS Lambda这样的FaaS技术，特别是由于Lambda函数可以被其他云服务触发的事件驱动方式，用例包括：
- en: Extract-Transform-Load (ETL) data processing, where, as an example, a file is
    uploaded to S3, which triggers the execution of a Lambda function that does ETL
    processing on the data and sends it to a queue or a backend database
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取-转换-加载（ETL）数据处理，其中，例如，将文件上传到S3，触发Lambda函数对数据进行ETL处理，并将其发送到队列或后端数据库
- en: ETL processing on logs sent by other services to CloudWatch
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对其他服务发送到CloudWatch的日志进行ETL处理
- en: Scheduling tasks in a cron-like manner based on CloudWatch Events triggering
    Lambda functions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于CloudWatch Events触发Lambda函数以类似cron的方式调度任务
- en: Real-time notifications based on Amazon SNS triggering Lambda functions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Amazon SNS触发Lambda函数的实时通知
- en: Email processing using Lambda and Amazon SES
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Lambda和Amazon SES处理电子邮件
- en: Serverless website hosting, with the static web resources such as Javascript,
    CSS, and HTML stored in S3 and fronted by the CloudFront CDN service, and a REST
    API handled by an API Gateway routing the API requests to Lambda functions, which
    communicate with a backend such as Amazon RDS or Amazon DynamoDB
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器网站托管，静态Web资源（如Javascript、CSS和HTML）存储在S3中，并由CloudFront CDN服务前端处理，以及由API Gateway处理的REST
    API将API请求路由到Lambda函数，后者与后端（如Amazon RDS或Amazon DynamoDB）通信
- en: Many serverless use cases are identified in each of the cloud service providers’
    online documentation. For example, in the Google Cloud serverless ecosystem, web
    applications are handled best by Google AppEngine, APIs are handled best by Google
    Functions, and CloudRun is preferred for running processes in Docker containers.
    For a concrete example, consider a service that needs to perform machine learning
    tasks such as object detection with the TensorFlow framework. Due to the compute,
    memory, and disk resource limitations of FaaS, combined with the limited availability
    of libraries in a FaaS setup, it is probably better to run such a service using
    a CaaS service such as Google Cloud Run, as opposed to a FaaS service such as
    Google Cloud Functions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 每个云服务提供商的在线文档中都可以找到许多无服务器使用案例。例如，在 Google Cloud 无服务器生态系统中，Web 应用程序最适合由 Google
    AppEngine 处理，API 最适合由 Google Functions 处理，而 CloudRun 则适合在 Docker 容器中运行进程。举个具体的例子，考虑一个需要执行
    TensorFlow 框架的机器学习任务（如对象检测）的服务。由于 FaaS 的计算、内存和磁盘资源限制，再加上 FaaS 设置中库的有限可用性，可能更适合使用
    Google Cloud Run 这样的 CaaS 服务来运行这样的服务，而不是使用 Google Cloud Functions 这样的 FaaS 服务。
- en: 'The Big Three cloud providers also offer a rich DevOps toolchain around their
    FaaS platforms. For example, when you use AWS Lambda, with little effort, you
    can also add these services from AWS:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 三大云服务提供商还围绕其 FaaS 平台提供丰富的 DevOps 工具链。例如，当你使用 AWS Lambda 时，你可以轻松地添加 AWS 的这些服务：
- en: AWS X-Ray for tracing/observability
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS X-Ray 用于追踪/可观测性。
- en: Amazon CloudWatch for logging, alerting, and event scheduling
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon CloudWatch 用于日志记录、警报和事件调度。
- en: AWS Step Functions for serverless workflow coordination
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Step Functions 用于无服务器工作流协调。
- en: AWS Cloud9 for an in-browser development environment
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Cloud9 用于基于浏览器的开发环境。
- en: How do you choose between FaaS and CaaS? In one dimension, it depends on the
    unit of deployment. If you only care about short-lived functions, with few dependencies
    and small amounts of data processing, then FaaS can work for you. If, on the other
    hand, you have long-running processes with lots of dependencies and heavy computing
    power requirements, then you may be better off using CaaS. Most FaaS services
    have severe limits for running time (15 minutes maximum for Lambda), computing
    power, memory size, disk space, and HTTP request and response limits. The upside
    to FaaS’ short execution times is that you only pay for the duration of the function.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如何选择 FaaS 和 CaaS？在一个维度上，这取决于部署的单位。如果你只关心短暂的函数，少量依赖和少量数据处理，那么 FaaS 可以适合你。另一方面，如果你有长时间运行的进程，有大量依赖和重的计算需求，那么使用
    CaaS 可能更好。大多数 FaaS 服务对运行时间（Lambda 的最长时间为 15 分钟）、计算能力、内存大小、磁盘空间、HTTP 请求和响应限制都有严格的限制。FaaS
    短执行时间的优势在于你只需支付函数运行的时长。
- en: If you remember the discussion at the beginning of [Chapter 12](ch12.html#containers-kubernetes)
    on pets versus cattle versus insects, functions can truly be considered ephemeral
    insects that briefly come into existence, perform some processing, and disappear.
    Because of their ephemeral nature, functions in FaaS are also stateless, which
    is an important fact to keep in mind as you architect your application.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得第 [第12章](ch12.html#containers-kubernetes) 开头关于宠物与牲畜与昆虫的讨论，函数可以真正被视为短暂存在、执行一些处理然后消失的短命昆虫。由于它们的短暂特性，FaaS
    中的函数也是无状态的，这是在设计应用程序时需要牢记的重要事实。
- en: Another dimension for choosing between FaaS and CaaS is the number and type
    of interactions that your service has with other services. For example, an AWS
    Lambda function can be triggered asynchronously by no less than eight other AWS
    services, including S3, Simple Notification Service (SNS), Simple Email Service
    (SES), and CloudWatch. This richness of interactions makes it easier to write
    functions that respond to events, so FaaS wins in this case.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 FaaS 和 CaaS 的另一个维度是你的服务与其他服务之间的交互次数和类型。例如，AWS Lambda 函数可以由其他至少八个 AWS 服务异步触发，包括
    S3、简单通知服务（SNS）、简单电子邮件服务（SES）和 CloudWatch。这种丰富的交互使得编写响应事件的函数更加容易，因此在这种情况下 FaaS
    胜出。
- en: As you’ll see in this chapter, many FaaS services are actually based on Kubernetes,
    which these days is the de facto container orchestration standard. Even though
    your unit of deployment is a function, behind the scenes the FaaS tooling creates
    and pushes Docker containers to a Kubernetes cluster that you might or might not
    manage. OpenFaas and OpenWhisk are examples of such Kubernetes-based FaaS technologies.
    When you self-host these FaaS platforms, you very quickly become aware that *server*
    makes up most of the word serverless. All of a sudden you have to worry a lot
    about the care and feeding of your Kubernetes clusters.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在本章中将看到的，许多FaaS服务实际上基于Kubernetes，这些天是事实上的容器编排标准。尽管您的部署单元是一个函数，但在幕后，FaaS工具会创建和推送Docker容器到一个您可能管理或可能不管理的Kubernetes集群中。OpenFaas和OpenWhisk是这种基于Kubernetes的FaaS技术的示例。当您自托管这些FaaS平台时，您很快就会意识到*服务器*构成了大部分无服务器的单词。突然间，您不得不非常关心如何照料和喂养您的Kubernetes集群。
- en: 'When we split the word DevOps into its parts, Dev and Ops, serverless technologies
    are targeted more toward the Dev side. They help developers feel less friction
    when it comes to deploying their code. The burden, especially in a self-hosted
    scenario, is on Ops to provision the infrastructure (sometimes very complex) that
    will support the FaaS or CaaS platforms. However, even if the Dev side might feel
    there is little need for Ops when it comes to serverless (which happens, although
    by definition this split makes it a non-DevOps situation), there are still plenty
    of Ops-related issues to worry about when it comes to using a Serverless platform:
    security, scalability, resource limitations and capacity planning, monitoring,
    logging, and observability. These have traditionally been considered the domain
    of Ops, but in the brave new DevOps world we are talking about, they need to be
    tackled by both Dev and Ops in tandem and with cooperation. A Dev team should
    not feel that its task is done when it finishes writing the code. Instead, it
    should take ownership and yes, pride, in getting the service all the way to production,
    with good monitoring, logging, and tracing built in.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将DevOps一词分为其部分Dev和Ops时，无服务器技术更多地针对Dev方面。它们帮助开发人员在部署其代码时感觉少一些摩擦。特别是在自托管场景中，负担在Ops身上，以提供将支持FaaS或CaaS平台的基础设施（有时非常复杂）。然而，即使Dev方面在使用无服务器时可能觉得Ops需求较少（这确实会发生，尽管根据定义这种分割使其成为非DevOps情况），在使用无服务器平台时仍然有很多与Ops相关的问题需要担心：安全性、可伸缩性、资源限制和容量规划、监视、日志记录和可观察性。传统上，这些被视为Ops的领域，但在我们讨论的新兴DevOps世界中，它们需要由Dev和Ops共同解决并合作。一个Dev团队在完成编写代码后不应该觉得任务已经完成。相反，它应该承担责任，并且是的，以在生产环境中全程完成服务，并内置良好的监控、日志记录和跟踪。
- en: We start this chapter with examples of how to deploy the same Python function,
    representing a simple HTTP endpoint, to the Big Three cloud providers using their
    FaaS offerings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从这一章开始，展示如何使用它们的FaaS提供的相同Python函数（表示简单HTTP端点），将其部署到“三巨头”云提供商。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Some of the commands used in the following examples produce large amounts of
    output. Except for cases where it is critical to the understanding of the command,
    we will omit the majority of the output lines to save trees and enable the reader
    to focus better on the text.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例中使用的某些命令会产生大量输出。除了在理解命令时必要的情况下，我们将省略大部分输出行，以节省树木并使读者能够更好地专注于文本。
- en: Deploying the Same Python Function to the “Big Three” Cloud Providers
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将相同的Python函数部署到“三巨头”云提供商
- en: For AWS and Google, we use the Serverless platform, which simplifies these deployments
    by abstracting the creation of cloud resources that are involved in the FaaS runtime
    environments. The Serverless platform does not yet support Python functions for
    Microsoft Azure, so in that case we show how to use Azure-specific CLI tooling.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AWS和Google，我们使用无服务器平台，通过抽象出参与FaaS运行时环境的云资源的创建来简化这些部署。无服务器平台目前尚不支持Microsoft
    Azure的Python函数，因此在这种情况下，我们展示如何使用Azure特定的CLI工具。
- en: Installing Serverless Framework
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装无服务器框架
- en: '[The Serverless platform](https://serverless.com) is based on nodejs. To install
    it, use `npm`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[无服务器平台](https://serverless.com)基于nodejs。要安装它，请使用`npm`：'
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Deploying Python Function to AWS Lambda
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Python函数部署到AWS Lambda
- en: 'Start by cloning the Serverless platform examples GitHub repository:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先克隆无服务器平台示例GitHub存储库：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The Python HTTP endpoint is defined in the file *handler.py*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Python HTTP端点定义在文件*handler.py*中：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The Serverless platform uses a declarative approach for specifying the resources
    it needs to create with a YAML file called *serverless.yaml*. Here is file that
    declares a function called `currentTime`, corresponding to the Python function
    `endpoint` from the `handler` module defined previously:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器平台使用声明性方法指定需要创建的资源，该方法使用一个名为*serverless.yaml*的YAML文件。以下是声明一个名为`currentTime`的函数的文件，对应于之前定义的`handler`模块中的Python函数`endpoint`：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Modify the Python version to 3.7 in *serverless.yaml*:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在*serverless.yaml*中修改Python版本为3.7：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Deploy the function to AWS Lambda by running the `serverless deploy` command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`serverless deploy`命令将函数部署到AWS Lambda：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Test the deployed AWS Lambda function by hitting its endpoint with `curl`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`curl`命中其端点来测试部署的AWS Lambda函数：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Invoke the Lambda function directly with the `serverless invoke` command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`serverless invoke`命令直接调用Lambda函数：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Invoke the Lambda function directly and inspect the log (which is sent to AWS
    CloudWatch Logs) at the same time:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 直接调用Lambda函数并同时检查日志（发送到AWS CloudWatch Logs）：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note how the `Billed Duration` in the preceding output is 100 ms. This shows
    one of the advantages of using FaaS—being billed in very short increments of time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前述输出中的`Billed Duration`为100毫秒。这显示了使用FaaS的一个优势——以非常短的时间段计费。
- en: 'One other thing we want to draw your attention to is the heavy lifting behind
    the scenes by the Serverless platform in the creation of AWS resources that are
    part of the Lambda setup. Serverless creates a CloudFormation stack called, in
    this case, `aws-python-simple-http-endpoint-dev`. You can inspect it with the
    `aws` CLI tool:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一件事我们想要引起您的注意，即无服务器平台在创建作为Lambda设置的一部分的AWS资源时在幕后进行了大量工作。无服务器平台创建了一个称为CloudFormation堆栈的栈，此案例中称为`aws-python-simple-http-endpoint-dev`。您可以使用`aws`
    CLI工具检查它：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note how this CloudFormation stack contains no less than 10 AWS resource types
    that you would have had to otherwise create or associate with one another manually.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个CloudFormation堆栈包含不少于10种AWS资源类型，否则您将不得不手动创建或手动关联这些资源。
- en: Deploying Python Function to Google Cloud Functions
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Python函数部署到Google Cloud Functions
- en: 'In this section, we will take as an example the code from the `google-python-simple-http-endpoint`
    directory from the Serverless platform examples GitHub repository:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将以服务器平台示例GitHub存储库中`google-python-simple-http-endpoint`目录中的代码为例：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Create a new GCP project:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的GCP项目：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Initialize the local `gcloud` environment:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化本地的`gcloud`环境：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Authorize local shell with GCP:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 授权本地Shell与GCP：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use the Serverless framework to deploy the same Python HTTP endpoint as in
    the AWS Lambda example, but this time as a Google Cloud Function:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用无服务器框架部署与AWS Lambda示例相同的Python HTTP端点，但这次作为Google Cloud Function：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The error we just encountered is due to the fact that the dependencies specified
    in *package.json* have not been installed yet:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚遇到的错误是由于尚未安装*package.json*中指定的依赖项：
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The Serverless platform is written in node.js, so its packages need to be installed
    with `npm install`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器平台是用node.js编写的，因此它的包需要使用`npm install`安装：
- en: '[PRE16]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Try deploying again:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 再次尝试部署：
- en: '[PRE17]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To generate a credentials key, create a new service account named `sa` on the
    GCP IAM service account page. In this case, the email for the new service account
    was set to `sa-255@pythonfordevops-cloudfunction.iam.gserviceaccount.com`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成凭据密钥，请在GCP IAM服务帐户页面上创建一个名为`sa`的新服务帐户。在此案例中，新服务帐户的电子邮件设置为`sa-255@pythonfordevops-cloudfunction.iam.gserviceaccount.com`。
- en: Create a credentials key and download it as `~/.gcloud/pythonfordevops-cloudfunction.json`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个凭据密钥，并将其下载为`~/.gcloud/pythonfordevops-cloudfunction.json`。
- en: 'Specify the project and the path to the key in *serverless.yml*:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 指定项目和*serverless.yml*中密钥的路径：
- en: '[PRE18]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Go to the GCP Deployment Manager page and enable the Cloud Deployment Manager
    API; then also enable billing for Google Cloud Storage.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 转到GCP部署管理器页面并启用Cloud Deployment Manager API；然后还为Google Cloud Storage启用计费。
- en: 'Try deploying again:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 再次尝试部署：
- en: '[PRE19]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Read through [the Serverless platform documentation on GCP credentials and roles](https://oreil.ly/scsRg).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读关于GCP凭据和角色的[无服务器平台文档](https://oreil.ly/scsRg)。
- en: 'The following roles need to be assigned to the service account used for the
    deployment:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 需要分配给部署所使用的服务帐户的以下角色：
- en: Deployment Manager Editor
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署管理器编辑器
- en: Storage Admin
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储管理员
- en: Logging Admin
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志管理员
- en: Cloud Functions Developer roles
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云函数开发者角色
- en: Also read through [the Serverless platform documentation on the GCP APIs that
    need to be enabled](https://oreil.ly/rKiHg).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 还要阅读有关需启用的GCP API的Serverless平台文档[文档](https://oreil.ly/rKiHg)：
- en: 'The following APIs need to be enabled in the GCP console:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP控制台中需要启用以下API：
- en: Google Cloud Functions
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Cloud Functions
- en: Google Cloud Deployment Manager
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Cloud Deployment Manager
- en: Google Cloud Storage
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Cloud Storage
- en: Stackdriver Logging
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stackdriver Logging
- en: 'Go to Deployment Manager in the GCP console and the inspect error messages:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 转到GCP控制台中的部署管理器，并检查错误消息：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Delete the `sls-python-simple-http-endpoint-dev` deployment in the GCP console
    and run `serverless deploy` again:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP控制台中删除`sls-python-simple-http-endpoint-dev`部署，并再次运行`serverless deploy`：
- en: '[PRE21]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `serverless deploy` command kept failing because initially we did not enable
    billing for Google Cloud Storage. The deployment was marked as failed for the
    service specified in *serverless.yml*, and subsequent `serverless deploy` commands
    failed even after enabling Cloud Storage billing. Once the failed deployment was
    deleted in the GCP console, the `serverless deploy` command started to work.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，由于我们没有为Google Cloud Storage启用计费，`serverless deploy`命令一直失败。在*serverless.yml*中指定的服务的部署标记为失败，并且即使启用了Cloud
    Storage计费后，后续的`serverless deploy`命令仍然失败。一旦在GCP控制台中删除了失败的部署，`serverless deploy`命令就开始工作了。
- en: 'Invoke the deployed Google Cloud Function directly:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 直接调用部署的Google Cloud Function：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Use the `serverless logs` command to inspect the logs:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`serverless logs`命令检查日志：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Test the function endpoint with `curl`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`测试函数端点：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Since we didn’t define a region in *serverless.yml*, the endpoint URL starts
    with `undefined` and returns an error.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有在*serverless.yml*中定义区域，端点URL以`undefined`开头并返回错误。
- en: 'Set the region to `us-central1` in *serverless.yml*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在*serverless.yml*中将区域设置为`us-central1`：
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Deploy the new version with `serverless deploy` and test the function endpoint
    with `curl`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`serverless deploy`部署新版本，并使用`curl`测试函数端点：
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Deploying Python Function to Azure
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Python函数部署到Azure
- en: The Serverless platform does not yet support [Azure Functions](https://oreil.ly/4WQKG)
    based on Python. We will demonstrate how to deploy Azure Python Functions using
    Azure-native tools.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Serverless平台尚不支持基于Python的[Azure Functions](https://oreil.ly/4WQKG)。我们将演示如何使用Azure本地工具部署Azure
    Python函数。
- en: 'Sign up for a Microsoft Azure account and install the Azure Functions runtime
    for your specific operating system, following the [official Microsoft documentation](https://oreil.ly/GHS4c).
    If you are on a macOS, use `brew`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您特定操作系统的[官方Microsoft文档](https://oreil.ly/GHS4c)注册Microsoft Azure账户并安装Azure
    Functions运行时。如果使用macOS，使用`brew`：
- en: '[PRE27]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create a new directory for the Python function code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为Python函数代码创建新目录：
- en: '[PRE28]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Install Python 3.6 because 3.7 is not supported by Azure Functions. Create
    and activate `virtualenv`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Python 3.6，因为Azure Functions不支持3.7。创建并激活`virtualenv`：
- en: '[PRE29]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Using the `Azure func` utility, create a local Functions project called `python-simple-http-endpoint`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure `func`实用程序创建名为`python-simple-http-endpoint`的本地函数项目：
- en: '[PRE30]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Change directories to the newly created *python-simple-http-endpoint* directory
    and create an Azure HTTP Trigger Function with the `func new` command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到新创建的*python-simple-http-endpoint*目录，并使用`func new`命令创建Azure HTTP触发器函数：
- en: '[PRE31]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Inspect the Python code created:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 检查创建的Python代码：
- en: '[PRE32]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Run the function locally:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地运行函数：
- en: '[PRE33]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Test from another terminal:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个终端中测试：
- en: '[PRE34]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Change HTTP handler in *currentTime/init.py* to include the current time in
    its response:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在*currentTime/init.py*中更改HTTP处理程序，以在其响应中包含当前时间：
- en: '[PRE35]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Test the new function with `curl`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`测试新函数：
- en: '[PRE36]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Install the Azure CLI with `pip`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pip`安装Azure CLI：
- en: '[PRE37]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Create an Azure Resource Group, Storage Account, and Function App using the
    `az` CLI utility in interactive mode. This mode places you in an interactive shell
    with auto-completion, command descriptions, and examples. Note that if you want
    to follow along, you will need to specify a different and unique `functionapp`
    name. You might also need to specify a different Azure region, such as `eastus`,
    that supports free trial accounts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`az`CLI实用程序在交互模式下创建Azure资源组、存储帐户和函数应用。此模式提供自动完成、命令描述和示例的交互式shell。请注意，如果要跟随操作，需要指定一个不同且唯一的`functionapp`名称。您可能还需要指定支持免费试用帐户的其他Azure区域，如`eastus`：
- en: '[PRE38]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Deploy the `functionapp` project to Azure using the `func` utility:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`func`实用程序将`functionapp`项目部署到Azure：
- en: '[PRE39]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Test the deployed function in Azure by hitting its endpoint with `curl`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`命中其端点测试在Azure上部署的函数：
- en: '[PRE40]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'It is always a good idea to remove any cloud resources you don’t need anymore.
    In this case, you can run:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 删除不再需要的任何云资源始终是个好主意。在这种情况下，您可以运行：
- en: '[PRE41]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Deploying a Python Function to Self-Hosted FaaS Platforms
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Python 函数部署到自托管 FaaS 平台
- en: As mentioned earlier in this chapter, many FaaS platforms are running on top
    of Kubernetes clusters. One advantage of this approach is that the functions you
    deploy run as regular Docker containers inside Kubernetes, so you can use your
    existing Kubernetes tooling, especially when it comes to observability (monitoring,
    logging, and tracing). Another advantage is potential cost savings. By running
    your serverless functions as containers inside an existing Kubernetes cluster,
    you can use the existing capacity of the cluster and not pay per function call
    as you would if you deployed your functions to a third-party FaaS platform.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章前面提到的，许多 FaaS 平台正在运行在 Kubernetes 集群之上。这种方法的一个优点是您部署的函数作为常规 Docker 容器在 Kubernetes
    内部运行，因此您可以使用现有的 Kubernetes 工具，特别是在可观察性方面（监视、日志记录和跟踪）。另一个优点是潜在的成本节约。通过将您的无服务器函数作为容器运行在现有的
    Kubernetes 集群中，您可以使用集群的现有容量，并且不像将您的函数部署到第三方 FaaS 平台时那样按函数调用付费。
- en: 'In this section, we consider one of these platforms: [OpenFaaS](https://www.openfaas.com).
    Some other examples of similar FaaS platforms running on Kubernetes include the
    following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考虑其中一个平台：[OpenFaaS](https://www.openfaas.com)。一些运行在 Kubernetes 上的类似 FaaS
    平台的其他示例包括以下内容：
- en: '[Kubeless](https://kubeless.io)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubeless](https://kubeless.io)'
- en: '[Fn Project](https://fnproject.io) (the underlying technology powering the
    Oracle FaaS offering called Oracle Functions)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Fn 项目](https://fnproject.io)（为 Oracle FaaS 提供动力的底层技术，称为 Oracle 函数）'
- en: '[Fission](https://fission.io)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Fission](https://fission.io)'
- en: '[Apache OpenWhisk](https://openwhisk.apache.org)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache OpenWhisk](https://openwhisk.apache.org)'
- en: Deploying Python Function to OpenFaaS
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Python 函数到 OpenFaaS
- en: For this example, we use a “Kubernetes-lite” distribution from Rancher called
    `k3s`. We use `k3s` instead of `minikube` to showcase the wide variety of tools
    available in the Kubernetes ecosystem.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本示例，我们使用 Rancher 的“Kubernetes-lite”分发称为 `k3s`。我们使用 `k3s` 而不是 `minikube` 来展示
    Kubernetes 生态系统中可用的各种工具。
- en: Start by running the [`k3sup`](https://oreil.ly/qK0xJ) utility to provision
    a `k3s` Kubernetes cluster on an Ubuntu EC2 instance.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行[`k3sup`](https://oreil.ly/qK0xJ) 实用程序，在 Ubuntu EC2 实例上设置 `k3s` Kubernetes
    集群。
- en: 'Download and install `k3sup`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并安装 `k3sup`：
- en: '[PRE42]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Verify SSH connectivity into the remote EC2 instance:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 验证远程 EC2 实例的 SSH 连通性：
- en: '[PRE43]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Install `k3s` via `k3sup install`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `k3sup install` 安装 `k3s`：
- en: '[PRE44]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Inspect the *kubeconfig* file:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 *kubeconfig* 文件：
- en: '[PRE45]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Point the `KUBECONFIG` environment variable to the local *kubeconfig* file
    and test `kubectl` commands against the remote k3s cluster:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `KUBECONFIG` 环境变量指向本地的 *kubeconfig* 文件，并针对远程 k3s 集群测试 `kubectl` 命令：
- en: '[PRE46]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The next step is to install the OpenFaas Serverless platform on the k3s Kubernetes
    cluster.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是在 k3s Kubernetes 集群上安装 OpenFaas 无服务器平台。
- en: 'Install `faas-cli` on the local macOS:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地的 macOS 上安装 `faas-cli`：
- en: '[PRE47]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Create RBAC permissions for Tiller, which is the server component of Helm:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为 Tiller 创建 RBAC 权限，Tiller 是 Helm 的服务器组件：
- en: '[PRE48]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Install Tiller via `helm init`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `helm init` 安装 Tiller：
- en: '[PRE49]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Download, configure, and install the Helm chart for OpenFaaS:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下载、配置并安装 OpenFaaS 的 Helm chart：
- en: '[PRE50]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Generate a random password for basic authentication to the OpenFaaS gateway:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为连接到 OpenFaaS 网关的基本身份验证生成随机密码：
- en: '[PRE51]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Deploy OpenFaaS by installing the Helm chart:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过安装 Helm chart 部署 OpenFaaS：
- en: '[PRE52]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Note
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `basic_auth` setup used here without TLS should ONLY be used for experimenting/learning.
    Any environment of consquence should be configured to ensure that credentials
    are passed over a secure TLS connection.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此处使用的没有 TLS 的 `basic_auth` 设置仅用于实验/学习。任何重要环境都应配置为确保凭据通过安全的 TLS 连接传递。
- en: 'Verify the services running in the `openfaas` namespace:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 验证在 `openfaas` 命名空间中运行的服务：
- en: '[PRE53]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Forward port 8080 from the remote instance to port 8080 locally:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 将远程实例的端口 `8080` 转发到本地端口 `8080`：
- en: '[PRE54]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Go to the OpenFaaS web UI at [*http://localhost:8080*](http://localhost:8080)
    and log in using username `admin` and password `$PASSWORD`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 转到 OpenFaaS Web UI，网址为[*http://localhost:8080*](http://localhost:8080)，使用用户名
    `admin` 和密码 `$PASSWORD` 登录。
- en: 'Continue by creating an OpenFaaS Python function. Use the `faas-cli` tool to
    create a new OpenFaaS function called `hello-python`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 继续通过创建一个 OpenFaaS Python 函数。使用 `faas-cli` 工具创建一个名为 `hello-python` 的新 OpenFaaS
    函数：
- en: '[PRE55]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Inspect the configuration file for the `hello-python` function:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 `hello-python` 函数的配置文件：
- en: '[PRE56]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Inspect the automatically created directory *hello-python*:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 检查自动创建的目录 *hello-python*：
- en: '[PRE57]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Edit *handler.py* and bring over the code that prints the current time from
    the Serverless platform’s simple-http-example:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 *handler.py* 并将从Serverless平台的simple-http-example打印当前时间的代码复制过来：
- en: '[PRE58]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The next step is to build the OpenFaaS Python function. Use the `faas-cli build`
    command, which will build a Docker image based on an autogenerated Dockerfile:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建OpenFaaS Python函数。 使用 `faas-cli build` 命令将根据自动生成的Dockerfile构建Docker镜像：
- en: '[PRE59]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Check that the Docker image is present locally:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 检查本地是否存在Docker镜像：
- en: '[PRE60]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Tag and push the Docker image to Docker Hub registry so it can be used on the
    remote Kubernetes cluster:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 将Docker镜像打标签并推送到Docker Hub注册表，以便在远程Kubernetes群集上使用：
- en: '[PRE61]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Edit *hello-python.yml* and change:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 *hello-python.yml* 并更改：
- en: '[PRE62]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Use the `faas-cli push` command to push the image to Docker Hub:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `faas-cli push` 命令将镜像推送到Docker Hub：
- en: '[PRE63]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Next, deploy the OpenFaaS Python function to the remote `k3s` cluster. Use
    the `faas-cli deploy` command to deploy the function:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将OpenFaaS Python函数部署到远程 `k3s` 群集。 使用 `faas-cli deploy` 命令部署函数：
- en: '[PRE64]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Use the `faas-cli login` command to obtain authenication credentials:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `faas-cli login` 命令获取认证凭据：
- en: '[PRE65]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Edit *hello-python.yml* and change:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑 *hello-python.yml* 并更改：
- en: '[PRE66]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Because we are returning JSON from our handler, add these lines to *hello-python.yml*:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们从处理程序返回JSON，请将这些行添加到 *hello-python.yml*：
- en: '[PRE67]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Contents of *hello-python.yml*:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*hello-python.yml* 的内容：'
- en: '[PRE68]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Run the `faas-cli deploy` command again:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行 `faas-cli deploy` 命令：
- en: '[PRE69]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'If a code change is needed, use the following commands to rebuild and redeploy
    the function. Note that the `faas-cli remove` command will delete the current
    version of the function:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要进行代码更改，请使用以下命令重新构建和重新部署函数。 请注意， `faas-cli remove` 命令将删除函数的当前版本：
- en: '[PRE70]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Now test the deployed function with `curl`:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用 `curl` 测试已部署的函数：
- en: '[PRE71]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Test by invoking the function directly with `faas-cli`:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `faas-cli` 直接调用函数进行测试：
- en: '[PRE72]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The next example will be more full featured. We will demonstrate how to use
    the AWS CDK to provision several Lambda functions behind an API Gateway for create/read/update/delete
    (CRUD) REST access to `todo` items stored in a DynamoDB table. We will also show
    how to load test our REST API with containers deployed in AWS Fargate and running
    the Locust load-testing tool against the API. The Fargate containers will also
    be provisioned with the AWS CDK.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例将更加全面。 我们将演示如何使用AWS CDK为存储在DynamoDB表中的`todo`项目提供创建/读取/更新/删除（CRUD）REST访问的API网关后面的几个Lambda函数。
    我们还将展示如何使用在AWS Fargate中部署的容器运行Locust负载测试工具来负载测试我们的REST API。 Fargate容器也将由AWS CDK提供。
- en: Provisioning DynamoDB Table, Lambda Functions, and API Gateway Methods Using
    the AWS CDK
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AWS CDK来配置DynamoDB表，Lambda函数和API Gateway方法：
- en: We briefly mentioned the AWS CDK in [Chapter 10](ch10.html#infra-as-code). AWS
    CDK is a product that allows you to define the desired state of the infrastructure
    using real code (currently supported languages are TypeScript and Python), as
    opposed to using a YAML definition file (as the Serverless platform does).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第10章](ch10.html#infra-as-code) 简要提到了AWS CDK。 AWS CDK是一款允许您使用真实代码（当前支持的语言为TypeScript和Python）定义基础架构期望状态的产品，与使用YAML定义文件（如Serverless平台所做的方式）不同。
- en: 'Install CDK CLI with `npm` at the global level (depending on your operating
    system, you may need to run the following command with `sudo`):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在全局级别使用 `npm` 安装 CDK CLI（根据您的操作系统，您可能需要使用 `sudo` 来运行以下命令）：
- en: '[PRE73]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Create a directory for the CDK application:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为CDK应用程序创建一个目录：
- en: '[PRE74]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Create a sample Python application with `cdk init`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `cdk init` 创建一个示例Python应用程序：
- en: '[PRE75]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'List the files created:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 列出创建的文件：
- en: '[PRE76]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Inspect the main file *app.py*:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 检查主文件 *app.py*：
- en: '[PRE77]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: A CDK program is composed of an *app* that can contain one or more *stacks*.
    A stack corresponds to a CloudFormation stack object.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: CDK程序由一个包含一个或多个堆栈的 *app* 组成。堆栈对应于CloudFormation堆栈对象。
- en: 'Inspect the module defining the CDK stack:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 检查定义CDK堆栈的模块：
- en: '[PRE78]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Because we are going to have two stacks, one for the DynamoDB/Lambda/API Gateway
    resources, and one for the Fargate resources, rename
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将有两个堆栈，一个用于DynamoDB/Lambda/API Gateway资源，另一个用于Fargate资源，请重命名：
- en: '*cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_fargate_stack.py*'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_fargate_stack.py*：'
- en: to *cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py*
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 到 *cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py*：
- en: and the class `CdkLambdaDynamodbFargateStack` to `CdkLambdaDynamodbStack`.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 将类 `CdkLambdaDynamodbFargateStack` 改为 `CdkLambdaDynamodbStack`。
- en: 'Also change *app.py* to refer to the changed module and class names:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 同时更改*app.py*以引用更改后的模块和类名：
- en: '[PRE79]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Activate `virtualenv`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 激活`virtualenv`：
- en: '[PRE80]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: We are going to take the [URL shortener CDK example](https://oreil.ly/q2dDF)
    and modify it with code from the [Serverless platform AWS Python REST API example](https://oreil.ly/o_gxS)
    to build a REST API for creating, listing, getting, updating, and deleting `todo`
    items. Amazon DynamoDB is used to store the data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用[URL缩短器CDK示例](https://oreil.ly/q2dDF)，并使用[无服务器平台AWS Python REST API示例](https://oreil.ly/o_gxS)中的代码修改它，以构建用于创建、列出、获取、更新和删除`todo`项目的REST
    API。使用Amazon DynamoDB来存储数据。
- en: 'Inspect the *serverless.yml* file from *examples/aws-python-rest-api-with-dynamodb*
    and deploy it with the `serverless` command to see what AWS resources get created:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 检查*examples/aws-python-rest-api-with-dynamodb*中的*serverless.yml*文件，并使用`serverless`命令部署它，以查看创建的AWS资源：
- en: '[PRE81]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The previous command created five Lambda functions, one API Gateway, and one
    DynamoDB table.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 上一条命令创建了五个Lambda函数、一个API Gateway和一个DynamoDB表。
- en: 'In the CDK directory, add a DynamoDB table to the stack we are building:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们正在构建的堆栈中的CDK目录中，添加一个DynamoDB表：
- en: '[PRE82]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Install the required Python modules:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 安装所需的Python模块：
- en: '[PRE83]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Inspect the CloudFormation stack that will be created by running `cdk synth`:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`cdk synth`来检查将要创建的CloudFormation堆栈：
- en: '[PRE84]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Pass a variable called `variable` containing the region value to the constructor
    `CdkLambdaDynamodbStack` in *app.py*:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在*app.py*中将包含区域值的名为`variable`的变量传递给构造函数`CdkLambdaDynamodbStack`：
- en: '[PRE85]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Run `cdk synth` again:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行`cdk synth`：
- en: '[PRE86]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Deploy the CDK stack by running `cdk deploy`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`cdk deploy`部署CDK堆栈：
- en: '[PRE87]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: The next step is to add Lambda functions and the API Gateway resource to the
    stack.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是向堆栈添加Lambda函数和API Gateway资源。
- en: 'In the CDK code directory, create a *lambda* directory and copy the Python
    modules from the [Serverless platform AWS Python REST API example](https://oreil.ly/mRSjn):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在CDK代码目录中，创建一个*lambda*目录，并从[无服务器平台AWS Python REST API示例](https://oreil.ly/mRSjn)复制Python模块：
- en: '[PRE88]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Add the required modules to *requirements.txt* and install them with `pip`:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 将所需模块添加到*requirements.txt*中，并使用`pip`安装它们：
- en: '[PRE89]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Create Lambda and API Gateway constructs in the stack module:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在堆栈模块中创建Lambda和API Gateway构造：
- en: '[PRE90]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'It is worth noting several features of the code we just reviewed:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是我们刚刚审查的代码的几个特点：
- en: We were able to use the `add_environment` method on each `handler` object to
    pass the environment variable `DYNAMODB_TABLE` used in the Python code for the
    Lambda functions and set it to `table.table_name`. The name of the DynamoDB table
    is not known at construction time, so the CDK will replace it with a token and
    will set the token to the correct name of the table when it deploys the stack
    (see the [Tokens](https://oreil.ly/XfdEU) documentation for more details).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能够在每个`handler`对象上使用`add_environment`方法，将在Python代码中用于Lambda函数的环境变量`DYNAMODB_TABLE`传递，并将其设置为`table.table_name`。在构建时不知道DynamoDB表的名称，因此CDK将其替换为令牌，并在部署堆栈时将令牌设置为表的正确名称（有关更多详细信息，请参阅[Tokens](https://oreil.ly/XfdEU)文档）。
- en: We made full use of a simple programming language construct, the `for` loop,
    when we iterated over the list of all Lambda handlers. While this may seem natural,
    it is still worth pointing out because loops and variable passing are features
    that are awkwardly implemented, if at all, in YAML-based Infrastructure as Code
    tools such as Terraform.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们遍历所有Lambda处理程序列表时，我们充分利用了一个简单的编程语言结构，即`for`循环。尽管这看起来很自然，但仍值得指出，因为循环和变量传递是基于YAML的基础设施即代码工具（如Terraform）中尴尬实现的功能，如果有的话。
- en: We defined the HTTP methods (GET, POST, PUT, DELETE) associated with various
    endpoints of the API Gateway and associated the correct Lambda function with each
    of them.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了与API Gateway的各个端点相关联的HTTP方法(GET、POST、PUT、DELETE)，并将正确的Lambda函数与每个端点关联。
- en: 'Deploy the stack with `cdk deploy`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cdk deploy`部署堆栈：
- en: '[PRE91]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Fix by running `cdk bootstrap`:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`cdk bootstrap`来修复：
- en: '[PRE92]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Deploy the CDK stack again:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 再次部署CDK堆栈：
- en: '[PRE93]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The next step is to test the REST API with `curl`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用`curl`测试REST API。
- en: 'First create a new `todo` item:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建一个新的`todo`项目：
- en: '[PRE94]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Create a second `todo` item:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 创建第二个`todo`项目：
- en: '[PRE95]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Try getting the details for the item just created by specifying its ID:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定其ID来尝试获取刚创建项目的详细信息：
- en: '[PRE96]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Investigate by inspecting the CloudWatch Logs for the Lambda function `TodoGetFunction:`
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查Lambda函数`TodoGetFunction`的CloudWatch日志来进行调查：
- en: '[PRE97]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'To fix, change the line in *lambda/get.py* from:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 要修复，请更改*lambda/get.py*中的行：
- en: '[PRE98]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'to:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 到：
- en: '[PRE99]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Redeploy the stack with `cdk deploy`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cdk deploy`重新部署堆栈。
- en: 'Try getting the `todo` item details with `curl` again:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 试着再次使用`curl`获取`todo`项目的详细信息：
- en: '[PRE100]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Make the `import decimalencoder` change to all modules in the *lambda* directory
    that need the decimalencoder module and redeploy with `cdk deploy`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 对需要 decimalencoder 模块的 *lambda* 目录中的所有模块进行 `import decimalencoder` 更改，并使用 `cdk
    deploy` 重新部署。
- en: 'List all `todos` and format the output with the `jq` utility:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 列出所有 `todos` 并使用 `jq` 工具格式化输出：
- en: '[PRE101]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Delete a `todo` and verify that the list does not contain it anymore:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 删除一个 `todo` 并验证列表不再包含它：
- en: '[PRE102]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Now test updating an existing `todo` item with `curl`:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在测试使用 `curl` 更新现有的 `todo` 项目：
- en: '[PRE103]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Inspecting the CloudWatch logs for the Lambda function associated with this
    endpoint shows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 检查与此端点相关联的 Lambda 函数的 CloudWatch 日志显示：
- en: '[PRE104]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'Change the validation test in *lambda/update.py* to:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 更改 *lambda/update.py* 中的验证测试为：
- en: '[PRE105]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Also change the value for `checked` to `True`, since we have already seen a
    post that we are trying to update:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 同样将 `checked` 的值更改为 `True`，因为我们已经看到了一个我们正在尝试更新的帖子：
- en: '[PRE106]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Redeploy the stack with `cdk deploy_`.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `cdk deploy` 重新部署堆栈。
- en: 'Test updating the `todo` item with `curl`:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `curl` 测试更新 `todo` 项目：
- en: '[PRE107]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'List the `todo` items to verify the update:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 列出 `todo` 项目以验证更新：
- en: '[PRE108]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: The next step is to provision AWS Fargate containers that will run a load test
    against the REST API we just deployed. Each container will run a Docker image
    that uses [the Taurus test automation framework](https://gettaurus.org) to run
    the [Molotov load-testing tool](https://oreil.ly/OGDne). We introduced Molotov
    in [Chapter 5](ch05.html#package_management) as a simple and very useful Python-based
    load-testing tool.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为我们刚刚部署的 REST API 运行负载测试的 AWS Fargate 容器。每个容器将运行一个 Docker 镜像，该镜像使用 [Taurus
    测试自动化框架](https://gettaurus.org) 运行 [Molotov 负载测试工具](https://oreil.ly/OGDne)。我们在
    [第 5 章](ch05.html#package_management) 中介绍了 Molotov 作为一个简单而非常有用的基于 Python 的负载测试工具。
- en: 'Start by creating a Dockerfile for running Taurus and Molotov in a directory
    called *loadtest*:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在名为 *loadtest* 的目录中创建一个运行 Taurus 和 Molotov 的 Dockerfile：
- en: '[PRE109]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The Dockerfile runs the Taurus `bzt` command line using the *taurus.yaml* configuration
    file:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 使用 *taurus.yaml* 配置文件运行 Taurus 的 `bzt` 命令行：
- en: '[PRE110]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'In this configuration file, the value for `concurrency` is set to 10, which
    means that we are simulating 10 concurrent users or virtual users (VUs). The `executor`
    is defined as a `molotov` test based on a script called *loadtest.py* in the *scripts*
    directory. Here is the script, which is a Python module:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配置文件中，`concurrency` 的值设置为 10，这意味着我们正在模拟 10 个并发用户或虚拟用户（VUs）。`executor` 被定义为一个基于名为
    *loadtest.py* 的脚本的 `molotov` 测试。以下是这个作为 Python 模块的脚本：
- en: '[PRE111]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: The script has four functions decorated as `scenarios` to be run by Molotov.
    They exercise various endpoints of the CRUD REST API. The weights indicate the
    approximate percentage of the time of the overall test duration that each scenario
    will be invoked. For example, the `_test_list_todos` function will be invoked
    in this example approximately 50% of the time, `_test_create_todo` will run approximately
    30% of the time, and `_test_update_todo` and `_test_delete_todo` will each run
    approximately 10% of the time.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本有四个装饰为 `scenarios` 的函数，由 Molotov 运行。它们会测试 CRUD REST API 的各种端点。权重指示每个场景在整体测试持续时间中被调用的大致百分比。例如，在这个例子中，函数
    `_test_list_todos` 将大约 50% 的时间被调用，`_test_create_todo` 将大约 30% 的时间被调用，而 `_test_update_todo`
    和 `_test_delete_todo` 每次将各自运行约 10% 的时间。
- en: 'Build the local Docker image:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 构建本地 Docker 镜像：
- en: '[PRE112]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Create the local *artifacts* directory:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 创建本地的 *artifacts* 目录：
- en: '[PRE113]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Run the local Docker image and mount the local *artifacts* directory as */tmp/artifacts*
    inside the Docker container:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 运行本地 Docker 镜像，并将本地 *artifacts* 目录挂载为 Docker 容器内的 */tmp/artifacts*：
- en: '[PRE114]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: Debug the Molotov script by inspecting the *artifacts/molotov.out* file.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查 *artifacts/molotov.out* 文件来调试 Molotov 脚本。
- en: Taurus results can be inspected either with `docker logs CONTAINER_ID` or by
    inspecting the file *artifacts/bzt.log*.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: Taurus 的结果可以通过 `docker logs CONTAINER_ID` 或检查文件 *artifacts/bzt.log* 进行检查。
- en: 'Results obtained by inspecting the Docker logs:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查 Docker 日志获得的结果：
- en: '[PRE115]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Create CloudWatch dashboards for the Lambda duration ([Figure 13-1](#Figure-13-1))
    and DynamoDB provisioned and consumed read and write capacity units ([Figure 13-2](#Figure-13-2)).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 为 Lambda 持续时间创建 CloudWatch 仪表板（[Figure 13-1](#Figure-13-1)）以及 DynamoDB 配置和消耗的读写能力单位（[Figure 13-2](#Figure-13-2)）：
- en: '![pydo 1301](assets/pydo_1301.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1301](assets/pydo_1301.png)'
- en: Figure 13-1\. Lambda duration
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 13-1\. Lambda 持续时间
- en: '![pydo 1302](assets/pydo_1302.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1302](assets/pydo_1302.png)'
- en: Figure 13-2\. DynamoDB provisioned and consumed read and write capacity units
  id: totrans-324
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 13-2\. DynamoDB 配置和消耗的读写能力单位
- en: The DynamoDB metrics show that we underprovisioned the DynamoDB read capacity
    units. This introduced latency, especially for the List function (shown in the
    Lambda duration graph as the red line going to 14.7 seconds), which retrieves
    all `todo` items from the DynamoDB table, and thus is heavy on read operations.
    We set the value of the provisioned read capacity units to 10 when we created
    the DynamoDB table, and the CloudWatch graph shows it going to 25.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB 的指标显示我们的 DynamoDB 读取容量单位配置不足。这导致了延迟，特别是在 List 函数中（Lambda 执行时长图中显示为红线，达到
    14.7 秒），该函数从 DynamoDB 表中检索所有 `todo` 项目，因此读取操作较重。我们在创建 DynamoDB 表时将配置的读取容量单位设置为
    10，CloudWatch 图表显示其上升至 25。
- en: 'Let’s change the DynamoDB table type from `PROVISIONED` to `PAY_PER_REQUEST`.
    Make the change in *cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py*:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将 DynamoDB 表类型从 `PROVISIONED` 更改为 `PAY_PER_REQUEST`。在 *cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py*
    中进行更改：
- en: '[PRE116]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: Run `cdk deploy` and then run the local Docker load-testing container.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `cdk deploy`，然后运行本地 Docker 负载测试容器。
- en: 'This time the results are much better:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这次结果好多了：
- en: '[PRE117]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: The graphs for Lambda duration ([Figure 13-3](#Figure-13-3)) and DynamoDB consumed
    read and write capacity units ([Figure 13-4](#Figure-13-4)) look much better as
    well.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 执行时长的图表（[图 13-3](#Figure-13-3)）和 DynamoDB 消耗的读取和写入容量单位的图表（[图 13-4](#Figure-13-4)）看起来也好多了。
- en: '![pydo 1303](assets/pydo_1303.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1303](assets/pydo_1303.png)'
- en: Figure 13-3\. Lambda duration
  id: totrans-333
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-3\. Lambda 执行时长
- en: '![pydo 1304](assets/pydo_1304.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1304](assets/pydo_1304.png)'
- en: Figure 13-4\. DynamoDB consumed read and write capacity units
  id: totrans-335
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-4\. DynamoDB 消耗的读取和写入容量单位
- en: Note that the DynamoDB consumed read capacity units are automatically allocated
    on demand by DynamoDB, and are scaling up to sustain the increased number of read
    requests from the Lambda functions. The function that contributes the most to
    the read requests is the List function that is called in the list, update, and
    delete scenarios in the Molotov *loadtest.py* script via `session.get(base_url
    + /todos)`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，DynamoDB 消耗的读取容量单位是由 DynamoDB 自动按需分配的，并且正在扩展以满足 Lambda 函数的增加读取请求。对读取请求贡献最大的函数是
    List 函数，在 Molotov *loadtest.py* 脚本中通过 `session.get(base_url + /todos)` 在列出、更新和删除场景中调用。
- en: 'Next, we will create a Fargate CDK stack that will run containers based on
    the Docker image created previously:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个 Fargate CDK 栈，该栈将根据先前创建的 Docker 镜像运行容器：
- en: '[PRE118]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'A few things to note in the code for the `FargateStack` class:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `FargateStack` 类的代码中需要注意的几点：
- en: A new VPC is created by using the `aws_ec2.Vpc` CDK construct.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `aws_ec2.Vpc` CDK 构造函数创建了一个新的 VPC。
- en: An ECS cluster is created in the new VPC.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在新 VPC 中创建了一个 ECS 集群。
- en: A Fargate task definition is created based on the Dockerfile from the *loadtest*
    directory; the CDK is smart enough to build a Docker image based on this Dockerfile
    and then push it to the ECR Docker registry.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 *loadtest* 目录中的 Dockerfile 创建了一个 Fargate 任务定义；CDK 聪明地根据此 Dockerfile 构建 Docker
    镜像，然后推送到 ECR Docker 注册表。
- en: An ECS service is created to run Fargate containers based on the image pushed
    to ECR; the `desired_count` parameter specifies how many containers we want to
    run.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个 ECS 服务来运行基于推送到 ECR 的镜像的 Fargate 容器；`desired_count` 参数指定我们要运行多少个容器。
- en: 'Call the `FargateStack` constructor in *app.py*:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *app.py* 中调用 `FargateStack` 构造函数：
- en: '[PRE119]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Deploy the `cdk-fargate` stack:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 `cdk-fargate` 栈：
- en: '[PRE120]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Go to the AWS console and inspect the ECS cluster with the running Fargate container
    ([Figure 13-5](#Figure-13-5)).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 转到 AWS 控制台，检查带有运行 Fargate 容器的 ECS 集群（[图 13-5](#Figure-13-5)）。
- en: '![pydo 1305](assets/pydo_1305.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1305](assets/pydo_1305.png)'
- en: Figure 13-5\. ECS cluster with running Fargate container
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-5\. 带有运行中 Fargate 容器的 ECS 集群
- en: Inspect the CloudWatch dashboards for Lambda duration ([Figure 13-6](#Figure-13-6))
    and DynamoDB consumed read and write capacity units ([Figure 13-7](#Figure-13-7)),
    noting that latency looks good.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 CloudWatch 仪表板，查看 Lambda 执行时长（[图 13-6](#Figure-13-6)）和 DynamoDB 消耗的读取和写入容量单位（[图
    13-7](#Figure-13-7)），注意延迟看起来不错。
- en: '![pydo 1306](assets/pydo_1306.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1306](assets/pydo_1306.png)'
- en: Figure 13-6\. Lambda duration
  id: totrans-353
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-6\. Lambda 执行时长
- en: '![pydo 1307](assets/pydo_1307.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1307](assets/pydo_1307.png)'
- en: Figure 13-7\. DynamoDB consumed read and write capacity units
  id: totrans-355
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-7\. DynamoDB 消耗的读取和写入容量单位
- en: 'Increase the Fargate container count to 5 in *cdk_lambda_dynamodb_fargate/cdk_fargate_stack.py*:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 将 *cdk_lambda_dynamodb_fargate/cdk_fargate_stack.py* 中的 Fargate 容器数量增加到 5：
- en: '[PRE121]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Redeploy the `cdk-fargate` stack:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 重新部署 `cdk-fargate` 栈：
- en: '[PRE122]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: Inspect the CloudWatch dashboards for Lambda duration ([Figure 13-8](#Figure-13-8))
    and DynamoDB consumed read and write capacity units ([Figure 13-9](#Figure-13-9)).
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 CloudWatch 仪表板以查看 Lambda 持续时间（[图 13-8](#Figure-13-8)）和 DynamoDB 消耗的读写容量单位（[图 13-9](#Figure-13-9)）。
- en: '![pydo 1308](assets/pydo_1308.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1308](assets/pydo_1308.png)'
- en: Figure 13-8\. Lambda duration
  id: totrans-362
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-8\. Lambda 持续时间
- en: '![pydo 1309](assets/pydo_1309.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![pydo 1309](assets/pydo_1309.png)'
- en: Figure 13-9\. DynamoDB consumed read and write capacity units
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-9\. DynamoDB 消耗的读写容量单位
- en: Both DynamoDB read capacity units and Lambda duration metrics increased as expected
    because we are now simulating 5 × 10 = 50 concurrent users.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在模拟了 5 × 10 = 50 个并发用户，DynamoDB 读取容量单位和 Lambda 持续时间指标均按预期增加。
- en: To simulate more users, we can both increase the `concurrency` value in the
    *taurus.yaml* configuration file, and increase the `desired_count` for the Fargate
    containers. Between these two values, we can easily increase the load on our REST
    API endpoints.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟更多用户，我们可以同时增加 *taurus.yaml* 配置文件中的`concurrency`值，并增加 Fargate 容器的`desired_count`。在这两个值之间，我们可以轻松增加对
    REST API 端点的负载。
- en: 'Delete the CDK stacks:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 删除 CDK 堆栈：
- en: '[PRE123]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: It is worth noting that the serverless architecture we deployed (API Gateway
    + five Lambda functions + DynamoDB table) turned out to be a good fit for our
    CRUD REST API application. We also followed best practices and defined all our
    infrastructure in Python code by using the AWS CDK.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们部署的无服务器架构（API Gateway + 五个 Lambda 函数 + DynamoDB 表）非常适合我们的 CRUD REST
    API 应用程序。我们还遵循了最佳实践，并通过 AWS CDK 使用 Python 代码定义了所有基础设施。
- en: Exercises
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'Run a simple HTTP endpoint using Google’s CaaS platform: [Cloud Run](https://cloud.google.com/run).'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Google 的 CaaS 平台上运行一个简单的 HTTP 端点：[Cloud Run](https://cloud.google.com/run)。
- en: 'Run a simple HTTP endpoint on the other FaaS platforms we mentioned that are
    based on Kubernetes: [Kubeless](https://kubeless.io), [Fn Project](https://fnproject.io),
    and [Fission](https://fission.io).'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们提到的基于 Kubernetes 的其他 FaaS 平台上运行一个简单的 HTTP 端点：[Kubeless](https://kubeless.io),
    [Fn Project](https://fnproject.io) 和 [Fission](https://fission.io)。
- en: Install and configure [Apache OpenWhisk](https://openwhisk.apache.org) inside
    a production-grade Kubernetes cluster such as Amazon EKS, Google GKE, or Azure
    AKS.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产级 Kubernetes 集群（如 Amazon EKS、Google GKE 或 Azure AKS）中安装和配置[Apache OpenWhisk](https://openwhisk.apache.org)。
- en: Port the AWS REST API example to GCP and Azure. GCP offers [Cloud Endpoints](https://cloud.google.com/endpoints)
    to manage multiple APIs. Similarly, Azure offers [API Management](https://oreil.ly/tmDh7).
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 AWS 的 REST API 示例移植到 GCP 和 Azure。GCP 提供 [Cloud Endpoints](https://cloud.google.com/endpoints)
    来管理多个 API。类似地，Azure 提供 [API Management](https://oreil.ly/tmDh7)。
