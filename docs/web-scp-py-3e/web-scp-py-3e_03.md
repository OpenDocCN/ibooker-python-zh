# 第二章。网络抓取的法律和伦理问题

2010 年，软件工程师 Pete Warden 构建了一个网络爬虫，从 Facebook 收集数据。他从大约 2 亿名 Facebook 用户那里收集了数据——姓名、位置信息、朋友和兴趣。当然，Facebook 注意到了并向他发送了停止和弃权信，他遵守了。当被问及为什么遵守停止和弃权时，他说：“大数据？便宜。律师？不便宜。”

在本章中，您将了解与网络抓取相关的美国法律（以及一些国际法律），并学习如何分析给定网络抓取情况的合法性和伦理性。

在您阅读以下章节之前，请考虑显而易见的事实：我是一名软件工程师，而不是律师。不要将您在本书的任何章节中或其他地方阅读到的内容解释为专业法律建议或据此采取行动。尽管我相信我能够就网络抓取的法律和伦理问题进行讨论，但在进行任何法律上含糊不清的网络抓取项目之前，您应咨询律师（而不是软件工程师）。

本章的目标是为您提供一个框架，以便能够理解和讨论网络抓取法律问题的各个方面，如知识产权、未经授权的计算机访问和服务器使用，但这不应替代实际的法律建议。

# 商标、版权、专利，哦，我的天啊！

是时候进行一次知识产权的速成课程了！知识产权基本上分为三种类型：商标（由™或®符号指示）、版权（普遍的©）和专利（有时由注明发明受专利保护的文本或专利号表示，但通常什么也没有）。

专利仅用于宣告对发明的所有权。您不能为图像、文字或任何信息本身申请专利。尽管某些专利，例如软件专利，比我们所想的“发明”更不具体，但请记住，专利的是*东西*（或技术）而不是组成软件的数据本身。除非您从抓取的图表中构建事物，或者有人对网络抓取方法申请专利，否则您不太可能通过抓取网络无意中侵犯专利。

商标也不太可能成为问题，但仍然必须考虑。根据美国专利商标局：

> *商标*是指一个词语、短语、符号和/或设计，用于识别和区分一方商品的来源与其他方的商品。*服务商标*是指一个词语、短语、符号和/或设计，用于识别和区分服务的来源而不是商品。术语“商标”通常用来指代商标和服务商标。

除了商标常见的文字和符号之外，其他描述性属性也可以注册商标。例如，容器的形状（如可口可乐瓶）甚至一种颜色（最著名的是欧文康宁公司的粉红色豹王玻璃纤维隔热材料）。

与专利不同，商标的所有权在很大程度上取决于其使用的上下文。例如，如果我希望发布一篇博客文章，并附带一张带有可口可乐标志的图片，只要我不暗示我的博客文章是由可口可乐赞助或发布的，我是可以这样做的。如果我想要生产一种新的软饮料，并在包装上展示相同的可口可乐标志，那显然就是商标侵权。同样地，虽然我可以将我的新软饮料包装成粉红色，但我不能使用相同的颜色来制造家用隔热材料。

这将我们带到了“公平使用”这个话题，这通常是在版权法的背景下讨论的，但也适用于商标。存储或展示商标以参考其代表的品牌是可以的。以可能误导消费者的方式使用商标是不行的。“公平使用”的概念不适用于专利。例如，一个行业中的专利发明不能在没有与专利持有人达成协议的情况下应用到另一个行业。

## 版权法

商标和专利有一个共同点，那就是它们必须经过正式注册才能被认可。与普遍认为的不同，版权材料并不需要这样做。什么使图像、文本、音乐等成为版权材料呢？并不是页面底部的“保留所有权利”警告或者关于“已出版”与“未出版”材料的任何特殊性质。你创作的每一件材料一旦存在，都会自动受到版权法的保护。

《关于文学和艺术作品保护的伯尔尼公约》以瑞士伯尔尼为名，于 1886 年首次通过，是版权的国际标准。该公约本质上规定，所有成员国必须承认其他成员国公民的作品的版权保护，就像它们是自己国家的公民一样。实际上，这意味着，作为美国公民，你在美国可以因侵犯来自法国等其他国家某人的版权而受到起诉（反之亦然）。

# 版权登记

尽管版权保护自动适用且无需任何注册，但也可以向美国政府正式注册版权。这通常用于有价值的创意作品，如主要电影，以便稍后进行诉讼时更容易，并为所有权创建强大的书面记录。然而，请不要让版权登记的存在使您困惑——除非特别属于公共领域，否则所有创意作品均受版权保护！

显然，版权对网络爬虫的关注要大于商标或专利。如果我从某人的博客中抓取内容并发布到我的博客上，我很可能会面临诉讼。幸运的是，我有几层保护措施，这可能使我的博客抓取项目具有防御性，具体取决于其功能。

首先，版权保护仅适用于创意作品。它不涵盖统计数据或事实。幸运的是，网络爬虫所追求的大部分内容确实是统计数据和事实。

从网络中收集诗歌并在您自己的网站上显示的网络爬虫可能会侵犯版权法；然而，从时间上看收集诗歌发布频率信息的网络爬虫则不会。诗歌本身是创造性作品。按月发布在网站上的诗歌的平均字数是事实数据，而不是创造性作品。

发布原文（而不是从原始抓取数据的聚合/计算内容）可能不违反版权法，如果数据是价格、公司高管姓名或其他一些事实信息。

即使版权内容也可以在合理范围内根据 1988 年数字千禧年版权法直接使用。 DMCA 概述了有关自动处理版权材料的一些规则。 DMCA 很长，具有许多具体规则，涵盖从电子书到电话的一切。但是，两个主要点可能特别与网络爬虫相关：

+   根据“安全港”保护，如果您从一个您被引导相信只包含免版权材料的来源中抓取材料，但用户已提交版权材料，则只要在收到通知后删除版权材料，您就受到保护。

+   您不能规避安全措施（如密码保护）以收集内容。

此外，DMCA 还承认 17 U.S. Code § 107 下的合理使用，并且如果使用版权材料符合合理使用，则根据安全港保护不会发出撤销通知。

简而言之，你绝不应直接发布未经原作者或版权持有人许可的受版权保护的材料。如果你正在将你可以自由访问的受版权保护材料存储在自己的非公开数据库中以进行分析，则可以。如果你将该数据库发布到你的网站以供查看或下载，则不行。如果你正在分析该数据库并发布有关字数统计、作者按创作产量排序的列表或其他数据的元分析，则可以。如果你将该元分析与少量选择的引用或数据简短样本配合使用以阐明观点，则可能也可以，但你可能需要查阅美国法典中的公平使用条款以确认。

### 版权与人工智能

基于现有创意作品语料库生成新的“创意”作品的生成人工智能程序，给版权法带来独特的挑战。

如果生成 AI 程序的输出类似于现有作品，则可能存在版权问题。已有许多案例作为先例，以指导“类似”在这里的定义，但根据国会研究服务[¹]：

> 实质相似性测试很难定义，并且在美国法院中各不相同。法院曾经以不同方式描述该测试，例如要求作品具有“基本相似的总体概念和感觉”或“总体外观和感觉”，或者要求“普通合理人无法区分两个作品”。

现代复杂算法的问题在于，很难自动确定你的 AI 是否产生了令人兴奋且新颖的混搭，还是更直接的衍生物。AI 可能无法将其输出标记为与特定输入“基本相似”，甚至无法识别其用于生成创作的哪些输入！表明任何事情出错的第一个迹象可能是一封停止和停止信函或法庭传票。

除了关于生成 AI 输出的版权侵权问题外，即将进行的法院案件还测试了训练过程本身是否可能侵犯版权持有人的权利。

为了训练这些系统，几乎总是需要下载、存储和复制受版权保护的作品。虽然下载受版权保护的图像或文本似乎并不是什么大事，但这与下载受版权保护的电影并无多少区别——你不会下载电影，对吧？

有些人声称这构成了公平使用，并且他们并未以可能影响其市场的方式发布或使用内容。

我们撰写本文时，OpenAI 正在美国专利商标局争论其使用大量受版权保护的材料是否构成合理使用。² 虽然这一论点主要是在 AI 生成算法的背景下，我认为其结果将适用于各种目的构建的网络爬虫。

# 进入个人财产

*侵入个人财产* 与我们所认为的“侵入法”根本不同，因为它适用于不动产或土地，而适用于法律术语中的可移动财产或*个人财产*。当您的财产受到某种方式的干扰，无法访问或使用时，它适用。

在这个云计算时代，很容易不把网络服务器看作是真实的、有形的资源。然而，服务器不仅由昂贵的组件组成，而且需要存储、监控、冷却、清洁，并提供大量电力。据估计，全球电力使用量的 10%用于计算机。³ 如果您的电子设备调查不能说服您，考虑一下谷歌的大型服务器农场，所有这些都需要连接到大型发电站。

虽然服务器是昂贵的资源，但从法律的角度来看，它们很有趣，因为网站管理员通常*希望*人们使用他们的资源（即访问他们的网站）；他们只是不希望他们过度使用他们的资源。通过浏览器查看网站是可以的；发起全面的分布式拒绝服务（DDOS）攻击显然是不可以的。

网络爬虫要违反侵入个人财产，需要满足三个标准：

缺乏同意

因为网络服务器对每个人开放，它们通常也“允许”网络爬虫。然而，许多网站的服务条款明确禁止使用爬虫。此外，任何发给您的停止和停止通知可能会撤销这种同意。

实际损害

服务器成本高昂。除了服务器成本外，如果您的爬虫使网站崩溃或限制其为其他用户提供服务的能力，这可能会增加您造成的“损害”。

故意性

如果你在写代码，你知道它的功能！在辩护你的网络爬虫时，争辩没有意图可能不会顺利。

您必须满足这三个标准，才能适用于个人财产的侵入。然而，如果您违反了服务条款协议，但并未造成实际损害，请不要认为自己免于法律行动。您很可能侵犯了版权法、DMCA、计算机欺诈与滥用法案（本章后面将详细介绍），或适用于网络爬虫的其他众多法律之一。

# 计算机欺诈与滥用法案

在 20 世纪 80 年代初，计算机开始从学术界进入商业界。这是第一次，病毒和蠕虫不再只被视为一种不便（甚至是一种有趣的爱好），而是作为可能造成经济损失的严重刑事问题。1983 年，由马修·布罗德里克主演的电影《战争游戏》也把这个问题带到了公众和总统罗纳德·里根的眼前。⁴ 作为对此的回应，1986 年制定了《计算机欺诈和滥用法》（CFAA）。

尽管你可能认为 CFAA 仅适用于典型的恶意黑客释放病毒的情况，但该法案对网络爬虫也有重要影响。想象一下一个扫描网页以寻找登录表单和易于猜测密码，或者收集意外泄露在隐藏但公共位置的政府机密的爬虫。所有这些活动在 CFAA 下都是非法的（而且理所当然）。

该法案定义了七种主要的刑事罪行，总结如下：

+   未经授权访问美国政府拥有的计算机并从这些计算机获取信息。

+   未经授权访问计算机并获取财务信息。

+   未经授权访问美国政府拥有的计算机，影响政府对该计算机的使用。

+   未经授权访问任何受保护计算机并企图欺诈。

+   未经授权访问计算机并造成损害。

+   共享或交易用于美国政府使用或影响跨州或国际贸易的计算机的密码或授权信息。

+   通过造成损害或威胁造成损害来敲诈钱财或“任何有价物品”。

简而言之：远离受保护的计算机，不要访问未授权访问的计算机（包括 Web 服务器），尤其是远离政府或金融计算机。

# robots.txt 和服务条款

从法律角度来看，网站的服务条款和 robots.txt 文件是一个有趣的领域。如果一个网站是公开访问的，网站管理员声明哪些软件可以访问它，哪些不能访问，这是一个有争议的问题。说“如果你使用浏览器查看该网站是可以的，但如果你使用自己编写的程序查看就不行”，这是一个棘手的问题。

大多数网站在每一页的页脚都有链接指向其服务条款（TOS）。TOS 不仅包含网络爬虫和自动访问的规则，通常还包括网站收集信息的类型及其处理方式，以及通常的免责声明，即网站提供的服务不带任何明示或暗示的保证。

如果您对搜索引擎优化（SEO）或搜索引擎技术感兴趣，您可能已经听说过*robots.txt*文件。如果您只需访问任何大型网站并查找其*robots.txt*文件，您将在根 Web 文件夹中找到它：*http://website.com/robots.txt*。

*robots.txt*文件的语法是在 1994 年 Web 搜索引擎技术初期的繁荣期间开发的。当像 AltaVista 和 DogPile 这样的搜索引擎开始竞争整个互联网的搜索时，它们开始真正有意义地与由主题组织的简单网站列表竞争，比如由 Yahoo！策划的那种。互联网搜索的这种增长不仅意味着网络爬虫数量的激增，还意味着这些网络爬虫收集的信息对普通公民的可用性激增。

尽管我们今天可能认为这种可用性理所当然，但是当一些网站管理员发现他们发布在网站文件结构深处的信息出现在主要搜索引擎的搜索结果首页时，他们感到震惊。作为回应，开发了*robots.txt*文件的语法，称为机器人排除协议。

与服务条款不同，通常以广义且非常人性化的语言讨论网络爬虫，*robots.txt*可以非常容易地被自动化程序解析和使用。虽然它看起来可能是解决不受欢迎的机器人问题的完美系统，但请记住：

+   *robots.txt*的语法没有官方的管理机构。它是一个普遍使用且通常遵循的惯例，但没有任何东西能阻止任何人创建他们自己的*robots.txt*文件的版本（除非没有机器人认可或遵守它，直到它变得流行）。尽管如此，它是一个被广泛接受的惯例，主要是因为它相对简单，并且公司没有动力去发明自己的标准或试图改进它。

+   没有法律或技术手段来强制执行*robots.txt*文件。它仅仅是一个标志，表示“请不要访问站点的这些部分”。许多网络爬虫库都能遵守*robots.txt*，尽管这通常是可以覆盖的默认设置。撇开库的默认设置，编写一个遵守*robots.txt*的网络爬虫实际上比完全忽略它更具技术挑战性。毕竟，您需要读取、解析和应用*robots.txt*的内容到您的代码逻辑中。

机器人排除协议的语法非常简单。与 Python（以及许多其他语言）一样，注释以`#`符号开头，以换行符结尾，并且可以在文件的任何位置使用。

除了任何注释之外，文件的第一行以`User-agent:`开头，指定规则适用于哪个用户。然后是一组规则，要么是`Allow:`要么是`Disallow:`，具体取决于该部分是否允许爬虫访问。星号（*）表示通配符，可用于描述`User-agent`或 URL。

如果一个规则遵循一个看似矛盾的规则，则最后的规则优先。例如：

```py
#Welcome to my robots.txt file!
User-agent: *
Disallow: *

User-agent: Googlebot
Allow: *
Disallow: /private
```

在这种情况下，所有机器人都被禁止访问网站的任何地方，除了 Googlebot，该机器人可以访问除了*/private*目录之外的任何地方。

Twitter 的*robots.txt*文件（也被称为“X”）对 Google、Yahoo!、Yandex（一家知名的俄罗斯搜索引擎）、Microsoft 和其他未涵盖在前述类别中的机器人或搜索引擎的机器人都有明确的指示。谷歌部分（看起来与允许所有其他类别机器人的权限相同）如下所示：

```py
#Google Search Engine Robot
User-agent: Googlebot
Allow: /?_escaped_fragment_

Allow: /?lang=
Allow: /hashtag/*?src=
Allow: /search?q=%23
Disallow: /search/realtime
Disallow: /search/users
Disallow: /search/*/grid

Disallow: /*?
Disallow: /*/followers
Disallow: /*/following
```

注意，Twitter 限制了其网站中具有 API 的部分的访问。因为 Twitter 拥有一个良好监管的 API（并且可以通过许可收费），所以不允许任何独立爬取其网站信息的“自制 API”是公司的最佳利益。

虽然一开始告诉你的爬虫不能访问哪里的文件可能看起来很限制，但对于网络爬虫的发展来说，这实际上是一种福音。如果你找到了一个*robots.txt*文件，禁止在网站的特定部分进行爬行，那么网站管理员基本上是在表明他们允许在网站的所有其他部分进行爬虫。毕竟，如果他们不允许，他们在首次编写*robots.txt*时就会限制访问。

例如，维基百科*robots.txt*文件中适用于一般网络爬取器（而不是搜索引擎）的部分非常宽松。它甚至包含了可供欢迎机器人（我们就是！）的人类可读文本，并且只阻止对少数页面的访问，例如登录页面、搜索页面和“随机文章”页面：

```py
#
# Friendly, low-speed bots are welcome viewing article pages, but not 
# dynamically generated pages please.
#
# Inktomi's "Slurp" can read a minimum delay between hits; if your bot supports
# such a thing using the 'Crawl-delay' or another instruction, please let us 
# know.
#
# There is a special exception for API mobileview to allow dynamic mobile web &
# app views to load section content.
# These views aren't HTTP-cached but use parser cache aggressively and don't 
# expose special: pages etc.
#
User-agent: *
Allow: /w/api.php?action=mobileview&
Disallow: /w/
Disallow: /trap/
Disallow: /wiki/Especial:Search
Disallow: /wiki/Especial%3ASearch
Disallow: /wiki/Special:Collection
Disallow: /wiki/Spezial:Sammlung
Disallow: /wiki/Special:Random
Disallow: /wiki/Special%3ARandom
Disallow: /wiki/Special:Search
Disallow: /wiki/Special%3ASearch
Disallow: /wiki/Spesial:Search
Disallow: /wiki/Spesial%3ASearch
Disallow: /wiki/Spezial:Search
Disallow: /wiki/Spezial%3ASearch
Disallow: /wiki/Specjalna:Search
Disallow: /wiki/Specjalna%3ASearch
Disallow: /wiki/Speciaal:Search
Disallow: /wiki/Speciaal%3ASearch
Disallow: /wiki/Speciaal:Random
Disallow: /wiki/Speciaal%3ARandom
Disallow: /wiki/Speciel:Search
Disallow: /wiki/Speciel%3ASearch
Disallow: /wiki/Speciale:Search
Disallow: /wiki/Speciale%3ASearch
Disallow: /wiki/Istimewa:Search
Disallow: /wiki/Istimewa%3ASearch
Disallow: /wiki/Toiminnot:Search
Disallow: /wiki/Toiminnot%3ASearch

```

是否选择编写遵守*robots.txt*的网络爬虫取决于你自己，但我强烈推荐这样做，特别是如果你的爬虫不加区分地爬行网络。

# 三个网络爬虫

因为网络抓取是一个无限可能的领域，有很多方法可能会让你陷入法律纠纷。本节介绍了三种涉及一些普遍适用于网络爬虫的法律形式的案例，以及它是如何在这些案例中使用的。

## eBay v. Bidder’s Edge 和动产侵权

1997 年，Beanie Baby 市场蓬勃发展，科技行业蓬勃发展，网络拍卖公司成为互联网上的新热门事物。一个名叫 Bidder’s Edge 的公司成立并创建了一种新型元拍卖网站。它不是强迫你从一个拍卖网站到另一个拍卖网站，比较价格，而是汇总了所有当前产品（比如热门的 Furby 娃娃或*Spice World*的副本）的拍卖数据，并指引你前往价格最低的网站。

Bidder’s Edge 通过一支由网络爬虫组成的部队实现了这一点，不断向各种拍卖网站的 Web 服务器发送请求以获取价格和产品信息。在所有的拍卖网站中，eBay 是最大的，Bidder’s Edge 每天向 eBay 的服务器发出约 10 万次请求。即使按照今天的标准，这也是相当多的流量。据 eBay 称，这占当时其总互联网流量的 1.53%，它肯定对此感到不满。

eBay 发出了一封停止侵权信，并提出许可其数据的提议。然而，这次许可的谈判失败了，Bidder’s Edge 继续爬取 eBay 的网站。

eBay 曾试图封锁 Bidder’s Edge 使用的 IP 地址，封锁了 169 个 IP 地址——尽管 Bidder’s Edge 通过使用代理服务器绕过了这一限制（代理服务器是指代表另一台机器转发请求，但使用代理服务器自己的 IP 地址）。我相信你可以想象到，这对双方来说都是一种令人沮丧且不可持续的解决方案——Bidder’s Edge 不断尝试寻找新的代理服务器并购买新的 IP 地址，而旧的 IP 地址被封锁后，eBay 则被迫维护大型防火墙列表（并且在每个数据包检查中增加了计算昂贵的 IP 地址比较开销）。

最后，1999 年 12 月，eBay 以财产侵权起诉了 Bidder’s Edge。

因为 eBay 的服务器是真实的、有形的资源，是它拥有的，而且它不喜欢 Bidder’s Edge 对它们的异常使用，因此财产侵权似乎是最理想的法律。事实上，在现代，财产侵权与网络爬虫诉讼密切相关，并且最常被视为一种 IT 法律。

法院裁定，为了让 eBay 在使用财产侵权赢得案件，eBay 必须证明两件事：

+   Bidder’s Edge 知道被明确禁止使用 eBay 的资源。

+   eBay 因 Bidder’s Edge 的行为而遭受了财务损失。

鉴于 eBay 的停止侵权信记录，以及 IT 记录显示的服务器使用情况和与服务器相关的实际成本，这对 eBay 来说相对容易。当然，没有大型法庭战斗会轻松结束：提起反诉，支付了许多律师费，这件事最终于 2001 年 3 月以保密金额在庭外和解。

那么这是否意味着未经授权使用他人服务器就自动违反财产侵入侵权？未必。Bidder’s Edge 是一个极端案例；它使用了 eBay 的很多资源，使公司不得不购买额外的服务器，支付更多的电费，并可能雇佣额外的人员。尽管 1.53%的增加看似微不足道，但在大公司中，这可能累积成显著的数额。

2003 年，加州最高法院就另一起案件 Intel Corp 对 Hamidi 作出裁决，前 Intel 员工 Hamidi 发送了 Intel 不喜欢的电子邮件，通过 Intel 的服务器发送给 Intel 员工。法院表示：

> Intel 的主张失败并不是因为通过互联网传输的电子邮件享有独特的免责权，而是因为侵入财产的侵害行为——与刚提到的原因不同——在加利福尼亚州，可能没有证据证明对原告的个人财产或法律利益的损害。

本质上，Intel 未能证明 Hamidi 发送给所有员工的六封电子邮件的传输成本（有趣的是，每封邮件都有一个选项可以从 Hamidi 的邮件列表中移除！）对 Intel 造成任何财务损失。它没有剥夺 Intel 任何财产或其财产的使用。

## 美国诉 Auernheimer 和计算机欺诈与滥用法案

如果信息可以通过网络浏览器轻松访问到，那么以自动化方式访问相同的信息不太可能让你与联邦政府陷入麻烦。然而，当自动化爬虫介入时，一个看似小的安全漏洞很快就可能变成一个更大更危险的问题。

2010 年，Andrew Auernheimer 和 Daniel Spitler 注意到 iPad 的一个很好的特性：当你在它们上访问 AT&T 的网站时，AT&T 会将你重定向到一个包含你 iPad 唯一 ID 号的 URL：

```py
https://dcp2.att.com/OEPClient/openPage?ICCID=<idNumber>&IMEI=
```

此页面将包含一个登录表单，其中包含 URL 中 ID 号的用户的电子邮件地址。这允许用户只需输入其密码即可访问其帐户。

尽管有大量潜在的 iPad ID 号码，但可以使用网络爬虫迭代可能的号码，一路收集电子邮件地址。通过提供用户这种便利的登录功能，AT&T 本质上将其客户电子邮件地址公开到了网络上。

Auernheimer 和 Spitler 创建了一个爬虫程序，收集了 114,000 个这些电子邮件地址，其中包括名人、CEO 和政府官员的私人电子邮件地址。Auernheimer（但不包括 Spitler）随后将列表及其获取方式的信息发送给了 Gawker Media，后者在标题为“Apple 最严重的安全漏洞：114,000 名 iPad 用户暴露”的报道中发布了这个故事（但未发布列表）。

2011 年 6 月，奥尔哈伊默的住所被 FBI 突袭，涉及电子邮件地址收集，尽管他们最终因毒品指控逮捕了他。2012 年 11 月，他因身份欺诈和未经授权访问计算机而被判有罪，并被判处 41 个月联邦监狱和支付 73,000 美元赔偿金。

他的案件引起了民权律师奥林·科尔的关注，后者加入了他的法律团队，并向第三巡回上诉法院上诉该案。2014 年 4 月 11 日（这些法律程序可能需要相当长的时间），他们提出了以下论点：

> 奥尔哈伊默对第一项指控的定罪必须被推翻，因为访问公开可用的网站并不构成《计算机欺诈和滥用法案》第 18 U.S.C. § 1030(a)(2)(C)条项下的未经授权访问。AT&T 选择不使用密码或任何其他保护措施来控制对其客户电子邮件地址的访问。AT&T 主观上希望外部人士不会偶然发现这些数据，或者奥尔哈伊默夸大地将访问描述为“窃取”是无关紧要的。公司配置其服务器以使信息对所有人可见，从而授权公众查看信息。通过 AT&T 的公共网站访问电子邮件地址是根据 CFAA 授权的，因此并不构成犯罪。

尽管奥尔哈伊默的定罪仅因地点不符而在上诉中被推翻，但第三巡回上诉法院在他们的决定中似乎对这一论点持开放态度，他们在脚注中写道：

> 尽管我们无需解决奥尔哈伊默的行为是否涉及此类违规，但在审判中并未提出证据表明账户抓手曾违反任何密码门或其他基于代码的障碍物。账户抓手只是访问了登陆屏幕的公开部分，并爬取了 AT&T 无意间发布的信息。

尽管奥尔哈伊默最终未因《计算机欺诈和滥用法案》而被定罪，但他的住所被 FBI 突袭，花费了数千美元的法律费用，并在法庭和监狱中度过了三年。

作为网络爬虫，我们能从中汲取哪些教训以避免类似情况？也许一个很好的开始是：不要表现得像个混蛋。

爬取任何敏感信息，无论是个人数据（在这种情况下是电子邮件地址）、商业秘密还是政府机密，可能并不是你想要在没有速拨律师的情况下做的事情。即使它是公开可用的，也要考虑：“普通计算机用户是否能够轻松访问这些信息？”或者“这是公司希望用户看到的内容吗？”

我曾多次致电公司报告其 Web 应用程序中的安全漏洞。这句话非常有效：“您好，我是一名安全专业人士，在您的网站上发现了一个潜在的漏洞。您能指引我找到相关负责人以便我报告并解决这个问题吗？”除了立即得到对你（白帽）黑客天才的承认的满足感外，你还可能获得免费订阅、现金奖励和其他好东西！

此外，奥伦海默将信息发布给 Gawker Media（在通知 AT&T 之前），并围绕漏洞利用炫耀，也使他成为 AT&T 律师特别青睐的目标。

如果您发现一个网站存在安全漏洞，最好的做法是通知网站的所有者，而不是媒体。你可能会想要写一篇博客文章并向全世界宣布，尤其是在问题没有得到立即解决的情况下。然而，你需要记住，这是公司的责任，而不是你的责任。你能做的最好的事情就是把你的网络爬虫（如果适用，你的业务）从该网站撤离！

## 菲尔德诉谷歌：版权和 robots.txt

布雷克·菲尔德，一位律师，基于谷歌网站缓存功能侵犯了版权法的基础，他认为谷歌的缓存（在他从网站上移除之后）剥夺了他对其分发的控制权。版权法允许原创作品的创作者控制其分发。菲尔德的论点是，谷歌的缓存（在他从网站上移除之后）剥夺了他对其分发的控制权。

# 谷歌网页缓存

当谷歌的网络爬虫（也称为*Googlebots*）抓取网站时，它们会复制该网站并将其托管在互联网上。任何人都可以访问这个缓存，使用以下 URL 格式：

+   *http://webcache.googleusercontent.com/search?q=cache:http://pythonscraping.com*

如果您正在搜索或爬取的网站不可用，您可能想检查是否存在可用的副本！

知道谷歌的缓存功能但不采取行动对菲尔德的案件没有帮助。毕竟，他本可以通过简单添加*robots.txt*文件来阻止 Googlebots 缓存他的网站，简单指示哪些页面应该被抓取，哪些不应该被抓取。

更重要的是，法院认为 DMCA 安全港条款允许谷歌合法缓存和显示像菲尔德的网站：“[a]服务提供商不应因在由或为服务提供商控制或操作的系统或网络上的材料的中间和临时存储而对版权侵权要求提供金钱补偿......”

¹ 详细分析请参见[“生成人工智能与版权法”](https://crsreports.congress.gov/product/pdf/LSB/LSB10922)，法律侧边栏，国会研究服务，2023 年 9 月 29 日。

² 见“关于知识产权保护对人工智能创新的评论”。Docket No. PTO-C-2019-0038，美国专利和商标局。

³ 布莱恩·沃尔什，[“数字经济的惊人能源足迹 [更新]”](http://ti.me/2IFOF3F)，TIME.com，2013 年 8 月 14 日。

⁴ 见“‘WarGames’和网络安全对好莱坞黑客的债务”，[*https://oreil.ly/nBCMT*](https://oreil.ly/nBCMT)，以及“不忠电脑使用和计算机欺诈和滥用法案的范围缩小”，[*https://oreil.ly/6TWJq*](https://oreil.ly/6TWJq)。
