["```py\nimport ray\nfrom ray import workflow\nfrom typing import List\n\n# Creating an arbitrary Ray remote function\n@ray.remote\ndef hello():\n    return \"hello\"\n\n# Defining a workflow step that puts an object into the object store\n@workflow.step\ndef words() -> List[ray.ObjectRef]:\n    return [hello.remote(), ray.put(\"world\")]\n\n# Defining a step that receives an object\n@workflow.step\ndef concat(words: List[ray.ObjectRef]) -> str:\n    return \" \".join([ray.get(w) for w in words])\n\n# Creating workflow\nworkflow.init(\"tmp/workflow_data\")\noutput: \"Workflow[int]\" = concat.step(words.step())\n\n# Running workflow\nassert output.run(workflow_id=\"workflow_1\") == \"hello world\"\nassert workflow.get_status(\"workflow_1\") == workflow.WorkflowStatus.SUCCESSFUL\nassert workflow.get_output(\"workflow_1\") == \"hello world\"\n```", "```py\nfrom ray import workflow\n@workflow.step(num_gpus=1)\ndef train_model() -> Model:\n    pass  # This step is assigned a GPU by Ray.\n\ntrain_model.step().run()\n```", "```py\nfrom ray import workflow\n\n@workflow.step\ndef factorial(n: int) -> int:\n    if n == 1:\n        return 1\n    else:\n        return mult.step(n, factorial.step(n - 1))\n\n@workflow.step\ndef mult(a: int, b: int) -> int:\n    return a * b\n\n# Calculate the factorial of 5 by creating a recursion of 5 steps\nfactorial_workflow = factorial.step(5).run()\nassert factorial_workflow.run() == 120\n```", "```py\nfrom ray import workflow\n\n@workflow.virtual_actor\nclass counter:\n    def __init__(self):\n        self.count = 0\n\n    def incr(self):\n        self.count += 1\n        return self.count\n\nworkflow.init(storage=\"/tmp/workflows\")\n\nworkflow1 = counter.get_or_create(\"counter_workflw\")\nassert c1.incr.run() == 1\nassert c1.incr.run() == 2\n```", "```py\nfrom ray import workflow\n\n@workflow.step\ndef sum(x: int, y: int, z: int) -> int:\n    return x + y + z\n\n@workflow.step\ndef get_value1() -> int:\n    return 100\n\n@workflow.step\ndef get_value2(x: int) -> int:\n    return 10*x\n\nsum_workflow = sum.step(get_val1.step(), get_val2.step(10), 100)\n\nassert sum_workflow.run(\"sum_example\") == 300\n```", "```py\nfrom ray import workflow\n\n@workflow.step\ndef add(a: int, b: int) -> int:\n    return a + b\n\n@workflow.step\ndef fib(n: int) -> int:\n    if n <= 1:\n        return n\n    return add.step(fib.step(n - 1), fib.step(n - 2))\n\nassert fib.step(10).run() == 55\n```", "```py\nfrom ray import workflow\n\n@workflow.step\ndef book_flight(...) -> Flight: ...\n\n@workflow.step\ndef book_hotel(...) -> Hotel: ...\n\n@workflow.step\ndef finalize_or_cancel(\n    flights: List[Flight],\n    hotels: List[Hotel]) -> Receipt: ...\n\n@workflow.step\ndef book_trip(origin: str, dest: str, dates) ->\n        \"Workflow[Receipt]\":\n    # Note that the workflow engine will not begin executing\n    # child workflows until the parent step returns.\n    # This avoids step overlap and ensures recoverability.\n    f1: Workflow = book_flight.step(origin, dest, dates[0])\n    f2: Workflow = book_flight.step(dest, origin, dates[1])\n    hotel: Workflow = book_hotel.step(dest, dates)\n    return finalize_or_cancel.step([f1, f2], [hotel])\n\nfut = book_trip.step(\"OAK\", \"SAN\", [\"6/12\", \"7/5\"])\nfut.run()  # Returns Receipt(...)\n```", "```py\nfrom ray import workflow\n@workflow.step\ndef random_failure() -> str:\n    if random.random() > 0.95:\n        raise RuntimeError(\"Found failure\")\n    return \"OK\"\n\n# Run 5 times before giving up\ns1 = faulty_function.options(max_retries=5).step()\ns1.run()\n\n@workflow.step\ndef handle_errors(result: Tuple[str, Exception]):\n    # Setting the exception field to NONE on success\n    err = result[1]\n    if err:\n        return \"There was an error: {}\".format(err)\n    else:\n        return \"OK\"\n\n# `handle_errors` receives a tuple of (result, exception).\ns2 = faulty_function.options(catch_exceptions=True).step()\nhandle_errors.step(s2).run()\n```", "```py\nfrom ray import workflow\n\n@workflow.step\ndef generate_id() -> str:\n   # Generate a unique idempotency token.\n   return uuid.uuid4().hex\n\n@workflow.step\ndef book_flight_idempotent(request_id: str) -> FlightTicket:\n   if service.has_ticket(request_id):\n       # Retrieve the previously created ticket.\n       return service.get_ticket(request_id)\n   return service.book_flight(request_id)\n\n# SAFE: book_flight is written to be idempotent\nrequest_id = generate_id.step()\nbook_flight_idempotent.step(request_id).run()\n```", "```py\nfrom ray import workflow\nimport ray\n\n@workflow.virtual_actor\nclass Counter:\n    def __init__(self, init_val):\n        self._val = init_val\n\n    def incr(self, val=1):\n        self._val += val\n        print(self._val)\n\n    @workflow.virtual_actor.readonly\n    def value(self):\n        return self._val\n\nworkflow.init()\n\n# Initialize a Counter actor with id=\"my_counter\".\ncounter = Counter.get_or_create(\"my_counter\", 0)\n\n# Similar to workflow steps, actor methods support:\n# - `run()`, which will return the value\n# - `run_async()`, which will return a ObjectRef\ncounter.incr.run(10)\nassert counter.value.run() == 10\n\n# Nonblocking execution.\ncounter.incr.run_async(10)\ncounter.incr.run(10)\nassert 30 == ray.get(counter.value.run_async())\n```", "```py\nfrom ray import workflow\nimport ray\n\n@workflow.step\ndef double(s):\n    return 2 * s\n\n@workflow.virtual_actor\nclass Actor:\n    def __init__(self):\n        self.val = 1\n\n    def double(self, update):\n        step = double.step(self.val)\n        if not update:\n            # Inside the method, a workflow can be launched\n            return step\n        else:\n            # Workflow can also be passed to another method\n            return self.update.step(step)\n\n    def update(self, v):\n        self.val = v\n        return self.val\n\nhandler = Actor.get_or_create(\"actor\")\nassert handler.double.run(False) == 2\nassert handler.double.run(False) == 2\nassert handler.double.run(True) == 2\nassert handler.double.run(True) == 4\n```", "```py\ntraining_tuple = (X_train, y_train, 'fit')\nclassification.step(scaling.step(training_tuple, 'standardscalar'),\n                    'decisiontree').run('training_pipeline')\n```", "```py\npredict_tuple = (X_test, y_test, 'predict')\n(X, pred_y, mode) = classification.step(scaling.step(predict_tuple,\n  'standardscalar'),'decisiontree').run('prediction_pipeline')\n```", "```py\nimport ray\nfrom ray import workflow\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import base\nfrom sklearn.base import BaseEstimator\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\nray.init(address='auto')\nworkflow.init()\n\n@ray.workflow.virtual_actor\nclass estimator_virtual_actor():\n    def __init__(self, estimator: BaseEstimator):\n        if estimator is not None:\n            self.estimator = estimator\n\n    def fit(self, inputtuple):\n        (X, y, mode)= inputtuple\n        if base.is_classifier(self.estimator) or base.is_regressor(self.estimator):\n            self.estimator.fit(X, y)\n            return X, y, mode\n        else:\n            X = self.estimator.fit_transform(X)\n            return X, y, mode\n\n    @workflow.virtual_actor.readonly\n    def predict(self, inputtuple):\n        (X, y, mode) = inputtuple\n        if base.is_classifier(self.estimator) or base.is_regressor(self.estimator):\n            pred_y = self.estimator.predict(X)\n            return X, pred_y, mode\n        else:\n            X = self.estimator.transform(X)\n            return X, y, mode\n\n    def run_workflow_step(self, inputtuple):\n        (X, y, mode) = inputtuple\n        if mode == 'fit':\n            return self.fit(inputtuple)\n        elif mode == 'predict':\n            return self.predict(inputtuple)\n\n    def __getstate__(self):\n        return self.estimator\n\n    def __setstate__(self, estimator):\n        self.estimator = estimator\n\n## Prepare the data\nX = pd.DataFrame(np.random.randint(0,100,size=(10000, 4)), columns=list('ABCD'))\ny = pd.DataFrame(np.random.randint(0,2,size=(10000, 1)), columns=['Label'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n@workflow.step\ndef scaling(inputtuple, name):\n    va = estimator_virtual_actor.get_or_create(name, StandardScaler())\n    outputtuple = va.run_workflow_step.run_async(inputtuple)\n    return outputtuple\n\n@workflow.step\ndef classification(inputtuple, name):\n    va = estimator_virtual_actor.get_or_create(name,\n                                               DecisionTreeClassifier(max_depth=3))\n    outputtuple = va.run_workflow_step.run_async(inputtuple)\n    return outputtuple\n\ntraining_tuple = (X_train, y_train, 'fit')\nclassification.step(scaling.step(training_tuple, 'standardscalar'), 'decisiontree').\n                    run('training_pipeline')\n\npredict_tuple = (X_test, y_test, 'predict')\n(X, pred_y, mode) = classification.step(scaling.step(predict_tuple,\n  'standardscalar'),'decisiontree').run('prediction_pipeline')\nassert pred_y.shape[0] == 2000\n```", "```py\nfrom ray import workflow\nimport ray\n\n@workflow.virtual_actor\nclass ShoppingCart:\n    ...\n    # Check status via ``self.shipment_workflow_id`` for avoid blocking\n    def do_checkout():\n        # Deterministically generate a workflow ID for idempotency.\n        self.shipment_workflow_id = \"ship_{}\".format(self.order_id)\n        # Run shipping workflow as a separate async workflow.\n        ship_items.step(self.items).run_async(\n            workflow_id=self.shipment_workflow_id)\n```", "```py\nfrom ray import workflow\n\n@ray.remote\ndef do_add(a, b):\n    return a + b\n\n@workflow.step\ndef add(a, b):\n    return do_add.remote(a, b)\n\nadd.step(ray.put(10), ray.put(20)).run() == 30\n```", "```py\nimport ray\nfrom ray import workflow\nfrom typing import List\n\n@workflow.step\ndef add(values: List[int]) -> int:\n    return sum(values)\n\n@workflow.step\ndef get_val() -> int:\n    return 10\n\nret = add.step([get_val.step() for _ in range(3)])\nassert ret.run() == 30\n```", "```py\nfrom ray import workflow\nimport time\n\n# Create an event that finishes after 60 seconds.\nevent1_step = workflow.wait_for_event(\n    workflow.event_listener.TimerListener, time.time() + 60)\n\n# Create another event that finishes after 30 seconds.\nevent2_step = workflow.wait_for_event(\n    workflow.event_listener.TimerListener, time.time() + 30)\n\n@workflow.step\ndef gather(*args):\n    return args;\n\n# Gather will run after 60 seconds, when both event1 and event2 are done.\ngather.step(event1_step, event2_step).run()\n```", "```py\nfrom ray import workflow\nclass EventListener:\n    def __init__(self):\n        \"\"\"Optional constructor. Only the constructor with no arguments will be\n called.\"\"\"\n        pass\n\n    async def poll_for_event(self, *args, **kwargs) -> Event:\n        \"\"\"Should return only when the event is received.\"\"\"\n        raise NotImplementedError\n\n    async def event_checkpointed(self, event: Event) -> None:\n        \"\"\"Optional. Called after an event has been checkpointed and a transaction\n can be safely committed.\"\"\"\n        pass\n```", "```py\nworkflow.get_metadata(workflow_id)\n```", "```py\nworkflow.get_metadata(workflow_id, name=<*step name*>)\n```"]