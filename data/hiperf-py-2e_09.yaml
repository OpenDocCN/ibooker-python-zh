- en: Chapter 9\. The multiprocessing Module
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。多进程模块
- en: CPython doesn’t use multiple CPUs by default. This is partly because Python
    was designed back in a single-core era, and partly because parallelizing can actually
    be quite difficult to do efficiently. Python gives us the tools to do it but leaves
    us to make our own choices. It is painful to see your multicore machine using
    just one CPU on a long-running process, though, so in this chapter we’ll review
    ways of using all the machine’s cores at once.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: CPython默认不使用多个CPU。这部分是因为Python是在单核时代设计的，部分原因是并行化实际上可能相当难以高效实现。Python给了我们实现的工具，但是让我们自己做选择。看到你的多核机器在长时间运行的进程中只使用一个CPU真是痛苦，所以在本章中，我们将回顾一些同时使用所有机器核心的方法。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We just mentioned *CPython*—the common implementation that we all use. Nothing
    in the Python language stops it from using multicore systems. CPython’s implementation
    cannot efficiently use multiple cores, but future implementations may not be bound
    by this restriction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚提到了*CPython*——这是我们所有人都使用的常见实现。Python语言本身并不阻止其在多核系统上的使用。CPython的实现不能有效地利用多核，但是未来的实现可能不受此限制。
- en: We live in a multicore world—4 cores are common in laptops, and 32-core desktop
    configurations are available. If your job can be split to run on multiple CPUs
    *without* too much engineering effort, this is a wise direction to consider.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个多核世界——笔记本电脑通常有4个核心，而32核心的桌面配置也是常见的。如果你的工作可以分解为在多个CPU上运行，而且不需要太多的工程工作，那么这是一个明智的方向值得考虑。
- en: When Python is used to parallelize a problem over a set of CPUs, you can expect
    *up to* an *n*-times (*n*×) speedup with *n* cores. If you have a quad-core machine
    and you can use all four cores for your task, it might run in a quarter of the
    original runtime. You are unlikely to see a greater than 4× speedup; in practice,
    you’ll probably see gains of 3–4×.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当Python用于在一组CPU上并行化问题时，你可以期待*最多*达到*n*倍的加速，其中*n*为核心数。如果你有一台四核机器，并且可以将所有四个核心用于任务，那么运行时间可能只有原始运行时间的四分之一。你不太可能看到超过4倍的加速；实际上，你可能会看到3到4倍的提升。
- en: Each additional process will increase the communication overhead and decrease
    the available RAM, so you rarely get a full *n*-times speedup. Depending on which
    problem you are solving, the communication overhead can even get so large that
    you can see very significant slowdowns. These sorts of problems are often where
    the complexity lies for any sort of parallel programming and normally require
    a change in algorithm. This is why parallel programming is often considered an
    art.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每增加一个进程都会增加通信开销并减少可用RAM，所以你很少能获得完全*n*倍的加速。取决于你正在解决的问题，通信开销甚至可能非常大，以至于可以看到非常显著的减速。这些问题通常是任何并行编程的复杂性所在，通常需要算法的改变。这就是为什么并行编程通常被认为是一门艺术。
- en: If you’re not familiar with [Amdahl’s law](https://oreil.ly/GC2CK), it is worth
    doing some background reading. The law shows that if only a small part of your
    code can be parallelized, it doesn’t matter how many CPUs you throw at it; it
    still won’t run much faster overall. Even if a large fraction of your runtime
    could be parallelized, there’s a finite number of CPUs that can be used efficiently
    to make the overall process run faster before you get to a point of diminishing
    returns.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对[Amdahl's law](https://oreil.ly/GC2CK)不熟悉，值得进行一些背景阅读。该定律表明，如果你的代码只有一小部分可以并行化，那么无论你投入多少CPU，整体速度提升都不会太大。即使你的运行时间的大部分可以并行化，也有一个有限数量的CPU可以有效地用于使整个过程在到达收益递减点之前更快地运行。
- en: The `multiprocessing` module lets you use process- and thread-based parallel
    processing, share work over queues, and share data among processes. It is mostly
    focused on single-machine multicore parallelism (there are better options for
    multimachine parallelism). A very common use is to parallelize a task over a set
    of processes for a CPU-bound problem. You might also use OpenMP to parallelize
    an I/O-bound problem, but as we saw in [Chapter 8](ch08.xhtml#chapter-concurrency),
    there are better tools for this (e.g., the new `asyncio` module in Python 3 and
    `tornado`).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块允许您使用基于进程和线程的并行处理，在队列中共享工作并在进程之间共享数据。它主要专注于单机多核并行性（在多机并行性方面有更好的选择）。非常常见的用法是将任务并行化到一组进程中，用于处理CPU密集型问题。您也可以使用OpenMP来并行化I/O密集型问题，但正如我们在[第8章](ch08.xhtml#chapter-concurrency)中所看到的，这方面有更好的工具（例如Python
    3中的新`asyncio`模块和`tornado`）。'
- en: Note
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: OpenMP is a low-level interface to multiple cores—you might wonder whether to
    focus on it rather than `multiprocessing`. We introduced it with Cython back in
    [Chapter 7](ch07.xhtml#chapter-compiling), but we don’t cover it in this chapter.
    `multiprocessing` works at a higher level, sharing Python data structures, while
    OpenMP works with C primitive objects (e.g., integers and floats) once you’ve
    compiled to C. Using it makes sense only if you’re compiling your code; if you’re
    not compiling (e.g., if you’re using efficient `numpy` code and you want to run
    on many cores), then sticking with `multiprocessing` is probably the right approach.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: OpenMP 是一个面向多核的低级接口——您可能会想集中精力在它上面，而不是`multiprocessing`。我们在[第7章](ch07.xhtml#chapter-compiling)中使用
    Cython 引入了它，但在本章中我们没有涉及。`multiprocessing`在更高的层面上工作，共享 Python 数据结构，而 OpenMP 在您编译为
    C 后使用 C 原始对象（例如整数和浮点数）工作。仅当您正在编译代码时才使用它是有意义的；如果您不编译代码（例如，如果您使用高效的`numpy`代码并且希望在许多核心上运行），那么坚持使用`multiprocessing`可能是正确的方法。
- en: To parallelize your task, you have to think a little differently from the normal
    way of writing a serial process. You must also accept that debugging a parallelized
    task is *harder*—often, it can be very frustrating. We’d recommend keeping the
    parallelism as simple as possible (even if you’re not squeezing every last drop
    of power from your machine) so that your development velocity is kept high.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要并行化您的任务，您必须以与编写串行进程的正常方式有所不同的方式思考。您还必须接受调试并行化任务更加困难—通常情况下，这可能会非常令人沮丧。我们建议保持并行性尽可能简单（即使您并没有从计算机中挤出最后一滴性能），这样可以保持您的开发速度。
- en: One particularly difficult topic is the sharing of state in a parallel system—it
    feels like it should be easy, but it incurs lots of overhead and can be hard to
    get right. There are many use cases, each with different trade-offs, so there’s
    definitely no one solution for everyone. In [“Verifying Primes Using Interprocess
    Communication”](ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication),
    we’ll go through state sharing with an eye on the synchronization costs. Avoiding
    shared state will make your life far easier.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 并行系统中一个特别困难的话题是共享状态——感觉应该很容易，但会带来很多开销，并且很难正确实现。有许多使用情况，每种情况都有不同的权衡，所以绝对没有一个适合所有人的解决方案。在[“使用进程间通信验证质数”](ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication)中，我们将关注共享状态并考虑同步成本。避免共享状态将使您的生活变得更加轻松。
- en: In fact, an algorithm can be analyzed to see how well it’ll perform in a parallel
    environment almost entirely by how much state must be shared. For example, if
    we can have multiple Python processes all solving the same problem without communicating
    with one another (a situation known as *embarrassingly parallel*), not much of
    a penalty will be incurred as we add more and more Python processes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，几乎完全可以通过要共享的状态量来分析算法在并行环境中的性能表现。例如，如果我们可以有多个 Python 进程同时解决相同的问题而不互相通信（这种情况称为*尴尬并行*），那么随着我们添加越来越多的
    Python 进程，将不会产生太大的惩罚。
- en: On the other hand, if each process needs to communicate with every other Python
    process, the communication overhead will slowly overwhelm the processing and slow
    things down. This means that as we add more and more Python processes, we can
    actually slow down our overall performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果每个进程都需要与其他每个 Python 进程通信，通信开销将会逐渐压倒处理并减慢速度。这意味着随着我们添加越来越多的 Python 进程，我们实际上可能会降低整体性能。
- en: As a result, sometimes some counterintuitive algorithmic changes must be made
    to efficiently solve a problem in parallel. For example, when solving the diffusion
    equation ([Chapter 6](ch06_split_000.xhtml#matrix_computation)) in parallel, each
    process actually does some redundant work that another process also does. This
    redundancy reduces the amount of communication required and speeds up the overall
    calculation!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有时候必须进行一些反直觉的算法更改，以有效地并行解决问题。例如，在并行解决扩散方程([第6章](ch06_split_000.xhtml#matrix_computation))时，每个进程实际上都会做一些另一个进程也在做的冗余工作。这种冗余减少了所需的通信量，并加快了整体计算速度！
- en: 'Here are some typical jobs for the `multiprocessing` module:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`multiprocessing`模块的一些典型用途：
- en: Parallelize a CPU-bound task with `Process` or `Pool` objects
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Process`或`Pool`对象对 CPU 密集型任务进行并行化处理
- en: Parallelize an I/O-bound task in a `Pool` with threads using the (oddly named)
    `dummy` module
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用（奇怪命名的）`dummy`模块在`Pool`中使用线程并行化 I/O 密集型任务
- en: Share pickled work via a `Queue`
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`Queue`共享序列化工作
- en: Share state between parallelized workers, including bytes, primitive datatypes,
    dictionaries, and lists
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在并行化的工作者之间共享状态，包括字节、基本数据类型、字典和列表
- en: If you come from a language where threads are used for CPU-bound tasks (e.g.,
    C++ or Java), you should know that while threads in Python are OS-native (they’re
    not simulated—they are actual operating system threads), they are bound by the
    GIL, so only one thread may interact with Python objects at a time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你来自一个使用线程进行CPU绑定任务的语言（例如C++或Java），你应该知道，虽然Python中的线程是操作系统本地的（它们不是模拟的——它们是真实的操作系统线程），但它们受到GIL的限制，因此一次只有一个线程可以与Python对象交互。
- en: By using processes, we run a number of Python interpreters in parallel, each
    with a private memory space with its own GIL, and each runs in series (so there’s
    no competition for each GIL). This is the easiest way to speed up a CPU-bound
    task in Python. If we need to share state, we need to add some communication overhead;
    we’ll explore that in [“Verifying Primes Using Interprocess Communication”](ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用进程，我们可以并行地运行多个Python解释器，每个解释器都有一个私有的内存空间，有自己的GIL，并且每个解释器都是连续运行的（因此没有GIL之间的竞争）。这是在Python中加速CPU密集型任务的最简单方法。如果我们需要共享状态，我们需要增加一些通信开销；我们将在[“使用进程间通信验证质数”](ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication)中探讨这个问题。
- en: If you work with `numpy` arrays, you might wonder if you can create a larger
    array (e.g., a large 2D matrix) and ask processes to work on segments of the array
    in parallel. You can, but it is hard to discover how by trial and error, so in
    [“Sharing numpy Data with multiprocessing”](ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing)
    we’ll work through sharing a 25 GB `numpy` array across four CPUs. Rather than
    sending partial copies of the data (which would at least double the working size
    required in RAM and create a massive communication overhead), we share the underlying
    bytes of the array among the processes. This is an ideal approach to sharing a
    large array among local workers on one machine.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用`numpy`数组，你可能会想知道是否可以创建一个更大的数组（例如，一个大型的二维矩阵），并让进程并行地处理数组的段。你可以，但是通过反复试验发现是很困难的，因此在[“使用多进程共享numpy数据”](ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing)中，我们将通过在四个CPU之间共享一个25
    GB的`numpy`数组来解决这个问题。与其发送数据的部分副本（这样至少会将RAM中所需的工作大小翻倍，并创建大量的通信开销），我们将数组的底层字节在进程之间共享。这是在一台机器上在本地工作者之间共享一个大型数组的理想方法。
- en: In this chapter we also introduce the [Joblib](https://oreil.ly/RqQXD) library—this
    builds on the `multiprocessing` library and offers improved cross-platform compatibility,
    a simple API for parallelization, and convenient persistence of cached results.
    Joblib is designed for scientific use, and we urge you to check it out.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们还介绍了[Joblib](https://oreil.ly/RqQXD)库——这建立在`multiprocessing`库的基础上，并提供了改进的跨平台兼容性，一个简单的用于并行化的API，以及方便的缓存结果的持久性。Joblib专为科学使用而设计，我们建议你去了解一下。
- en: Note
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Here, we discuss `multiprocessing` on *nix-based machines (this chapter is written
    using Ubuntu; the code should run unchanged on a Mac). Since Python 3.4, the quirks
    that appeared on Windows have been dealt with. Joblib has stronger cross-platform
    support than `multiprocessing`, and we recommend you review it ahead of `multiprocessing`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论*nix-based（本章是使用Ubuntu编写的；代码应该在Mac上不变）机器上的`multiprocessing`。自Python
    3.4以来，出现在Windows上的怪癖已经被处理。Joblib比`multiprocessing`具有更强的跨平台支持，我们建议您在使用`multiprocessing`之前先查看它。
- en: In this chapter we’ll hardcode the number of processes (`NUM_PROCESSES=4`) to
    match the four physical cores on Ian’s laptop. By default, `multiprocessing` will
    use as many cores as it can see (the machine presents eight—four CPUs and four
    hyperthreads). Normally you’d avoid hardcoding the number of processes to create
    unless you were specifically managing your resources.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将硬编码进程的数量（`NUM_PROCESSES=4`）以匹配Ian笔记本电脑上的四个物理核心。默认情况下，`multiprocessing`将使用它能够看到的尽可能多的核心（机器呈现出八个——四个CPU和四个超线程）。通常情况下，除非你专门管理你的资源，否则你应该避免硬编码要创建的进程数量。
- en: An Overview of the multiprocessing Module
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对`multiprocessing`模块的概述
- en: 'The `multiprocessing` module provides a low-level interface to process- and
    thread-based parallelism. Its main components are as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块提供了一个低级别的接口，用于进程和基于线程的并行处理。它的主要组件如下：'
- en: '`Process`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`Process`'
- en: A forked copy of the current process; this creates a new process identifier,
    and the task runs as an independent child process in the operating system. You
    can start and query the state of the `Process` and provide it with a `target`
    method to run.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当前进程的分叉副本；这将创建一个新的进程标识符，并在操作系统中作为独立的子进程运行任务。您可以启动并查询`Process`的状态，并为其提供一个`target`方法来运行。
- en: '`Pool`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`Pool`'
- en: Wraps the `Process` or `threading.Thread` API into a convenient pool of workers
    that share a chunk of work and return an aggregated result.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将`Process`或`threading.Thread`API包装为一个方便的工作池，共享一块工作并返回聚合结果。
- en: '`Queue`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`Queue`'
- en: A FIFO queue allowing multiple producers and consumers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 允许多个生产者和消费者的FIFO队列。
- en: '`Pipe`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`Pipe`'
- en: A uni- or bidirectional communication channel between two processes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个单向或双向通信通道，用于两个进程之间的通信。
- en: '`Manager`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`Manager`'
- en: A high-level managed interface to share Python objects between processes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高级管理接口，用于在进程之间共享Python对象。
- en: '`ctypes`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`ctypes`'
- en: Allows sharing of primitive datatypes (e.g., integers, floats, and bytes) between
    processes after they have forked.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 允许在进程分叉后共享原始数据类型（例如整数、浮点数和字节）。
- en: Synchronization primitives
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 同步原语
- en: Locks and semaphores to synchronize control flow between processes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在进程之间同步控制流的锁和信号量。
- en: Note
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In Python 3.2, the `concurrent.futures` module was introduced (via [PEP 3148](http://bit.ly/concurrent_add));
    this provides the core behavior of `multiprocessing`, with a simpler interface
    based on Java’s `java.util.concurrent`. It is available as a [backport to earlier
    versions of Python](https://oreil.ly/G9e5e). We expect `multiprocessing` to continue
    to be preferred for CPU-intensive work and won’t be surprised if `concurrent.futures`
    becomes more popular for I/O-bound tasks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python 3.2中，通过[PEP 3148](http://bit.ly/concurrent_add)引入了`concurrent.futures`模块；这提供了`multiprocessing`的核心行为，接口更简单，基于Java的`java.util.concurrent`。它作为一个[回退到早期Python版本的扩展](https://oreil.ly/G9e5e)可用。我们期望`multiprocessing`在CPU密集型工作中继续被偏爱，并且如果`concurrent.futures`在I/O绑定任务中变得更受欢迎，我们也不会感到惊讶。
- en: In the rest of the chapter, we’ll introduce a set of examples to demonstrate
    common ways of using the `multiprocessing` module.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将介绍一系列示例，展示使用`multiprocessing`模块的常见方法。
- en: We’ll estimate pi using a Monte Carlo approach with a `Pool` of processes or
    threads, using normal Python and `numpy`. This is a simple problem with well-understood
    complexity, so it parallelizes easily; we can also see an unexpected result from
    using threads with `numpy`. Next, we’ll search for primes using the same `Pool`
    approach; we’ll investigate the nonpredictable complexity of searching for primes
    and look at how we can efficiently (and inefficiently!) split the workload to
    best use our computing resources. We’ll finish the primes search by switching
    to queues, where we introduce `Process` objects in place of a `Pool` and use a
    list of work and poison pills to control the lifetime of workers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一组进程或线程的`Pool`，使用普通Python和`numpy`以蒙特卡洛方法估算圆周率。这是一个简单的问题，复杂性易于理解，因此可以很容易地并行化；我们还可以看到使用线程与`numpy`时的意外结果。接下来，我们将使用相同的`Pool`方法搜索质数；我们将调查搜索质数的不可预测复杂性，并查看如何有效（以及无效！）地分割工作负载以最佳利用我们的计算资源。我们将通过切换到队列来完成质数搜索，在那里我们使用`Process`对象代替`Pool`并使用一系列工作和毒丸来控制工作者的生命周期。
- en: Next, we’ll tackle interprocess communication (IPC) to validate a small set
    of possible primes. By splitting each number’s workload across multiple CPUs,
    we use IPC to end the search early if a factor is found so that we can significantly
    beat the speed of a single-CPU search process. We’ll cover shared Python objects,
    OS primitives, and a Redis server to investigate the complexity and capability
    trade-offs of each approach.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将处理进程间通信（IPC），以验证一小组可能的质数。通过将每个数字的工作负载跨多个CPU分割，我们使用IPC提前结束搜索，如果发现因子，以便显著超过单CPU搜索进程的速度。我们将涵盖共享Python对象、操作系统原语和Redis服务器，以调查每种方法的复杂性和能力折衷。
- en: We can share a 25 GB `numpy` array across four CPUs to split a large workload
    *without* copying data. If you have large arrays with parallelizable operations,
    this technique should buy you a great speedup, since you have to allocate less
    space in RAM and copy less data. Finally, we’ll look at synchronizing access to
    a file and a variable (as a `Value`) between processes without corrupting data
    to illustrate how to correctly lock shared state.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在四个 CPU 上共享一个 25 GB 的`numpy`数组，以分割大型工作负载，*无需*复制数据。如果您有具有可并行操作的大型数组，这种技术应该能显著加快速度，因为您需要在
    RAM 中分配更少的空间并复制更少的数据。最后，我们将看看如何在进程之间同步访问文件和变量（作为`Value`）而不会损坏数据，以说明如何正确锁定共享状态。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: PyPy (discussed in [Chapter 7](ch07.xhtml#chapter-compiling)) has full support
    for the `multiprocessing` library, and the following CPython examples (though
    not the `numpy` examples, at the time of this writing) all run far quicker using
    PyPy. If you’re using only CPython code (no C extensions or more complex libraries)
    for parallel processing, PyPy might be a quick win for you.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PyPy（在[第 7 章](ch07.xhtml#chapter-compiling)中讨论）完全支持`multiprocessing`库，尽管在撰写本文时的`numpy`示例尚未完全支持。如果您仅使用
    CPython 代码（没有 C 扩展或更复杂的库）进行并行处理，PyPy 可能是一个快速的胜利。
- en: Estimating Pi Using the Monte Carlo Method
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用蒙特卡洛方法估算π
- en: We can estimate pi by throwing thousands of imaginary darts into a “dartboard”
    represented by a unit circle. The relationship between the number of darts falling
    inside the circle’s edge and the number falling outside it will allow us to approximate
    pi.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向单位圆表示的“飞镖板”投掷数千次想象中的飞镖来估算π。落入圆边缘内的飞镖数量与落入圆外的数量之间的关系将允许我们近似π的值。
- en: This is an ideal first problem, as we can split the total workload evenly across
    a number of processes, each one running on a separate CPU. Each process will end
    at the same time since the workload for each is equal, so we can investigate the
    speedups available as we add new CPUs and hyperthreads to the problem.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个理想的首个问题，因为我们可以将总工作负载均匀分配到多个进程中，每个进程在单独的 CPU 上运行。由于每个进程的工作负载相等，因此它们将同时结束，因此我们可以在增加新的
    CPU 和超线程时探索可用的加速效果。
- en: In [Figure 9-1](ch09_split_000.xhtml#FIG-pi_monte_carlo_estimate), we throw
    10,000 darts into the unit square, and a percentage of them fall into the quarter
    of the unit circle that’s drawn. This estimate is rather bad—10,000 dart throws
    does not reliably give us a three-decimal-place result. If you ran your own code,
    you’d see this estimate vary between 3.0 and 3.2 on each run.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 9-1](ch09_split_000.xhtml#FIG-pi_monte_carlo_estimate)中，我们向单位正方形投掷了 10,000
    个飞镖，其中一部分落入了绘制的单位圆的四分之一中。这个估计相当不准确——10,000 次飞镖投掷不能可靠地给出三位小数的结果。如果您运行您自己的代码，您会看到每次运行这个估计在
    3.0 到 3.2 之间变化。
- en: To be confident of the first three decimal places, we need to generate 10,000,000
    random dart throws.^([1](ch09_split_001.xhtml#idm46122410678856)) This is massively
    inefficient (and better methods for pi’s estimation exist), but it is rather convenient
    to demonstrate the benefits of parallelization using `multiprocessing`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要确保前三位小数的准确性，我们需要生成 10,000,000 次随机飞镖投掷。^([1](ch09_split_001.xhtml#idm46122410678856))
    这是非常低效的（估算π的更好方法存在），但用来演示使用`multiprocessing`进行并行化的好处非常方便。
- en: 'With the Monte Carlo method, we use the [Pythagorean theorem](https://oreil.ly/toFkX)
    to test if a dart has landed inside our circle:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用蒙特卡洛方法，我们使用[毕达哥拉斯定理](https://oreil.ly/toFkX)来测试一个飞镖是否落入我们的圆内：
- en: <math alttext="dollar-sign x squared plus y squared less-than-or-equal-to 1
    squared equals 1 dollar-sign"><mrow><mrow><msup><mi>x</mi> <mn>2</mn></msup> <mo>+</mo>
    <msup><mi>y</mi> <mn>2</mn></msup></mrow> <mo>≤</mo> <msup><mn>1</mn> <mn>2</mn></msup>
    <mo>=</mo> <mn>1</mn></mrow></math>![Estimating Pi using the Monte Carlo method](Images/hpp2_0901.png)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="dollar-sign x squared plus y squared less-than-or-equal-to 1
    squared equals 1 dollar-sign"><mrow><mrow><msup><mi>x</mi> <mn>2</mn></msup> <mo>+</mo>
    <msup><mi>y</mi> <mn>2</mn></msup></mrow> <mo>≤</mo> <msup><mn>1</mn> <mn>2</mn></msup>
    <mo>=</mo> <mn>1</mn></mrow></math>![用蒙特卡洛方法估算π](Images/hpp2_0901.png)
- en: Figure 9-1\. Estimating pi using the Monte Carlo method
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. 使用蒙特卡洛方法估算π
- en: We’ll look at a loop version of this in [Example 9-1](ch09_split_000.xhtml#code-pi-lists-calculation).
    We’ll implement both a normal Python version and, later, a `numpy` version, and
    we’ll use both threads and processes to parallelize the problem.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[示例 9-1](ch09_split_000.xhtml#code-pi-lists-calculation)中查看一个循环版本。我们将实现一个普通的
    Python 版本和稍后的`numpy`版本，并使用线程和进程来并行化解决方案。
- en: Estimating Pi Using Processes and Threads
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用进程和线程估算π
- en: It is easier to understand a normal Python implementation, so we’ll start with
    that in this section, using float objects in a loop. We’ll parallelize this using
    processes to use all of our available CPUs, and we’ll visualize the state of the
    machine as we use more CPUs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将从一个普通的 Python 实现开始，这样更容易理解，使用循环中的浮点对象。我们将通过进程并行化，以利用所有可用的 CPU，并且在使用更多
    CPU 时可视化机器的状态。
- en: Using Python Objects
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 对象
- en: The Python implementation is easy to follow, but it carries an overhead, as
    each Python float object has to be managed, referenced, and synchronized in turn.
    This overhead slows down our runtime, but it has bought us thinking time, as the
    implementation was quick to put together. By parallelizing this version, we get
    additional speedups for very little extra work.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Python 实现易于跟踪，但每个 Python 浮点对象都需要被管理、引用和依次同步，这带来了一些额外开销。这种开销减慢了我们的运行时，但却为我们赢得了思考时间，因为实现起来非常快速。通过并行化这个版本，我们可以在几乎不增加额外工作的情况下获得额外的加速。
- en: '[Figure 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists)
    shows three implementations of the Python example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists)
    展示了 Python 示例的三种实现方式：'
- en: No use of `multiprocessing` (named “Serial”)—one `for` loop in the main process
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不使用 `multiprocessing`（称为“串行”）——在主进程中使用一个 `for` 循环
- en: Using threads
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程
- en: Using processes
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用进程
- en: '![not set](Images/hpp2_0902.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![未设置](Images/hpp2_0902.png)'
- en: Figure 9-2\. Working in series, with threads, and with processes
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-2\. 串行工作，使用线程和进程
- en: When we use more than one thread or process, we’re asking Python to calculate
    the same total number of dart throws and to divide the work evenly between workers.
    If we want 100,000,000 dart throws in total using our Python implementation and
    we use two workers, we’ll be asking both threads or both processes to generate
    50,000,000 dart throws per worker.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用多个线程或进程时，我们要求 Python 计算相同数量的飞镖投掷，并在工作人员之间均匀分配工作。如果我们希望使用我们的 Python 实现总共
    1 亿次飞镖投掷，并且使用两个工作者，我们将要求两个线程或两个进程生成每个工作者 5000 万次飞镖投掷。
- en: Using one thread takes approximately 71 seconds, with no speedup when using
    more threads. By using two or more processes, we make the runtime *shorter*. The
    cost of using no processes or threads (the series implementation) is the same
    as running with one process.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个线程大约需要 71 秒，使用更多线程时没有加速。通过使用两个或更多进程，我们使运行时*更短*。不使用进程或线程的成本（串行实现）与使用一个进程的成本相同。
- en: By using processes, we get a linear speedup when using two or four cores on
    Ian’s laptop. For the eight-worker case, we’re using Intel’s Hyper-Threading Technology—the
    laptop has only four physical cores, so we get barely any change in speedup by
    running eight processes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用进程，在 Ian 的笔记本上使用两个或四个核心时，我们获得线性加速。对于八个工作者的情况，我们使用了英特尔的超线程技术——笔记本只有四个物理核心，因此在运行八个进程时，速度几乎没有变化。
- en: '[Example 9-1](ch09_split_000.xhtml#code-pi-lists-calculation) shows the Python
    version of our pi estimator. If we’re using threads, each instruction is bound
    by the GIL, so although each thread could run on a separate CPU, it will execute
    only when no other threads are running. The process version is not bound by this
    restriction, as each forked process has a private Python interpreter running as
    a single thread—there’s no GIL contention, as no objects are shared. We use Python’s
    built-in random number generator, but see [“Random Numbers in Parallel Systems”](ch09_split_000.xhtml#multiprocessing-random-numbers)
    for some notes about the dangers of parallelized random number sequences.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-1](ch09_split_000.xhtml#code-pi-lists-calculation) 展示了我们 pi 估算器的 Python
    版本。如果我们使用线程，每个指令都受 GIL 限制，因此尽管每个线程可以在不同的 CPU 上运行，但只有在没有其他线程运行时才会执行。进程版本不受此限制，因为每个分叉进程都有一个作为单个线程运行的私有
    Python 解释器——没有 GIL 竞争，因为没有共享对象。我们使用 Python 的内置随机数生成器，但请参阅[“并行系统中的随机数”](ch09_split_000.xhtml#multiprocessing-random-numbers)以了解并行化随机数序列的危险注意事项。'
- en: Example 9-1\. Estimating pi using a loop in Python
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-1\. 在 Python 中使用循环估算 pi
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[Example 9-2](ch09_split_000.xhtml#code-pi-lists-main) shows the `__main__`
    block. Note that we build the `Pool` before we start the timer. Spawning threads
    is relatively instant; spawning processes involves a fork, and this takes a measurable
    fraction of a second. We ignore this overhead in [Figure 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists),
    as this cost will be a tiny fraction of the overall execution time.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-2](ch09_split_000.xhtml#code-pi-lists-main)显示了`__main__`块。请注意，在启动计时器之前，我们构建了`Pool`。生成线程相对即时；生成进程涉及分叉，这需要测量时间的一部分。我们在[图 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists)中忽略了这个开销，因为这个成本将是整体执行时间的一小部分。'
- en: Example 9-2\. main for estimating pi using a loop
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-2\. 使用循环估计圆周率的主要代码
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We create a list containing `nbr_estimates` divided by the number of workers.
    This new argument will be sent to each worker. After execution, we’ll receive
    the same number of results back; we’ll sum these to estimate the number of darts
    in the unit circle.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个包含`nbr_estimates`除以工作程序数的列表。这个新参数将发送给每个工作程序。执行后，我们将收到相同数量的结果；我们将这些结果相加以估计单位圆中的飞镖数。
- en: We import the process-based `Pool` from `multiprocessing`. We also could have
    used `from multiprocessing.dummy import Pool` to get a threaded version. The “dummy”
    name is rather misleading (we confess to not understanding why it is named this
    way); it is simply a light wrapper around the `threading` module to present the
    same interface as the process-based `Pool`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`multiprocessing`中导入基于进程的`Pool`。我们也可以使用`from multiprocessing.dummy import
    Pool`来获取一个线程化版本。 “dummy”名称相当误导（我们承认我们不理解为什么它以这种方式命名）；它只是一个围绕`threading`模块的轻量级包装，以呈现与基于进程的`Pool`相同的接口。
- en: Warning
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Each process we create consumes some RAM from the system. You can expect a forked
    process using the standard libraries to take on the order of 10–20 MB of RAM;
    if you’re using many libraries and lots of data, you might expect each forked
    copy to take hundreds of megabytes. On a system with a RAM constraint, this might
    be a significant issue—if you run out of RAM and the system reverts to using the
    disk’s swap space, any parallelization advantage will be massively lost to the
    slow paging of RAM back and forth to disk!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的每个进程都会从系统中消耗一些RAM。您可以预期使用标准库的分叉进程将占用大约10-20 MB的RAM；如果您使用许多库和大量数据，则可能每个分叉副本将占用数百兆字节。在具有RAM约束的系统上，这可能是一个重大问题
    - 如果RAM用完，系统将回到使用磁盘的交换空间，那么任何并行化优势都将因缓慢的RAM回写到磁盘而大量丧失！
- en: The following figures plot the average CPU utilization of Ian’s laptop’s four
    physical cores and their four associated hyperthreads (each hyperthread runs on
    unutilized silicon in a physical core). The data gathered for these figures *includes*
    the startup time of the first Python process and the cost of starting subprocesses.
    The CPU sampler records the entire state of the laptop, not just the CPU time
    used by this task.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下图绘制了Ian笔记本电脑的四个物理核心及其四个关联的超线程的平均CPU利用率（每个超线程在物理核心中的未使用硅上运行）。这些图表收集的数据*包括*第一个Python进程的启动时间和启动子进程的成本。CPU采样器记录笔记本电脑的整个状态，而不仅仅是此任务使用的CPU时间。
- en: Note that the following diagrams are created using a different timing method
    with a slower sampling rate than [Figure 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists),
    so the overall runtime is a little longer.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以下图表是使用比[图 9-2](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists)慢一些的采样率创建的，因此整体运行时间略长。
- en: The execution behavior in [Figure 9-3](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes)
    with one process in the `Pool` (along with the parent process) shows some overhead
    in the first seconds as the `Pool` is created, and then a consistent close-to-100%
    CPU utilization throughout the run. With one process, we’re efficiently using
    one core.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 9-3](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes)中，使用一个进程在`Pool`（以及父进程）中的执行行为显示出一些开销，在创建`Pool`时首几秒钟内，然后在整个运行过程中保持接近100%的CPU利用率。使用一个进程，我们有效地利用了一个核心。
- en: '![Estimating pi using lists and 1 process](Images/hpp2_0903.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![使用列表和一个进程估计圆周率](Images/hpp2_0903.png)'
- en: Figure 9-3\. Estimating pi using Python objects and one process
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-3\. 使用Python对象和一个进程估计圆周率
- en: Next we’ll add a second process, effectively saying `Pool(processes=2)`. As
    you can see in [Figure 9-4](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes),
    adding a second process roughly halves the execution time to 37 seconds, and two
    CPUs are fully occupied. This is the best result we can expect—we’ve efficiently
    used all the new computing resources, and we’re not losing any speed to other
    overheads like communication, paging to disk, or contention with competing processes
    that want to use the same CPUs.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将添加第二个进程，相当于说`Pool(processes=2)`。如你在[图 9-4](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes)中所见，添加第二个进程将执行时间大致减半至37秒，并且两个CPU完全被占用。这是我们能期待的最佳结果——我们已经高效地利用了所有新的计算资源，而且没有因通信、分页到磁盘或与竞争使用相同CPU的其他进程的争用等开销而损失速度。
- en: '![Estimating Pi using lists and 2 processes](Images/hpp2_0904.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![使用列表和2个进程估算Pi](Images/hpp2_0904.png)'
- en: Figure 9-4\. Estimating pi using Python objects and two processes
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-4\. 使用Python对象和两个进程估算Pi
- en: '[Figure 9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes) shows
    the results when using all four physical CPUs—now we are using all of the raw
    power of this laptop. Execution time is roughly a quarter that of the single-process
    version, at 19 seconds.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes)显示了在使用所有四个物理CPU时的结果——现在我们正在使用这台笔记本电脑的全部原始计算能力。执行时间大约是单进程版本的四分之一，为19秒。'
- en: '![Estimating Pi using lists and 4 processes](Images/hpp2_0905.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![使用列表和4个进程估算Pi](Images/hpp2_0905.png)'
- en: Figure 9-5\. Estimating pi using Python objects and four processes
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-5\. 使用Python对象和四个进程估算Pi
- en: By switching to eight processes, as seen in [Figure 9-6](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes),
    we cannot achieve more than a tiny speedup compared to the four-process version.
    That is because the four hyperthreads are able to squeeze only a little extra
    processing power out of the spare silicon on the CPUs, and the four CPUs are already
    maximally utilized.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过切换到八个进程，如[图 9-6](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes)所示，与四进程版本相比，我们不能实现更大的速度提升。这是因为四个超线程只能从CPU上的备用硅中挤出一点额外的处理能力，而四个CPU已经达到最大利用率。
- en: '![Estimating Pi using lists and 8 processes](Images/hpp2_0906.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![使用列表和8个进程估算Pi](Images/hpp2_0906.png)'
- en: Figure 9-6\. Estimating pi using Python objects and eight processes, with little
    additional gain
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-6\. 使用Python对象和八个进程估算Pi，但额外收益微乎其微
- en: These diagrams show that we’re efficiently using more of the available CPU resources
    at each step, and that the hyperthread resources are a poor addition. The biggest
    problem when using hyperthreads is that CPython is using a lot of RAM—hyperthreading
    is not cache friendly, so the spare resources on each chip are very poorly utilized.
    As we’ll see in the next section, `numpy` makes better use of these resources.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表显示，我们在每个步骤中都有效地利用了更多的可用CPU资源，并且超线程资源是一个糟糕的补充。在使用超线程时最大的问题是CPython使用了大量RAM——超线程对缓存不友好，因此每个芯片上的备用资源利用非常低效。正如我们将在下一节看到的，`numpy`更好地利用了这些资源。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In our experience, hyperthreading can give up to a 30% performance gain *if*
    there are enough spare computing resources. This works if, for example, you have
    a mix of floating-point and integer arithmetic rather than just the floating-point
    operations we have here. By mixing the resource requirements, the hyperthreads
    can schedule more of the CPU’s silicon to be working concurrently. Generally,
    we see hyperthreads as an added bonus and not a resource to be optimized against,
    as adding more CPUs is probably more economical than tuning your code (which adds
    a support overhead).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的经验，如果有足够的备用计算资源，超线程可以提供高达30%的性能增益*如果*有浮点和整数算术的混合而不仅仅是我们这里的浮点操作。通过混合资源需求，超线程可以同时调度更多CPU硅工作。一般来说，我们将超线程视为额外的奖励而不是需要优化的资源，因为添加更多CPU可能比调整代码（增加支持开销）更经济。
- en: Now we’ll switch to using threads in one process, rather than multiple processes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将切换到一个进程中使用线程，而不是多个进程。
- en: '[Figure 9-7](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_threads) shows
    the results of running the same code that we used in [Figure 9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes),
    but with threads in place of processes. Although a number of CPUs are being used,
    they each share the workload lightly. If each thread was running without the GIL,
    then we’d see 100% CPU utilization on the four CPUs. Instead, each CPU is partially
    utilized (because of the GIL).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-7](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_threads) 显示了在同一个代码中运行相同的代码的结果，我们用线程代替进程。尽管使用了多个CPU，但它们轻度共享负载。如果每个线程都在没有GIL的情况下运行，那么我们将在四个CPU上看到100%的CPU利用率。相反，每个CPU都被部分利用（因为有GIL）。'
- en: '![Estimating Pi using lists and 4 threads](Images/hpp2_0907.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![使用列表和4个线程估算 Pi](Images/hpp2_0907.png)'
- en: Figure 9-7\. Estimating pi using Python objects and four threads
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-7\. 使用Python对象和四个线程估算 Pi
- en: Replacing multiprocessing with Joblib
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用Joblib替换multiprocessing
- en: Joblib is an improvement on `multiprocessing` that enables lightweight pipelining
    with a focus on easy parallel computing and transparent disk-based caching of
    results. It focuses on NumPy arrays for scientific computing. It may offer a quick
    win for you if you’re
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib是`multiprocessing`的改进版本，支持轻量级流水线处理，专注于简化并行计算和透明的基于磁盘的缓存结果。它专注于科学计算中的NumPy数组。如果您正在使用纯Python编写，无论是否使用NumPy，来处理可以简单并行化的循环，它可能会为您带来快速成功。
- en: Using pure Python, with or without NumPy, to process a loop that could be embarrassingly
    parallel
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python纯代码时，无论是否使用NumPy，都可以处理可以使人尴尬的并行化循环。
- en: Calling expensive functions that have no side effects, where the output could
    be cached to disk between sessions
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用昂贵的没有副作用的函数，其中输出可以在会话之间缓存到磁盘
- en: Able to share NumPy data between processes but don’t know how (and you haven’t
    yet read [“Sharing numpy Data with multiprocessing”](ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing))
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够在进程之间共享NumPy数据，但不知道如何操作（并且您尚未阅读过[“使用多进程共享NumPy数据”](ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing)）。
- en: Joblib builds on the Loky library (itself an improvement over Python’s `concurrent.futures`)
    and uses `cloudpickle` to enable the pickling of functions defined in the interactive
    scope. This solves a couple of common issues that are encountered with the built-in
    `multiprocessing` library.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib基于Loky库构建（它本身是Python `concurrent.futures` 的改进），并使用`cloudpickle`来实现在交互作用域中定义函数的序列化。这解决了使用内置`multiprocessing`库时遇到的几个常见问题。
- en: For parallel computing, we need the `Parallel` class and the `delayed` decorator.
    The `Parallel` class sets up a process pool, similar to the `multiprocessing`
    `pool` we used in the previous section. The `delayed` decorator wraps our target
    function so it can be applied to the instantiated `Parallel` object via an iterator.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行计算，我们需要`Parallel`类和`delayed`装饰器。`Parallel`类设置了一个进程池，类似于我们在前一节中使用的`multiprocessing`的`pool`。`delayed`装饰器包装了我们的目标函数，使其可以通过迭代器应用于实例化的`Parallel`对象。
- en: The syntax is a little confusing to read—take a look at [Example 9-3](ch09_split_000.xhtml#code-pi-joblib).
    The call is written on one line; this includes our target function `estimate_nbr_points_in_quarter_circle`
    and the iterator `(delayed(...)(nbr_samples_per_worker) for sample_idx in range(nbr_parallel_blocks))`.
    Let’s break this down.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 语法有点令人困惑——看看[示例 9-3](ch09_split_000.xhtml#code-pi-joblib)。调用写在一行上；这包括我们的目标函数`estimate_nbr_points_in_quarter_circle`和迭代器`(delayed(...)(nbr_samples_per_worker)
    for sample_idx in range(nbr_parallel_blocks))`。让我们来分解一下这个过程。
- en: Example 9-3\. Using Joblib to parallelize pi estimation
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-3\. 使用Joblib并行化估算 Pi
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`Parallel` is a class; we can set parameters such as `n_jobs` to dictate how
    many processes will run, along with optional arguments like `verbose` for debugging
    information. Other arguments can set time-outs, change between threads or processes,
    change the backends (which can help speed up certain edge cases), and configure
    memory mapping.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel`是一个类；我们可以设置参数，如`n_jobs`来指定将运行多少进程，以及像`verbose`这样的可选参数来获取调试信息。其他参数可以设置超时时间，选择线程或进程之间切换，更改后端（这可以帮助加速某些极端情况），并配置内存映射。'
- en: '`Parallel` has a `__call__` callable method that takes an iterable. We supply
    the iterable in the following round brackets `(... for sample_idx in range(...))`.
    The callable iterates over each `delayed(estimate_nbr_points_in_quarter_circle)`
    function, batching the execution of these functions to their arguments (in this
    case, `nbr_samples_per_worker`). Ian has found it helpful to build up a parallelized
    call one step at a time, starting from a function with no arguments and building
    up arguments as needed. This makes diagnosing missteps much easier.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel`具有一个可调用方法`__call__`，接受一个可迭代对象。我们在以下圆括号中提供了可迭代对象`(... for sample_idx
    in range(...))`。该可调用对象迭代每个`delayed(estimate_nbr_points_in_quarter_circle)`函数，批处理这些函数的参数执行（在本例中为`nbr_samples_per_worker`）。Ian发现逐步构建并行调用非常有帮助，从一个没有参数的函数开始，根据需要逐步构建参数。这样可以更容易地诊断错误步骤。'
- en: '`nbr_in_quarter_unit_circles` will be a list containing the count of positive
    cases for each call as before. [Example 9-4](ch09_split_000.xhtml#code-pi-joblib-output)
    shows the console output for eight parallel blocks; each process ID (PID) is freshly
    created, and a summary is printed in a progress bar at the end of the output.
    In total this takes 19 seconds, the same amount of time as when we created our
    own `Pool` in the previous section.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`nbr_in_quarter_unit_circles`将是一个包含每次调用正例计数的列表，如前所述。[示例 9-4](ch09_split_000.xhtml#code-pi-joblib-output)显示了八个并行块的控制台输出；每个进程ID（PID）都是全新创建的，并且在输出末尾打印了进度条的摘要。总共需要19秒，与我们在前一节中创建自己的`Pool`时相同的时间。'
- en: Tip
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Avoid passing large structures; passing large pickled objects to each process
    may be expensive. Ian had a case with a prebuilt cache of Pandas DataFrames in
    a dictionary object; the cost of serializing these via the `Pickle` module negated
    the gains from parallelization, and the serial version actually worked faster
    overall. The solution in this case was to build the DataFrame cache using Python’s
    built-in [`shelve` module](https://oreil.ly/e9dJs), storing the dictionary to
    a file. A single DataFrame was loaded with `shelve` on each call to the target
    function; hardly anything had to be passed to the functions, and then the parallelized
    benefit of `Joblib` was clear.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 避免传递大结构；将大型Pickle对象传递给每个进程可能会很昂贵。Ian曾经有过一个预先构建的Pandas DataFrame字典对象的情况；通过`Pickle`模块对其进行序列化的成本抵消了并行化带来的收益，而串行版本实际上总体上运行得更快。在这种情况下的解决方案是使用Python的内置[`shelve`模块](https://oreil.ly/e9dJs)构建DataFrame缓存，并将字典存储到文件中。每次调用目标函数时，使用`shelve`加载单个DataFrame；几乎不需要传递任何东西给函数，然后`Joblib`的并行化效益变得明显。
- en: Example 9-4\. Output of `Joblib` calls
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-4\. `Joblib`调用的输出
- en: '[PRE3]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tip
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: To simplify debugging, we can set `n_jobs=1`, and the parallelized code is dropped.
    You don’t have to modify your code any further, and you can drop a call to `breakpoint()`
    in your function to ease your debugging.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化调试，我们可以设置`n_jobs=1`，并且并行化代码被禁用。您不必进一步修改代码，可以在函数中放置一个`breakpoint()`调用以便轻松调试。
- en: Intelligent caching of function call results
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数调用结果的智能缓存
- en: A useful feature in Joblib is the `Memory` cache; this is a decorator that caches
    function results based on the input arguments to a disk cache. This cache persists
    between Python sessions, so if you turn off your machine and then run the same
    code the next day, the cached results will be used.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib中一个有用的功能是`Memory`缓存；这是一个基于输入参数将函数结果缓存到磁盘缓存的装饰器。此缓存在Python会话之间持久存在，因此如果关闭计算机然后第二天运行相同的代码，将使用缓存的结果。
- en: For our pi estimation, this presents a small problem. We don’t pass in unique
    arguments to `estimate_nbr_points_in_quarter_circle`; for each call we pass in
    `nbr_estimates`, so the call signature is the same, but we’re after different
    results.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的π估计，这提出了一个小问题。我们不会向`estimate_nbr_points_in_quarter_circle`传递唯一的参数；对于每次调用，我们都会传递`nbr_estimates`，因此调用签名相同，但我们寻求的是不同的结果。
- en: In this situation, once the first call has completed (taking around 19 seconds),
    any subsequent call with the same argument will get the cached result. This means
    that if we rerun our code a second time, it completes instantly, but it uses only
    one of the eight sample results as the result for each call—this obviously breaks
    our Monte Carlo sampling! If the last process to complete resulted in `9815738`
    points in the quarter circle, the cache for the function call would always answer
    this. Repeating the call eight times would generate `[9815738, 9815738, 9815738,
    9815738, 9815738, 9815738, 9815738, 9815738]` rather than eight unique estimates.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，一旦第一次调用完成（大约需要19秒），任何使用相同参数的后续调用都将获得缓存的结果。这意味着如果我们第二次运行代码，它将立即完成，但每次调用只使用八个样本结果中的一个作为结果——这显然破坏了我们的蒙特卡洛抽样！如果最后一个完成的进程导致在四分之一圆中有`9815738`个点，则函数调用的缓存将始终回答这个结果。重复调用八次将生成`[9815738,
    9815738, 9815738, 9815738, 9815738, 9815738, 9815738, 9815738]`，而不是八个唯一的估计值。
- en: The solution in [Example 9-5](ch09_split_000.xhtml#code-pi-joblib-cache) is
    to pass in a second argument, `idx`, which takes on a value between 0 and `nbr_parallel_blocks-1`.
    This unique combination of arguments will let the cache store each positive count,
    so that on the second run we get the same result as on the first run, but without
    the wait.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-5](ch09_split_000.xhtml#code-pi-joblib-cache)中的解决方案是传入第二个参数`idx`，它接受0到`nbr_parallel_blocks-1`之间的值。这些唯一参数的组合将允许缓存存储每个正计数，因此在第二次运行时，我们得到与第一次运行相同的结果，但无需等待。'
- en: This is configured using `Memory`, which takes a folder for persisting the function
    results. This persistence is kept between Python sessions; it is refreshed if
    you change the function that is being called, or if you empty the files in the
    cache folder.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过`Memory`配置的，它需要一个用于持久化函数结果的文件夹。这种持久性在Python会话之间保持；如果更改被调用的函数或清空缓存文件夹中的文件，则会刷新它。
- en: Note that this refresh applies only to a change to the function that’s been
    decorated (in this case, `estimate_nbr_points_in_quarter_circle_with_idx`), not
    to any sub-functions that are called from inside that function.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此刷新仅适用于已装饰函数的更改（在本例中为`estimate_nbr_points_in_quarter_circle_with_idx`），而不适用于从该函数内部调用的任何子函数。
- en: Example 9-5\. Caching results with Joblib
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-5\. 使用Joblib缓存结果
- en: '[PRE4]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In [Example 9-6](ch09_split_000.xhtml#code-pi-joblib-cache-output), we can see
    that while the first call costs 19 seconds, the second call takes only a fraction
    of a second and has the same estimated pi. In this run, the estimates were `[9817605,
    9821064, 9818420, 9817571, 9817688, 9819788, 9816377, 9816478]`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 9-6](ch09_split_000.xhtml#code-pi-joblib-cache-output)中，我们可以看到，第一次调用花费了19秒，而第二次调用仅花费了几分之一秒，并且估算的π值相同。在这次运行中，估计值为`[9817605,
    9821064, 9818420, 9817571, 9817688, 9819788, 9816377, 9816478]`。
- en: Example 9-6\. The zero-cost second call to the code thanks to cached results
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-6\. 由于缓存结果，代码的零成本第二次调用
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Joblib wraps up a lot of `multiprocessing` functionality with a simple (if slightly
    hard to read) interface. Ian has moved to using Joblib in favor of `multiprocessing`;
    he recommends you try it too.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib用一个简单（尽管有点难以阅读）的接口包装了许多`multiprocessing`功能。Ian已经开始使用Joblib来替代`multiprocessing`，他建议你也试试。
- en: Random Numbers in Parallel Systems
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行系统中的随机数
- en: Generating good random number sequences is a hard problem, and it is easy to
    get it wrong if you try to do it yourself. Getting a good sequence quickly in
    parallel is even harder—suddenly you have to worry about whether you’ll get repeating
    or correlated sequences in the parallel processes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 生成良好的随机数序列是一个棘手的问题，如果尝试自行实现很容易出错。在并行中快速获得良好的序列更难——突然间，您必须担心是否会在并行进程中获得重复或相关的序列。
- en: We used Python’s built-in random number generator in [Example 9-1](ch09_split_000.xhtml#code-pi-lists-calculation),
    and we’ll use the `numpy` random number generator in [Example 9-7](ch09_split_000.xhtml#code-pi-numpy-calculation)
    in the next section. In both cases, the random number generators are seeded in
    their forked process. For the Python `random` example, the seeding is handled
    internally by `multiprocessing`—if during a fork it sees that `random` is in the
    namespace, it will force a call to seed the generators in each of the new processes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[示例 9-1](ch09_split_000.xhtml#code-pi-lists-calculation)中使用了Python内置的随机数生成器，在下一节中的[示例 9-7](ch09_split_000.xhtml#code-pi-numpy-calculation)中，我们将使用`numpy`的随机数生成器。在这两种情况下，随机数生成器都在其分叉进程中进行了种子化。对于Python的`random`示例，种子化由`multiprocessing`内部处理——如果在分叉时看到`random`存在于命名空间中，它将强制调用以在每个新进程中种子化生成器。
- en: Tip
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Set the numpy seed when parallelizing your function calls. In the forthcoming
    `numpy` example, we have to explicitly set the random number seed. If you forget
    to seed the random number sequence with `numpy`, each of your forked processes
    will generate an identical sequence of random numbers—it’ll appear to be working
    as you wanted it to, but behind the scenes each parallel process will evolve with
    identical results!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行化函数调用时设置 numpy 种子。在接下来的 `numpy` 示例中，我们必须显式设置随机数种子。如果您忘记使用 `numpy` 设置随机数序列的种子，每个分叉进程将生成相同的随机数序列
    —— 它看起来会按照您期望的方式工作，但在背后每个并行进程将以相同的结果演化！
- en: If you care about the quality of the random numbers used in the parallel processes,
    we urge you to research this topic. *Probably* the `numpy` and Python random number
    generators are good enough, but if significant outcomes depend on the quality
    of the random sequences (e.g., for medical or financial systems), then you must
    read up on this area.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您关心并行进程中使用的随机数质量，请务必研究这个话题。*可能* `numpy` 和 Python 的随机数生成器已经足够好，但如果重要的结果依赖于随机序列的质量（例如医疗或金融系统），那么您必须深入了解这个领域。
- en: In Python 3, the [Mersenne Twister algorithm](https://oreil.ly/yNINO) is used—it
    has a long period, so the sequence won’t repeat for a long time. It is heavily
    tested, as it is used in other languages, and it is thread-safe. It is probably
    not suitable for cryptographic purposes.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 3 中，使用 [Mersenne Twister 算法](https://oreil.ly/yNINO) —— 它具有长周期，因此序列在很长时间内不会重复。它经过了大量测试，因为它也被其他语言使用，并且是线程安全的。但可能不适合用于加密目的。
- en: Using numpy
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 numpy
- en: In this section, we switch to using `numpy`. Our dart-throwing problem is ideal
    for `numpy` vectorized operations—we generate the same estimate 25 times faster
    than the previous Python examples.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们转而使用 `numpy`。我们的投镖问题非常适合 `numpy` 的向量化操作——我们的估算比之前的 Python 示例快 25 倍。
- en: The main reason that `numpy` is faster than pure Python when solving the same
    problem is that `numpy` is creating and manipulating the same object types at
    a very low level in contiguous blocks of RAM, rather than creating many higher-level
    Python objects that each require individual management and addressing.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`numpy` 比纯 Python 解决同样问题更快的主要原因是，`numpy` 在连续的 RAM 块中以非常低的级别创建和操作相同的对象类型，而不是创建许多需要单独管理和寻址的更高级别的
    Python 对象。'
- en: As `numpy` is far more cache friendly, we’ll also get a small speed boost when
    using the four hyperthreads. We didn’t get this in the pure Python version, as
    caches aren’t used efficiently by larger Python objects.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `numpy` 更加友好于缓存，当使用四个超线程时我们也会得到轻微的速度提升。在纯 Python 版本中，我们没有得到这个好处，因为较大的 Python
    对象未能有效利用缓存。
- en: 'In [Figure 9-8](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_numpy),
    we see three scenarios:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 9-8](ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_numpy)
    中，我们看到三种情况：
- en: No use of `multiprocessing` (named “Serial”)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不使用 `multiprocessing`（名为“串行”）
- en: Using threads
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程
- en: Using processes
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用进程
- en: The serial and single-worker versions execute at the same speed—there’s no overhead
    to using threads with `numpy` (and with only one worker, there’s also no gain).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 串行和单工作者版本的执行速度相同——使用 `numpy` 时没有使用线程的额外开销（并且只有一个工作者时也没有收益）。
- en: When using multiple processes, we see a classic 100% utilization of each additional
    CPU. The result mirrors the plots shown in Figures [9-3](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes),
    [9-4](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes), [9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes),
    and [9-6](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes), but the
    code is much faster using `numpy`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用多个进程时，我们看到每个额外 CPU 的经典 100% 利用率。结果与图 [9-3](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes)、[9-4](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes)、[9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes)
    和 [9-6](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes) 中显示的情况相似，但使用
    `numpy` 的代码速度要快得多。
- en: Interestingly, the threaded version runs *faster* with more threads. As discussed
    on the [SciPy wiki](https://oreil.ly/XXKNo), by working outside the GIL, `numpy`
    can achieve some level of additional speedup around threads.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，线程版本随着线程数的增加运行得*更快*。正如在 [SciPy wiki](https://oreil.ly/XXKNo) 上讨论的那样，通过在全局解释器锁之外工作，`numpy`
    可以实现一定程度的额外加速。
- en: '![Working in series, with threads, and with processes](Images/hpp2_0908.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![串行工作、使用线程和使用 numpy 的进程](Images/hpp2_0908.png)'
- en: Figure 9-8\. Working in series, with threads, and with processes using numpy
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-8\. 使用 numpy 串行工作、使用线程和使用进程
- en: Using processes gives us a predictable speedup, just as it did in the pure Python
    example. A second CPU doubles the speed, and using four CPUs quadruples the speed.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用进程给我们带来可预测的加速，就像在纯Python示例中一样。第二个CPU会将速度提高一倍，而使用四个CPU会将速度提高四倍。
- en: '[Example 9-7](ch09_split_000.xhtml#code-pi-numpy-calculation) shows the vectorized
    form of our code. Note that the random number generator is seeded when this function
    is called. For the threaded version, this isn’t necessary, as each thread shares
    the same random number generator and they access it in series. For the process
    version, as each new process is a fork, all the forked versions will share the
    *same state*. This means the random number calls in each will return the same
    sequence!'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-7](ch09_split_000.xhtml#code-pi-numpy-calculation)展示了我们代码的向量化形式。请注意，当调用此函数时，随机数生成器会被种子化。对于多线程版本，这不是必要的，因为每个线程共享同一个随机数生成器，并且它们是串行访问的。对于进程版本，由于每个新进程都是一个分支，所有分叉版本都将共享*相同的状态*。这意味着每个版本中的随机数调用将返回相同的序列！'
- en: Tip
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Remember to call `seed()` per process with `numpy` to ensure that each of the
    forked processes generates a unique sequence of random numbers, as a random source
    is used to set the seed for each call. Look back at [“Random Numbers in Parallel
    Systems”](ch09_split_000.xhtml#multiprocessing-random-numbers) for some notes
    about the dangers of parallelized random number sequences.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 记得使用`numpy`为每个进程调用`seed()`来确保每个分叉进程生成唯一的随机数序列，因为随机源用于为每次调用设置种子。回顾一下[“并行系统中的随机数”](ch09_split_000.xhtml#multiprocessing-random-numbers)中有关并行随机数序列危险的注意事项。
- en: Example 9-7\. Estimating pi using `numpy`
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-7\. 使用 `numpy` 估算 π
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A short code analysis shows that the calls to `random` run a little slower on
    this machine when executed with multiple threads, and the call to `(xs * xs +
    ys * ys) <= 1` parallelizes well. Calls to the random number generator are GIL-bound,
    as the internal state variable is a Python object.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 简短的代码分析表明，在此计算机上，使用多个线程执行时，对`random`的调用速度稍慢，而对`(xs * xs + ys * ys) <= 1`的调用可以很好地并行化。对随机数生成器的调用受制于GIL，因为内部状态变量是一个Python对象。
- en: 'The process to understand this was basic but reliable:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个过程是基本但可靠的：
- en: Comment out all of the `numpy` lines, and run with *no* threads using the serial
    version. Run several times and record the execution times using `time.time()`
    in `__main__`.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注释掉所有`numpy`行，并使用串行版本在*无*线程下运行。运行多次，并在`__main__`中使用`time.time()`记录执行时间。
- en: Add a line back (we added `xs = np.random.uniform(...)` first) and run several
    times, again recording completion times.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在添加一行返回代码（我们首先添加了`xs = np.random.uniform(...)`）并运行多次，再次记录完成时间。
- en: Add the next line back (now adding `ys = ...`), run again, and record completion
    time.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加下一行代码（现在添加`ys = ...`），再次运行，并记录完成时间。
- en: Repeat, including the `nbr_trials_in_quarter_unit_circle = np.sum(...)` line.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复，包括`nbr_trials_in_quarter_unit_circle = np.sum(...)`行。
- en: Repeat this process again, but this time with four threads. Repeat line by line.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次重复此过程，但这次使用四个线程。逐行重复。
- en: Compare the difference in runtime at each step for no threads and four threads.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较无线程和四个线程在每个步骤的运行时差异。
- en: Because we’re running code in parallel, it becomes harder to use tools like
    `line_profiler` or `cProfile`. Recording the raw runtimes and observing the differences
    in behavior with different configurations takes patience but gives solid evidence
    from which to draw conclusions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们正在并行运行代码，所以使用`line_profiler`或`cProfile`等工具变得更加困难。记录原始运行时间并观察使用不同配置时的行为差异需要耐心，但可以提供可靠的证据来得出结论。
- en: Note
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to understand the serial behavior of the `uniform` call, take a
    look at the [`mtrand` code](https://oreil.ly/HxHQD) in the `numpy` source and
    follow the call to `def uniform` in *mtrand.pyx*. This is a useful exercise if
    you haven’t looked at the `numpy` source code before.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解`uniform`调用的串行行为，请查看[`numpy`源码](https://oreil.ly/HxHQD)中的`mtrand`代码，并跟随在*mtrand.pyx*中的`def
    uniform`调用。如果你以前没有查看过`numpy`源代码，这是一个有用的练习。
- en: The libraries used when building `numpy` are important for some of the parallelization
    opportunities. Depending on the underlying libraries used when building `numpy`
    (e.g., whether Intel’s Math Kernel Library or OpenBLAS were included or not),
    you’ll see different speedup behavior.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建`numpy`时使用的库对于某些并行化机会非常重要。取决于构建`numpy`时使用的底层库（例如是否包含了英特尔数学核心库或OpenBLAS等），您将看到不同的加速行为。
- en: You can check your `numpy` configuration using `numpy.show_config()`. Stack
    Overflow has some [example timings](http://bit.ly/BLAS_benchmarking) if you’re
    curious about the possibilities. Only some `numpy` calls will benefit from parallelization
    by external libraries.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`numpy.show_config()`检查您的`numpy`配置。如果您对可能性感到好奇，Stack Overflow 上有一些[示例时间](http://bit.ly/BLAS_benchmarking)。只有一些`numpy`调用会从外部库的并行化中受益。
- en: Finding Prime Numbers
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找素数
- en: Next, we’ll look at testing for prime numbers over a large number range. This
    is a different problem from estimating pi, as the workload varies depending on
    your location in the number range, and each individual number’s check has an unpredictable
    complexity. We can create a serial routine that checks for primality and then
    pass sets of possible factors to each process for checking. This problem is embarrassingly
    parallel, which means there is no state that needs to be shared.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将测试大范围内的素数。这与估算π的问题不同，因为工作量取决于您在数字范围中的位置，每个单独数字的检查具有不可预测的复杂性。我们可以创建一个串行程序来检查素数性质，然后将可能的因子集传递给每个进程进行检查。这个问题是令人尴尬地并行的，这意味着没有需要共享的状态。
- en: The `multiprocessing` module makes it easy to control the workload, so we shall
    investigate how we can tune the work queue to use (and misuse!) our computing
    resources, and we will explore an easy way to use our resources slightly more
    efficiently. This means we’ll be looking at *load balancing* to try to efficiently
    distribute our varying-complexity tasks to our fixed set of resources.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing` 模块使得控制工作负载变得容易，因此我们将调查如何调整工作队列以使用（和滥用！）我们的计算资源，并探索一种更有效地利用我们资源的简单方法。这意味着我们将关注*负载平衡*，试图将我们变化复杂度的任务有效地分配给我们固定的资源集。'
- en: We’ll use an algorithm that is slightly removed from the one earlier in the
    book (see [“Idealized Computing Versus the Python Virtual Machine”](ch01_split_000.xhtml#understanding-performance-idealized-computing));
    it exits early if we have an even number—see [Example 9-8](ch09_split_000.xhtml#code-primes-serial-generation-calculation).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个与本书中稍有不同的算法（见[“理想化计算与Python虚拟机”](ch01_split_000.xhtml#understanding-performance-idealized-computing)）；如果我们有一个偶数，它会提前退出——见[示例 9-8](ch09_split_000.xhtml#code-primes-serial-generation-calculation)。
- en: Example 9-8\. Finding prime numbers using Python
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-8\. 使用Python查找素数
- en: '[PRE7]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How much variety in the workload do we see when testing for a prime with this
    approach? [Figure 9-9](ch09_split_000.xhtml#FIG-primes-cost-to-check-primality)
    shows the increasing time cost to check for primality as the possibly prime `n`
    increases from `10,000` to `1,000,000`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 用这种方法测试素数时，我们能看到工作负载的多大变化？[图 9-9](ch09_split_000.xhtml#FIG-primes-cost-to-check-primality)显示了检查素数的时间成本随可能是素数的`n`从`10,000`增加到`1,000,000`而增加。
- en: Most numbers are nonprime; they’re drawn with a dot. Some can be cheap to check
    for, while others require the checking of many factors. Primes are drawn with
    an `x` and form the thick darker band; they’re the most expensive to check for.
    The time cost of checking a number increases as `n` increases, as the range of
    possible factors to check increases with the square root of `n`. The sequence
    of primes is not predictable, so we can’t determine the expected cost of a range
    of numbers (we could estimate it, but we can’t be sure of its complexity).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数字都不是素数；它们用一个点表示。有些检查起来很便宜，而其他则需要检查许多因子。素数用一个`x`表示，并形成浓密的黑带；检查它们是最昂贵的。随着`n`的增加，检查一个数字的时间成本增加，因为要检查的可能因子范围随着`n`的平方根增加。素数序列是不可预测的，因此我们无法确定一系列数字的预期成本（我们可以估计，但无法确定其复杂性）。
- en: For the figure, we test each `n` two hundred times and take the fastest result
    to remove jitter from the results. If we took only one result, we’d see wide variance
    in timing that would be caused by system load from other processes; by taking
    many readings and keeping the fastest, we get to see the expected best-case timing.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图表，我们对每个`n`进行了两百次测试，并选择最快的结果来消除结果的抖动。如果我们只取一个结果，由于其他进程的系统负载，计时会出现广泛变化；通过多次读数并保留最快的结果，我们可以看到预期的最佳情况计时。
- en: '![Time to check primality](Images/hpp2_0909.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![检查素数所需时间](Images/hpp2_0909.png)'
- en: Figure 9-9\. Time required to check primality as `n` increases
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-9\. 随着`n`的增加，检查素数所需的时间
- en: When we distribute work to a `Pool` of processes, we can specify how much work
    is passed to each worker. We could divide all of the work evenly and aim for one
    pass, or we could make many chunks of work and pass them out whenever a CPU is
    free. This is controlled using the `chunksize` parameter. Larger chunks of work
    mean less communication overhead, while smaller chunks of work mean more control
    over how resources are allocated.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将工作分配给一个进程池时，我们可以指定每个工作人员处理多少工作。我们可以均匀分配所有工作并争取一次通过，或者我们可以制作许多工作块并在 CPU 空闲时将它们传递出去。这由`chunksize`参数控制。更大的工作块意味着更少的通信开销，而更小的工作块意味着更多地控制资源分配方式。
- en: For our prime finder, a single piece of work is a number `n` that is checked
    by `check_prime`. A `chunksize` of `10` would mean that each process handles a
    list of 10 integers, one list at a time.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的素数查找器，一个单独的工作是由`check_prime`检查的数字`n`。`chunksize`为`10`意味着每个进程处理一个包含 10 个整数的列表，一次处理一个列表。
- en: In [Figure 9-10](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type2),
    we can see the effect of varying the `chunksize` from `1` (every job is a single
    piece of work) to `64` (every job is a list of 64 numbers). Although having many
    tiny jobs gives us the greatest flexibility, it also imposes the greatest communication
    overhead. All four CPUs will be utilized efficiently, but the communication pipe
    will become a bottleneck as each job and result is passed through this single
    channel. If we double the `chunksize` to `2`, our task gets solved twice as quickly,
    as we have less contention on the communication pipe. We might naively assume
    that by increasing the `chunksize`, we will continue to improve the execution
    time. However, as you can see in the figure, we will again come to a point of
    diminishing returns.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 9-10](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type2) 中，我们可以看到从`1`（每个作业是单独的工作）到`64`（每个作业是包含
    64 个数字的列表）变化`chunksize`的效果。尽管有许多微小的作业给了我们最大的灵活性，但也带来了最大的通信开销。四个 CPU 将被有效利用，但是通信管道会成为瓶颈，因为每个作业和结果都通过这个单一通道传递。如果我们将`chunksize`加倍到`2`，我们的任务完成速度将加快一倍，因为通信管道上的竞争减少了。我们可能天真地假设通过增加`chunksize`，我们将继续改善执行时间。然而，正如你在图中看到的，我们最终会遇到收益递减的点。
- en: '![notset](Images/hpp2_0910.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0910.png)'
- en: Figure 9-10\. Choosing a sensible `chunksize` value
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-10\. 选择合理的`chunksize`值
- en: We can continue to increase the `chunksize` until we start to see a worsening
    of behavior. In [Figure 9-11](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1),
    we expand the range of chunksizes, making them not just tiny but also huge. At
    the larger end of the scale, the worst result shown is 1.08 seconds, where we’ve
    asked for `chunksize` to be `50000`—this means our 100,000 items are divided into
    two work chunks, leaving two CPUs idle for that entire pass. With a `chunksize`
    of `10000` items, we are creating ten chunks of work; this means that four chunks
    of work will run twice in parallel, followed by the two remaining chunks. This
    leaves two CPUs idle in the third round of work, which is an inefficient usage
    of resources.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续增加`chunksize`，直到我们开始看到行为恶化。在 [图 9-11](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1)
    中，我们扩展了`chunksize`范围，使它们不仅小而且巨大。在较大的端点上，最坏的结果显示为 1.08 秒，我们要求`chunksize`为`50000`——这意味着我们的
    100,000 个项目被分成两个工作块，使得两个 CPU 在整个通过过程中空闲。使用`chunksize`为`10000`项，我们正在创建十个工作块；这意味着四个工作块将在并行中运行两次，然后是剩下的两个工作块。这在第三轮工作中使得两个
    CPU 空闲，这是资源使用的低效方式。
- en: An optimal solution in this case is to divide the total number of jobs by the
    number of CPUs. This is the default behavior in `multiprocessing`, shown as the
    “default” blue dot in the figure.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下的最佳解决方案是将总作业数除以 CPU 数量。这是`multiprocessing`的默认行为，显示为图中的“default”蓝点。
- en: As a general rule, the default behavior is sensible; tune it only if you expect
    to see a real gain, and definitely confirm your hypothesis against the default
    behavior.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般规则，默认行为是明智的；只有当您预计真正获益时才调整它，并且一定要针对默认行为确认您的假设。
- en: Unlike the Monte Carlo pi problem, our prime testing calculation has varying
    complexity—sometimes a job exits quickly (an even number is detected the fastest),
    and sometimes the number is large and a prime (this takes a much longer time to
    check).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 与蒙特卡罗π问题不同，我们的素数测试计算具有不同的复杂性——有时一个工作很快退出（检测到偶数），有时数字很大且是素数（这需要更长时间来检查）。
- en: '![notset](Images/hpp2_0911.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0911.png)'
- en: Figure 9-11\. Choosing a sensible `chunksize` value (continued)
  id: totrans-197
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-11\. 选择合理的`chunksize`值（续）
- en: What happens if we randomize our job sequence? For this problem, we squeeze
    out a 2% performance gain, as you can see in [Figure 9-12](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1-shuffled).
    By randomizing, we reduce the likelihood of the final job in the sequence taking
    longer than the others, leaving all but one CPU active.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们随机化我们的工作序列会发生什么？对于这个问题，我们挤出了 2% 的性能增益，正如您在[图 9-12](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1-shuffled)中所看到的。通过随机化，我们减少了最后一个作业花费更长时间的可能性，使除一个
    CPU 外的所有 CPU 都保持活跃。
- en: 'As our earlier example using a `chunksize` of `10000` demonstrated, misaligning
    the workload with the number of available resources leads to inefficiency. In
    that case, we created three rounds of work: the first two rounds used 100% of
    the resources, and the last round used only 50%.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前使用`chunksize`为`10000`的示例所示，将工作量与可用资源数量不匹配会导致效率低下。在那种情况下，我们创建了三轮工作：前两轮使用了资源的
    100%，而最后一轮仅使用了 50%。
- en: '![notset](Images/hpp2_0912.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0912.png)'
- en: Figure 9-12\. Randomizing the job sequence
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-12\. 随机化工作序列
- en: '[Figure 9-13](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-by-nbrchunks-sawtoothpattern)
    shows the odd effect that occurs when we misalign the number of chunks of work
    against the number of processors. Mismatches will underutilize the available resources.
    The slowest overall runtime occurs when only one chunk of work is created: this
    leaves three unutilized. Two work chunks leave two CPUs unutilized, and so on;
    only when we have four work chunks are we using all of our resources. But if we
    add a fifth work chunk, we’re underutilizing our resources again—four CPUs will
    work on their chunks, and then one CPU will run to calculate the fifth chunk.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-13](ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-by-nbrchunks-sawtoothpattern)展示了当我们将工作块的数量与处理器数量不匹配时出现的奇特效果。不匹配会导致可用资源利用不足。当只创建一个工作块时，总运行时间最慢：这样会使得三个处理器未被利用。两个工作块会使得两个
    CPU 未被利用，依此类推；只有当我们有四个工作块时，我们才能充分利用所有资源。但是如果我们添加第五个工作块，我们又会浪费资源 —— 四个 CPU 将处理它们的工作块，然后一个
    CPU 将用于计算第五个工作块。'
- en: As we increase the number of chunks of work, we see that the inefficiencies
    decrease—the difference in runtime between 29 and 32 work chunks is approximately
    0.03 seconds. The general rule is to make lots of small jobs for efficient resource
    utilization if your jobs have varying runtimes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 随着工作块数量的增加，我们看到效率的不足减少 —— 在 29 和 32 个工作块之间的运行时间差约为 0.03 秒。一般规则是为了有效利用资源，如果您的工作具有不同的运行时间，则制作大量小型工作。
- en: '![notset](Images/hpp2_0913.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0913.png)'
- en: Figure 9-13\. The danger of choosing an inappropriate number of chunks
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-13\. 选择不合适的工作块数量的危险
- en: 'Here are some strategies for efficiently using `multiprocessing` for embarrassingly
    parallel problems:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些有效使用`multiprocessing`处理尴尬并行问题的策略：
- en: Split your jobs into independent units of work.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的工作分成独立的工作单元。
- en: If your workers take varying amounts of time, consider randomizing the sequence
    of work (another example would be for processing variable-sized files).
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的工作人员需要不同的时间量，请考虑随机化工作序列（另一个例子是处理不同大小的文件）。
- en: Sorting your work queue so that the slowest jobs go first may be an equally
    useful strategy.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对工作队列进行排序，以便最慢的工作先进行，可能是一个同样有效的策略。
- en: Use the default `chunksize` unless you have verified reasons for adjusting it.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非您已验证调整的原因，否则请使用默认的`chunksize`。
- en: Align the number of jobs with the number of physical CPUs. (Again, the default
    `chunksize` takes care of this for you, although it will use any hyperthreads
    by default, which may not offer any additional gain.)
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将工作数量与物理 CPU 数量对齐。（再次强调，默认的`chunksize`会为您处理这个问题，尽管它默认使用超线程，这可能不会提供额外的增益。）
- en: Note that by default `multiprocessing` will see hyperthreads as additional CPUs.
    This means that on Ian’s laptop, it will allocate eight processes when only four
    will really be running at 100% speed. The additional four processes could be taking
    up valuable RAM while barely offering any additional speed gain.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，`multiprocessing`将超线程视为额外的 CPU。这意味着在 Ian 的笔记本电脑上，它会分配八个进程，但只有四个进程会以
    100% 的速度运行。额外的四个进程可能会占用宝贵的内存，而几乎没有提供额外的速度增益。
- en: With a `Pool`, we can split up a chunk of predefined work up front among the
    available CPUs. This is less helpful if we have dynamic workloads, though, and
    particularly if we have workloads that arrive over time. For this sort of workload,
    we might want to use a `Queue`, introduced in the next section.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Pool`，我们可以将预定义的工作块提前分配给可用的CPU。然而，如果我们有动态工作负载，特别是随时间到达的工作负载，则这种方法帮助较少。对于这种类型的工作负载，我们可能需要使用下一节介绍的`Queue`。
- en: Queues of Work
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作队列
- en: '`multiprocessing.Queue` objects give us nonpersistent queues that can send
    any pickleable Python objects between processes. They carry an overhead, as each
    object must be pickled to be sent and then unpickled in the consumer (along with
    some locking operations). In the following example, we’ll see that this cost is
    not negligible. However, if your workers are processing larger jobs, the communication
    overhead is probably acceptable.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Queue`对象提供给我们非持久化队列，可以在进程之间发送任何可 pickle 的Python对象。它们带来一些额外开销，因为每个对象必须被
    pickled 以便发送，然后在消费者端进行反序列化（还伴随一些锁操作）。在接下来的示例中，我们将看到这种成本是不可忽视的。然而，如果您的工作进程处理的是较大的作业，通信开销可能是可以接受的。'
- en: Working with the queues is fairly easy. In this example, we’ll check for primes
    by consuming a list of candidate numbers and posting confirmed primes back to
    a `definite_primes_queue`. We’ll run this with one, two, four, and eight processes
    and confirm that the latter three approaches all take longer than just running
    a single process that checks the same range.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 使用队列进行工作相当容易。在本示例中，我们将通过消费候选数列表来检查素数，并将确认的质数发布回`definite_primes_queue`。我们将以单进程、双进程、四进程和八进程运行此示例，并确认后三种方法的时间比仅运行检查相同范围的单个进程更长。
- en: A `Queue` gives us the ability to perform lots of interprocess communication
    using native Python objects. This can be useful if you’re passing around objects
    with lots of state. Since the `Queue` lacks persistence, though, you probably
    don’t want to use queues for jobs that might require robustness in the face of
    failure (e.g., if you lose power or a hard drive gets corrupted).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`Queue`为我们提供了使用本地Python对象进行大量进程间通信的能力。如果您传递的对象具有大量状态，这可能非常有用。然而，由于`Queue`缺乏持久性，您可能不希望将其用于可能需要在面对故障时保持鲁棒性的作业（例如，如果断电或硬盘损坏）。'
- en: '[Example 9-9](ch09_split_000.xhtml#code-queues-of-work-fullwork-check-prime)
    shows the `check_prime` function. We’re already familiar with the basic primality
    test. We run in an infinite loop, blocking (waiting until work is available) on
    `possible_primes_queue.get()` to consume an item from the queue. Only one process
    can get an item at a time, as the `Queue` object takes care of synchronizing the
    accesses. If there’s no work in the queue, the `.get()` blocks until a task is
    available. When primes are found, they are `put` back on the `definite_primes_queue`
    for consumption by the parent process.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-9](ch09_split_000.xhtml#code-queues-of-work-fullwork-check-prime)展示了`check_prime`函数。我们已经熟悉基本的素数测试。我们在一个无限循环中运行，在`possible_primes_queue.get()`上阻塞（等待直到有可用的工作），以消费队列中的项目。由于`Queue`对象负责同步访问，因此一次只能有一个进程获取项目。如果队列中没有工作，`.get()`将阻塞，直到有任务可用。当找到质数时，它们会被`put`回`definite_primes_queue`，供父进程消费。'
- en: Example 9-9\. Using two queues for interprocess communication (IPC)
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例9-9。使用两个队列进行进程间通信（IPC）
- en: '[PRE8]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We define two flags: one is fed by the parent process as a poison pill to indicate
    that no more work is available, while the second is fed by the worker to confirm
    that it has seen the poison pill and has closed itself down. The first poison
    pill is also known as a [*sentinel*](https://oreil.ly/mfR2s), as it guarantees
    the termination of the processing loop.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了两个标志：一个由父进程作为毒丸喂入，指示没有更多工作可用，另一个由工作进程确认它已看到毒丸并关闭自身。第一个毒丸也被称为[*sentinel*](https://oreil.ly/mfR2s)，因为它保证了处理循环的终止。
- en: When dealing with queues of work and remote workers, it can be helpful to use
    flags like these to record that the poison pills were sent and to check that responses
    were sent from the children in a sensible time window, indicating that they are
    shutting down. We don’t handle that process here, but adding some timekeeping
    is a fairly simple addition to the code. The receipt of these flags can be logged
    or printed during debugging.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 处理工作队列和远程工作者时，使用这些标志记录毒丸的发送并检查子进程在合理时间窗口内发送的响应可以很有帮助，表明它们正在关闭。我们在这里不处理这个过程，但是添加一些时间记录是代码的一个相当简单的补充。接收这些标志的情况可以在调试期间记录或打印。
- en: The `Queue` objects are created out of a `Manager` in [Example 9-10](ch09_split_000.xhtml#code-queues-of-work-fullwork-main1).
    We’ll use the familiar process of building a list of `Process` objects that each
    contain a forked process. The two queues are sent as arguments, and `multiprocessing`
    handles their synchronization. Having started the new processes, we hand a list
    of jobs to the `possible_primes_queue` and end with one poison pill per process.
    The jobs will be consumed in FIFO order, leaving the poison pills for last. In
    `check_prime` we use a blocking `.get()`, as the new processes will have to wait
    for work to appear in the queue. Since we use flags, we could add some work, deal
    with the results, and then iterate by adding more work, and signal the end of
    life of the workers by adding the poison pills later.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`Queue` 对象是在 [示例 9-10](ch09_split_000.xhtml#code-queues-of-work-fullwork-main1)
    中由 `Manager` 创建的。我们将使用构建 `Process` 对象列表的熟悉过程，每个对象都包含一个分叉的进程。这两个队列作为参数发送，并且 `multiprocessing`
    处理它们的同步。启动了新进程后，我们将一系列作业交给 `possible_primes_queue`，并以每个进程一个毒丸结束。作业将以 FIFO 顺序消耗，最后留下毒丸。在
    `check_prime` 中，我们使用阻塞的 `.get()`，因为新进程必须等待队列中出现工作。由于我们使用标志，我们可以添加一些工作，处理结果，然后通过稍后添加毒丸迭代添加更多工作，并通过稍后添加毒丸来标志工作人员的生命结束。'
- en: Example 9-10\. Building two queues for IPC
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-10\. 为 IPC 构建两个队列
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To consume the results, we start another infinite loop in [Example 9-11](ch09_split_000.xhtml#code-queues-of-work-fullwork-main2),
    using a blocking `.get()` on the `definite_primes_queue`. If the `finished-processing`
    flag is found, we take a count of the number of processes that have signaled their
    exit. If not, we have a new prime, and we add this to the `primes` list. We exit
    the infinite loop when all of our processes have signaled their exit.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要消费结果，我们在 [示例 9-11](ch09_split_000.xhtml#code-queues-of-work-fullwork-main2)
    中启动另一个无限循环，并在 `definite_primes_queue` 上使用阻塞的 `.get()`。如果找到 `finished-processing`
    标志，则计算已经信号退出的进程数。如果没有，则表示有一个新的质数，我们将其添加到 `primes` 列表中。当所有进程都已经信号退出时，我们退出无限循环。
- en: Example 9-11\. Using two queues for IPC
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-11\. 使用两个队列进行 IPC
- en: '[PRE10]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: There is quite an overhead to using a `Queue`, due to the pickling and synchronization.
    As you can see in [Figure 9-14](ch09_split_000.xhtml#FIG-queues-of-work-fullwork),
    using a `Queue`-less single-process solution is significantly faster than using
    two or more processes. The reason in this case is because our workload is very
    light—the communication cost dominates the overall time for this task. With `Queue`s,
    two processes complete this example a little faster than one process, while four
    and eight processes are both slower.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `Queue` 存在相当大的开销，这是由于 pickling 和同步造成的。正如您在 [图 9-14](ch09_split_000.xhtml#FIG-queues-of-work-fullwork)
    中所见，使用 `Queue` 的单进程解决方案明显快于使用两个或更多进程。在本例中的原因是因为我们的工作负载非常轻——通信成本主导了此任务的整体时间。使用
    `Queue`，两个进程完成这个示例比一个进程稍快，而四个和八个进程则都较慢。
- en: '![notset](Images/hpp2_0914.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0914.png)'
- en: Figure 9-14\. Cost of using Queue objects
  id: totrans-231
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-14\. 使用队列对象的成本
- en: If your task has a long completion time (at least a sizable fraction of a second)
    with a small amount of communication, a `Queue` approach might be the right answer.
    You will have to verify whether the communication cost makes this approach useful
    enough.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的任务完成时间较长（至少占据几分之一秒），但通信量很少，则使用 `Queue` 方法可能是正确的选择。您需要验证通信成本是否足够使用此方法。
- en: You might wonder what happens if we remove the redundant half of the job queue
    (all the even numbers—these are rejected very quickly in `check_prime`). Halving
    the size of the input queue halves our execution time in each case, but it still
    doesn’t beat the single-process non-`Queue` example! This helps to illustrate
    that the communication cost is the dominating factor in this problem.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想知道如果我们移除作业队列的多余一半（所有偶数——在 `check_prime` 中这些会被非常快速地拒绝），会发生什么。减少输入队列的大小会减少每种情况下的执行时间，但仍然无法超过单进程非
    `Queue` 示例！这有助于说明通信成本在此问题中是主导因素。
- en: Asynchronously adding jobs to the Queue
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步向队列添加作业
- en: 'By adding a `Thread` into the main process, we can feed jobs asynchronously
    into the `possible_primes_queue`. In [Example 9-12](ch09_split_000.xhtml#code-queues-of-work-fullwork-jobs-feeder-thread),
    we define a `feed_new_jobs` function: it performs the same job as the job setup
    routine that we had in `__main__` before, but it does it in a separate thread.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在主进程中添加一个`Thread`，我们可以将作业异步地放入`possible_primes_queue`中。在[示例 9-12](ch09_split_000.xhtml#code-queues-of-work-fullwork-jobs-feeder-thread)中，我们定义了一个`feed_new_jobs`函数：它执行与我们之前在`__main__`中设置的作业设置例程相同的工作，但是它在一个单独的线程中执行。
- en: Example 9-12\. Asynchronous job-feeding function
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-12\. 异步作业供给函数
- en: '[PRE11]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, in [Example 9-13](ch09_split_000.xhtml#code-queues-of-work-fullwork-main),
    our `__main__` will set up the `Thread` using the `possible_primes_queue` and
    then move on to the result-collection phase *before* any work has been issued.
    The asynchronous job feeder could consume work from external sources (e.g., from
    a database or I/O-bound communication) while the `__main__` thread handles each
    processed result. This means that the input sequence and output sequence do not
    need to be created in advance; they can both be handled on the fly.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在[示例 9-13](ch09_split_000.xhtml#code-queues-of-work-fullwork-main)中，我们的`__main__`将使用`possible_primes_queue`设置`Thread`，然后继续到结果收集阶段*之前*发出任何工作。异步作业供给器可以从外部源（例如数据库或I/O限制通信）消耗工作，而`__main__`线程则处理每个处理过的结果。这意味着输入序列和输出序列不需要预先创建；它们都可以即时处理。
- en: Example 9-13\. Using a thread to set up an asynchronous job feeder
  id: totrans-239
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-13\. 使用线程设置异步作业供给器
- en: '[PRE12]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If you want robust asynchronous systems, you should almost certainly look to
    using `asyncio` or an external library such as `tornado`. For a full discussion
    of these approaches, check out [Chapter 8](ch08.xhtml#chapter-concurrency). The
    examples we’ve looked at here will get you started, but pragmatically they are
    more useful for very simple systems and education than for production systems.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要稳健的异步系统，几乎可以肯定要使用`asyncio`或者像`tornado`这样的外部库。关于这些方法的全面讨论，请查看[第 8 章](ch08.xhtml#chapter-concurrency)。我们在这里看到的例子可以帮助你入门，但实际上它们对于非常简单的系统和教育而言更有用，而不是用于生产系统。
- en: 'Be *very aware* that asynchronous systems require a special level of patience—you
    will end up tearing out your hair while you are debugging. We suggest the following:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要*非常注意*异步系统需要特别耐心——在调试时你可能会抓狂。我们建议如下操作：
- en: Applying the “Keep It Simple, Stupid” principle
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用“保持简单愚蠢”原则
- en: Avoiding asynchronous self-contained systems (like our example) if possible,
    as they will grow in complexity and quickly become hard to maintain
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能，应避免使用异步自包含系统（如我们的示例），因为它们会变得越来越复杂并很快难以维护
- en: Using mature libraries like `gevent` (described in the previous chapter) that
    give you tried-and-tested approaches to dealing with certain problem sets
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用像`gevent`这样的成熟库（在上一章中描述），这些库为处理某些问题集提供了经过验证的方法
- en: Furthermore, we strongly suggest using an external queue system that gives you
    external visibility on the state of the queues (e.g., NSQ, discussed in [“NSQ
    for Robust Production Clustering”](ch10.xhtml#nsq); ZeroMQ; or Celery). This requires
    more thought but is likely to save you time because of increased debug efficiency
    and better system visibility for production systems.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们强烈建议使用提供队列状态外部可见性的外部队列系统（例如，在[“NSQ 用于稳健的生产集群”](ch10.xhtml#nsq)中讨论的 NSQ、ZeroMQ
    或 Celery）。这需要更多的思考，但可能会因提高调试效率和生产系统的更好可见性而节省您的时间。
- en: Tip
  id: totrans-247
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Consider using a task graph for resilience. Data science tasks requiring long-running
    queues are frequently served well by specifying pipelines of work in acyclic graphs.
    Two strong libraries are [Airflow](https://airflow.apache.org) and [Luigi](https://oreil.ly/rBfGh).
    These are very frequently used in industrial settings and enable arbitrary task
    chaining, online monitoring, and flexible scaling.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑使用任务图形以增强韧性。需要长时间运行队列的数据科学任务通常通过在无环图中指定工作流来有效服务。两个强大的库是[Airflow](https://airflow.apache.org)和[Luigi](https://oreil.ly/rBfGh)。这些在工业环境中广泛使用，支持任意任务链接、在线监控和灵活扩展。
- en: Verifying Primes Using Interprocess Communication
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用进程间通信验证质数
- en: Prime numbers are numbers that have no factor other than themselves and 1\.
    It stands to reason that the most common factor is 2 (every even number cannot
    be a prime). After that, the low prime numbers (e.g., 3, 5, 7) become common factors
    of larger nonprimes (e.g., 9, 15, and 21, respectively).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 质数是除了它们自己和1之外没有其他因子的数字。可以说最常见的因子是2（每个偶数都不可能是质数）。之后，低质数（例如3、5、7）成为较大的非质数（例如9、15和21）的常见因子。
- en: Let’s say that we are given a large number and are asked to verify if it is
    prime. We will probably have a large space of factors to search. [Figure 9-15](ch09_split_000.xhtml#FIG-verifying-primes-count-of-factors-of-nonprimes)
    shows the frequency of each factor for nonprimes up to 10,000,000\. Low factors
    are far more likely to occur than high factors, but there’s no predictable pattern.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个大数，并被要求验证它是否是质数。我们可能会有一个大量的因子空间需要搜索。[图 9-15](ch09_split_000.xhtml#FIG-verifying-primes-count-of-factors-of-nonprimes)显示了非质数的每个因子在10,000,000以内的频率。低因子比高因子更有可能出现，但没有可预测的模式。
- en: '![notset](Images/hpp2_0915.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0915.png)'
- en: Figure 9-15\. The frequency of factors of nonprimes
  id: totrans-253
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-15\. 非质数因子的频率
- en: Let’s define a new problem—suppose we have a *small* set of numbers, and our
    task is to efficiently use our CPU resources to figure out if each number is a
    prime, one number at a time. Possibly we’ll have just one large number to test.
    It no longer makes sense to use one CPU to do the check; we want to coordinate
    the work across many CPUs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个新问题——假设我们有一个*小*数字集，我们的任务是有效地使用CPU资源来逐个确定每个数字是否是质数。可能我们只有一个大数需要测试。现在不再有必要使用一个CPU来进行检查；我们希望跨多个CPU协调工作。
- en: 'For this section we’ll look at some larger numbers, one with 15 digits and
    four with 18 digits:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一部分，我们将查看一些更大的数字，一个有15位数，四个有18位数：
- en: 'Small nonprime: 112,272,535,095,295'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小非质数：112,272,535,095,295
- en: 'Large nonprime 1: 100,109,100,129,100,369'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大非质数1：100,109,100,129,100,369
- en: 'Large nonprime 2: 100,109,100,129,101,027'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大非质数2：100,109,100,129,101,027
- en: 'Prime 1: 100,109,100,129,100,151'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质数1：100,109,100,129,100,151
- en: 'Prime 2: 100,109,100,129,162,907'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质数2：100,109,100,129,162,907
- en: By using a smaller nonprime and some larger nonprimes, we get to verify that
    our chosen process not only is faster at checking for primes but also is not getting
    slower at checking nonprimes. We’ll assume that we don’t know the size or type
    of numbers that we’re being given, so we want the fastest possible result for
    all our use cases.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用一个较小的非质数和一些较大的非质数，我们得以验证我们选择的处理过程不仅更快地检查质数，而且在检查非质数时也不会变慢。我们假设我们不知道被给定的数字的大小或类型，因此我们希望对所有用例都获得尽可能快的结果。
- en: Note
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you own the previous edition of the book, you might be surprised to see that
    these runtimes with CPython 3.7 are *slightly slower* than the CPython 2.7 runtimes
    in the last edition, which ran on a slower laptop. The code here is one edge case
    where Python 3.*x* is currently slower than CPython 2.7\. This code depends on
    integer operations; CPython 2.7 had system integers mixed with “long” integers
    (which can store arbitrarily sized numbers but at a cost in speed). CPython 3.*x*
    uses only “long” integers for all operations. This implementation is optimized
    but is still slower in some cases compared to the old (and more complicated) implementation.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您拥有这本书的旧版，您可能会惊讶地发现，使用CPython 3.7的这些运行时间*稍慢*于上一版中在较慢的笔记本电脑上运行的CPython 2.7的运行时间。这里的代码是一个特例，Python
    3.*x*目前比CPython 2.7慢。这段代码依赖于整数操作；CPython 2.7混合使用系统整数和“long”整数（可以存储任意大小的数字，但速度较慢）。CPython
    3.*x*对所有操作只使用“long”整数。这个实现已经经过优化，但在某些情况下仍然比旧的（和更复杂的）实现慢。
- en: We never have to worry about which “kind” of integer is being used, and in CPython
    3.7 we take a small speed hit as a consequence. This is a microbenchmark that
    is incredibly unlikely to affect your own code, as CPython 3.*x* is faster than
    CPython 2.*x* in so many other ways. Our recommendation is not to worry about
    this, unless you depend on integer operations for most of your execution time—and
    in that case, we’d strongly suggest you look at PyPy, which doesn’t suffer from
    this slowdown.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从不必担心正在使用的“种类”整数，并且在CPython 3.7中，我们因此会稍微降低速度。这是一个微型基准测试，几乎不可能影响您自己的代码，因为CPython
    3.*x*在许多其他方面都比CPython 2.*x*更快。我们的建议是不要担心这个问题，除非您大部分执行时间都依赖于整数操作——在这种情况下，我们强烈建议您查看PyPy，它不会受到这种减速的影响。
- en: Cooperation comes at a cost—the cost of synchronizing data and checking the
    shared data can be quite high. We’ll work through several approaches here that
    can be used in different ways for task coordination.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 合作是有代价的——同步数据和检查共享数据的成本可能会非常高。我们将在这里讨论几种可以用于任务协调的不同方法。
- en: Note that we’re *not* covering the somewhat specialized message passing interface
    (MPI) here; we’re looking at batteries-included modules and Redis (which is very
    common). If you want to use MPI, we assume you already know what you’re doing.
    The [MPI4PY project](http://bit.ly/MPI4PY_proj) would be a good place to start.
    It is an ideal technology if you want to control latency when lots of processes
    are collaborating, whether you have one or many machines.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在这里*不*涵盖有些专业的消息传递接口（MPI）；我们关注的是一些内置的模块和Redis（非常常见）。如果你想使用MPI，我们假设你已经知道你在做什么。[MPI4PY项目](http://bit.ly/MPI4PY_proj)可能是一个很好的起点。当许多进程协作时，如果你想控制延迟，无论是一台还是多台机器，它是一种理想的技术。
- en: For the following runs, each test is performed 20 times, and the minimum time
    is taken to show the fastest speed that is possible for that method. In these
    examples we’re using various techniques to share a flag (often as 1 byte). We
    could use a basic object like a `Lock`, but then we’d be able to share only 1
    bit of state. We’re choosing to show you how to share a primitive type so that
    more expressive state sharing is possible (even though we don’t need a more expressive
    state for this example).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下运行中，每个测试重复进行20次，并取最小时间以显示可能的最快速度。在这些示例中，我们使用各种技术来共享一个标志（通常为1字节）。我们可以使用像`Lock`这样的基本对象，但是这样只能共享1位状态。我们选择向您展示如何共享原始类型，以便进行更多表达式状态共享（即使对于此示例我们不需要更多表达式状态）。
- en: We must emphasize that sharing state tends to make things *complicated*—you
    can easily end up in another hair-pulling state. Be careful and try to keep things
    as simple as they can be. It might be the case that less efficient resource usage
    is trumped by developer time spent on other challenges.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须强调，共享状态往往会使事情变得*复杂*——你很容易陷入另一种令人头疼的状态。要小心，并尽量保持事情尽可能简单。也许更有效的资源使用效果会被开发人员在其他挑战上的时间所超越。
- en: First we’ll discuss the results and then we’ll work through the code.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们将讨论结果，然后我们将详细阅读代码。
- en: '[Figure 9-16](ch09_split_001.xhtml#FIG-validating-primes-slower-results) shows
    the first approaches to trying to use interprocess communication to test for primality
    faster. The benchmark is the serial version, which does not use any interprocess
    communication; each attempt to speed up our code must at least be faster than
    this.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-16](ch09_split_001.xhtml#FIG-validating-primes-slower-results)展示了尝试使用进程间通信更快地测试素性的初步方法。基准是串行版本，它不使用任何进程间通信；我们尝试加速代码的每一次尝试至少比这个版本更快。'
- en: '![notset](Images/hpp2_0916.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0916.png)'
- en: Figure 9-16\. The slower ways to use IPC to validate primality
  id: totrans-272
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-16\. 用于验证素性的IPC较慢的方法
- en: The Less Naive Pool version has a predictable (and good) speed. It is good enough
    to be rather hard to beat. Don’t overlook the obvious in your search for high-speed
    solutions—sometimes a dumb and good-enough solution is all you need.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Less Naive Pool版本具有可预测的（并且良好的）速度。它足够好，非常难以超越。在寻找高速解决方案时不要忽视显而易见的东西——有时一个愚蠢但足够好的解决方案就是你需要的。
- en: The approach for the Less Naive Pool solution is to take our number under test,
    divide its possible-factor range evenly among the available CPUs, and then push
    the work out to each CPU. If any CPU finds a factor, it will exit early, but it
    won’t communicate this fact; the other CPUs will continue to work through their
    part of the range. This means for an 18-digit number (our four larger examples),
    the search time is the same whether it is prime or nonprime.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Less Naive Pool解决方案的方法是将我们要测试的数按可能的因子范围均匀分配给可用的CPU，然后将工作分配给每个CPU。如果任何CPU找到因子，它将提前退出，但它不会传达这一事实；其他CPU将继续处理它们范围内的工作。这意味着对于一个18位数（我们的四个较大示例），无论它是素数还是非素数，搜索时间都是相同的。
- en: The Redis and `Manager` solutions are slower when it comes to testing a larger
    number of factors for primality because of the communication overhead. They use
    a shared flag to indicate that a factor has been found and the search should be
    called off.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 当测试大量因子以确定素性时，Redis和`Manager`解决方案由于通信开销而较慢。它们使用共享标志来指示是否已找到因子并且搜索应该停止。
- en: Redis lets you share state not just with other Python processes but also with
    other tools and other machines, and even to expose that state over a web-browser
    interface (which might be useful for remote monitoring). The `Manager` is a part
    of `multiprocessing`; it provides a high-level synchronized set of Python objects
    (including primitives, the `list`, and the `dict`).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 让您不仅可以与其他 Python 进程共享状态，还可以与其他工具和其他计算机共享状态，甚至可以通过 Web 浏览器界面公开该状态（这对于远程监视可能很有用）。`Manager`
    是 `multiprocessing` 的一部分；它提供了一组高级同步的 Python 对象（包括原语、`list` 和 `dict`）。
- en: For the larger nonprime cases, although there is a cost to checking the shared
    flag, this is dwarfed by the savings in search time gained by signaling early
    that a factor has been found.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更大的非素数情况，尽管检查共享标志会产生一些成本，但这个成本在早期发现因子并发出信号的搜索时间节省中微不足道。
- en: For the prime cases, though, there is no way to exit early, as no factor will
    be found, so the cost of checking the shared flag will become the dominating cost.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 对于素数情况，无法提前退出，因为不会找到任何因子，所以检查共享标志的成本将成为主导成本。
- en: Tip
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: A little bit of thought is often enough. Here we explore various IPC-based solutions
    to making the prime-validation task faster. In terms of “minutes of typing” versus
    “gains made,” the first step—introducing naive parallel processing—gave us the
    largest win for the smallest effort. Subsequent gains took a lot of extra experimentation.
    Always think about the ultimate run-time, especially for ad hoc tasks. Sometimes
    it is just easier to let a loop run all weekend for a one-off task than to optimize
    the code so it runs quicker.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一点思考往往就足够了。在这里，我们探讨了各种基于 IPC 的解决方案，以使素数验证任务更快。就“打字分钟”与“收益增加”而言，第一步——引入天真的并行处理——为我们带来了最大的收益，而付出的努力却最小。后续的收益需要进行大量额外的实验。始终考虑最终运行时间，特别是对于临时任务。有时，让一个循环运行整个周末来完成一个临时任务比优化代码以更快地运行更容易。
- en: '[Figure 9-17](ch09_split_001.xhtml#FIG-validating-primes-faster-results) shows
    that we can get a considerably faster result with a bit of effort. The Less Naive
    Pool result is still our benchmark, but the `RawValue` and MMap (memory map) results
    are much faster than the previous Redis and `Manager` results. The real magic
    comes from taking the fastest solution and performing some less-obvious code manipulations
    to make a near-optimal MMap solution—this final version is faster than the Less
    Naive Pool solution for nonprimes and almost as fast for primes.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9-17](ch09_split_001.xhtml#FIG-validating-primes-faster-results) 显示，通过一些努力，我们可以获得一个明显更快的结果。较不天真的
    Pool 结果仍然是我们的基准线，但 `RawValue` 和 MMap（内存映射）的结果比以前的 Redis 和 `Manager` 结果快得多。真正的魔法来自于采取最快的解决方案，并执行一些不那么明显的代码操作，使得几乎最佳的
    MMap 解决方案比 Less Naive Pool 解决方案在非素数情况下更快，并且在素数情况下几乎一样快。'
- en: In the following sections, we’ll work through various ways of using IPC in Python
    to solve our cooperative search problem. We hope you’ll see that IPC is fairly
    easy but generally comes with a cost.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将通过各种方式来使用 Python 中的 IPC 来解决我们的协同搜索问题。我们希望您能看到 IPC 虽然相当容易，但通常会带来一些成本。
- en: '![notset](Images/hpp2_0917.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0917.png)'
- en: Figure 9-17\. The faster ways to use IPC to validate primality
  id: totrans-284
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-17\. 使用 IPC 进行验证素数的更快方法
- en: Serial Solution
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 串行解决方案
- en: We’ll start with the same serial factor-checking code that we used before, shown
    again in [Example 9-14](ch09_split_001.xhtml#code-verifying-primes-serial). As
    noted earlier, for any nonprime with a large factor, we could more efficiently
    search the space of factors in parallel. Still, a serial sweep will give us a
    sensible baseline to work from.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从之前使用过的相同的串行因子检查代码开始，如 [示例 9-14](ch09_split_001.xhtml#code-verifying-primes-serial)
    中再次显示的那样。正如之前注意到的那样，对于任何具有较大因子的非素数，我们可以更有效地并行搜索因子空间。但是，串行扫描将为我们提供一个明智的基准线。
- en: Example 9-14\. Serial verification
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-14\. 串行验证
- en: '[PRE13]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Naive Pool Solution
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Naive Pool 解决方案
- en: The Naive Pool solution works with a `multiprocessing.Pool`, similar to what
    we saw in [“Finding Prime Numbers”](ch09_split_000.xhtml#multiprocessing-finding-prime-numbers)
    and [“Estimating Pi Using Processes and Threads”](ch09_split_000.xhtml#multiprocessing-estimating-pi)
    with four forked processes. We have a number to test for primality, and we divide
    the range of possible factors into four tuples of subranges and send these into
    the `Pool`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Naive Pool 解决方案使用了一个 `multiprocessing.Pool`，类似于我们在 [“寻找素数”](ch09_split_000.xhtml#multiprocessing-finding-prime-numbers)
    和 [“使用进程和线程估算π”](ch09_split_000.xhtml#multiprocessing-estimating-pi) 中看到的，有四个
    forked 进程。我们有一个要测试素数性的数字，我们将可能的因子范围分成了四个子范围的元组，并将这些发送到 `Pool` 中。
- en: In [Example 9-15](ch09_split_001.xhtml#code-verifying-primes-pool1-1), we use
    a new method, `create_range.create` (which we won’t show—it’s quite boring), that
    splits the work space into equal-sized regions. Each item in `ranges_to_check`
    is a pair of lower and upper bounds to search between. For the first 18-digit
    nonprime (100,109,100,129,100,369), with four processes we’ll have the factor
    ranges `ranges_to_check == [(3, 79_100_057), (79_100_057, 158_200_111), (158_200_111,
    237_300_165), (237_300_165, 316_400_222)]` (where 316,400,222 is the square root
    of 100,109,100,129,100,369 plus 1). In `__main__` we first establish a `Pool`;
    `check_prime` then splits the `ranges_to_check` for each possibly prime number
    `n` via a `map`. If the result is `False`, we have found a factor and we do not
    have a prime.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 9-15](ch09_split_001.xhtml#code-verifying-primes-pool1-1) 中，我们使用了一个新方法`create_range.create`（我们不会展示它——它相当无聊），它将工作空间分割成大小相等的区域。`ranges_to_check`
    中的每个项目是一对下限和上限，用于搜索之间。对于第一个18位数的非质数（100,109,100,129,100,369），使用四个进程，我们将得到因子范围
    `ranges_to_check == [(3, 79_100_057), (79_100_057, 158_200_111), (158_200_111,
    237_300_165), (237_300_165, 316_400_222)]`（其中316,400,222是100,109,100,129,100,369的平方根加1）。在`__main__`中，我们首先建立一个`Pool`；然后`check_prime`通过`map`方法将`ranges_to_check`拆分为每个可能的质数`n`。如果结果为`False`，则找到了一个因子，这不是一个质数。
- en: Example 9-15\. Naive Pool solution
  id: totrans-292
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-15\. 幼稚池解决方案
- en: '[PRE14]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We modify the previous `check_prime` in [Example 9-16](ch09_split_001.xhtml#code-verifying-primes-pool1-2)
    to take a lower and upper bound for the range to check. There’s no value in passing
    a complete list of possible factors to check, so we save time and memory by passing
    just two numbers that define our range.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们修改了前面[示例 9-16](ch09_split_001.xhtml#code-verifying-primes-pool1-2) 中的`check_prime`，以获取要检查范围的下限和上限。传递完整的可能因子列表没有意义，因此通过传递仅定义我们范围的两个数字，我们节省了时间和内存。
- en: Example 9-16\. `check_prime_in_range`
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-16\. `check_prime_in_range`
- en: '[PRE15]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: For the “small nonprime” case, the verification time via the `Pool` is 0.1 seconds,
    a significantly longer time than the original 0.000002 seconds in the Serial solution.
    Despite this one worse result, the overall result is a speedup across the board.
    We could perhaps accept that one slower result isn’t a problem—but what if we
    might get lots of smaller nonprimes to check? It turns out we can avoid this slowdown;
    we’ll see that next with the Less Naive Pool solution.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“小非质数”情况，通过`Pool`验证的时间为0.1秒，远远长于串行解决方案中的原始0.000002秒。尽管有一个更差的结果，整体结果是全面加速。也许我们可以接受一个较慢的结果不是问题——但如果我们可能有很多小非质数需要检查呢？事实证明我们可以避免这种减速；接下来我们将看到更为成熟的池解决方案。
- en: A Less Naive Pool Solution
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更为成熟的池解决方案
- en: The previous solution was inefficient at validating the smaller nonprime. For
    any smaller (fewer than 18 digits) nonprime, it is likely to be slower than the
    serial method, because of the overhead of sending out partitioned work and not
    knowing if a very small factor (which is a more likely factor) will be found.
    If a small factor is found, the process will still have to wait for the other
    larger factor searches to complete.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的解决方案在验证较小的非质数时效率低下。对于任何较小（少于18位数）的非质数，由于发送分区工作的开销和不知道是否会找到一个非常小的因子（这是更有可能的因子），它可能比串行方法更慢。如果找到一个小因子，该过程仍然必须等待其他更大因子的搜索完成。
- en: We could start to signal between the processes that a small factor has been
    found, but since this happens so frequently, it will add a lot of communication
    overhead. The solution presented in [Example 9-17](ch09_split_001.xhtml#code-verifying-primes-pool2-1)
    is a more pragmatic approach—a serial check is performed quickly for likely small
    factors, and if none are found, then a parallel search is started. Combining a
    serial precheck before launching a relatively more expensive parallel operation
    is a common approach to avoiding some of the costs of parallel computing.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以开始在进程之间发信号，表明已找到一个小因子，但由于这种情况非常频繁，这将增加大量的通信开销。[示例 9-17](ch09_split_001.xhtml#code-verifying-primes-pool2-1)
    中提出的解决方案是一种更加实用的方法——快速执行串行检查以查找可能的小因子，如果没有找到，则启动并行搜索。在启动相对更昂贵的并行操作之前进行串行预检查是避免一些并行计算成本的常见方法。
- en: Example 9-17\. Improving the Naive Pool solution for the small-nonprime case
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-17\. 改进小非质数情况下的幼稚池解决方案
- en: '[PRE16]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The speed of this solution is equal to or better than that of the original serial
    search for each of our test numbers. This is our new benchmark.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的每个测试数字，这种解决方案的速度要么相等，要么优于原始串行搜索。这是我们的新基准。
- en: Importantly, this `Pool` approach gives us an optimal case for the prime-checking
    situation. If we have a prime, there’s no way to exit early; we have to manually
    check all possible factors before we can exit.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，这种 `Pool` 方法为素数检查提供了一个最佳案例。如果我们有一个素数，就没有办法提前退出；我们必须在退出之前手动检查所有可能的因子。
- en: 'There’s no faster way to check though these factors: any approach that adds
    complexity will have more instructions, so the check-all-factors case will cause
    the most instructions to be executed. See the various `mmap` solutions covered
    in [“Using mmap as a Flag”](ch09_split_001.xhtml#multiprocessing-mmap) for a discussion
    on how to get as close to this current result for primes as possible.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 检查这些因素没有更快的方法：任何增加复杂性的方法都会有更多的指令，因此检查所有因素的情况将导致执行最多的指令。参见 [“使用 mmap 作为标志”](ch09_split_001.xhtml#multiprocessing-mmap)
    中涵盖的各种 `mmap` 解决方案，讨论如何尽可能接近当前用于素数的结果。
- en: Using Manager.Value as a Flag
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 `Manager.Value` 作为标志
- en: The `multiprocessing.Manager()` lets us share higher-level Python objects between
    processes as managed shared objects; the lower-level objects are wrapped in proxy
    objects. The wrapping and safety have a speed cost but also offer great flexibility.
    You can share both lower-level objects (e.g., integers and floats) and lists and
    dictionaries.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.Manager()` 允许我们在进程之间共享更高级别的 Python 对象作为托管共享对象；较低级别的对象被包装在代理对象中。包装和安全性会增加速度成本，但也提供了极大的灵活性。可以共享较低级别的对象（例如整数和浮点数）以及列表和字典。'
- en: In [Example 9-18](ch09_split_001.xhtml#code-verifying-primes-managervalue1),
    we create a `Manager` and then create a 1-byte (character) `manager.Value(b"c",
    FLAG_CLEAR)` flag. You could create any of the `ctypes` primitives (which are
    the same as the `array.array` primitives) if you wanted to share strings or numbers.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 9-18](ch09_split_001.xhtml#code-verifying-primes-managervalue1) 中，我们创建了一个
    `Manager`，然后创建了一个 1 字节（字符）的 `manager.Value(b"c", FLAG_CLEAR)` 标志。如果需要共享字符串或数字，可以创建任何
    `ctypes` 原语（与 `array.array` 原语相同）。
- en: Note that `FLAG_CLEAR` and `FLAG_SET` are assigned a byte (`b'0'` and `b'1'`,
    respectively). We chose to use the leading `b` to be very explicit (it might default
    to a Unicode or string object if left as an implicit string, depending on your
    environment and Python version).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `FLAG_CLEAR` 和 `FLAG_SET` 被分配了一个字节（`b'0'` 和 `b'1'`）。我们选择使用前缀 `b` 来显式说明（如果不加
    `b`，可能会根据您的环境和 Python 版本默认为 Unicode 或字符串对象）。
- en: Now we can flag across all of our processes that a factor has been found, so
    the search can be called off early. The difficulty is balancing the cost of reading
    the flag against the speed savings that is possible. Because the flag is synchronized,
    we don’t want to check it too frequently—this adds more overhead.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在所有进程中传播一个因子已被发现的标志，因此可以提前结束搜索。难点在于平衡读取标志的成本与可能的速度节省。由于标志是同步的，我们不希望过于频繁地检查它
    —— 这会增加更多的开销。
- en: Example 9-18\. Passing a `Manager.Value` object as a flag
  id: totrans-311
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-18\. 将 `Manager.Value` 对象作为标志传递
- en: '[PRE17]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`check_prime_in_range` will now be aware of the shared flag, and the routine
    will be checking to see if a prime has been spotted by another process. Even though
    we’ve yet to begin the parallel search, we must clear the flag as shown in [Example 9-19](ch09_split_001.xhtml#code-verifying-primes-managervalue2)
    before we start the serial check. Having completed the serial check, if we haven’t
    found a factor, we know that the flag must still be false.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`check_prime_in_range` 现在将意识到共享的标志，并且该例程将检查是否有其他进程发现了素数。即使我们尚未开始并行搜索，我们必须像
    [示例 9-19](ch09_split_001.xhtml#code-verifying-primes-managervalue2) 中所示那样在开始串行检查之前清除标志。完成串行检查后，如果我们没有找到因子，我们知道标志必须仍然为假。'
- en: Example 9-19\. Clearing the flag with a `Manager.Value`
  id: totrans-314
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-19\. 使用 `Manager.Value` 清除标志
- en: '[PRE18]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How frequently should we check the shared flag? Each check has a cost, both
    because we’re adding more instructions to our tight inner loop and because checking
    requires a lock to be made on the shared variable, which adds more cost. The solution
    we’ve chosen is to check the flag every one thousand iterations. Every time we
    check, we look to see if `value.value` has been set to `FLAG_SET`, and if so,
    we exit the search. If in the search the process finds a factor, then it sets
    `value.value = FLAG_SET` and exits (see [Example 9-20](ch09_split_001.xhtml#code-verifying-primes-managervalue3)).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该多频繁地检查共享标志？每次检查都有成本，因为我们将更多指令添加到紧密的内部循环中，并且检查需要对共享变量进行锁定，这会增加更多成本。我们选择的解决方案是每一千次迭代检查一次标志。每次检查时，我们都会查看`value.value`是否已设置为`FLAG_SET`，如果是，我们会退出搜索。如果在搜索中进程找到一个因子，则会将`value.value
    = FLAG_SET`并退出（参见 [示例 9-20](ch09_split_001.xhtml#code-verifying-primes-managervalue3)）。
- en: Example 9-20\. Passing a `Manager.Value` object as a flag
  id: totrans-317
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-20\. 传递一个`Manager.Value`对象作为标志
- en: '[PRE19]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The thousand-iteration check in this code is performed using a `check_every`
    local counter. It turns out that this approach, although readable, is suboptimal
    for speed. By the end of this section, we’ll replace it with a less readable but
    significantly faster approach.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码中的千次迭代检查是使用`check_every`本地计数器执行的。事实证明，尽管可读性强，但速度不佳。在本节结束时，我们将用一种可读性较差但显著更快的方法来替换它。
- en: You might be curious about the total number of times we check for the shared
    flag. In the case of the two large primes, with four processes we check for the
    flag 316,405 times (we check it this many times in all of the following examples).
    Since each check has an overhead due to locking, this cost really adds up.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会对我们检查共享标志的总次数感到好奇。对于两个大质数的情况，使用四个进程我们检查了316,405次标志（在所有后续示例中我们都会检查这么多次）。由于每次检查都因锁定而带来开销，这种成本真的会累积起来。
- en: Using Redis as a Flag
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Redis 作为标志
- en: '*Redis* is a key/value in-memory storage engine. It provides its own locking
    and each operation is atomic, so we don’t have to worry about using locks from
    inside Python (or from any other interfacing language).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '*Redis* 是一个键/值内存存储引擎。它提供了自己的锁定机制，每个操作都是原子的，因此我们无需担心从Python（或任何其他接口语言）内部使用锁。'
- en: By using Redis, we make the data storage language-agnostic—any language or tool
    with an interface to Redis can share data in a compatible way. You could share
    data between Python, Ruby, C++, and PHP equally easily. You can share data on
    the local machine or over a network; to share to other machines, all you need
    to do is change the Redis default of sharing only on `localhost`.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 Redis，我们使数据存储与语言无关—任何具有与Redis接口的语言或工具都可以以兼容的方式共享数据。您可以轻松在Python、Ruby、C++和PHP之间共享数据。您可以在本地机器上或通过网络共享数据；要共享到其他机器，您只需更改Redis默认仅在`localhost`上共享的设置。
- en: 'Redis lets you store the following:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 允许您存储以下内容：
- en: Lists of strings
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串的列表
- en: Sets of strings
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串的集合
- en: Sorted sets of strings
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串的排序集合
- en: Hashes of strings
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串的哈希
- en: Redis stores everything in RAM and snapshots to disk (optionally using journaling)
    and supports master/slave replication to a cluster of instances. One possibility
    with Redis is to use it to share a workload across a cluster, where other machines
    read and write state and Redis acts as a fast centralized data repository.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 将所有数据存储在RAM中，并进行快照到磁盘（可选使用日志记录），并支持主/从复制到一组实例的集群。Redis 的一个可能应用是将其用于在集群中分享工作负载，其中其他机器读取和写入状态，而Redis
    充当快速的集中式数据存储库。
- en: We can read and write a flag as a text string (all values in Redis are strings)
    in just the same way as we have been using Python flags previously. We create
    a `StrictRedis` interface as a global object, which talks to the external Redis
    server. We could create a new connection inside `check_prime_in_range`, but this
    is slower and can exhaust the limited number of Redis handles that are available.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像以前使用Python标志一样读取和写入文本字符串（Redis中的所有值都是字符串）。我们创建一个`StrictRedis`接口作为全局对象，它与外部Redis服务器通信。我们可以在`check_prime_in_range`内部创建一个新连接，但这样做会更慢，并且可能耗尽可用的有限Redis句柄数量。
- en: We talk to the Redis server using a dictionary-like access. We can set a value
    using `rds[SOME_KEY] = SOME_VALUE` and read the string back using `rds[SOME_KEY]`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用类似字典的访问方式与Redis服务器通信。我们可以使用`rds[SOME_KEY] = SOME_VALUE`设置一个值，并使用`rds[SOME_KEY]`读取字符串返回。
- en: '[Example 9-21](ch09_split_001.xhtml#code-verifying-primes-redis1) is very similar
    to the previous `Manager` example—we’re using Redis as a substitute for the local
    `Manager`. It comes with a similar access cost. You should note that Redis supports
    other (more complex) data structures; it is a powerful storage engine that we’re
    using just to share a flag for this example. We encourage you to familiarize yourself
    with its features.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-21](ch09_split_001.xhtml#code-verifying-primes-redis1)与之前的`Manager`示例非常相似——我们使用Redis替代了本地的`Manager`。它具有类似的访问成本。需要注意的是，Redis支持其他（更复杂的）数据结构；它是一个强大的存储引擎，我们仅在此示例中使用它来共享一个标志。我们鼓励您熟悉其特性。'
- en: Example 9-21\. Using an external Redis server for our flag
  id: totrans-333
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-21\. 使用外部Redis服务器作为我们的标志
- en: '[PRE20]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: To confirm that the data is stored outside these Python instances, we can invoke
    `redis-cli` at the command line, as in [Example 9-22](ch09_split_001.xhtml#code-08-redis-cli),
    and get the value stored in the key `redis_primes_flag`. You’ll note that the
    returned item is a string (not an integer). All values returned from Redis are
    strings, so if you want to manipulate them in Python, you’ll have to convert them
    to an appropriate datatype first.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 要确认数据存储在这些Python实例之外，我们可以像在[示例 9-22](ch09_split_001.xhtml#code-08-redis-cli)中那样，在命令行上调用`redis-cli`，并获取存储在键`redis_primes_flag`中的值。您会注意到返回的项是一个字符串（而不是整数）。从Redis返回的所有值都是字符串，因此如果您想在Python中操作它们，您需要先将它们转换为适当的数据类型。
- en: Example 9-22\. `redis-cli`
  id: totrans-336
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-22\. `redis-cli`
- en: '[PRE21]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: One powerful argument in favor of the use of Redis for data sharing is that
    it lives outside the Python world—non-Python developers on your team will understand
    it, and many tools exist for it. They’ll be able to look at its state while reading
    (but not necessarily running and debugging) your code and follow what’s happening.
    From a team-velocity perspective, this might be a big win for you, despite the
    communication overhead of using Redis. While Redis is an additional dependency
    on your project, you should note that it is a very commonly deployed tool, and
    one that is well debugged and well understood. Consider it a powerful tool to
    add to your armory.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 支持将Redis用于数据共享的一个强有力的论点是它存在于Python世界之外——您团队中不熟悉Python的开发人员也能理解它，并且存在许多针对它的工具。在阅读代码时，他们可以查看其状态，了解发生了什么（尽管不一定运行和调试）。从团队效率的角度来看，尽管使用Redis会增加沟通成本，但这可能对您来说是一个巨大的胜利。尽管Redis是项目中的额外依赖，但需要注意的是它是一个非常常见的部署工具，经过了良好的调试和理解。考虑将其作为增强您武器库的强大工具。
- en: 'Redis has many configuration options. By default it uses a TCP interface (that’s
    what we’re using), although the benchmark documentation notes that sockets might
    be much faster. It also states that while TCP/IP lets you share data over a network
    between different types of OS, other configuration options are likely to be faster
    (but also are likely to limit your communication options):'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: Redis有许多配置选项。默认情况下，它使用TCP接口（这就是我们正在使用的），尽管基准文档指出套接字可能更快。它还指出，虽然TCP/IP允许您在不同类型的操作系统之间共享数据网络，但其他配置选项可能更快（但也可能限制您的通信选项）：
- en: When the server and client benchmark programs run on the same box, both the
    TCP/IP loopback and unix domain sockets can be used. It depends on the platform,
    but unix domain sockets can achieve around 50% more throughput than the TCP/IP
    loopback (on Linux for instance). The default behavior of redis-benchmark is to
    use the TCP/IP loopback. The performance benefit of unix domain sockets compared
    to TCP/IP loopback tends to decrease when pipelining is heavily used (i.e., long
    pipelines).
  id: totrans-340
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当服务器和客户端基准程序在同一台计算机上运行时，可以同时使用TCP/IP回环和Unix域套接字。这取决于平台，但Unix域套接字在Linux上可以实现大约比TCP/IP回环高出50%的吞吐量。redis-benchmark的默认行为是使用TCP/IP回环。与TCP/IP回环相比，Unix域套接字的性能优势在大量使用流水线时倾向于减少（即长流水线）。
- en: ''
  id: totrans-341
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Redis documentation](http://redis.io/topics/benchmarks)'
  id: totrans-342
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Redis文档](http://redis.io/topics/benchmarks)'
- en: Redis is widely used in industry and is mature and well trusted. If you’re not
    familiar with the tool, we strongly suggest you take a look at it; it has a place
    in your high performance toolkit.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: Redis在工业界广泛使用，成熟且信任。如果您对这个工具不熟悉，我们强烈建议您了解一下；它在您的高性能工具包中占据一席之地。
- en: Using RawValue as a Flag
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用RawValue作为标志
- en: '`multiprocessing.RawValue` is a thin wrapper around a `ctypes` block of bytes.
    It lacks synchronization primitives, so there’s little to get in our way in our
    search for the fastest way to set a flag between processes. It will be almost
    as fast as the following `mmap` example (it is slower only because a few more
    instructions get in the way).'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.RawValue` 是围绕 `ctypes` 字节块的薄包装。它缺乏同步原语，因此在我们寻找在进程之间设置标志位的最快方法时，几乎不会有阻碍。它几乎和下面的
    `mmap` 示例一样快（它只慢了一点，因为多了几条指令）。'
- en: Again, we could use any `ctypes` primitive; there’s also a `RawArray` option
    for sharing an array of primitive objects (which will behave similarly to `array.array`).
    `RawValue` avoids any locking—it is faster to use, but you don’t get atomic operations.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以使用任何 `ctypes` 原始类型；还有一个 `RawArray` 选项用于共享一组原始对象（它们的行为类似于 `array.array`）。`RawValue`
    避免了任何锁定——使用起来更快，但你不能获得原子操作。
- en: Generally, if you avoid the synchronization that Python provides during IPC,
    you’ll come unstuck (once again, back to that pulling-your-hair-out situation).
    *However*, in this problem it doesn’t matter if one or more processes set the
    flag at the same time—the flag gets switched in only one direction, and every
    other time it is read, it is just to learn if the search can be called off.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，如果避免了 Python 在 IPC 期间提供的同步，你可能会遇到麻烦（再次回到那种让你抓狂的情况）。*但是*，在这个问题中，如果一个或多个进程同时设置标志位并不重要——标志位只会单向切换，并且每次读取时，只是用来判断是否可以终止搜索。
- en: Because we never reset the state of the flag during the parallel search, we
    don’t need synchronization. Be aware that this may not apply to your problem.
    If you avoid synchronization, please make sure you are doing it for the right
    reasons.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们在并行搜索过程中从未重置标志位的状态，所以我们不需要同步。请注意，这可能不适用于你的问题。如果你避免同步，请确保你是出于正确的原因这样做。
- en: If you want to do things like update a shared counter, look at the documentation
    for the `Value` and use a context manager with `value.get_lock()`, as the implicit
    locking on a `Value` doesn’t allow for atomic operations.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想做类似更新共享计数器的事情，请查看 `Value` 的文档，并使用带有 `value.get_lock()` 的上下文管理器，因为 `Value`
    上的隐式锁定不允许原子操作。
- en: This example looks very similar to the previous `Manager` example. The only
    difference is that in [Example 9-23](ch09_split_001.xhtml#code-verifying-primes-value1)
    we create the `RawValue` as a one-character (byte) flag.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例看起来与之前的 `Manager` 示例非常相似。唯一的区别是在 [示例 9-23](ch09_split_001.xhtml#code-verifying-primes-value1)
    中，我们将 `RawValue` 创建为一个字符（字节）的标志位。
- en: Example 9-23\. Creating and passing a `RawValue`
  id: totrans-351
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-23\. 创建和传递 `RawValue`
- en: '[PRE22]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The flexibility to use managed and raw values is a benefit of the clean design
    for data sharing in `multiprocessing`.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `multiprocessing` 中，使用受控和原始值的灵活性是数据共享清洁设计的一个优点。
- en: Using mmap as a Flag
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 mmap 作为标志位
- en: Finally, we get to the fastest way of sharing bytes. [Example 9-24](ch09_split_001.xhtml#code-verifying-primes-mmap1)
    shows a memory-mapped (shared memory) solution using the `mmap` module. The bytes
    in a shared memory block are not synchronized, and they come with very little
    overhead. They act like a file—in this case, they are a block of memory with a
    file-like interface. We have to `seek` to a location and read or write sequentially.
    Typically, `mmap` is used to give a short (memory-mapped) view into a larger file,
    but in our case, rather than specifying a file number as the first argument, we
    instead pass `-1` to indicate that we want an anonymous block of memory. We could
    also specify whether we want read-only or write-only access (we want both, which
    is the default).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来讨论最快的字节共享方式。[示例 9-24](ch09_split_001.xhtml#code-verifying-primes-mmap1)
    展示了使用 `mmap` 模块的内存映射（共享内存）解决方案。共享内存块中的字节不同步，并且带有非常少的开销。它们的行为类似于文件——在这种情况下，它们是一个带有文件接口的内存块。我们必须
    `seek` 到某个位置，然后顺序读取或写入。通常情况下，`mmap` 用于在较大文件中创建一个短视图（内存映射），但在我们的情况下，作为第一个参数而不是指定文件号，我们传递
    `-1` 表示我们想要一个匿名内存块。我们还可以指定我们是想要只读或只写访问（我们两者都要，这是默认值）。
- en: Example 9-24\. Using a shared memory flag via `mmap`
  id: totrans-356
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-24\. 使用 `mmap` 进行共享内存标志
- en: '[PRE23]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`mmap` supports a number of methods that can be used to move around in the
    file that it represents (including `find`, `readline`, and `write`). We are using
    it in the most basic way—we `seek` to the start of the memory block before each
    read or write, and since we’re sharing just 1 byte, we use `read_byte` and `write_byte`
    to be explicit.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`mmap`支持多种方法，可用于在其表示的文件中移动（包括`find`、`readline`和`write`）。我们正在以最基本的方式使用它 —— 每次读取或写入前，我们都会`seek`到内存块的开头，并且由于我们只共享
    1 字节，所以我们使用`read_byte`和`write_byte`以明确方式。'
- en: There is no Python overhead for locking and no interpretation of the data; we’re
    dealing with bytes directly with the operating system, so this is our fastest
    communication method.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 没有Python锁定的开销，也没有数据的解释；我们直接与操作系统处理字节，因此这是我们最快的通信方法。
- en: Using mmap as a Flag Redux
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用mmap作为旗帜的再现
- en: While the previous `mmap` result was the best overall, we couldn’t help but
    think that we should be able to get back to the Naive Pool result for the most
    expensive case of having primes. The goal is to accept that there is no early
    exit from the inner loop and to minimize the cost of anything extraneous.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管先前的`mmap`结果在整体上表现最佳，但我们不禁要考虑是否能够回到最昂贵的素数案例的天真池结果。目标是接受内部循环没有早期退出，并尽量减少任何不必要的成本。
- en: This section presents a slightly more complex solution. The same changes can
    be made to the other flag-based approaches we’ve seen, although this `mmap` result
    will still be fastest.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提出了一个稍微复杂的解决方案。虽然我们看到了基于其他基于标志的方法的相同变化，但这个`mmap`结果仍然是最快的。
- en: In our previous examples, we’ve used `CHECK_EVERY`. This means we have the `check_next`
    local variable to track, decrement, and use in Boolean tests—and each operation
    adds a bit of extra time to every iteration. In the case of validating a large
    prime, this extra management overhead occurs over 300,000 times.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的示例中，我们使用了`CHECK_EVERY`。这意味着我们有`check_next`本地变量来跟踪、递减和在布尔测试中使用 — 每个操作都会在每次迭代中增加一点额外的时间。在验证大素数的情况下，这种额外的管理开销发生了超过
    300,000 次。
- en: The first optimization, shown in [Example 9-25](ch09_split_001.xhtml#code-verifying-primes-mmap2-1),
    is to realize that we can replace the decremented counter with a look-ahead value,
    and then we only have to do a Boolean comparison on the inner loop. This removes
    a decrement, which, because of Python’s interpreted style, is quite slow. This
    optimization works in this test in CPython 3.7, but it is unlikely to offer any
    benefit in a smarter compiler (e.g., PyPy or Cython). This step saved 0.1 seconds
    when checking one of our large primes.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个优化，在[示例 9-25](ch09_split_001.xhtml#code-verifying-primes-mmap2-1)中展示，是意识到我们可以用一个预先查看的值替换递减的计数器，然后我们只需要在内循环中进行布尔比较。这样就可以去掉一个递减操作，因为Python的解释风格，这样做相当慢。这种优化在CPython
    3.7中有效，但不太可能在更智能的编译器（如PyPy或Cython）中带来任何好处。在检查我们的一个大素数时，这一步节省了 0.1 秒。
- en: Example 9-25\. Starting to optimize away our expensive logic
  id: totrans-365
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-25\. 开始优化我们昂贵逻辑
- en: '[PRE24]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can also entirely replace the logic that the counter represents, as shown
    in [Example 9-26](ch09_split_001.xhtml#code-verifying-primes-mmap3-1), by unrolling
    our loop into a two-stage process. First, the outer loop covers the expected range,
    but in steps, on `CHECK_EVERY`. Second, a new inner loop replaces the `check_every`
    logic—it checks the local range of factors and then finishes. This is equivalent
    to the `if not check_every:` test. We follow this with the previous `sh_mem` logic
    to check the early-exit flag.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以完全替换计数器表示的逻辑，如[示例 9-26](ch09_split_001.xhtml#code-verifying-primes-mmap3-1)所示，将我们的循环展开为两个阶段的过程。首先，外循环按步长覆盖预期范围，但在`CHECK_EVERY`上。其次，一个新的内循环替换了`check_every`逻辑
    —— 它检查因子的本地范围，然后完成。这等同于`if not check_every:`测试。我们紧随其后的是先前的`sh_mem`逻辑，以检查早期退出标志。
- en: Example 9-26\. Optimizing away our expensive logic
  id: totrans-368
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-26\. 优化我们昂贵逻辑的方法
- en: '[PRE25]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The speed impact is dramatic. Our nonprime case improves even further, but more
    importantly, our prime-checking case is nearly as fast as the Less Naive Pool
    version (it is now just 0.1 seconds slower). Given that we’re doing a lot of extra
    work with interprocess communication, this is an interesting result. Do note,
    though, that it is specific to CPython and unlikely to offer any gains when run
    through a compiler.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 速度影响是显著的。即使是我们的非素数案例也进一步改进，但更重要的是，我们的素数检查案例几乎与较不天真的池版本一样快（现在只慢了 0.1 秒）。考虑到我们在进程间通信中做了大量额外的工作，这是一个有趣的结果。请注意，这只适用于CPython，并且在编译器中运行时不太可能带来任何收益。
- en: In the last edition of the book we went even further with a final example that
    used loop unrolling and local references to global objects and eked out a further
    performance gain at the expense of readability. This example in Python 3 yields
    a minor slowdown, so we’ve removed it. We’re happy about this—fewer hoops needed
    jumping through to get the most performant example, and the preceding code is
    more likely to be supported correctly in a team than one that makes implementation-specific
    code changes.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在书的最后一版中，我们通过一个最终示例进一步展示了循环展开和全局对象的局部引用，以牺牲可读性换取了更高的性能。在 Python 3 中，这个例子稍微慢了一点，所以我们将其删除了。我们对此感到高兴——为了得到最高性能的示例，不需要跳过太多障碍，前面的代码更可能在团队中得到正确支持，而不是进行特定于实现的代码更改。
- en: Tip
  id: totrans-372
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: These examples work just fine with PyPy, where they run around seven times faster
    than in CPython. Sometimes the better solution will be to investigate other runtimes
    rather than to go down rabbit holes with CPython.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例在 PyPy 中运行得非常好，比在 CPython 中快大约七倍。有时候，更好的解决方案是调查其他运行时，而不是在 CPython 的兔子洞里跳来跳去。
- en: Sharing numpy Data with multiprocessing
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多处理共享 numpy 数据
- en: When working with large `numpy` arrays, you’re bound to wonder if you can share
    the data for read and write access, without a copy, between processes. It is possible,
    though a little fiddly. We’d like to acknowledge Stack Overflow user *pv* for
    the inspiration for this demo.^([2](ch09_split_001.xhtml#idm46122406714360))
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理大型 `numpy` 数组时，你可能会想知道是否可以在进程之间共享数据以进行读写访问，而无需复制。虽然有点棘手，但是这是可能的。我们要感谢 Stack
    Overflow 用户 *pv*，他的灵感激发了这个演示。^([2](ch09_split_001.xhtml#idm46122406714360))
- en: Warning
  id: totrans-376
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Do not use this method to re-create the behaviors of BLAS, MKL, Accelerate,
    and ATLAS. These libraries all have multithreading support in their primitives,
    and they likely are better-debugged than any new routine that you create. They
    can require some configuration to enable multithreading support, but it would
    be wise to see if these libraries can give you free speedups before you invest
    time (and lose time to debugging!) writing your own.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 不要使用此方法来重新创建 BLAS、MKL、Accelerate 和 ATLAS 的行为。这些库在它们的基本操作中都支持多线程，并且它们可能比你创建的任何新例程更经过充分调试。它们可能需要一些配置来启用多线程支持，但在你投入时间（和在调试中浪费的时间！）编写自己的代码之前，最好看看这些库是否可以为你提供免费的加速。
- en: 'Sharing a large matrix between processes has several benefits:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在进程之间共享大型矩阵有几个好处：
- en: Only one copy means no wasted RAM.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有一个副本意味着没有浪费的 RAM。
- en: No time is wasted copying large blocks of RAM.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有浪费时间复制大块 RAM。
- en: You gain the possibility of sharing partial results between the processes.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在进程之间共享部分结果。
- en: Thinking back to the pi estimation demo using `numpy` in [“Using numpy”](ch09_split_000.xhtml#multiprocessing-estimating-pi-using-numpy),
    we had the problem that the random number generation was a serial process. Here,
    we can imagine forking processes that share one large array, each one using a
    differently seeded random number generator to fill in a section of the array with
    random numbers, and therefore completing the generation of a large random block
    faster than is possible with a single process.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 回想起在[“使用 numpy”](ch09_split_000.xhtml#multiprocessing-estimating-pi-using-numpy)中使用
    `numpy` 估算 pi 的演示，我们遇到的问题是随机数生成是一个串行进程。在这里，我们可以想象分叉进程，它们共享一个大数组，每个进程使用不同的种子随机数生成器填充数组的一部分，从而比单进程更快地生成一个大的随机块。
- en: To verify this, we modified the forthcoming demo to create a large random matrix
    (10,000 × 320,000 elements) as a serial process and by splitting the matrix into
    four segments where `random` is called in parallel (in both cases, one row at
    a time). The serial process took 53 seconds, and the parallel version took 29
    seconds. Refer back to [“Random Numbers in Parallel Systems”](ch09_split_000.xhtml#multiprocessing-random-numbers)
    to understand some of the dangers of parallelized random number generation.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这一点，我们修改了即将展示的演示，创建了一个大型随机矩阵（10,000 × 320,000 元素）作为串行进程，并将矩阵分成四段，在并行调用 `random`（在这两种情况下，每次一行）。串行进程花费了
    53 秒，而并行版本只花了 29 秒。请参考[“并行系统中的随机数”](ch09_split_000.xhtml#multiprocessing-random-numbers)了解一些并行随机数生成的潜在风险。
- en: For the rest of this section, we’ll use a simplified demo that illustrates the
    point while remaining easy to verify.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我们将使用一个简化的演示来说明这一点，同时保持易于验证。
- en: In [Figure 9-18](ch09_split_001.xhtml#FIG-numpy-shared-multiprocessing-htop),
    you can see the output from `htop` on Ian’s laptop. It shows four child processes
    of the parent (with PID 27628), where all five processes are sharing a single
    10,000-by-320,000-element `numpy` array of doubles. One copy of this array costs
    25.6 GB, and the laptop has only 32 GB—you can see in `htop` by the process meters
    that the `Mem` reading shows a maximum of 31.1 GB RAM.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 9-18](ch09_split_001.xhtml#FIG-numpy-shared-multiprocessing-htop) 中，您可以看到
    Ian 笔记本电脑上 `htop` 的输出。显示父进程（PID 27628）的四个子进程，这五个进程共享一个 10,000 × 320,000 元素的 `numpy`
    双精度数组。这个数组的一个副本占用了 25.6 GB，而笔记本只有 32 GB 内存 —— 您可以在 `htop` 中看到，进程仪表显示 `Mem` 读数最大为
    31.1 GB RAM。
- en: '![notset](Images/hpp2_0918.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![notset](Images/hpp2_0918.png)'
- en: Figure 9-18\. `htop` showing RAM and swap usage
  id: totrans-387
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-18\. `htop` 显示 RAM 和交换使用情况
- en: 'To understand this demo, we’ll first walk through the console output, and then
    we’ll look at the code. In [Example 9-27](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-setup),
    we start the parent process: it allocates a 25.6 GB double array of dimensions
    10,000 × 320,000, filled with the value zero. The 10,000 rows will be passed out
    as indices to the worker function, and the worker will operate on each column
    of 320,000 items in turn. Having allocated the array, we fill it with the answer
    to life, the universe, and everything (`42`!). We can test in the worker function
    that we’re receiving this modified array and not a filled-with-0s version to confirm
    that this code is behaving as expected.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这个演示，我们首先会浏览控制台输出，然后查看代码。在 [示例 9-27](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-setup)
    中，我们启动父进程：它分配了一个大小为 25.6 GB 的双精度数组，尺寸为 10,000 × 320,000，用值零填充。这 10,000 行将作为索引传递给工作函数，工作函数将依次操作每个
    320,000 项的列。分配完数组后，我们将它填充为生命、宇宙和一切的答案 (`42`！)。我们可以在工作函数中测试，我们收到的是修改后的数组，而不是填充为
    0 的版本，以确认此代码的行为是否符合预期。
- en: Example 9-27\. Setting up the shared array
  id: totrans-389
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-27\. 设置共享数组
- en: '[PRE26]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In [Example 9-28](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-worker-fn),
    we’ve started four processes working on this shared array. No copy of the array
    was made; each process is looking at the same large block of memory, and each
    process has a different set of indices to work from. Every few thousand lines,
    the worker outputs the current index and its PID, so we can observe its behavior.
    The worker’s job is trivial—it will check that the current element is still set
    to the default (so we know that no other process has modified it already), and
    then it will overwrite this value with the current PID. Once the workers have
    completed, we return to the parent process and print the array again. This time,
    we see that it is filled with PIDs rather than `42`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 9-28](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-worker-fn)
    中，我们启动了四个进程来处理这个共享数组。没有复制数组；每个进程都在查看相同的大内存块，并且每个进程有一组不同的索引来操作。每隔几千行，工作进程输出当前索引和其
    PID，以便我们观察其行为。工作进程的工作是微不足道的 —— 它将检查当前元素是否仍设置为默认值（这样我们就知道没有其他进程已经修改它），然后将该值覆盖为当前
    PID。一旦工作进程完成，我们返回到父进程并再次打印数组。这次，我们看到它填满了 PID，而不是 `42`。
- en: Example 9-28\. Running `worker_fn` on the shared array
  id: totrans-392
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-28\. 在共享数组上运行 `worker_fn`
- en: '[PRE27]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Finally, in [Example 9-29](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-verify)
    we use a `Counter` to confirm the frequency of each PID in the array. As the work
    was evenly divided, we expect to see each of the four PIDs represented an equal
    number of times. In our 3,200,000,000-element array, we see four sets of 800,000,000
    PIDs. The table output is presented using [PrettyTable](https://oreil.ly/tXL3a).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 [示例 9-29](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-verify)
    中，我们使用 `Counter` 来确认数组中每个 PID 的频率。由于工作被均匀分配，我们期望看到四个 PID 各自表示相等次数。在我们的 32 亿元素数组中，我们看到四组
    8 亿次 PID。表格输出使用 [PrettyTable](https://oreil.ly/tXL3a) 呈现。
- en: Example 9-29\. Verifying the result on the shared array
  id: totrans-395
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-29\. 验证共享数组的结果
- en: '[PRE28]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Having completed, the program now exits, and the array is deleted.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，程序退出，数组被删除。
- en: 'We can take a peek inside each process under Linux by using `ps` and `pmap`.
    [Example 9-30](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-pmap)
    shows the result of calling `ps`. Breaking apart this command line:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 `ps` 和 `pmap` 在 Linux 下查看每个进程的详细信息。[示例 9-30](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-pmap)
    显示了调用 `ps` 的结果。分解这个命令行：
- en: '`ps` tells us about the process.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ps` 告诉我们关于进程的信息。'
- en: '`-A` lists all processes.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-A` 列出所有进程。'
- en: '`-o pid,size,vsize,cmd` outputs the PID, size information, and the command
    name.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-o pid,size,vsize,cmd` 输出PID、大小信息和命令名称。'
- en: '`grep` is used to filter all other results and leave only the lines for our
    demo.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grep`用于过滤所有其他结果，仅保留演示的行。'
- en: The parent process (PID 27628) and its four forked children are shown in the
    output. The result is similar to what we saw in `htop`. We can use `pmap` to look
    at the memory map of each process, requesting extended output with `-x`. We `grep`
    for the pattern `s-` to list blocks of memory that are marked as being shared.
    In the parent process and the child processes, we see a 25,000,000 KB (25.6 GB)
    block that is shared between them.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 父进程（PID 27628）及其四个分叉子进程显示在输出中。结果类似于我们在`htop`中看到的。我们可以使用`pmap`查看每个进程的内存映射，并使用`-x`请求扩展输出。我们使用`grep`筛选标记为共享的内存块的模式`s-`。在父进程和子进程中，我们看到一个共享的
    25,000,000 KB（25.6 GB）块。
- en: Example 9-30\. Using `pmap` and `ps` to investigate the operating system’s view
    of the processes
  id: totrans-404
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-30。使用 `pmap` 和 `ps` 来调查操作系统对进程的视图
- en: '[PRE29]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We’ll use a `multprocessing.Array` to allocate a shared block of memory as a
    1D array and then instantiate a `numpy` array from this object and reshape it
    to a 2D array. Now we have a `numpy`-wrapped block of memory that can be shared
    between processes and addressed as though it were a normal `numpy` array. `numpy`
    is not managing the RAM; `multiprocessing.Array` is managing it.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `multiprocessing.Array` 来分配一个共享的内存块作为一个 1D 数组，然后从这个对象实例化一个 `numpy` 数组并将其重塑为一个
    2D 数组。现在我们有一个可以在进程之间共享并像普通 `numpy` 数组一样访问的 `numpy` 包装的内存块。`numpy` 不管理 RAM；`multiprocessing.Array`
    在管理它。
- en: In [Example 9-31](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-worker-fn),
    you can see that each forked process has access to a global `main_nparray`. While
    the forked process has a copy of the `numpy` object, the underlying bytes that
    the object accesses are stored as shared memory. Our `worker_fn` will overwrite
    a chosen row (via `idx`) with the current process identifier.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 9-31](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-worker-fn)
    中，您可以看到每个分叉进程都可以访问全局的`main_nparray`。虽然分叉的进程拥有`numpy`对象的副本，但对象访问的底层字节存储为共享内存。我们的`worker_fn`将使用当前进程标识符覆盖选择的行（通过`idx`）。
- en: Example 9-31\. `worker_fn` for sharing `numpy` arrays using `multiprocessing`
  id: totrans-408
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-31。使用 `multiprocessing` 共享 `numpy` 数组的 `worker_fn`
- en: '[PRE30]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In our `__main__` in [Example 9-32](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1),
    we’ll work through three major stages:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `__main__` 中 [示例 9-32](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1)，我们将通过三个主要阶段来进行工作：
- en: Build a shared `multiprocessing.Array` and convert it into a `numpy` array.
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个共享的 `multiprocessing.Array` 并将其转换为一个 `numpy` 数组。
- en: Set a default value into the array, and spawn four processes to work on the
    array in parallel.
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将默认值设置到数组中，并生成四个进程以并行处理数组。
- en: Verify the array’s contents after the processes return.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进程返回后验证数组的内容。
- en: Typically, you’d set up a `numpy` array and work on it in a single process,
    probably doing something like `arr = np.array((100, 5), dtype=np.float_)`. This
    is fine in a single process, but you can’t share this data across processes for
    both reading and writing.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您会设置一个`numpy`数组并在单个进程中处理它，可能会执行类似于`arr = np.array((100, 5), dtype=np.float_)`的操作。在单个进程中这样做没问题，但是您无法将这些数据跨进程进行读写共享。
- en: The trick is to make a shared block of bytes. One way is to create a `multiprocessing.Array`.
    By default the `Array` is wrapped in a lock to prevent concurrent edits, but we
    don’t need this lock as we’ll be careful about our access patterns. To communicate
    this clearly to other team members, it is worth being explicit and setting `lock=False`.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 制作共享字节块的技巧之一是创建`multiprocessing.Array`。默认情况下，`Array` 被包装在一个锁中以防止并发编辑，但我们不需要这个锁，因为我们将小心处理我们的访问模式。为了清楚地向其他团队成员传达这一点，明确设置`lock=False`是值得的。
- en: If you don’t set `lock=False`, you’ll have an object rather than a reference
    to the bytes, and you’ll need to call `.get_obj()` to get to the bytes. By calling
    `.get_obj()`, you bypass the lock, so there’s no value in not being explicit about
    this in the first place.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不设置 `lock=False`，您将得到一个对象而不是字节的引用，您需要调用 `.get_obj()` 来获取字节。通过调用 `.get_obj()`，您绕过了锁，因此在一开始明确这一点是非常重要的。
- en: Next, we take this block of shareable bytes and wrap a `numpy` array around
    them using `frombuffer`. The `dtype` is optional, but since we’re passing bytes
    around, it is always sensible to be explicit. We `reshape` so we can address the
    bytes as a 2D array. By default the array values are set to `0`. [Example 9-32](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1)
    shows our `__main__` in full.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将这一块可共享的字节块使用 `frombuffer` 包装成一个 `numpy` 数组。`dtype` 是可选的，但由于我们传递的是字节，显式指定类型总是明智的。我们使用
    `reshape` 来将字节地址化为二维数组。默认情况下，数组的值被设置为 `0`。[示例 9-32](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1)
    显示了我们的 `__main__` 完整内容。
- en: Example 9-32\. `__main__` to set up `numpy` arrays for sharing
  id: totrans-418
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-32\. `__main__` 用于设置 `numpy` 数组以供共享
- en: '[PRE31]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: To confirm that our processes are operating on the same block of data that we
    started with, we set each item to a new `DEFAULT_VALUE` (we again use `42`, the
    answer to life, the universe, and everything)—you’ll see that at the top of [Example 9-33](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main2).
    Next, we build a `Pool` of processes (four in this case) and then send batches
    of row indices via the call to `map`.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认我们的进程是否在我们开始时的同一块数据上运行，我们将每个项目设置为一个新的 `DEFAULT_VALUE`（我们再次使用 `42`，生命、宇宙和一切的答案）。您可以在
    [示例 9-33](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main2)
    的顶部看到。接下来，我们构建了一个进程池（这里是四个进程），然后通过调用 `map` 发送批次的行索引。
- en: Example 9-33\. `__main__` for sharing `numpy` arrays using `multiprocessing`
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-33\. 使用 `multiprocessing` 共享 `numpy` 数组的 `__main__`
- en: '[PRE32]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Once we’ve completed the parallel processing, we return to the parent process
    to verify the result ([Example 9-34](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main3)).
    The verification step runs through a flattened view on the array (note that the
    view does *not* make a copy; it just creates a 1D iterable view on the 2D array),
    counting the frequency of each PID. Finally, we perform some `assert` checks to
    make sure we have the expected counts.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 当并行处理完成后，我们返回到父进程验证结果（[示例 9-34](ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main3)）。验证步骤通过数组的展平视图来执行（请注意，视图*不会*进行复制；它只是在二维数组上创建一个一维可迭代视图），计算每个进程
    ID 的频率。最后，我们执行一些 `assert` 检查以确保得到预期的计数。
- en: Example 9-34\. `__main__` to verify the shared result
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-34\. 用于验证共享结果的 `__main__`
- en: '[PRE33]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We’ve just created a 1D array of bytes, converted it into a 2D array, shared
    the array among four processes, and allowed them to process concurrently on the
    same block of memory. This recipe will help you parallelize over many cores. Be
    careful with concurrent access to the *same* data points, though—you’ll have to
    use the locks in `multiprocessing` if you want to avoid synchronization problems,
    and this will slow down your code.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 刚刚我们创建了一个字节的一维数组，将其转换为二维数组，共享该数组给四个进程，并允许它们同时处理同一块内存区域。这个技巧将帮助您在许多核心上实现并行化。不过要注意并发访问*相同*的数据点——如果想避免同步问题，就必须使用
    `multiprocessing` 中的锁，但这会减慢您的代码执行速度。
- en: Synchronizing File and Variable Access
  id: totrans-427
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同步文件和变量访问
- en: In the following examples, we’ll look at multiple processes sharing and manipulating
    a state—in this case, four processes incrementing a shared counter a set number
    of times. Without a synchronization process, the counting is incorrect. If you’re
    sharing data in a coherent way you’ll always need a method to synchronize the
    reading and writing of data, or you’ll end up with errors.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，我们将看到多个进程共享和操作状态——在这种情况下，四个进程递增一个共享计数器一定次数。如果没有同步过程，计数将不正确。如果您要以一致的方式共享数据，您总是需要一种同步读写数据的方法，否则会出现错误。
- en: Typically, the synchronization methods are specific to the OS you’re using,
    and they’re often specific to the language you use. Here, we look at file-based
    synchronization using a Python library and sharing an integer object between Python
    processes.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，同步方法特定于您使用的操作系统，并且通常特定于您使用的语言。在这里，我们使用 Python 库来进行基于文件的同步，并在 Python 进程之间共享整数对象。
- en: File Locking
  id: totrans-430
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件锁定
- en: Reading and writing to a file will be the slowest example of data sharing in
    this section.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，文件读写将是数据共享中最慢的例子。
- en: You can see our first `work` function in [Example 9-35](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-work).
    The function iterates over a local counter. In each iteration it opens a file
    and reads the existing value, increments it by one, and then writes the new value
    over the old one. On the first iteration the file will be empty or won’t exist,
    so it will catch an exception and assume the value should be zero.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [示例 9-35](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-work)
    中看到我们的第一个 `work` 函数。该函数迭代一个本地计数器。在每次迭代中，它打开一个文件并读取现有值，将其增加一，然后将新值写入旧值所在的位置。在第一次迭代中，文件将为空或不存在，因此它将捕获异常并假定该值应为零。
- en: Tip
  id: totrans-433
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The examples given here are simplified—in practice it is safer to use a context
    manager to open a file using `with open(*filename*, "r") as f:`. If an exception
    is raised inside the context, the file `f` will correctly be closed.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这里给出的示例是简化的—在实践中，更安全的做法是使用上下文管理器打开文件，例如 `with open(*filename*, "r") as f:`。如果上下文中引发异常，文件
    `f` 将被正确关闭。
- en: Example 9-35\. `work` function without a lock
  id: totrans-435
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-35\. 没有锁定的 `work` 函数
- en: '[PRE34]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Let’s run this example with one process. You can see the output in [Example 9-36](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console1).
    `work` is called one thousand times, and as expected it counts correctly without
    losing any data. On the first read, it sees an empty file. This raises the `invalid
    literal for int()` error for `int()` (as `int()` is called on an empty string).
    This error occurs only once; afterward, we always have a valid value to read and
    convert into an integer.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个进程运行这个示例。您可以在 [示例 9-36](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console1)
    中看到输出。`work` 被调用一千次，预期的是它能正确计数而不丢失任何数据。在第一次读取时，它看到一个空文件。这导致了 `int()` 的 `invalid
    literal for int()` 错误（因为在空字符串上调用了 `int()`）。这个错误只会发生一次；之后我们总是有一个有效的值来读取并转换为整数。
- en: Example 9-36\. Timing of file-based counting without a lock and with one process
  id: totrans-438
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-36\. 在没有锁定并且使用一个进程的文件计数的时间安排
- en: '[PRE35]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now we’ll run the same `work` function with four concurrent processes. We don’t
    have any locking code, so we’ll expect some odd results.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用四个并发进程运行相同的 `work` 函数。我们没有任何锁定代码，因此我们预计会得到一些奇怪的结果。
- en: Tip
  id: totrans-441
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Before you look at the following code, what *two* types of error can you expect
    to see when two processes simultaneously read from or write to the same file?
    Think about the two main states of the code (the start of execution for each process
    and the normal running state of each process).
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在您查看以下代码之前，请思考当两个进程同时从同一文件读取或写入时，您可以期望看到什么 *两种* 类型的错误？考虑代码的两个主要状态（每个进程的执行开始和每个进程的正常运行状态）。
- en: Take a look at [Example 9-37](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console2)
    to see the problems. First, when each process starts, the file is empty, so each
    tries to start counting from zero. Second, as one process writes, the other can
    read a partially written result that can’t be parsed. This causes an exception,
    and a zero will be written back. This, in turn, causes our counter to keep getting
    reset! Can you see how `\n` and two values have been written by two concurrent
    processes to the same open file, causing an invalid entry to be read by a third
    process?
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下 [示例 9-37](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console2)
    以查看问题。首先，当每个进程启动时，文件为空，因此每个进程都试图从零开始计数。其次，当一个进程写入时，另一个进程可以读取部分写入的结果，无法解析。这会导致异常，并且将回写一个零。这反过来导致我们的计数器不断被重置！您能看到两个并发进程写入了
    `\n` 和两个值到同一个打开的文件，导致第三个进程读取到一个无效的条目吗？
- en: Example 9-37\. Timing of file-based counting without a lock and with four processes
  id: totrans-444
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-37\. 在没有锁定并且使用四个进程的文件计数的时间安排
- en: '[PRE36]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[Example 9-38](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-main)
    shows the `multiprocessing` code that calls `work` with four processes. Note that
    rather than using a `map`, we’re building a list of `Process` objects. Although
    we don’t use the functionality here, the `Process` object gives us the power to
    introspect the state of each `Process`. We encourage you to [read the documentation](https://oreil.ly/B4_G7)
    to learn about why you might want to use a `Process`.'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 9-38](ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-main)
    展示了调用带有四个进程的 `work` 的 `multiprocessing` 代码。请注意，我们不是使用 `map`，而是在建立 `Process` 对象的列表。虽然在此处我们没有使用这个功能，但
    `Process` 对象使我们能够审视每个 `Process` 的状态。我们鼓励您 [阅读文档](https://oreil.ly/B4_G7) 了解为什么您可能希望使用
    `Process`。'
- en: Example 9-38\. `run_workers` setting up four processes
  id: totrans-447
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-38\. `run_workers` 设置四个进程
- en: '[PRE37]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Using the [`fasteners` module](https://oreil.ly/n8ZlV), we can introduce a synchronization
    method so only one process gets to write at a time and the others each await their
    turn. The overall process therefore runs more slowly, but it doesn’t make mistakes.
    You can see the correct output in [Example 9-39](ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1-console).
    Be aware that the locking mechanism is specific to Python, so other processes
    that are looking at this file will *not* care about the “locked” nature of this
    file.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[`fasteners`模块](https://oreil.ly/n8ZlV)，我们可以引入一种同步方法，这样一次只有一个进程可以写入，其他进程则各自等待它们的轮次。因此整个过程运行速度较慢，但不会出错。您可以在[示例 9-39](ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1-console)中看到正确的输出。请注意，锁定机制特定于Python，因此查看此文件的其他进程将*不会*关心此文件的“锁定”性质。
- en: Example 9-39\. Timing of file-based counting with a lock and four processes
  id: totrans-450
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-39\. 带锁和四个进程的文件计数时间
- en: '[PRE38]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Using `fasteners` adds a single line of code in [Example 9-40](ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1)
    with the `@fasteners.interprocess_locked` decorator; the filename can be anything,
    but using a similar name as the file you want to lock probably makes debugging
    from the command line easier. Note that we haven’t had to change the inner function;
    the decorator gets the lock on each call, and it will wait until it can get the
    lock before the call into `work` proceeds.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`fasteners`在[示例 9-40](ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1)中加入了一行代码，使用`@fasteners.interprocess_locked`装饰器；文件名可以是任何东西，但最好与您想要锁定的文件名称相似，这样在命令行中进行调试会更容易。请注意，我们没有必要更改内部函数；装饰器在每次调用时获取锁，并且在进入`work`之前会等待能够获取锁。
- en: Example 9-40\. `work` function with a lock
  id: totrans-453
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-40\. 带锁的`work`函数
- en: '[PRE39]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Locking a Value
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 锁定一个值
- en: The `multiprocessing` module offers several options for sharing Python objects
    between processes. We can share primitive objects with a low communication overhead,
    and we can also share higher-level Python objects (e.g., dictionaries and lists)
    using a `Manager` (but note that the synchronization cost will significantly slow
    down the data sharing).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing`模块为在进程之间共享Python对象提供了几种选项。我们可以使用低通信开销共享原始对象，还可以使用`Manager`共享更高级的Python对象（例如字典和列表），但请注意同步成本会显著减慢数据共享的速度。'
- en: Here, we’ll use a [`multiprocessing.Value` object](https://oreil.ly/nGKnY) to
    share an integer between processes. While a `Value` has a lock, the lock doesn’t
    do quite what you might expect—it prevents simultaneous reads or writes but does
    *not* provide an atomic increment. [Example 9-41](ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1-console)
    illustrates this. You can see that we end up with an incorrect count; this is
    similar to the file-based unsynchronized example we looked at earlier.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用一个[`multiprocessing.Value`对象](https://oreil.ly/nGKnY)来在进程之间共享整数。虽然`Value`有一个锁，但锁并不完全符合您的期望——它防止同时读取或写入，但*不*提供原子增量。[示例 9-41](ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1-console)说明了这一点。您可以看到我们最终得到了一个不正确的计数；这与我们之前查看的基于文件的未同步示例类似。
- en: Example 9-41\. No locking leads to an incorrect count
  id: totrans-458
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-41\. 无锁导致计数不正确
- en: '[PRE40]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: No corruption occurs to the data, but we do miss some of the updates. This approach
    might be suitable if you’re writing to a `Value` from one process and consuming
    (but not modifying) that `Value` in other processes.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 数据未损坏，但我们错过了一些更新。如果您从一个进程向`Value`写入并在其他进程中消耗（但不修改）该`Value`，这种方法可能适合。
- en: The code to share the `Value` is shown in [Example 9-42](ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1).
    We have to specify a datatype and an initialization value—using `Value("i", 0)`,
    we request a signed integer with a default value of `0`. This is passed as a regular
    argument to our `Process` object, which takes care of sharing the same block of
    bytes between processes behind the scenes. To access the primitive object held
    by our `Value`, we use `.value`. Note that we’re asking for an in-place addition—we’d
    expect this to be an atomic operation, but that’s not supported by `Value`, so
    our final count is lower than expected.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 共享`Value`的代码显示在[示例 9-42](ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1)中。我们必须指定数据类型和初始化值——使用`Value("i",
    0)`，我们请求一个带有默认值`0`的有符号整数。这作为常规参数传递给我们的`Process`对象，后者在幕后负责在进程之间共享同一块字节。要访问`Value`持有的原始对象，我们使用`.value`。请注意，我们要求原地添加——我们期望这是一个原子操作，但`Value`不支持这一点，因此我们的最终计数低于预期。
- en: Example 9-42\. The counting code without a `Lock`
  id: totrans-462
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-42\. 没有`Lock`的计数代码
- en: '[PRE41]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: You can see the correctly synchronized count in [Example 9-43](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-console)
    using a `multiprocessing.Lock`.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[示例 9-43](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-console)中看到使用`multiprocessing.Lock`的正确同步计数。
- en: Example 9-43\. Using a `Lock` to synchronize writes to a `Value`
  id: totrans-465
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-43\. 使用`Lock`同步对`Value`的写入
- en: '[PRE42]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In [Example 9-44](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1),
    we’ve used a context manager (`with Lock`) to acquire the lock.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 9-44](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1)中，我们使用了上下文管理器(`with
    Lock`)来获取锁定。
- en: Example 9-44\. Acquiring a `Lock` using a context manager
  id: totrans-468
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-44\. 使用上下文管理器获取`Lock`
- en: '[PRE43]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: If we avoid the context manager and directly wrap our increment with `acquire`
    and `release`, we can go a little faster, but the code is less readable compared
    to using the context manager. We suggest sticking to the context manager to improve
    readability. The snippet in [Example 9-45](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-inline-lock)
    shows how to `acquire` and `release` the `Lock` object.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们避免使用上下文管理器，直接用`acquire`和`release`包装我们的增量，我们可以稍微快一点，但与使用上下文管理器相比，代码可读性较差。我们建议坚持使用上下文管理器以提高可读性。[示例
    9-45](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-inline-lock)中的片段显示了如何`acquire`和`release`
    `Lock`对象。
- en: Example 9-45\. Inline locking rather than using a context manager
  id: totrans-471
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-45\. 内联锁定而不使用上下文管理器
- en: '[PRE44]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Since a `Lock` doesn’t give us the level of granularity that we’re after, the
    basic locking that it provides wastes a bit of time unnecessarily. We can replace
    the `Value` with a [`RawValue`](https://oreil.ly/MYjtB), as in [Example 9-46](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1-console),
    and achieve an incremental speedup. If you’re interested in seeing the bytecode
    behind this change, read [Eli Bendersky’s blog post](http://bit.ly/shared_counter)
    on the subject.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Lock`无法提供我们所需的粒度级别，它提供的基本锁定会不必要地浪费一些时间。我们可以将`Value`替换为[`RawValue`](https://oreil.ly/MYjtB)，如[示例
    9-46](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1-console)中所示，并实现渐进式加速。如果你对查看这种更改背后的字节码感兴趣，请阅读[Eli
    Bendersky的博客文章](http://bit.ly/shared_counter)。
- en: Example 9-46\. Console output showing the faster `RawValue` and `Lock` approach
  id: totrans-474
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-46\. 显示更快`RawValue`和`Lock`方法的控制台输出
- en: '[PRE45]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: To use a `RawValue`, just swap it for a `Value`, as shown in [Example 9-47](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1).
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`RawValue`，只需将其替换为`Value`，如[示例 9-47](ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1)所示。
- en: Example 9-47\. Example of using a <code>RawValue</code> integer
  id: totrans-477
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 9-47\. 使用`RawValue`整数的示例
- en: '[PRE46]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We could also use a `RawArray` in place of a `multiprocessing.Array` if we were
    sharing an array of primitive objects.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们共享的是原始对象数组，则可以使用`RawArray`代替`multiprocessing.Array`。
- en: We’ve looked at various ways of dividing up work on a single machine between
    multiple processes, along with sharing a flag and synchronizing data sharing between
    these processes. Remember, though, that sharing data can lead to headaches—try
    to avoid it if possible. Making a machine deal with all the edge cases of state
    sharing is hard; the first time you have to debug the interactions of multiple
    processes, you’ll realize why the accepted wisdom is to avoid this situation if
    possible.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过了在单台机器上将工作分配给多个进程的各种方式，以及在这些进程之间共享标志和同步数据共享的方法。但请记住，数据共享可能会带来麻烦—尽量避免。让一台机器处理所有状态共享的边缘情况是困难的；当你第一次必须调试多个进程的交互时，你会意识到为什么公认的智慧是尽可能避免这种情况。
- en: Do consider writing code that runs a bit slower but is more likely to be understood
    by your team. Using an external tool like Redis to share state leads to a system
    that can be inspected at runtime by people *other* than the developers—this is
    a powerful way to enable your team to keep on top of what’s happening in your
    parallel systems.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑编写运行速度稍慢但更容易被团队理解的代码。使用像 Redis 这样的外部工具来共享状态，可以使系统在运行时由**开发人员之外的其他人**检查—这是一种强大的方式，可以使你的团队了解并掌控并行系统的运行情况。
- en: Definitely bear in mind that tweaked performant Python code is less likely to
    be understood by more junior members of your team—they’ll either be scared of
    it or break it. Avoid this problem (and accept a sacrifice in speed) to keep team
    velocity high.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 一定要记住，经过调整的高性能Python代码不太可能被团队中较新手的成员理解—他们要么会对此感到恐惧，要么会破坏它。为了保持团队的速度，避免这个问题（并接受速度上的牺牲）。
- en: Wrap-Up
  id: totrans-483
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We’ve covered a lot in this chapter. First, we looked at two embarrassingly
    parallel problems, one with predictable complexity and the other with nonpredictable
    complexity. We’ll use these examples again on multiple machines when we discuss
    clustering in [Chapter 10](ch10.xhtml#clustering).
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了很多内容。首先，我们看了两个尴尬的并行问题，一个具有可预测的复杂性，另一个具有不可预测的复杂性。当我们讨论聚类时，我们将在多台机器上再次使用这些示例。
- en: Next, we looked at `Queue` support in `multiprocessing` and its overheads. In
    general, we recommend using an external queue library so that the state of the
    queue is more transparent. Preferably, you should use an easy-to-read job format
    so that it is easy to debug, rather than pickled data.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看了看`multiprocessing`中的`Queue`支持及其开销。总的来说，我们建议使用外部队列库，以便队列的状态更透明。最好使用易于阅读的作业格式，以便易于调试，而不是使用
    pickled 数据。
- en: The IPC discussion should have impressed upon you how difficult it is to use
    IPC efficiently, and that it can make sense just to use a naive parallel solution
    (without IPC). Buying a faster computer with more cores might be a far more pragmatic
    solution than trying to use IPC to exploit an existing machine.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: IPC 讨论应该让您了解到使用 IPC 有效地有多困难，以及仅仅使用天真的并行解决方案（没有 IPC）可能是有道理的。购买一台更快的具有更多核心的计算机可能比尝试使用
    IPC 来利用现有机器更为务实。
- en: Sharing `numpy` matrices in parallel without making copies is important for
    only a small set of problems, but when it counts, it’ll really count. It takes
    a few extra lines of code and requires some sanity checking to make sure that
    you’re really not copying the data between processes.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行情况下共享`numpy`矩阵而不复制对于只有少数一些问题非常重要，但在关键时刻，它将真正重要。这需要写入一些额外的代码，并需要一些合理性检查，以确保在进程之间确实没有复制数据。
- en: Finally, we looked at using file and memory locks to avoid corrupting data—this
    is a source of subtle and hard-to-track errors, and this section showed you some
    robust and lightweight solutions.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讨论了使用文件和内存锁来避免数据损坏的问题——这是一个难以察觉和难以追踪错误的来源，本节向您展示了一些强大且轻量级的解决方案。
- en: In the next chapter we’ll look at clustering using Python. With a cluster, we
    can move beyond single-machine parallelism and utilize the CPUs on a group of
    machines. This introduces a new world of debugging pain—not only can your code
    have errors, but the other machines can also have errors (either from bad configuration
    or from failing hardware). We’ll show how to parallelize the pi estimation demo
    using the Parallel Python module and how to run research code inside IPython using
    an IPython cluster.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论使用 Python 进行聚类。通过使用集群，我们可以摆脱单机并行性，并利用一组机器上的 CPU。这引入了一种新的调试痛苦的世界——不仅您的代码可能存在错误，而且其他机器也可能存在错误（无论是由于错误的配置还是由于硬件故障）。我们将展示如何使用
    Parallel Python 模块并如何在 IPython 中运行研究代码，以在 IPython 集群中并行化 pi 估算演示。
- en: ^([1](ch09_split_000.xhtml#idm46122410678856-marker)) See [Brett Foster’s PowerPoint
    presentation](https://oreil.ly/DdIuv) on using the Monte Carlo method to estimate
    pi.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09_split_000.xhtml#idm46122410678856-marker)) 参见[Brett Foster的 PowerPoint
    演示](https://oreil.ly/DdIuv)，讲解如何使用蒙特卡洛方法估算 pi。
- en: ^([2](ch09_split_001.xhtml#idm46122406714360-marker)) See the [Stack Overflow
    topic](http://bit.ly/Python_multiprocessing).
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch09_split_001.xhtml#idm46122406714360-marker)) 请参阅 [Stack Overflow 主题](http://bit.ly/Python_multiprocessing)。
