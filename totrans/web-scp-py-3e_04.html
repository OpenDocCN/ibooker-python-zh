<html><head></head><body><section data-pdf-bookmark="Chapter 3. Applications of Web Scraping" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-3">&#13;
<h1><span class="label">Chapter 3. </span>Applications of Web Scraping</h1>&#13;
&#13;
<p>While web scrapers can help almost any business, often the real trick is figuring out <em>how</em>. Like artificial intelligence, or really, programming in general, you can’t just wave a magic wand and expect it to improve your bottom line.</p>&#13;
&#13;
<p>Applying the practice of web scraping to your business takes real strategy and careful planning in order to use it effectively. You need to identify specific problems, figure out what data you need to fix those problems, and then outline the inputs, outputs, and algorithms that will allow your web scrapers to create that data.</p>&#13;
&#13;
<section data-pdf-bookmark="Classifying Projects" data-type="sect1"><div class="sect1" id="id22">&#13;
<h1>Classifying Projects</h1>&#13;
&#13;
<p>When planning a web scraping project, you <a contenteditable="false" data-primary="projects, classifying" data-type="indexterm" id="prjcfy"/>should think about how it fits into one of several categories.</p>&#13;
&#13;
<p>Is your web scraper “broad” or “targeted”? You can write templates to instruct a targeted web scraper but need different techniques for a broad one:</p>&#13;
&#13;
<ul>&#13;
	<li>Will you be scraping a single website or perhaps even a fixed set of pages within that website? If so, this is an extremely targeted web scraping project. </li>&#13;
	<li>Do you need to scrape a fixed number of known websites? This is still a fairly targeted scraper, but you may need to write a small amount of custom code for each website and invest a little more time into the architecture of your web <span class="keep-together">scraper.</span> </li>&#13;
	<li>Are you scraping a large number of unknown websites and discovering new targets dynamically? Will you build a crawler that must automatically detect and make assumptions about the structure of the websites? You may be writing a broad or untargeted scraper. </li>&#13;
</ul>&#13;
&#13;
<p>Do you need to run the scraper just one time or will this be an ongoing job that re-fetches the data or is constantly on the lookout for new pages to scrape?</p>&#13;
&#13;
<ul>&#13;
	<li>A one-time web scraping project can be quick and cheap to write. The code doesn’t have to be pretty! The end result of this project is the data itself—you might hand off an Excel or CSV file to business, and they’re happy. The code goes in the trash when you’re done. </li>&#13;
	<li>Any project that involves monitoring, re-scanning for new data, or updating data, will require more robust code that is able to be maintained. It may also need its own monitoring infrastructure to detect when it encounters an error, fails to run, or uses more time or resources than expected. </li>&#13;
</ul>&#13;
&#13;
<p>Is the collected data your end product or is more in-depth analysis or manipulation required?</p>&#13;
&#13;
<ul>&#13;
	<li>In cases of simple data collection, the web scraper deposits data into the database exactly as it finds it, or perhaps with a few lines of simple cleaning (e.g., stripping dollar signs from product prices).</li>&#13;
	<li>When more advanced analysis is required, you may not even know what data will be important. Here too, you must put more thought into the architecture of your scraper. </li>&#13;
</ul>&#13;
&#13;
<p>I encourage you to consider which categories each of these projects might fall into, and how the scope of that project <a contenteditable="false" data-primary="projects, classifying" data-startref="prjcfy" data-type="indexterm" id="id337"/>might need to be modified to fit the needs of your business.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="E-commerce" data-type="sect1"><div class="sect1" id="id23">&#13;
<h1>E-commerce</h1>&#13;
&#13;
<p>Although I’ve written web scrapers <a contenteditable="false" data-primary="e-commerce" data-seealso="marketing applications" data-type="indexterm" id="ecmrec"/>that have collected all sorts of interesting data from the web, the most popular request I get is to collect product and pricing data from e-commerce sites.</p>&#13;
&#13;
<p>Generally, these requests come from people who own a competing e-commerce site or are doing research, planning to launch a new product or market. The first metric you might think of in e-commerce is “pricing.” You want to find out how your price compares with the competition. However, there’s a huge space of other possibilities and data you may want to collect.</p>&#13;
&#13;
<p>Many, but not all, products come in a variety of sizes, colors, and styles. These variations can be associated with different costs and availabilities. It may be helpful to keep track of every variation available for each product, as well as each major product listing. Note that for each variation you can likely find a unique SKU (stock-keeping unit) identification code, which is unique to a single product variation and <span class="keep-together">e-commerce</span> website (Target will have a different SKU than Walmart for each product variation, but the SKUs will remain the same if you go back and check later). Even if the SKU isn’t immediately visible on the website, you’ll likely find it hidden in the page’s HTML somewhere, or in a JavaScript API that populates the website’s product data.</p>&#13;
&#13;
<p>While scraping e-commerce sites, it might also be important to record how many units of the product are available. Like SKUs, units might not be immediately visible on the website. You may find this information hidden in the HTML or APIs that the website uses. Make sure to also track when products are out of stock! This can be useful for gauging market demand and perhaps even influencing the pricing of your own products if you have them in stock.</p>&#13;
&#13;
<p>When a product is on sale, you’ll generally find the sale price and original price clearly marked on the website. Make sure to record both prices separately. By tracking sales over time, you can analyze your competitor’s promotion and discount <span class="keep-together">strategies.</span></p>&#13;
&#13;
<p>Product reviews and ratings are another useful piece of information to capture. Of course, you cannot directly display the text of product reviews from competitors’ websites on your own site. However, analyzing the raw data from these reviews can be useful to see which products are popular or trending.</p>&#13;
&#13;
<section data-pdf-bookmark="Marketing" data-type="sect2"><div class="sect2" id="id24">&#13;
<h2>Marketing</h2>&#13;
&#13;
<p>Online brand management and marketing <a contenteditable="false" data-primary="marketing applications" data-type="indexterm" id="mktg"/>often involve the aggregation of large amounts of data. Rather than scrolling through social media or spending hours searching for a company’s name, you can let web scrapers do all the heavy lifting!</p>&#13;
&#13;
<p>Web scrapers can be used by malicious attackers to essentially “copy” a website with the aim of selling counterfeit goods or defrauding would-be customers. Fortunately, web scrapers can also assist in combating this by scanning search engine results for fraudulent or improper use of a company’s trademarks and other IP. Some companies, <a contenteditable="false" data-primary="MarqVision" data-type="indexterm" id="id338"/><a contenteditable="false" data-primary="trademark use" data-type="indexterm" id="id339"/>such as MarqVision, also sell these web scrapers as a service, allowing brands to outsource the process of scraping the web, detecting fraud, and issuing takedown notices.</p>&#13;
&#13;
<p>On the other hand, not all use of a brand’s trademarks is infringing. If your company is mentioned for the purpose of commentary or review, you’ll probably want to know about it! Web scrapers can aggregate and track public sentiment and perceptions about a company and its brand.</p>&#13;
&#13;
<p>While you’re tracking your brand across the web, don’t forget about your competitors! You might consider scraping the information of people who have reviewed competing products, or talk about competitors’ brands, in order to offer them discounts or introductory promotions.</p>&#13;
&#13;
<p>Of course, when it comes to marketing and the internet, the first thing that often comes to mind <a contenteditable="false" data-primary="social media" data-type="indexterm" id="id340"/>is “social media.” The benefit of scraping social media is that there are usually only a handful of large sites that allow you to write targeted scrapers. These sites contain millions of well-formatted posts with similar data and attributes (such as likes, shares, and comments) that easily can be compared across sites.</p>&#13;
&#13;
<p>The downside to social media is that there may be roadblocks to obtaining the data. Some sites, like Twitter, provide APIs, either available for free or for a fee. Other social media sites protect their data with both technology and lawyers. I recommend that you consult with your company’s legal representation before scraping websites like Facebook and LinkedIn, especially.</p>&#13;
&#13;
<p>Tracking metrics (likes, shares, and comments) of posts about topics relevant to your brand can help to identify trending topics or opportunities for engagement. Tracking popularity against attributes such as content length, inclusion of images/media, and language usage can also identify what tends to resonate best with your target <span class="keep-together">audience.</span></p>&#13;
&#13;
<p>If getting your product sponsored by someone with hundreds of millions of followers is outside of your company’s budget, you might consider “micro-influencers” or “nano-influencers”—users with smaller social media presences who may not even consider themselves to be influencers! Building a web scraper to find and target accounts that frequently <a contenteditable="false" data-primary="e-commerce" data-seealso="marketing applications" data-startref="ecmrec" data-type="indexterm" id="id341"/><a contenteditable="false" data-primary="marketing applications" data-startref="mktg" data-type="indexterm" id="id342"/>post about relevant topics to your brand would be helpful here.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Academic Research" data-type="sect1"><div class="sect1" id="id25">&#13;
<h1>Academic Research</h1>&#13;
&#13;
<p>While most of the examples in this chapter ultimately serve to grease the wheels of capitalism, web scrapers are <a contenteditable="false" data-primary="academic research applications" data-type="indexterm" id="acdcrs"/><a contenteditable="false" data-primary="research applications" data-type="indexterm" id="rserch"/>also used in the pursuit of knowledge. Web scrapers are commonly used in medical, sociological, and psychological research, among many other fields.</p>&#13;
&#13;
<p>For example, Rutgers University offers a course called “Computational Social Science” which teaches students web scraping to collect data for research projects. Some university courses, such as the University of Oslo’s “Collecting and Analyzing Big Data” even feature this book on the syllabus!</p>&#13;
&#13;
<p>In 2017, a project supported by the National Institutes of Health scraped the records of jail inmates in US prisons to estimate the number of inmates infected with HIV.<sup><a data-type="noteref" href="ch03.html#id343" id="id343-marker">1</a></sup> This project precipitated an extensive ethical analysis, weighing the benefits of this research with the risk to privacy of the inmate population. Ultimately, the research continued, but I recommend examining the ethics of your project before using web scraping for research, particularly in the medical field.</p>&#13;
&#13;
<p>Another health research study scraped hundreds of comments from news articles in <em>The Guardian</em> about obesity and analyzed the rhetoric of those comments.<sup><a data-type="noteref" href="ch03.html#id344" id="id344-marker">2</a></sup> Although smaller in scale than other research projects, it’s worth considering that web scrapers can be used for projects that require “small data” and qualitative analysis as well.</p>&#13;
&#13;
<p>Here’s another example of a niche research project that utilized web scraping. In 2016, a comprehensive study was done to scrape and perform qualitative analysis on marketing materials for every Canadian community college. <sup><a data-type="noteref" href="ch03.html#id345" id="id345-marker">3</a></sup> Researchers determined that modern facilities and “unconventional organizational symbols” are most popularly promoted.</p>&#13;
&#13;
<p>In economics research, the Bank of Japan published a paper<sup><a data-type="noteref" href="ch03.html#id346" id="id346-marker">4</a></sup> about their use of web scraping to obtain “alternative data.” That is, data outside of what banks normally use, such as GDP statistics and corporate financial reports. In this paper, they revealed that one source of alternative data is web scrapers, which <a contenteditable="false" data-primary="academic research applications" data-startref="acdcrs" data-type="indexterm" id="id347"/><a contenteditable="false" data-primary="research applications" data-startref="rserch" data-type="indexterm" id="id348"/>they use to adjust price <span class="keep-together">indices.</span></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Product Building" data-type="sect1"><div class="sect1" id="id26">&#13;
<h1>Product Building</h1>&#13;
&#13;
<p>Do you have a business idea and just <a contenteditable="false" data-primary="product building applications" data-type="indexterm" id="id349"/>need a database of relatively public, common-knowledge information to get it off the ground? Can’t seem to find a reasonably-priced and convenient source of this information just lying around? You may need a web scraper.</p>&#13;
&#13;
<p>Web scrapers can quickly provide data that will get you a minimum viable product for launch. Here are a few situations in which a web scraper may be the best solution:</p>&#13;
&#13;
<dl>&#13;
<dt>A travel site with a list of popular <a contenteditable="false" data-primary="travel sites" data-type="indexterm" id="id350"/>tourist destinations and activities</dt>&#13;
<dd>In this case, a database of simple geographic information won’t cut it. You want to know that people are going to view  Cristo Redentor, not simply visit Rio de Janeiro, Brazil. A directory of businesses won’t quite work either. While people might be very interested in the British Museum, the Sainsbury’s down the street doesn’t have the same appeal. However, there are many travel review sites that already contain information about popular tourist destinations.</dd>&#13;
<dt>A product review blog</dt> &#13;
<dd>Scrape a list of product names and <a contenteditable="false" data-primary="product review blogs" data-type="indexterm" id="id351"/>keywords or descriptions and use your favorite generative chat AI to fill in the rest.</dd>&#13;
</dl>&#13;
&#13;
<p>Speaking of artificial intelligence, those models require data—often, a lot of it! Whether you’re looking to predict trends or generate realistic natural language, web scraping is often the best way to get a training dataset for your product.</p>&#13;
&#13;
<p>Many business services products require having closely guarded industry knowledge that may be expensive or difficult to obtain, such as a list of industrial materials suppliers, contact information for experts in niche fields, or open employment positions by company. A web scraper can aggregate bits of this information found in various locations online, allowing you to build a comprehensive database with relatively little up-front cost.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Travel" data-type="sect1"><div class="sect1" id="id27">&#13;
<h1>Travel</h1>&#13;
&#13;
<p>Whether you’re looking to start a <a contenteditable="false" data-primary="travel applications" data-type="indexterm" id="trlv"/>travel-based business or are very enthusiastic about saving money on your next vacation, the travel industry deserves special recognition for the myriad of web scraping applications it provides.</p>&#13;
&#13;
<p>Hotels, airlines, and car rentals all have very little product differentiation and many competitors within their respective markets. This means that prices are generally very similar to each other, with frequent fluctuations over time as they respond to market conditions.</p>&#13;
&#13;
<p>While websites like Kayak and Trivago may now be large and powerful enough that they can pay for, or be provided with, APIs, all companies have to start somewhere. A web scraper can be a great way to start a new travel aggregation site that finds users the best deals from across the web.</p>&#13;
&#13;
<p>Even if you’re not looking to start a new business, have you flown on an airplane or anticipate doing so in the future? If you’re looking for ideas for testing the skills in this book, I highly recommend writing a travel site scraper as a good first project. The sheer volume of data and the chronological fluctuations in that data make for some interesting engineering challenges.</p>&#13;
&#13;
<p>Travel sites are also a good middle ground when it comes to anti-scraper defenses. They want to be crawled and indexed by search engines, and they want to make their data user-friendly and accessible to all. However, they’re in strong competition with other travel sites, which may require using some of the more advanced techniques later in this book. Paying attention to your browser headers and cookies is a good first step.</p>&#13;
&#13;
<p>If you do find yourself blocked by a particular travel site and aren’t sure how to access its content via Python, rest assured that there’s probably another travel site with the exact same <a contenteditable="false" data-primary="travel applications" data-startref="trlv" data-type="indexterm" id="id352"/>data that you can try.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Sales" data-type="sect1"><div class="sect1" id="id28">&#13;
<h1>Sales</h1>&#13;
&#13;
<p>Web scrapers are an ideal tool for <a contenteditable="false" data-primary="sales applications" data-type="indexterm" id="id353"/>getting sales leads. If you know of a website with sources of contact information for people in your target market, the rest is easy. It doesn’t matter how niche your area is. In my work with sales clients, I’ve scraped lists of youth sports team coaches, fitness gym owners, skin care vendors, and many other types of target audiences for sales purposes.</p>&#13;
&#13;
<p>The recruiting industry (which I think of as a subset of sales) often takes advantage of web scrapers on both sides. Both candidate profiles and job listings are scraped. Because of LinkedIn’s strong anti-scraping policies, plug-ins, such as <a contenteditable="false" data-primary="recruiting industry" data-type="indexterm" id="id354"/><a contenteditable="false" data-primary="plug-ins" data-secondary="Instant Data Scraper" data-type="indexterm" id="id355"/><a contenteditable="false" data-primary="plug-ins" data-secondary="Dux-Soup" data-type="indexterm" id="id356"/><a contenteditable="false" data-primary="Instant Data Scraper" data-type="indexterm" id="id357"/><a contenteditable="false" data-primary="Dux-Soup" data-type="indexterm" id="id358"/>Instant Data Scraper or Dux-Soup, are often used scrape candidate profiles as they’re manually visited in a browser. This gives recruiters the advantage of being able to give candidates a quick glance to make sure they’re suitable for the job description before scraping the page.</p>&#13;
&#13;
<p>Directories like Yelp can help tailor <a contenteditable="false" data-primary="Yelp" data-type="indexterm" id="id359"/>searches of brick-and-mortar businesses on attributes like “expensiveness,” whether or not they accept credit cards, offer delivery or catering, or serve alcohol. Although Yelp is mostly known for its restaurant reviews, it also has detailed information about local carpenters, retail stores, accountants, auto repair shops, and more.</p>&#13;
&#13;
<p>Sites like Yelp do more than just advertise the businesses to customers—the contact information can also be used to make a sales introduction. Again, the detailed filtering tools will help tailor your target market.</p>&#13;
&#13;
<p>Scraping employee directories or career sites can also be a valuable source of employee names and contact information that will help make more personal sales introductions. Checking for Google’s structured data tags (see the next section, <a data-type="xref" data-xrefstyle="select:nopage" href="#SERP-ch3">“SERP Scraping”</a>) is a good strategy for building a broad web scraper that can target many websites while scraping reliable, well-formatted contact information.</p>&#13;
&#13;
<p>Nearly all the examples in this book are about scraping the “content” of websites—the human-readable information they present. However, even the underlying code of the website can be revealing. What content management system is it using? Are there any clues about what server-side stack it might have? What kind of customer chatbot or analytics system, if any, is present?</p>&#13;
&#13;
<p>Knowing what technologies a potential customer might already have, or might need, can be valuable for sales and <a contenteditable="false" data-primary="sales applications" data-startref="salse" data-type="indexterm" id="id360"/>marketing.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="SERP Scraping" data-type="sect1"><div class="sect1" id="SERP-ch3">&#13;
<h1>SERP Scraping</h1>&#13;
&#13;
<p>SERP, or <em>search engine <a contenteditable="false" data-primary="SERP (search engine results page)" data-type="indexterm" id="id361"/>results page</em> scraping, is the practice of scraping useful data directly from search engine results without going to the linked pages themselves. Search engine results have the benefit of having a known, consistent format. The pages that search engines link to have varied and unknown formats—dealing with those is a messy business that’s best avoided if possible.</p>&#13;
&#13;
<p>Search engine companies have dedicated staff whose entire job is to use metadata analysis, clever programming, and AI tools to extract page summaries, statistics, and keywords from websites. By using their results, rather than trying to replicate them in-house, you can save a lot of time and money.</p>&#13;
&#13;
<p>For example, if you want the standings for every major American sports league for the past 40 years, you might find various sources of that information. <a href="http://nhl.com"><em>http://nhl.com</em></a> has hockey standings in one format, while <a href="http://nfl.com"><em>http://nfl.com</em></a>  has the standings in another format. However, searching Google for “nba standings 2008” or “mlb standings 2004” will provide consistently formatted results, with drill downs available into individual game scores and players for that season.</p>&#13;
&#13;
<p>You might also want information about the existence and positioning of the search results themselves, for instance, tracking which websites appear, and in which order, for certain search terms. This can help to monitor your brand and keep an eye out for competitors.</p>&#13;
&#13;
<p>If you’re running a search engine ad campaign, or interested in launching one, you can monitor just the ads rather than all search results. Again, you track which ads appear, in what order, and perhaps how those results change over time.</p>&#13;
&#13;
<p>Make sure you’re not limiting yourself to the main search results page. Google, for example, has Google Maps, Google Images, Google Shopping, Google Flights, Google News, etc. All of these are essentially search engines for different types of content that may be relevant to your project.</p>&#13;
&#13;
<p>Even if you’re not scraping data from the search engine itself, it may be helpful to learn more about how search engines find and tag the data that they display in special search result features and enhancements. Search engines don’t play a lot of guessing games to figure out how to display data; they request that web developers format the content specifically for display by third parties like themselves.</p>&#13;
&#13;
<p>The documentation for Google’s structured data <a href="https://developers.google.com/search/docs/appearance/structured-data">can be found here</a>. If you encounter this data while scraping the web, now you’ll know how to use it.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id343"><sup><a href="ch03.html#id343-marker">1</a></sup> Stuart Rennie, Mara Buchbinder, and Eric Juengst, “Scraping the Web for Public Health Gains: Ethical Considerations from a ‘Big Data’ Research Project on HIV and Incarceration,” <em>National Library of Medicine</em> 13(1): April 2020, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7392638/.</p><p data-type="footnote" id="id344"><sup><a href="ch03.html#id344-marker">2</a></sup>  Philip Brooker et al., “Doing Stigma: Online Commentary Around Weight-Related News Media.” <em>New Media &amp; Society</em> 20(9): 1—22, December 2017. </p><p data-type="footnote" id="id345"><sup><a href="ch03.html#id345-marker">3</a></sup> Roger Pizarro Milian, “Modern Campuses, Local Connections, and Unconventional Symbols: Promotional Practises in the Canadian Community College Sector,” <em>Tertiary Education and Management</em> 22:218-30, September 2016, <a href="https://link.springer.com/article/10.1080/13583883.2016.1193764"><em>https://link.springer.com/article/10.1080/13583883.2016.1193764</em></a>.</p><p data-type="footnote" id="id346"><sup><a href="ch03.html#id346-marker">4</a></sup> Seisaku Kameda, “Use of Alternative Data in the Bank of Japan’s Research Activities,” <em>Bank of Japan Review</em> 2022-E-1, January 2022, <a href="https://www.boj.or.jp/en/research/wps_rev/rev_2022/data/rev22e01.pdf"><em>https://www.boj.or.jp/en/research/wps_rev/rev_2022/data/rev22e01.pdf</em></a>.</p></div></div></section></body></html>