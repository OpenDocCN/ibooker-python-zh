- en: Chapter 11\. Working with Dirty Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, I’ve ignored the problem of badly formatted data by using
    generally well-formatted data sources, dropping data entirely if it deviated from
    what was expected. But, in web scraping, you often can’t be too picky about where
    you get your data, or what it looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Because of errant punctuation, inconsistent capitalization, line breaks, and
    misspellings, dirty data can be a big problem on the web. This chapter covers
    a few tools and techniques to help you prevent the problem at the source by changing
    the way you write code and cleaning the data after it’s in the database.
  prefs: []
  type: TYPE_NORMAL
- en: This is the chapter where web scraping intersects with its close relative, data
    science. While the job title of “data scientist” might conjure mental images of
    cutting-edge programming techniques and advanced mathematics, the truth is that
    a lot of it is grunt work. Someone has to clean and normalize these millions of
    records before they can be used to build a machine learning model, and that person
    is the data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python is a programming language that lends itself very well to text processing.
    It’s easy to write clean, functional, modular code to do even complex text processing
    projects. With the following code, we can scrape text from the Wikipedia article
    on Python at [*http://en.wikipedia.org/wiki/Python_(programming_language)*](http://en.wikipedia.org/wiki/Python_(programming_language)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This content begins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will perform several actions on this text:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove citations, of the form “[123]”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove newline characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split the text into sentences
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove any parenthesized text containing an aside in the middle of a sentence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove descriptions of illustrations not included in the text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make text lowercase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove all punctuation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to note that these functions must be applied in a particular
    order. For instance, removing punctuation (including square brackets) would make
    it difficult to identify and remove citations later on. Removing punctuation and
    making all text lowercase would also make it impossible to split the text into
    sentences.
  prefs: []
  type: TYPE_NORMAL
- en: 'The functions for removing newline characters and making the text lowercase
    are fairly straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here the newlines are replaced with a space character (“ ”) rather than removed
    altogether to avoid text like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'being turned into text like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Inserting the space ensures that all sentences still get a space between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this in mind, we can write the function for splitting sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Rather than splitting simply on the period, we split on the period and a space.
    This prevents decimals, for instance in the ubiquitous “Python 2.5,” or code examples
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: from being split erroneously into sentences. In addition, we want to make sure
    that any double-spaced or otherwise odd sentences are cleaned by stripping each
    leading or trailing whitespace using the `strip` function before returning.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, `split_sentences` can’t be called right away. Many sentences contain
    citations immediately after them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The function for removing citations can be written like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The variable name `CITATION_REGEX` is written in uppercase, indicating that
    it’s a constant, and pre-compiled outside of the function itself. The function
    could also be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: However, this forces Python to recompile this regular expression every time
    the function is run (which could be thousands or millions of times, depending
    on the project), rather than having it pre-compiled and ready to go. While the
    speed of the program is not necessarily a significant bottleneck in web scraping,
    pre-compiling regular expressions outside of functions is easy to do and allows
    you to document the code through an appropriate variable name for the regular
    expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Removing parenthesized text, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'and:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'is a similar pattern to removing the citations. A good first approach might
    be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, this does remove parenthesized text in the examples above, but it also
    removes anything in parentheses from sections like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In addition, it presents a danger if there are unmatched parentheses in the
    text. An opening parenthesis may cause large sections of text to be removed the
    next time any sort of closing parenthesis is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this, we can examine the types of characters generally seen in parenthesized
    text, look only for them, and limit the length of that parenthesized text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Occasionally, descriptions of illustrations not extracted in the text might
    be present. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: which precedes a block of code not extracted in text.
  prefs: []
  type: TYPE_NORMAL
- en: 'These descriptions are generally short, start with a newline, contain only
    letters, and end with a colon. We can remove them with a regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we can remove the punctuation. Because so many of the previous
    steps depend on punctuation to be present in order to identify what text to keep
    and what to remove, stripping the punctuation is generally one of the last steps
    of any text cleaning task.
  prefs: []
  type: TYPE_NORMAL
- en: '[Python’s string module](https://docs.python.org/3/library/string.html) contains
    many handy sets of characters, one of which is `string.punctuation`. This is a
    set of all the ASCII punctuation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can take this string containing all ASCII punctuation and turn it into a
    regular expression using `re.escape` (which escapes any reserved regular expression
    symbols) and joining everything with a `|` character:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'It’s common, with all this string manipulation, for unicode characters to become
    misrepresented in the string. Especially common is the unicode “nonbreaking space”
    which is represented by a `&nbsp;` in HTML and can be found frequently in text
    on the web. This can be seen in our Wikipedia text printed out as `\xa0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Regardless of which strange characters you encounter, you can fix them with
    Python’s `unicodedata` package. Normalizing unicode characters will be the final
    step in cleaning the text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you have a set of short, well-organized functions that perform
    a variety of text cleaning operations. Because we might want to add, remove, or
    change the order that the functions are called in, we can add these functions
    to a list and call them in a general way on our text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Although Python is not generally thought of as a functional language like JavaScript
    or—as a more extreme example—Haskell, it’s useful to remember that functions can
    be passed around as variables in situations like this!
  prefs: []
  type: TYPE_NORMAL
- en: Working with Normalized Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve cleaned the text, what do you do with it? One common technique is
    to break it up into smaller pieces of text that can be more easily quantified
    and analyzed. Computational linguists call these *n-grams*, where n represents
    the number of words in each piece of text. In this example, we’ll be working specifically
    with 2-grams, or 2 word pieces of text.
  prefs: []
  type: TYPE_NORMAL
- en: N-grams typically do not span sentences. So we can use the text obtained in
    the previous section, split into sentences, and create 2-grams with each sentence
    in the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Python function for breaking text into n-grams can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this function on the text “web scraping with python” is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: One problem with this function is that it returns many duplicate 2-grams. Every
    2-gram it encounters gets added to the list, with no record of its frequency.
    Not only is it interesting to record the frequency of these 2-grams, rather than
    just their existence, but it can be useful in charting the effects of changes
    to the cleaning and data normalization algorithms. If data is normalized successfully,
    the total number of unique n-grams will be reduced, while the total count of n-grams
    found (i.e., the number of unique or nonunique items identified as n-grams) will
    not be reduced. In other words, there will be fewer “buckets” for the same number
    of n-grams.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can do this by modifying the code that collects the n-grams to add them
    to a `Counter` object, rather than a list. Here, the `cleaned` variable is our
    list of cleaned sentences obtained in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: There are many other ways to create counts of n-grams, such as adding them to
    a dictionary object in which the value of the list points at a count for the number
    of times it was seen. That has a disadvantage in that it requires a bit more management
    and makes sorting tricky.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, using a `Counter` object also has a disadvantage: it cannot store
    lists, because lists are unhashable. Converting these to tuples (which are hashable)
    would work well and make sense in this context, as would joining the lists to
    strings. In this case, I’ve chosen to convert them to strings by using a `'' ''.join(text[i:i+n])`
    inside the list comprehension for each n-gram.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can call the `countNGramsFromSentences` function with our cleaned text from
    the previous section and use the `most_common` function to get a list of 2-grams
    sorted by the most common ones first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As of this writing, there are 2,814 unique 2-grams, with the most popular ones
    containing word combinations that are very common in any English text, such as
    “such as.” Depending on your project, you may want to remove n-grams like this
    that do not have much relevance to the page’s actual subject matter. Doing this
    is a topic for [Chapter 12](ch12.html#c-12).
  prefs: []
  type: TYPE_NORMAL
- en: Beyond this, it’s usually good to stop and consider how much computing power
    you want to expend normalizing data. There are a number of situations in which
    different spellings of words are equivalent, but to resolve this equivalency,
    you need to run a check on every single word to see whether it matches any of
    your preprogrammed equivalencies.
  prefs: []
  type: TYPE_NORMAL
- en: For example, “Python 1st” and “Python first” both appear in the list of 2-grams.
    However, to make a blanket rule that says, “All first, second, third, etc., will
    be resolved to 1st, 2nd, 3rd, etc. (or vice versa)” would result in an additional
    10 or so checks per word.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the inconsistent use of hyphens (“co-ordinated” versus “coordinated”),
    misspellings, and other natural language incongruities will affect the groupings
    of n-grams and might muddy the results of the output if the incongruities are
    common enough.
  prefs: []
  type: TYPE_NORMAL
- en: One solution, in the case of hyphenated words, might be to remove hyphens entirely
    and treat the word as a single string, which would require only a single operation.
    However, this would also mean that hyphenated phrases (an all-too-common occurrence)
    will be treated  as a single word. Going the other route and treating hyphens
    as spaces might be a better option. Just be prepared for the occasional “co ordinated”
    and “ordinated attack” to slip in!
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning Data with Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is not about the endearing bears native to China, but the Python
    data analysis package: *pandas*. If you’ve done any work with data science and
    machine learning, you’ve likely encountered it before, as it is ubiquitous in
    the field.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas was created as a solo project for work in 2008 by programmer Wes McKinney.
    In 2009, he made the project public and it quickly took off. The package filled
    a particular niche in data wrangling. It functioned much like a spreadsheet in
    some ways, with pretty printing and easy reshaping pivot functions. It also harnessed
    the power and flexibility of the underlying Python code and data science libraries
    that it was built on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some might recommend the [Anaconda package management system](https://www.anaconda.com) when
    installing data science libraries like numpy, pandas, and scikit-learn. Although
    there is excellent support for these packages with Anaconda, pandas is also straightforward
    to install with pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The package is, by convention, imported as `pd` rather than the full name `pandas`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Don’t Import Individual Methods and Classes from Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pandas ecosystem is large, complex, and often overlaps the namespace of
    built-in Python functions and packages. For this reason, pandas functions should
    almost always be referenced starting from `pd` rather than importing them directly,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In these cases, the above imports might cause confusion with the built-in Python `array` module
    and `min` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'One accepted exception may be for the DataFrame class, imported as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `DataFrame` is not found in the Python standard library and is
    easily-recognized as a pandas class. However, this is the one exception you are
    likely to see, and many still prefer to reference the DataFrame class as `pd.DataFrame`.
    Because the library is so-often referenced in code, this is one reason why the
    convention is to import pandas as `pd` rather than the full name!
  prefs: []
  type: TYPE_NORMAL
- en: 'The object you will be working with most often in the pandas library is the
    DataFrame. These are similar to spreadsheets or tables, and can be constructed
    in a variety of ways. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The `head` method produces a pretty-printed DataFrame of the data and its columns
    and headers, as shown in [Figure 11-1](#fig1101).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-1\. A simple pandas DataFrame
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: DataFrames are required to always have an index and column names. If those are
    not provided, as in this case, where only a simple matrix of data is supplied,
    they will be automatically generated. The DataFrame’s index (0, 1, 2) can be seen
    in bold to the left, and the column names (0, 1) are at the top in bold.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than working with raw Python lists and dictionaries, DataFrames provide
    an enormous variety convenient helper functions to sort, clean, manipulate, arrange,
    and display your data. If you are working with larger data sets, they also provide
    a speed and memory advantage over lists and dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following examples, you’ll use data scraped from [Wikipedia’s List of
    Countries with McDonald’s Restaurants](https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants).
    We can use the `pd.read_csv` function to read data directly from a CSV file to
    a dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Optionally, an integer can be passed to the `head` method to print out a number
    of rows other than the default of 5\. This gives a nice view of the CSV data scraped
    from earlier, as shown in [Figure 11-2](#1102).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-2\. Displaying a list of countries with lds
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The column names here are somewhat wordy and not well-formatted. We can rename
    them using the `rename` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Here, we pass in a dictionary to the `columns` keyword argument, where the keys
    are the original column names and the value is the new column name. The boolean
    argument `inplace` means that the columns are renamed in-place in the original
    DataFrame, rather than a new DataFrame being returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can isolate only the columns that we want to work with by passing
    in a list of those column names to a sort of slicing syntax using `[]` brackets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the relabeled DataFrame columns we want, we can look at the
    data. There are a few things we will want to fix up. First, the dates in the “Date
    of first store” or “Date” column are usually well-formatted, but they also contain
    extra text or even other dates. As a simple strategy, we may decide to keep the
    first thing that matches the “date” format and discard the rest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Functions can be applied to an entire column in a DataFrame by first selecting
    that column using the same “slicing” syntax used above. A single selected column
    a pandas `Series` instance. The `Series` class has an `apply` method which applies
    a single function to each value in the Series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Here, I am using a lambda operator to apply a function that gets all `date_regex` matches
    and returns the first one as the date.
  prefs: []
  type: TYPE_NORMAL
- en: 'After cleaning, these dates can be converted to actual pandas datetime values
    using the `to_datetime` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Often, there is a delicate balance between the fast and efficient production
    of “clean” data, and the preservation of completely accurate and nuanced data.
    For instance, our date cleaning reduced the following text in the United Kingdom
    row:  "*England: November 13, 1974[21] Wales: December 3, 1984 Scotland: November
    23, 1987[22] Northern Ireland: October 12, 1991*" into the single date: "*1974-11-13*“.'
  prefs: []
  type: TYPE_NORMAL
- en: Technically, this is correct. If the country of the United Kingdom as a whole
    is considered, then 1974-11-13 is the first date a McDonald’s appeared in it.
    However, it is simply happenstance that the dates were written in the cell in
    chronological order, and that we decided to take the first one, and also that
    the earliest date was the right one to choose. One might imagine many other circumstances
    where we might not be so lucky.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, you may do a survey of the data and decide that your chosen cleaning
    method is good enough. Perhaps it is correct in most of the cases you look at.
    Perhaps it’s incorrect in one direction half the time, incorrect in the other
    direction the other half of the time, and things balance out for your purposes
    over large datasets. Or you may decide you need another method to clean or capture
    the data more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: 'The “Outlets” column of the dataset presents similar challenges. This column
    contains text such as "*13,515[10][failed verification][11]*" and " *(excl. seasonal
    restaurants) 43 (including seasonal and mobile restaurants)*" which are not the
    clean integers that we might like for further analysis. Again, we can use a simple
    approach to get the first integer available in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Although this could also be written as a lambda function, you may consider
    breaking the logic out into a separate function if several steps are required.
    This also has the advantage of allowing you to easily print out any exceptions
    found during exploratory data processing, for further consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the DataFrame is cleaned and ready for further analysis, as shown in
    [Figure 11-3](#1103).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11-3\. DataFrame with clean column headers, formatted dates, and integer
    data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Indexing, Sorting, and Filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember from earlier that all DataFrames have an index, whether you explicitly
    provide one or not. The McDonald’s data itself has a convenient index: the “Order”
    column, which signifies the chronological order in which the countries received
    their first McDonald’s restaurant. We can set the index using the `set_index`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This discards the old index and moves the “Order” column into the index. Again,
    the `inplace` keyword argument means that this is done in-place on the original
    DataFrame, rather than have a copy of the DataFrame returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sort_values` method can be used to sort data by one or many columns. The `inplace` keyword
    can be used in this method as well. However, because sorting is usually done for
    exploratory analysis and a permanent sort is not desired, it may be more useful
    to return the DataFrame for printing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This shows that the countries with the most McDonald’s are the United States,
    followed by China, and then Japan. France,  I’m sure it will be pleased to know,
    comes in fourth place, with the greatest number of McDonald’s of any European
    country!
  prefs: []
  type: TYPE_NORMAL
- en: 'Filtering DataFrames is easy with the `query` method. It takes, as an argument,
    a query string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns a DataFrame containing only records where the number of Outlets
    is less than 100\. Most of the usual Python comparison operators work for DataFrame
    filtering using the query method, however this query language is not Python syntax.
    For instance, this will raise an Exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to test for the presence or absence of any empty values, the correct
    pandas way to do it is using the `isnull` and `notnull` query functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As you might guess, these statements capture both `None` values as well as `NaN` objects
    from the underlying numpy package that pandas is built on top of.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to add another logic clause, you can separate them by a single ampersand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'An `or` statement is represented with a single pipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Note that the entire date (`"1990-01-01"`) is not required here, but will also
    work with just the year `"1990"`. Pandas is fairly forgiving about interpreting
    strings as dates, although you should always double-check that the data coming
    back is what you expect it to be.
  prefs: []
  type: TYPE_NORMAL
- en: More About Pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I sincerely hope that your journey with pandas does not end here. We are fortunate
    that Wes McKinney, the creator and [Benevolent Dictator for Life](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life) of
    pandas, has also written a book about it: [*Python for Data Analysis*](https://www.oreilly.com/library/view/python-for-data/9781098104023/).'
  prefs: []
  type: TYPE_NORMAL
- en: If you plan to do more with data science, or simply want a good tool to clean
    and analyze data occasionally in Python, I recommend that you check it out.
  prefs: []
  type: TYPE_NORMAL
