# 第一章 什么是 Dask？

Dask 是一个用于 Python 的并行计算框架，从单机多核扩展到拥有数千台机器的数据中心。它既有低级任务 API，也有更高级的面向数据的 API。低级任务 API 支持 Dask 与多种 Python 库的集成。公共 API 的存在使得围绕 Dask 发展了各种工具的生态系统。

Continuum Analytics，现在被称为 Anaconda Inc，启动了开源、DARPA 资助的 [Blaze 项目](https://oreil.ly/FyqwQ)，该项目演变为 Dask。Continuum 参与开发了 Python 数据分析领域许多重要库甚至会议。Dask 仍然是一个开源项目，现在大部分开发得到 [Coiled](https://oreil.ly/BMLuP) 的支持。

Dask 在分布式计算生态系统中独具一格，因为它整合了流行的数据科学、并行和科学计算库。Dask 整合不同库的能力允许开发者在规模化时重复使用他们的现有知识。他们还可以最小程度地更改一些代码并频繁重复使用它们。

# 为什么需要使用 Dask？

Dask 简化了用 Python 编写的分析、机器学习和其他代码的扩展，¹ 允许你处理更大更复杂的数据和问题。Dask 的目标是填补现有工具（如 pandas DataFrames 或你的 scikit-learn 机器学习流水线）在处理速度变慢（或无法成功）时的空白。虽然“大数据”这个术语可能比几年前少流行一些，但问题的数据规模并没有减小，计算和模型的复杂性也没有变得更简单。Dask 允许你主要使用你习惯的现有接口（如 pandas 和多进程），同时超越单个核心甚至单台机器的规模。

###### 注意

另一方面，如果你所有的数据都能在笔记本电脑的内存中处理，并且你能在你喝完一杯最喜欢的热饮之前完成分析，那么你可能还不需要使用 Dask。

# Dask 在生态系统中的位置？

Dask 提供了对多个传统上独立工具的可扩展性。它通常用于扩展 Python 数据库库，如 pandas 和 NumPy。Dask 扩展了现有的扩展工具，例如多进程，使它们能够超越单机的当前限制，扩展到多核和多机。以下是生态系统演变的简要概述：

先“大数据”查询

Apache Hadoop 和 Apache Hive

后“大数据”查询

Apache Flink 和 Apache Spark

集中于 DataFrame 的分布式工具

Koalas、Ray 和 Dask

从抽象角度来看，Dask 位于机器和集群管理工具之上，使你能够专注于 Python 代码，而不是机器间通信的复杂性：

可扩展的数据和机器学习工具

Hadoop、Hive、Flink、Spark、TensorFlow、Koalas、Ray、Dask 等

计算资源

Apache Hadoop YARN、Kubernetes、Amazon Web Services、Slurm Workload Manager 等。

如果限制因素不是数据量而是我们对数据的处理工作，则我们说问题是*计算密集型*。*内存限制*问题是指计算不是限制因素；相反，能否将所有数据存储在内存中是限制因素。某些问题既可以是计算密集型又可以是内存密集型，这在大型深度学习问题中经常发生。

多核心（考虑多线程）处理可以帮助解决计算密集型问题（在机器核心数限制内）。通常情况下，多核心处理无法帮助解决内存密集型问题，因为所有中央处理单元（CPU）对内存的访问方式相似。²

加速处理，包括使用专门的指令集或专用硬件如张量处理单元（TPU）或图形处理单元（GPU），通常仅对计算密集型问题有用。有时使用加速处理会引入内存限制问题，因为加速计算的内存可用量可能小于“主”系统内存。

对于这两类问题，多机处理都很重要。因为即使在某些规模上问题“仅”是计算密集型，您也需要考虑多机处理，因为在一台机器上您能（负担得起的话）获得的核心数量有限。更常见的是，内存限制问题非常适合多机扩展，因为 Dask 常常能够将数据分割到不同的机器上。

Dask 既支持多核心，也支持多机器扩展，允许您根据需要扩展 Python 代码。

Dask 的许多功能来自于建立在其之上的工具和库，这些工具和库适应其在数据处理生态系统中的各个部分（如 BlazingSQL）。您的背景和兴趣自然会影响您首次查看 Dask 的方式，因此在接下来的小节中，我们将简要讨论您如何在不同类型的问题上使用 Dask，以及它与一些现有工具的比较。

## 大数据

Dask 拥有比许多替代方案更好的 Python 库集成和较低的任务开销。Apache Spark（及其 Python 伴侣 PySpark）是最流行的大数据工具之一。现有的大数据工具，如 PySpark，具有更多的数据源和优化器（如谓词下推），但每个任务的开销更高。Dask 的较低开销主要归因于 Python 大数据生态系统的其他部分主要构建在 JVM 之上。这些工具具有高级功能，如查询优化器，但以在 JVM 和 Python 之间复制数据为代价。

与许多其他传统的大数据工具不同，如 Spark 和 Hadoop，Dask 将本地模式视为一等公民。传统的大数据生态系统侧重于在测试时使用本地模式，但 Dask 专注于在单个节点上运行时的良好性能。

另一个显著的文化差异来自打包，许多大数据项目将所有内容整合在一起（例如，Spark SQL、Spark Kubernetes 等一起发布）。Dask 采用更模块化的方法，其组件遵循其自己的开发和发布节奏。Dask 的这种方法可以更快地迭代，但有时会导致库之间的不兼容性。

## 数据科学

在数据科学生态系统中，最受欢迎的 Python 库之一是 pandas。Apache Spark（及其 Python 伴侣 PySpark）也是最受欢迎的分布式数据科学工具之一。它支持 Python 和 JVM 语言。Spark 最初的 DataFrame 尝试更接近 SQL，而不是您可能认为的 DataFrame。虽然 Spark 已开始与 [Koalas 项目](https://oreil.ly/VmU6O) 集成 pandas 支持，但我们认为 Dask 对数据科学库 API 的支持是最佳的。³ 除了 pandas API，Dask 还支持 NumPy、scikit-learn 和其他数据科学工具的扩展。

###### 注意

Dask 可以扩展以支持除了 NumPy 和 pandas 之外的数据类型，这正是如何通过 [cuDF](https://oreil.ly/m-K8W) 实现 GPU 支持的。

## 并行到分布式 Python

*并行计算* 指同时运行多个操作，*分布式计算* 将此扩展到多个机器上的多个操作。并行 Python 涵盖了从多进程到 Celery 等各种工具。⁴ Dask 允许您指定一个任意的依赖图，并并行执行它们。在内部，这种执行可以由单台机器（使用线程或进程）支持，也可以分布在多个工作节点上。

###### 注意

许多大数据工具具有类似的低级任务 API，但这些 API 是内部的，不会向我们公开使用，也没有受到故障保护。

## Dask 社区库

Dask 的真正力量来自于围绕它构建的生态系统。不同的库建立在 Dask 之上，使您能够在同一框架中使用多个工具。这些社区库之所以如此强大，部分原因在于低级和高级 API 的结合，这些 API 不仅适用于第一方开发。

### 加速 Python

您可以通过几种不同的方式加速 Python，从代码生成（如 Numba）到针对特殊硬件的库，如 NVidia 的 CUDA（以及 cuDF 类似的包装器）、AMD 的 ROCm 和 Intel 的 MKL。

Dask 本身并不是加速 Python 的库，但您可以与加速 Python 工具一起使用它。为了方便使用，一些社区项目将加速工具（如 cuDF 和 dask-cuda）与 Dask 集成。当与 Dask 一起使用加速 Python 工具时，您需要小心地构造代码，以避免序列化错误（参见 “序列化和 Pickling”）。

###### 注意

加速 Python 库通常使用更“本地”的内存结构，这些结构不容易通过 pickle 处理。

### SQL 引擎

Dask 本身没有 SQL 引擎；但是，[FugueSQL](https://oreil.ly/sBLQM)，[Dask-SQL](https://oreil.ly/ZMVD1)，和 [BlazingSQL](https://oreil.ly/4gHru) 使用 Dask 提供分布式 SQL 引擎。⁵ Dask-SQL 使用流行的 Apache Calcite 项目，该项目支持许多其他 SQL 引擎。BlazingSQL 扩展了 Dask DataFrames 以支持 GPU 操作。cuDF DataFrames 具有略有不同的表示形式。Apache Arrow 使得将 Dask DataFrame 转换为 cuDF 及其相反变得简单直接。

Dask 允许这些不同的 SQL 引擎在内存和计算方面进行扩展，处理比单台计算机内存能容纳的更大数据量，并在多台计算机上处理行。Dask 还负责重要的聚合步骤，将不同机器的结果组合成数据的一致视图。

###### 提示

Dask-SQL 可以从 Dask 无法读取的 Hadoop 生态系统的部分读取数据（例如 Hive）。

### 工作流调度

大多数组织都需要某种形式的定期工作，从在特定时间运行的程序（例如计算每日或月末财务数据的程序）到响应事件运行的程序。这些事件可以是数据可用（例如每日财务数据运行后）或新邮件到达，或者可以是用户触发的。在最简单的情况下，定期工作可以是单个程序，但通常情况下比这更复杂。

如前所述，您可以在 Dask 中指定任意图形，如果选择的话，可以使用 Dask 编写工作流程。您可以调用系统命令并解析其结果，但仅仅因为您可以做某事并不意味着它将是有趣或简单的。

大数据生态系统中的工作流调度的家喻户晓的名字⁶ 是 Apache Airflow。虽然 Airflow 拥有一套精彩的操作器集合，使得表达复杂任务类型变得容易，但它以难以扩展而著称。⁷ Dask 可以用于运行 [Airflow 任务](https://oreil.ly/Vw54J)。或者，它可以用作其他任务调度系统（如 [Prefect](https://oreil.ly/9Xmvo)）的后端。Prefect 旨在将类似 Airflow 的功能带到 Dask，具有一个大型预定义的任务库。由于 Prefect 从开始就将 Dask 作为执行后端，因此它与 Dask 的集成更紧密，开销更低。

###### 注意

少数工具涵盖了完全相同的领域，最相似的工具是 Ray。Dask 和 Ray 都暴露了 Python API，在需要时有底层扩展。有一个 [GitHub 问题](https://oreil.ly/cPJpW)，其中两个系统的创作者比较了它们的相似之处和差异。从系统角度来看，Ray 和 Dask 之间的最大区别在于状态处理、容错性和集中式与分散式调度。Ray 在 C++ 中实现了更多的逻辑，这可能会带来性能上的好处，但也更难阅读。从用户角度来看，Dask 更加注重数据科学，而 Ray 强调分布式状态和 actor 支持。Dask 可以使用 Ray 作为调度的后端。

# Dask 不是什么

虽然 Dask 是很多东西，但它不是你可以挥舞在代码上使其更快的魔术棒。Dask 在某些地方具有兼容的 API，但误用它们可能导致执行速度变慢。Dask 不是代码重写或即时编译（JIT）工具；相反，Dask 允许你将这些工具扩展到集群上运行。Dask 着重于 Python，并且可能不适合与 Python 集成不紧密的语言（如 Go）扩展。Dask 没有内置的目录支持（例如 Hive 或 Iceberg），因此从存储在目录中的表中读取和写入数据可能会带来挑战。

# 结论

Dask 是扩展你的分析 Python 代码的可能选项之一。它涵盖了从单台计算机上的多个核心到数据中心的各种部署选项。与许多类似领域的其他工具相比，Dask 采用了模块化的方法，这意味着理解其周围的生态系统和库是至关重要的。选择正确的软件扩展取决于你的代码、生态系统、数据消费者以及项目的数据源。我们希望我们已经说服你，值得在下一章节中稍微尝试一下 Dask。

¹ 不是 *所有* Python 代码；例如，Dask 在扩展 Web 服务器（从 Web Socket 需求来看非常有状态）方面是一个不好的选择。

² 除了非均匀内存访问（NUMA）系统。

³ 当然，意见有所不同。例如，参见 [“单节点处理 — Spark、Dask、Pandas、Modin、Koalas Vol. 1”](https://oreil.ly/HBExc)，[“基准测试：Koalas（PySpark）和 Dask”](https://oreil.ly/PNZPm)，以及 [“Spark vs. Dask vs. Ray”](https://oreil.ly/eA28o)。

⁴ Celery，通常用于后台作业管理，是一个异步任务队列，也可以分割和分发工作。但它比 Dask 低级，并且没有与 Dask 相同的高级便利性。

⁵ BlazingSQL 不再维护，尽管其概念很有趣，可能会在其他项目中找到用武之地。

⁶ 假设家庭比较书呆子。

⁷ 每小时进行一千项任务，需要进行大量调整和手动考虑；参见[“将 Airflow 扩展到 1000 任务/小时”](https://oreil.ly/tVbSf)。

⁸ 或者，换个角度看，Ray 能够利用 Dask 提供数据科学功能。
