["```py\nimport random\nsearch_space = []\nfor i in range(10):\n    random_choice = {\n        'weight': random.uniform(0, 1),\n        'discount_factor': random.uniform(0, 1)\n    }\n    search_space.append(random_choice)\n```", "```py\nimport ray\n\n@ray.remote\ndef objective(config):  ![1](assets/1.png)\n    environment = Environment()\n    policy = train_policy(  ![2](assets/2.png)\n        environment, weight=config[\"weight\"], discount_factor=config[\"discount_factor\"]\n    )\n    score = evaluate_policy(environment, policy)  ![3](assets/3.png)\n    return [score, config]  ![4](assets/4.png)\n```", "```py\nresult_objects = [objective.remote(choice) for choice in search_space]\nresults = ray.get(result_objects)\n\nresults.sort(key=lambda x: x[0])\nprint(results[-1])\n```", "```py\nfrom ray import tune\n\nsearch_space = {\n    \"weight\": tune.uniform(0, 1),\n    \"discount_factor\": tune.uniform(0, 1),\n}\n```", "```py\ndef tune_objective(config):\n    environment = Environment()\n    policy = train_policy(\n        environment, weight=config[\"weight\"], discount_factor=config[\"discount_factor\"]\n    )\n    score = evaluate_policy(environment, policy)\n\n    return {\"score\": score}\n```", "```py\nanalysis = tune.run(tune_objective, config=search_space)\nprint(analysis.get_best_config(metric=\"score\", mode=\"min\"))\n```", "```py\nfrom ray.tune.suggest.bayesopt import BayesOptSearch\n\nalgo = BayesOptSearch(random_search_steps=4)\n\ntune.run(\n    tune_objective,\n    config=search_space,\n    metric=\"score\",\n    mode=\"min\",\n    search_alg=algo,\n    stop={\"training_iteration\": 10},\n)\n```", "```py\ndef objective(config):\n    for step in range(30):  ![1](assets/1.png)\n        score = config[\"weight\"] * (step ** 0.5) + config[\"bias\"]\n        tune.report(score=score)  ![2](assets/2.png)\n\nsearch_space = {\"weight\": tune.uniform(0, 1), \"bias\": tune.uniform(0, 1)}\n```", "```py\nfrom ray.tune.schedulers import HyperBandScheduler\n\nscheduler = HyperBandScheduler(metric=\"score\", mode=\"min\")\n\nanalysis = tune.run(\n    objective,\n    config=search_space,\n    scheduler=scheduler,\n    num_samples=10,\n)\n\nprint(analysis.get_best_config(metric=\"score\", mode=\"min\"))\n```", "```py\nfrom ray import tune\n\ntune.run(objective, num_samples=10, resources_per_trial={\"cpu\": 2, \"gpu\": 0.5})\n```", "```py\nfrom ray import tune\nfrom ray.tune import Callback\nfrom ray.tune.logger import pretty_print\n\nclass PrintResultCallback(Callback):\n    def on_trial_result(self, iteration, trials, trial, result, **info):\n        print(f\"Trial {trial} in iteration {iteration}, got result: {result['score']}\")\n\ndef objective(config):\n    for step in range(30):\n        score = config[\"weight\"] * (step ** 0.5) + config[\"bias\"]\n        tune.report(score=score, step=step, more_metrics={})\n```", "```py\nsearch_space = {\"weight\": tune.uniform(0, 1), \"bias\": tune.uniform(0, 1)}\n\nanalysis = tune.run(\n    objective,\n    config=search_space,\n    mode=\"min\",\n    metric=\"score\",\n    callbacks=[PrintResultCallback()])\n\nbest = analysis.best_trial\nprint(pretty_print(best.last_result))\n```", "```py\n...\nTrial objective_85955_00000 in iteration 57, got result: 1.5379782083952644\nTrial objective_85955_00000 in iteration 58, got result: 1.5539087627537493\nTrial objective_85955_00000 in iteration 59, got result: 1.569535794562848\nTrial objective_85955_00000 in iteration 60, got result: 1.5848760187255326\nTrial objective_85955_00000 in iteration 61, got result: 1.5999446700996236\n...\n```", "```py\nResult logdir: /Users/maxpumperla/ray_results/objective_2022-05-23_15-52-01\n...\ndone: true\nexperiment_id: ea5d89c2018f483183a005a1b5d47302\nexperiment_tag: 0_bias=0.73356,weight=0.16088\nhostname: mac\niterations_since_restore: 30\nmore_metrics: {}\nscore: 1.5999446700996236\nstep: 29\ntrial_id: '85955_00000'\n...\n```", "```py\nanalysis = tune.run(\n    objective,\n    name=\"/Users/maxpumperla/ray_results/objective_2022-05-23_15-52-01\",\n    resume=True,\n    config=search_space)\n```", "```py\ntune.run(\n    objective,\n    config=search_space,\n    stop={\"training_iteration\": 10})\n```", "```py\ndef stopper(trial_id, result):\n    return result[\"score\"] < 2\n\ntune.run(\n    objective,\n    config=search_space,\n    stop=stopper)\n```", "```py\nfrom ray import tune\nimport numpy as np\n\nsearch_space = {\n    \"weight\": tune.sample_from(lambda context: np.random.uniform(low=0.0, high=1.0)),\n    \"bias\": tune.sample_from(lambda context: context.config.alpha * np.random.normal())\n}\n\ntune.run(objective, config=search_space)\n```", "```py\nfrom ray import tune\n\nanalysis = tune.run(\n    \"DQN\",\n    metric=\"episode_reward_mean\",\n    mode=\"max\",\n    config={\n        \"env\": \"CartPole-v0\",\n        \"lr\": tune.uniform(1e-5, 1e-4),\n        \"train_batch_size\": tune.choice([10000, 20000, 40000]),\n    },\n)\n```", "```py\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\n\ndef load_data():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    num_classes = 10\n    x_train, x_test = x_train / 255.0, x_test / 255.0\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n    return (x_train, y_train), (x_test, y_test)\n```", "```py\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom ray.tune.integration.keras import TuneReportCallback\n\ndef objective(config):\n    (x_train, y_train), (x_test, y_test) = load_data()\n    model = Sequential()\n    model.add(Flatten(input_shape=(28, 28)))\n    model.add(Dense(config[\"hidden\"], activation=config[\"activation\"]))\n    model.add(Dropout(config[\"rate\"]))\n    model.add(Dense(10, activation=\"softmax\"))\n\n    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    model.fit(x_train, y_train, batch_size=128, epochs=10,\n              validation_data=(x_test, y_test),\n              callbacks=[TuneReportCallback({\"mean_accuracy\": \"accuracy\"})])\n```", "```py\nfrom ray import tune\nfrom ray.tune.suggest.hyperopt import HyperOptSearch\n\ninitial_params = [{\"rate\": 0.2, \"hidden\": 128, \"activation\": \"relu\"}]\nalgo = HyperOptSearch(points_to_evaluate=initial_params)\n\nsearch_space = {\n    \"rate\": tune.uniform(0.1, 0.5),\n    \"hidden\": tune.randint(32, 512),\n    \"activation\": tune.choice([\"relu\", \"tanh\"])\n}\n\nanalysis = tune.run(\n    objective,\n    name=\"keras_hyperopt_exp\",\n    search_alg=algo,\n    metric=\"mean_accuracy\",\n    mode=\"max\",\n    stop={\"mean_accuracy\": 0.99},\n    num_samples=10,\n    config=search_space,\n)\nprint(\"Best hyperparameters found were: \", analysis.best_config)\n```"]