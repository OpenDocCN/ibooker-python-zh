- en: Chapter 9\. Storing Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。存储数据
- en: Although printing to the terminal is a lot of fun, it’s not incredibly useful
    when it comes to data aggregation and analysis. To make the majority of web scrapers
    remotely useful, you need to be able to save the information that they scrape.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在终端打印输出很有趣，但在数据聚合和分析方面却不是非常有用。要使大多数网络爬虫实用，你需要能够保存它们抓取的信息。
- en: This chapter covers three main methods of data management that are sufficient
    for almost any imaginable application. Do you need to power the backend of a website
    or create your own API? You’ll probably want your scrapers to write to a database.
    Need a fast and easy way to collect documents off the internet and put them on
    your hard drive? You’ll probably want to create a file stream for that. Need occasional
    alerts, or aggregated data once a day? Send yourself an email!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了三种主要的数据管理方法，几乎适用于任何想象得到的应用程序。需要支持网站的后端或创建自己的API吗？你可能希望你的爬虫将数据写入数据库。需要快速简便地从互联网上收集文档并将它们存储到硬盘吗？你可能需要为此创建文件流。需要偶尔的提醒或每天的聚合数据吗？给自己发送邮件吧！
- en: Above and beyond web scraping, the ability to store and interact with large
    amounts of data is incredibly important for just about any modern programming
    application. In fact, the information in this chapter is necessary for implementing
    many of the examples in later sections of the book. I highly recommend that you
    at least skim this chapter if you’re unfamiliar with automated data storage.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 除了网页抓取之外，存储和处理大量数据的能力对于几乎任何现代编程应用都非常重要。事实上，本章的信息对于实现书后部分示例中的许多示例是必要的。如果你对自动化数据存储不熟悉，我强烈建议你至少浏览一下本章。
- en: Media Files
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 媒体文件
- en: 'You can store media files in two main ways: by reference and by downloading
    the file itself. Storing a file by reference is as simple as saving the text URL
    where the file is located on the host server but not actually downloading the
    file. This has several advantages:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过两种主要方式存储媒体文件：通过引用和通过下载文件本身。将文件存储为引用只需保存主机服务器上文件所在位置的文本URL，而不实际下载文件。这有几个优点：
- en: Scrapers run much faster and require much less bandwidth when they don’t have
    to download files.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当爬虫无需下载文件时，其运行速度更快，需要的带宽更少。
- en: You save space on your own machine by storing only the URLs.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过仅存储URL，你可以节省自己机器上的空间。
- en: It is easier to write code that stores only URLs and doesn’t need to deal with
    additional file downloads.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写仅存储URL并且不需要处理额外文件下载的代码更容易。
- en: You can lessen the load on the host server by avoiding large file downloads.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免下载大文件可以减轻主机服务器的负载。
- en: 'Here are the disadvantages:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是缺点：
- en: Embedding these URLs in your own website or application is known as *hotlinking*, and
    doing it is a quick way to get you in hot water on the internet.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你自己的网站或应用程序中嵌入这些URL被称为*热链接*，这样做是在互联网上迅速陷入麻烦的一种方式。
- en: You do not want to use someone else’s server cycles to host media for your own
    applications.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不希望使用别人的服务器周期来为自己的应用程序托管媒体文件。
- en: 'The file hosted at any particular URL is subject to change. This might lead
    to embarrassing effects if, say, you’re embedding a hotlinked image on a public
    blog, the blog owner finds out, and they decide to change the image to something
    unsavory. Less serious but still inconvenient: if you’re storing the URLs with
    the intent to use them later, they might eventually go missing at a later date.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储在特定URL上的文件可能会发生变化。如果例如你在公共博客上嵌入了热链接图像，博客所有者发现并决定将图像更改为不良内容，可能会导致尴尬的影响。虽然不严重但仍然不便的是，如果你打算稍后使用它们，存储的URL可能在以后某个时候消失。
- en: Real web browsers do not just request a page’s HTML and move on. They download
    all of the assets required by the page as well. Downloading files can make your
    scraper look like a human browsing the site, an advantage over merely recording
    links.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真正的网络浏览器不仅仅请求页面的HTML然后离开。它们还下载页面所需的所有资产。下载文件可以使你的爬虫看起来像是人类在浏览网站，这是比仅仅记录链接更具优势的地方。
- en: If you’re debating whether to store a file or a URL to a file, you should ask
    yourself whether you’re likely to view or read that file more than once or twice,
    or if this database of files is going to be sitting around gathering electronic
    dust for most of its life. If the answer is the latter, it’s probably best to
    simply store the URL. If it’s the former, read on!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在考虑是将文件还是文件的 URL 存储到文件中，则应自问您是否有可能多次查看或阅读该文件，或者这个文件的数据库是否将在其生命周期的大部分时间内闲置。如果答案是后者，则最好只存储URL。如果是前者，请继续阅读！
- en: 'The urllib library, used to retrieve the content of web pages, also contains
    functions to retrieve the content of files. The following program uses `urllib.request.urlretrieve`
    to download images from a remote URL:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检索网页内容的 urllib 库还包含用于检索文件内容的功能。以下程序使用`urllib.request.urlretrieve`从远程 URL 下载图像：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This downloads the Python logo from *http://pythonscraping.com* and stores it
    as *logo.jpg* in the same directory from which the script is running.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这将从 *http://pythonscraping.com* 下载Python标志并将其存储为*logo.jpg*在脚本运行的同一目录中。
- en: 'This works well if you need to download only a single file and know what to
    call it and what the file extension is. But most scrapers don’t download a single
    file and call it a day. The following downloads all internal files, linked to
    by any tag’s `src` attribute, from the home page of *http://pythonscraping.com*:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只需要下载单个文件并知道如何命名它以及文件扩展名是什么，则此方法效果很好。但大多数爬虫不会只下载一个文件并结束。以下内容将从 *http://pythonscraping.com* 的主页下载所有内部文件，这些文件由任何标签的`src`属性链接到：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Run with Caution
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谨慎运行
- en: You know all those warnings you hear about downloading unknown files off the
    internet? This script downloads everything it comes across to your computer’s
    hard drive. This includes random bash scripts, *.exe* files, and other potential
    malware.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道那些关于从互联网下载未知文件的警告吗？这个脚本会将它遇到的一切都下载到您计算机的硬盘上。这包括随机的 bash 脚本、*.exe*文件和其他可能的恶意软件。
- en: Think you’re safe because you’d never actually execute anything sent to your
    downloads folder? Especially if you run this program as an administrator, you’re
    asking for trouble. What happens if you run across a file on a website that sends
    itself to *../../../../usr/bin/python*? The next time you run a Python script
    from the command line, you could be deploying malware on your machine!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你以为自己是安全的，因为你从未真正执行过发送到你的下载文件夹的任何内容吗？特别是如果您以管理员身份运行此程序，您就在自找麻烦。如果您遇到一个发送自身到*../../../../usr/bin/python*的网站文件会发生什么？下次您从命令行运行Python脚本时，您可能会在您的机器上部署恶意软件！
- en: This program is written for illustrative purposes only; it should not be randomly
    deployed without more extensive filename checking, and it should be run only in
    an account with limited permissions. As always, backing up your files, not storing
    sensitive information on your hard drive, and using a little common sense go a
    long way.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本程序仅供示例目的编写；不应随意部署而没有更广泛的文件名检查，并且只应在具有有限权限的帐户中运行。一如既往，备份您的文件，不要将敏感信息存储在硬盘上，并且运用一些常识会事半功倍。
- en: This script uses a lambda function (introduced in [Chapter 5](ch05.html#c-5))
    to select all tags on the front page that have the `src` attribute, and then cleans
    and normalizes the URLs to get an absolute path for each download (making sure
    to discard external links). Then, each file is downloaded to its own path in the
    local folder *downloaded* on your own machine.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本使用了一个 lambda 函数（在[第五章](ch05.html#c-5)介绍）来选择首页上具有`src`属性的所有标签，然后清理和规范化 URL
    以获取每个下载的绝对路径（确保丢弃外部链接）。然后，每个文件都将下载到本地文件夹*downloaded*中的自己的路径上。
- en: Notice that Python’s `os` module is used briefly to retrieve the target directory
    for each download and create missing directories along the path if needed. The
    `os` module acts as an interface between Python and the operating system, allowing
    it to manipulate file paths, create directories, get information about running
    processes and environment variables, and many other useful things.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Python的`os`模块被简要用于检索每个下载的目标目录，并在需要时创建丢失的目录路径。`os`模块充当Python与操作系统之间的接口，允许它操作文件路径，创建目录，获取有关运行进程和环境变量的信息，以及许多其他有用的事情。
- en: Storing Data to CSV
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据存储到 CSV
- en: '*CSV*, or *comma-separated values*, is one of the most popular file formats
    in which to store spreadsheet data. It is supported by Microsoft Excel and many
    other applications because of its simplicity. The following is an example of a
    perfectly valid CSV file:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*CSV*，或称为*逗号分隔值*，是存储电子表格数据的最流行的文件格式之一。由于其简单性，它受到Microsoft Excel和许多其他应用程序的支持。以下是一个完全有效的CSV文件示例：'
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As with Python, whitespace is important here: each row is separated by a newline
    character, while columns within the row are separated by commas (hence the name
    “comma-separated”). Other forms of CSV files (sometimes called *character-separated
    value* files) use tabs or other characters to separate rows, but these file formats
    are less common and less widely supported.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与Python一样，在这里空白字符很重要：每行由换行符分隔，而行内列则由逗号分隔（因此称为“逗号分隔”）。其他形式的CSV文件（有时称为*字符分隔值*文件）使用制表符或其他字符分隔行，但这些文件格式较不常见且支持较少。
- en: If you’re looking to download CSV files directly off the web and store them
    locally, without any parsing or modification, you don’t need this section. Download
    them like you would any other file and save them with the CSV file format by using
    the methods described in the previous section.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望直接从网上下载CSV文件并将其存储在本地，而无需进行任何解析或修改，您不需要阅读这一部分。使用前一部分描述的方法下载它们，就像下载任何其他文件并使用CSV文件格式保存它们一样。
- en: 'Modifying a CSV file, or even creating one entirely from scratch, is extremely
    easy with Python’s *csv* library:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python的*csv*库非常容易修改CSV文件，甚至可以从头开始创建一个：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'A precautionary reminder: file creation in Python is fairly bulletproof. If
    *test.csv* does not already exist, Python will create the file  (but not the directory) automatically.
    If it already exists, Python will overwrite *test.csv* with the new data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 预防性提醒：在Python中创建文件是相当防弹的。如果*test.csv*不存在，Python将自动创建该文件（但不会创建目录）。如果已存在，则Python将用新数据覆盖*test.csv*。
- en: 'After running, you should see a CSV file:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 运行后，您应该会看到一个CSV文件：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'One common web scraping task is to retrieve an HTML table and write it as a
    CSV file. [Wikipedia’s List of Countries with McDonald’s Restaurants](https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants)
    provides a fairly complex HTML table with links, sorting, and other HTML garbage
    that needs to be discarded before it can be written to CSV. Using BeautifulSoup
    and the `get_text()` function copiously, you can do that in fewer than 20 lines:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的网页抓取任务是检索HTML表格并将其写入CSV文件。[维基百科的麦当劳餐厅列表](https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants)提供了一个包含链接、排序和其他HTML垃圾的相当复杂的HTML表格，需要在写入CSV之前将其丢弃。使用BeautifulSoup和`get_text()`函数，您可以在不到20行的代码中完成这一任务：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There Is an Easier Way to Fetch a Single Table
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取单个表格的更简单方法
- en: 'This script is great to integrate into scrapers if you encounter many HTML
    tables that need to be converted to CSV files, or many HTML tables that need to
    be collected into a single CSV file. However, if you only need to do it just once,
    there’s a better tool for that: copying and pasting. Selecting and copying all
    the content of an HTML table and pasting it into Excel or Google Docs will get
    you the CSV file you’re looking for without running a script!'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您经常遇到需要将多个HTML表格转换为CSV文件，或者需要将多个HTML表格收集到单个CSV文件中，这段脚本非常适合集成到爬虫中。然而，如果您只需要做一次，还有更好的工具可用：复制和粘贴。选择并复制HTML表格的所有内容，然后将其粘贴到Excel或Google文档中，即可获得所需的CSV文件，而无需运行脚本！
- en: The result should be a well-formatted CSV file saved locally, at *countries.csv*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是一个保存在本地的格式良好的CSV文件，命名为*countries.csv*。
- en: MySQL
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MySQL
- en: '*MySQL* (officially pronounced “my es-kew-el,” although many say, “my sequel”)
    is the most popular open source relational database management system today. Somewhat
    unusually for an open source project with large competitors, its popularity has
    historically been neck and neck with the two other major closed source database
    systems: Microsoft’s SQL Server and Oracle’s DBMS.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*MySQL*（正式发音为“my es-kew-el”，尽管许多人说“my sequel”）是当今最流行的开源关系数据库管理系统。与其他大型竞争对手相比，它的流行度在历史上一直与两个其他主要的闭源数据库系统：Microsoft的SQL
    Server和Oracle的DBMS齐头并进，这在开源项目中是相当不寻常的。'
- en: 'Its popularity is not without cause. For most applications, it’s hard to go
    wrong with MySQL. It’s a scalable, robust, and full-featured DBMS, used by top
    websites: YouTube,^([1](ch09.html#id556)) Twitter,^([2](ch09.html#id557)) and
    Facebook,^([3](ch09.html#id558)) among many others.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 它的流行不是没有原因的。对于大多数应用程序来说，选择 MySQL 很难出错。它是一个可扩展的、强大的、功能齐全的数据库管理系统，被顶级网站使用：YouTube[^1]、Twitter[^2]
    和 Facebook[^3]，以及许多其他网站。
- en: Because of its ubiquity, price (“free” is a pretty great price), and out-of-box
    usability, it makes a fantastic database for web scraping projects, and we will
    use it throughout the remainder of this book.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 MySQL 的普及性、价格（“免费”是一个非常好的价格）和开箱即用性，它非常适合用于网络抓取项目，并且我们将在本书的余下部分中继续使用它。
- en: Installing MySQL
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 MySQL
- en: 'If you’re new to MySQL, installing a database might sound a little intimidating
    (if you’re an old hat at it, feel free to skip this section). In reality, it’s
    as simple as installing just about any other kind of software. At its core, MySQL
    is powered by a set of data files, stored on your server or local machine, that
    contain all the information stored in your database. The MySQL software layer
    on top of that provides a convenient way of interacting with the data via a command-line
    interface. For example, the following command digs through the data files and
    returns a list of all users in your database whose first name is “Ryan”:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对 MySQL 还不熟悉，安装数据库可能听起来有点吓人（如果你已经很熟悉了，可以跳过这一部分）。实际上，它和安装其他类型的软件一样简单。在核心层面，MySQL
    由一组数据文件驱动，存储在服务器或本地机器上，这些文件包含数据库中存储的所有信息。MySQL 软件层在此基础上提供了通过命令行界面方便地与数据交互的方式。例如，以下命令会浏览数据文件并返回数据库中所有名字为“Ryan”的用户的列表：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you’re on a Debian-based Linux distribution (or anything with `apt-get`),
    installing MySQL is as easy as this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用基于 Debian 的 Linux 发行版（或者任何带有 `apt-get` 的系统），安装 MySQL 就像这样简单：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Just keep an eye on the installation process, approve the memory requirements,
    and enter a new password for your new root user when prompted.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 只需关注安装过程，批准内存要求，并在提示时为新的 root 用户输入新密码即可。
- en: For macOS and Windows, things are a little trickier. If you haven’t already,
    you need to create an Oracle account before downloading the package.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 macOS 和 Windows，情况会有些棘手。如果还没有，请先创建一个 Oracle 账户然后再下载安装包。
- en: If you’re on macOS, you first need to get [the installation package](http://dev.mysql.com/downloads/mysql/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 macOS 上，首先需要获取[安装包](http://dev.mysql.com/downloads/mysql/)。
- en: Select the *.dmg* package, and log in with or create your Oracle account to
    download the file. After the file opens, you should be guided through a fairly
    straightforward installation wizard (see [Figure 9-1](#mac_installer)).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 *.dmg* 包，并使用或创建 Oracle 账户来下载文件。文件打开后，你应该会被引导通过一个相当简单的安装向导（参见[图 9-1](#mac_installer)）。
- en: The default installation steps should suffice, and for the purposes of this
    book, I assume you have a default MySQL installation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的安装步骤应该足够，对于本书的目的，我假设你已经安装了默认的 MySQL。
- en: 'After MySQL is installed on macOS, you can start the MySQL server as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在 macOS 上安装 MySQL 后，可以按照以下步骤启动 MySQL 服务器：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: On Windows, installing and running MySQL is slightly more complicated, but the
    good news is that [a convenient installer](http://dev.mysql.com/downloads/windows/installer/)
    simplifies the process. Once downloaded, it will guide you through the steps you
    need to take (see [Figure 9-2](#mysql_installer)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，安装和运行 MySQL 稍微复杂一些，但好消息是有[一个便捷的安装程序](http://dev.mysql.com/downloads/windows/installer/)简化了这个过程。一旦下载完成，它将指导你完成所需的步骤（参见[图 9-2](#mysql_installer)）。
- en: '![Alt Text](assets/wsp3_0901.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Alt Text](assets/wsp3_0901.png)'
- en: Figure 9-1\. The macOS MySQL installer
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. macOS 上的 MySQL 安装程序
- en: '![Alt Text](assets/wsp3_0902.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![Alt Text](assets/wsp3_0902.png)'
- en: Figure 9-2\. The Windows MySQL Installer
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-2\. Windows 上的 MySQL 安装程序
- en: 'You should be able to install MySQL by using the default selections, with one
    exception: on the Setup Type page, I recommend you choose Server Only to avoid
    installing a lot of additional Microsoft software and libraries. From there, you
    should be able to use the default installation settings and follow the prompts
    to start your MySQL server.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够通过选择默认选项来安装 MySQL，只有一个例外：在设置类型页面上，我建议你选择仅安装服务器，以避免安装大量额外的 Microsoft 软件和库。接下来，你可以使用默认的安装设置并按照提示启动你的
    MySQL 服务器。
- en: 'After your MySQL server is installed and running, you will still need to be
    able to interact with it using the command line. On Windows, you can use the [MySQL
    Shell](https://dev.mysql.com/downloads/shell/) tools. On Macs, I like to install
    the command-line tools with the [Homebrew package manager](https://brew.sh):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 安装并运行 MySQL 服务器后，您仍然需要能够使用命令行与其进行交互。在 Windows 上，您可以使用[MySQL Shell](https://dev.mysql.com/downloads/shell/)工具。在
    Mac 上，我喜欢使用[Homebrew package manager](https://brew.sh)安装命令行工具：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After installing the command-line tools, you should be able to connect to your
    MySQL server:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 安装命令行工具后，您应该能够连接到 MySQL 服务器：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This will prompt you to enter the root password that you created during installation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提示您输入安装过程中创建的根密码。
- en: Some Basic Commands
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一些基本命令
- en: After your MySQL server is running, you have many options for interacting with
    the database. Plenty of software tools act as an intermediary so that you don’t
    have to deal with MySQL commands (or at least deal with them less often). Tools
    such as phpMyAdmin and MySQL Workbench can make it easy to quickly view, sort,
    and insert data. However, it’s still important to know your way around the command
    line.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MySQL 服务器运行后，您有多种选项可以与数据库进行交互。许多软件工具作为中介，使您不必经常处理 MySQL 命令（或至少较少处理）。诸如 phpMyAdmin
    和 MySQL Workbench 的工具可以使快速查看、排序和插入数据变得简单。但是，熟悉命令行操作仍然非常重要。
- en: Except for variable names, MySQL is case insensitive; for example, `SELECT` is
    the same as `sElEcT`. However, by convention, all MySQL keywords are in all caps
    when you are writing a MySQL statement. Conversely, most developers prefer to
    name their tables and databases in lowercase, although this standard is often
    ignored.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 除了变量名外，MySQL 是不区分大小写的；例如，`SELECT` 和 `sElEcT` 是相同的。然而，按照惯例，编写 MySQL 语句时所有 MySQL
    关键字都应为大写。相反，大多数开发者更喜欢将其表和数据库名称使用小写，尽管这种标准经常被忽略。
- en: 'When you first log in to MySQL, there are no databases to add data to, but
    you can create one:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当您首次登录 MySQL 时，还没有数据库可以添加数据，但是您可以创建一个：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Because every MySQL instance can have multiple databases, before you can start
    interacting with a database, you need to specify to MySQL which database you want
    to use:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个 MySQL 实例可以有多个数据库，在您开始与数据库交互之前，您需要告诉 MySQL 您要使用哪个数据库：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: From this point on (at least until you close the MySQL connection or switch
    to another database), all commands entered will be run against the new `scraping`
    database.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从此时起（至少直到您关闭 MySQL 连接或切换到另一个数据库），所有输入的命令都将针对新创建的`scraping`数据库运行。
- en: 'That all seems pretty straightforward. It must be similarly easy to create
    a table in the database, right? Let’s try to create a table to store a collection
    of scraped web pages:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一切看起来都很简单。在数据库中创建表应该也同样简单吧？让我们试着创建一个用于存储抓取的网页集合的表：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This results in an error:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致错误：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Unlike a database, which can exist without any tables, a table in MySQL cannot
    exist without columns. To define columns in MySQL, you must enter them in a comma-delimited
    list, within parentheses, after the `CREATE TABLE <tablename>` statement:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据库可以不含任何表存在不同，MySQL 中的表不能没有列存在。要在 MySQL 中定义列，必须在`CREATE TABLE <tablename>`语句后的括号内输入以逗号分隔的列列表：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Each column definition has three parts:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 每个列定义有三个部分：
- en: The name (`id`, `title`, `created`, etc.)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称（`id`，`title`，`created`，等等）
- en: The variable type (`BIGINT(7)`, `VARCHAR`, `TIMESTAMP`)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量类型（`BIGINT(7)`，`VARCHAR`，`TIMESTAMP`）
- en: Optionally, any additional attributes (`NOT NULL AUTO_INCREMENT`)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选的任何其他属性（`NOT NULL AUTO_INCREMENT`）
- en: At the end of the list of columns, you must define a table’s *key*. MySQL uses
    keys to organize the content in the table for fast lookups. Later in this chapter,
    I’ll describe how to use these keys to your advantage for speedier databases,
    but for now, using a table’s `id` column as the key is generally the best way
    to go.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在列列表的末尾，您必须定义表的*关键字*。MySQL 使用关键字来组织表中的内容，以便进行快速查找。在本章后面，我将描述如何利用这些关键字来加快数据库操作，但现在，通常将表的`id`列作为关键字是最佳选择。
- en: 'After the query executes, you can see what the structure of the table looks
    like at any time by using `DESCRIBE`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 执行查询后，您可以随时使用`DESCRIBE`命令查看表的结构：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Of course, this is still an empty table. You can insert test data into the
    *pages* table by using the following line:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这仍然是一个空表。您可以使用以下命令将测试数据插入到*pages*表中：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Notice that although the table has four columns (`id`, `title`, `content`, `created`),
    you need to define only two of them (`title` and `content`) in order to insert
    a row. That’s because the `id` column is autoincremented (MySQL automatically
    adds a 1 each time a new row is inserted) and generally can take care of itself.
    In addition, the `timestamp` column is set to contain the current time as a default.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管表有四列 (`id`, `title`, `content`, `created`), 但你只需定义其中两列 (`title` 和 `content`)
    就可以插入一行数据。这是因为 `id` 列是自动增加的（每次插入新行时 MySQL 自动添加 1），通常可以自行处理。此外，`timestamp` 列设置为默认包含当前时间。
- en: 'Of course, you *can* override these defaults:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以覆盖这些默认设置：
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As long as the integer you provide for the `id` column doesn’t already exist
    in the database, this override will work perfectly fine. However, it is generally
    bad practice to do this; it’s best to let MySQL handle the `id` and `timestamp`
    columns unless there is a compelling reason to do it differently.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你提供给 `id` 列的整数在数据库中不存在，这个覆盖就可以完美运行。然而，这通常不是一个好的做法；最好让 MySQL 自行处理 `id` 和 `timestamp`
    列，除非有充分的理由要做出不同的处理。
- en: 'Now that you have some data in the table, you can use a wide variety of methods
    to select this data. Here are a few examples of `SELECT` statements:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你的表中有了一些数据，你可以使用多种方法来选择这些数据。以下是几个 `SELECT` 语句的示例：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This statement tells MySQL, “Select all from pages where `id` equals 2.” The
    asterisk (*) acts as a wildcard, returning all the rows where the clause (`where
    id equals 2`) is true. It returns the second row in the table, or an empty result
    if there is no row with an `id` of 2\. For example, the following case-insensitive
    query returns all the rows where the `title` field contains “test” (the % symbol
    acts as a wildcard in MySQL strings):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句告诉 MySQL，“从 `pages` 中选择所有 `id` 等于 2 的行。”星号 (*) 充当通配符，在 `where id equals
    2` 条件为真时返回所有行。它返回表中的第二行，或者如果没有 `id` 等于 2 的行，则返回空结果。例如，以下不区分大小写的查询返回所有 `title`
    字段包含 “test” 的行（% 符号在 MySQL 字符串中充当通配符）：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'But what if you have a table with many columns, and you want only a particular
    piece of data returned? Rather than selecting all, you can do something like this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果你有一张有很多列的表，你只想返回特定的一部分数据怎么办？不必选择全部，你可以像这样做：
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This returns just the `id` and `title` where the content contains the phrase
    “page content.”
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这将只返回包含短语 “page content” 的 `id` 和 `title`。
- en: '`DELETE` statements have much the same syntax as `SELECT` statements:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`DELETE` 语句与 `SELECT` 语句的语法基本相同：'
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For this reason, it is a good idea, especially when working on important databases
    that can’t be easily restored, to write any `DELETE` statements as a `SELECT`
    statement first (in this case, `SELECT * FROM pages WHERE  id = 1`), test to make
    sure only the rows you want to delete are returned, and then replace `SELECT *`
    with `DELETE`. Many programmers have horror stories of miscoding the clause on
    a `DELETE` statement, or worse, leaving it off entirely when they were in a hurry
    and ruining customer data. Don’t let it happen to you!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特别是在处理不能轻易恢复的重要数据库时，最好将任何 `DELETE` 语句首先编写为 `SELECT` 语句（在本例中为 `SELECT * FROM
    pages WHERE  id = 1`），测试以确保只返回要删除的行，然后用 `DELETE` 替换 `SELECT *`。许多程序员有编写 `DELETE`
    语句时错用了条件或更糟糕的是匆忙时完全忽略了它的恐怖故事，导致客户数据丢失。不要让这种情况发生在你身上！
- en: 'Similar precautions should be taken with `UPDATE` statements:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `UPDATE` 语句也应该采取类似的预防措施：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For the purposes of this book, you will be working with only simple MySQL statements,
    doing basic selecting, inserting, and updating. If you’re interested in learning
    more commands and techniques with this powerful database tool, I recommend Paul
    DuBois’s [*MySQL Cookbook*](http://shop.oreilly.com/product/0636920032274.do)
    (O’Reilly).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本书只涉及简单的 MySQL 语句，进行基本的选择、插入和更新。如果你有兴趣学习更多关于这个强大数据库工具的命令和技巧，我推荐 Paul DuBois
    的 [*MySQL Cookbook*](http://shop.oreilly.com/product/0636920032274.do)（O’Reilly）。
- en: Integrating with Python
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 Python 集成
- en: Unfortunately, Python support for MySQL is not built in. However, many open
    source libraries allow you to interact with a MySQL database. One of the most
    popular of these is [PyMySQL](https://pypi.python.org/pypi/PyMySQL).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Python 对于 MySQL 的支持不是内置的。然而，许多开源库允许你与 MySQL 数据库交互。其中最流行的之一是 [PyMySQL](https://pypi.python.org/pypi/PyMySQL)。
- en: 'As of this writing, the current version of PyMySQL is 1.0.3, which can be installed
    using pip:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 截至撰写本文时，PyMySQL 的当前版本是 1.0.3，可以使用 pip 安装：
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After installation, you should have access to the PyMySQL package automatically.
    While your local MySQL server is running, you should be able to execute the following
    script successfully (remember to add the root password for your database):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，你应该自动拥有PyMySQL包的访问权限。当你的本地MySQL服务器运行时，你应该能够成功执行以下脚本（记得为你的数据库添加root密码）：
- en: '[PRE25]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Two new types of objects are at work in this example: the connection object
    (`conn`) and the cursor object (`cur`).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，引入了两种新的对象类型：连接对象（`conn`）和游标对象（`cur`）。
- en: The connection/cursor model is commonly used in database programming, although
    some users might find it tricky to differentiate between the two at first. The
    connection is responsible for, well, connecting to the database, of course, but
    also sending the database information, handling rollbacks (when a query or set
    of queries needs to be aborted and the database needs to be returned to its previous
    state), and creating new cursor objects.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 连接/游标模型在数据库编程中常用，尽管一些用户可能起初会发现区分这两者有些棘手。连接负责连接数据库，当然，还负责发送数据库信息，处理回滚（当需要中止一个查询或一组查询，并且需要将数据库返回到之前的状态时），以及创建新的游标对象。
- en: A connection can have many cursors. A cursor keeps track of certain *state*
    information, such as which database it is using. If you have multiple databases
    and need to write information across all of them, you might have multiple cursors
    to handle this. A cursor also contains the results of the latest query it has
    executed. By calling functions on the cursor, such as `cur.fetchone()`, you can
    access this information.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一个连接可以有多个游标。游标跟踪某些*状态*信息，比如它正在使用哪个数据库。如果你有多个数据库并且需要在所有数据库中写入信息，你可能需要多个游标来处理这个任务。游标还包含它执行的最新查询的结果。通过调用游标的函数，比如`cur.fetchone()`，你可以访问这些信息。
- en: It is important that both the cursor and the connection are closed after you
    are finished using them. Not doing this might result in *connection leaks*, a
    buildup of unclosed connections that are no longer being used, but the software
    isn’t able to close because it’s under the impression that you might still use
    them. This is the sort of thing that brings databases down all the time (I have
    both written and fixed many connection leak bugs), so remember to close your connections!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用完游标和连接后，重要的是要关闭它们。如果不这样做，可能会导致*连接泄漏*，即未关闭的连接会积累起来，虽然不再使用，但软件无法关闭，因为它认为你可能仍在使用它们。这是经常导致数据库故障的问题之一（我既写过也修复过许多连接泄漏的bug），所以记得关闭你的连接！
- en: 'The most common thing you’ll probably want to do, starting out, is to be able
    to store your scraping results in a database. Let’s take a look at how this could
    be done, using a previous example: the Wikipedia scraper.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的事情，你可能一开始想做的就是能够将你的爬取结果存储在数据库中。让我们看看如何实现这一点，使用之前的示例：维基百科爬虫。
- en: 'Dealing with Unicode text can be tough when web scraping. By default, MySQL
    does not handle Unicode. Fortunately, you can turn on this feature (just keep
    in mind that doing so will increase the size of your database). Because you’re
    bound to run into a variety of colorful characters on Wikipedia, now is a good
    time to tell your database to expect some Unicode:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在网页抓取时处理Unicode文本可能会很棘手。默认情况下，MySQL不处理Unicode。幸运的是，你可以启用这个功能（只需记住这样做会增加数据库的大小）。因为你可能会在维基百科上遇到各种丰富多彩的字符，现在是告诉你的数据库期望一些Unicode字符的好时机：
- en: '[PRE26]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: These four lines change the default character set for the database, for the
    table, and for both of the two columns—from `utf8mb4` (still technically Unicode,
    but with notoriously terrible support for most Unicode characters) to `utf8mb4_unicode_ci`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这四行改变了数据库的默认字符集，表格的字符集，以及两列的字符集，从`utf8mb4`（仍然是Unicode，但对大多数Unicode字符的支持非常糟糕）到`utf8mb4_unicode_ci`。
- en: You’ll know that you’re successful if you try inserting a few umlauts or Mandarin
    characters into the `title` or `content` field in the database and it succeeds
    with no errors.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试将几个umlauts或者汉字插入数据库中的`title`或`content`字段，并且成功执行而没有错误，那么你就知道你成功了。
- en: 'Now that the database is prepared to accept a wide variety of all that Wikipedia
    can throw at it, you can run the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据库已经准备好接受维基百科可能投射给它的各种内容，你可以运行以下操作：
- en: '[PRE27]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'There are a few things to note here: first, `"charset=''utf8''"` is added to
    the database connection string. This tells the connection that it should send
    all information to the database as UTF-8 (and, of course, the database should
    already be configured to handle this).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里需要注意几点：首先，在数据库连接字符串中添加了`"charset='utf8'"`。这告诉连接应将所有信息以UTF-8发送到数据库（当然，数据库应已配置为处理此信息）。
- en: Second, note the addition of a `store` function. This takes in two string variables,
    `title` and `content`, and adds them to an `INSERT` statement that is executed
    by the cursor and then committed by the cursor’s connection. This is an excellent
    example of the separation of the cursor and the connection; while the cursor has
    stored information about the database and its own context, it needs to operate
    through the connection in order to send information back to the database and insert
    information.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，注意添加了一个`store`函数。它接收两个字符串变量`title`和`content`，并将它们添加到一个`INSERT`语句中，该语句由游标执行，然后由游标的连接提交。这是游标和连接分离的一个很好的例子；虽然游标存储了关于数据库及其自身上下文的信息，但它需要通过连接操作才能将信息发送回数据库并插入信息。
- en: Last, you’ll see that a `finally` statement is added to the program’s main loop,
    at the bottom of the code. This ensures that, regardless of how the program is
    interrupted or the exceptions that might be thrown during its execution (and because
    the web is messy, you should always assume exceptions will be thrown), the cursor
    and the connection will both be closed immediately before the program ends. It
    is a good idea to include a `try...finally` statement like this whenever you are
    scraping the web and have an open database connection.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你会发现在程序的主循环底部添加了一个`finally`语句。这确保了无论程序如何被中断或其执行过程中可能抛出的异常（因为网络是混乱的，你应该始终假设会抛出异常），在程序结束之前光标和连接都会立即关闭。在进行网络爬取并且有开放的数据库连接时，包括像这样的`try...finally`语句是个好主意。
- en: Although PyMySQL is not a huge package, there are a fair number of useful functions
    that this book can’t accommodate. You can check out their [documentation](https://pymysql.readthedocs.io/en/latest/)
    at the PyMySQL site.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然PyMySQL不是一个庞大的包，但这本书无法涵盖大量有用的功能。你可以在PyMySQL网站的[文档](https://pymysql.readthedocs.io/en/latest/)中查看更多信息。
- en: Database Techniques and Good Practice
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库技术和良好实践
- en: Some people spend their entire careers studying, tuning, and inventing databases.
    I am not one of those people, and this is not that kind of book. However, as with
    many subjects in computer science, there are a few tricks you can learn quickly
    to at least make your databases sufficient, and sufficiently speedy, for most
    applications.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人将他们整个职业生涯都花在研究、调优和发明数据库上。我不是这些人之一，这本书也不是那种类型的书。然而，就计算机科学中的许多主题而言，你可以快速学到一些技巧，至少能使你的数据库对大多数应用程序足够、而且足够快速。
- en: First, with few exceptions, always add `id` columns to your tables. All tables
    in MySQL must have at least one primary key (the key column that MySQL sorts on),
    so that MySQL knows how to order it, and it can often be difficult to choose these
    keys intelligently.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，除了少数例外情况，始终向你的表中添加`id`列。MySQL中的所有表都必须至少有一个主键（MySQL用来排序的关键列），因此MySQL需要知道如何对其进行排序，而且通常难以明智地选择这些键。
- en: The debate over whether to use an artificially created `id` column for this
    key or a unique attribute such as `username` has raged among data scientists and
    software engineers for years, although I tend to lean on the side of creating
    `id` columns. This is *especially* true when you’re dealing with web scraping
    and storing someone else’s data. You have no idea what’s actually unique or not
    unique, and I’ve been surprised before.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 关于是使用人工创建的`id`列作为此键还是像`username`这样的唯一属性的争论已经在数据科学家和软件工程师中持续了多年，虽然我倾向于创建`id`列。尤其是当你处理网页抓取和存储他人数据时，这一点尤为真实。你根本不知道什么是真正独特的或非独特的，我之前也曾感到惊讶。
- en: Your `id` column should be autoincremented and used as the primary key for all
    of your tables.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你的`id`列应该是自增的，并且作为所有表的主键使用。
- en: 'Second, use intelligent indexing. A dictionary (like the book, not the Python
    object) is a list of words indexed alphabetically. This allows quick lookups whenever
    you need a word, as long as you know how it’s spelled. You could also imagine
    a dictionary that is organized alphabetically by the word’s definition. This wouldn’t
    be nearly as useful unless you were playing some strange game of *Jeopardy!* in
    which a definition was presented and you needed to come up with the word. But
    in the world of database lookups, these sorts of situations happen. For example,
    you might have a field in your database that you will often be querying against:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，使用智能索引。一个词典（就像书中的那种，而不是Python对象）是按字母顺序索引的单词列表。这样，每当你需要一个单词时，只要知道它的拼写方式，就可以快速查找。你还可以想象一个根据单词定义按字母顺序排列的词典。除非你在玩某种奇怪的*危险边缘*游戏，需要根据定义找出单词，否则这种词典几乎没有用处。但是在数据库查找中，这类情况确实会发生。例如，你的数据库中可能有一个经常需要查询的字段：
- en: '[PRE28]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You might very well want to add an index to this table (in addition to the
    index presumably already in place on the `id`) to the `definition` column to make
    lookups on this column faster. Keep in mind, though, that adding indexing requires
    more space for the new index, as well as additional processing time when inserting
    new rows. Especially when you’re dealing with large amounts of data, you should
    carefully consider the trade-offs of your indexes and how much you need to index.
    To make this “definitions” index a little lighter, you can tell MySQL to index
    only the first few characters in the column value. This command creates an index
    on the first 16 characters in the `definition` field:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你很可能想要在这个表中添加一个索引（除了已经存在的`id`索引），以使对`definition`列的查找更快速。不过，请记住，添加索引会增加新索引的空间占用，并在插入新行时增加额外的处理时间。特别是当你处理大量数据时，你应仔细考虑索引的权衡以及你需要索引多少的问题。为了使这个“definitions”索引变得更加轻便，你可以告诉MySQL仅对列值中的前16个字符进行索引。这条命令将在`definition`字段的前16个字符上创建一个索引：
- en: '[PRE29]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This index will make your lookups much faster when searching for words by their
    full definition (especially if the first 16 characters in definition values tend
    to be very different from each other), and not add too much in the way of extra
    space and up-front processing time.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要通过完整定义来搜索单词时（尤其是如果定义值的前16个字符彼此非常不同），这个索引将使你的查找速度大大加快，并且不会显著增加额外的空间和前期处理时间。
- en: 'On the subject of query time versus database size (one of the fundamental balancing
    acts in database engineering), one of the common mistakes made, especially with
    web scraping of large amounts of natural text data, is to store lots of repeating
    data. For example, say you want to measure the frequency of certain phrases that
    crop up across websites. These phrases might be found from a given list or automatically
    generated via a text-analysis algorithm. You might be tempted to store the data
    as something like this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 关于查询时间与数据库大小之间的平衡（数据库工程中的基本平衡之一），特别是在大量自然文本数据的网络抓取中，常见的一个错误是存储大量重复数据。例如，假设你想要测量出现在多个网站上的某些短语的频率。这些短语可以从给定列表中找到，也可以通过文本分析算法自动生成。也许你会被诱惑将数据存储为这样的格式：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This adds a row to the database each time you find a phrase on a site and records
    the URL where it was found. However, by splitting the data into three separate
    tables, you can shrink your dataset enormously:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 每次在网站上找到一个短语并记录它所在的URL时，这样会向数据库中添加一行。然而，通过将数据拆分为三个单独的表，你可以极大地减少数据集：
- en: '[PRE31]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Although the table definitions are larger, you can see that the majority of
    the columns are just integer `id` fields. These take up far less space. In addition,
    the full text of each URL and phrase is stored exactly once.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管表定义更大，但你可以看到大多数列只是整数`id`字段，它们占用的空间要少得多。此外，每个URL和短语的完整文本仅存储一次。
- en: 'Unless you install a third-party package or keep meticulous logs, it can be
    impossible to tell when a piece of data was added, updated, or removed from your
    database. Depending on the available space for your data, the frequency of changes,
    and the importance of determining when those changes happened, you might want
    to consider keeping several timestamps in place: `created`, `updated`, and `deleted`.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 除非安装第三方包或保持详细的日志记录，否则无法确定数据何时添加、更新或从数据库中删除。根据数据的可用空间、更改的频率以及确定这些更改发生时间的重要性，你可能需要考虑保留多个时间戳：`created`、`updated`和`deleted`。
- en: “Six Degrees” in MySQL
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'MySQL 中的“六度” '
- en: '[Chapter 6](ch06.html#c-6) introduced the Six Degrees of Wikipedia problem,
    in which the goal is to find the connection between any two Wikipedia articles
    through a series of links (i.e., find a way to get from one Wikipedia article
    to the next just by clicking links from one page to the next). To solve this problem,
    it is necessary not only to build bots that can crawl the site (which you have
    already done) but also store the information in an architecturally sound way to
    make data analysis easy later.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[第六章](ch06.html#c-6)介绍了维基百科的六度问题，即通过一系列链接找到任意两个维基百科文章之间的连接的目标（即，通过从一个页面点击链接到达下一个页面的方式找到一种方法）。要解决这个问题，不仅需要构建可以爬取网站的机器人（这一点你已经做到了），还需要以建筑上合理的方式存储信息，以便以后轻松进行数据分析。'
- en: 'Autoincremented `id` columns, timestamps, and multiple tables: they all come
    into play here. To figure out how to best store this information, you need to
    think abstractly. A link is simply something that connects Page A to Page B. It
    could just as easily connect Page B to Page A, but this would be a separate link.
    You can uniquely identify a link by saying, “There exists a link on page A, which
    connects to page B. That is, `INSERT INTO` links (`fromPageId`, `toPageId`) VALUES
    (A, B); (where A and B are the unique IDs for the two pages).”'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 自增的 `id` 列，时间戳，和多个表格：它们在这里都发挥作用。为了找出如何最好地存储这些信息，你需要抽象地思考。一个链接简单地是连接页面 A 和页面
    B 的东西。它同样可以将页面 B 连接到页面 A，但这将是一个独立的链接。你可以通过说，“在页面 A 上存在一个连接到页面 B 的链接来唯一标识一个链接。也就是说，`INSERT
    INTO` links (`fromPageId`, `toPageId`) VALUES (A, B);（其中 A 和 B 是两个页面的唯一 ID）。”
- en: 'A two-table system designed to store pages and links, along with creation dates
    and unique IDs, can be constructed as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一个旨在存储页面和链接、创建日期和唯一 ID 的两表系统可以按以下方式构建：
- en: '[PRE32]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Notice that, unlike with previous crawlers that print the title of the page,
    you’re not even storing the title of the page in the `pages` table. Why is that?
    Well, recording the title of the page requires that you visit the page to retrieve
    it. If you want to build an efficient web crawler to fill out these tables, you
    want to be able to store the page, as well as links to it, even if you haven’t
    necessarily visited the page yet.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与之前打印页面标题的爬虫不同，你甚至没有将页面标题存储在 `pages` 表中。为什么呢？嗯，记录页面标题需要访问页面以检索它。如果你想要构建一个高效的网络爬虫来填充这些表，你希望能够存储页面以及链接到它的链接，即使你还没有必要访问页面。
- en: Although this doesn’t hold true for all sites, the nice thing about Wikipedia
    links and page titles is that one can be turned into the other through simple
    manipulation. For example, *http://en.wikipedia.org/wiki/Monty_Python* indicates
    that the title of the page is “Monty Python.”
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这并不适用于所有网站，但维基百科链接和页面标题之间的好处在于，一个可以通过简单操作变成另一个。例如，*http://en.wikipedia.org/wiki/Monty_Python*
    表示页面的标题是“蒙提·派森”。
- en: 'The following will store all pages on Wikipedia that have a “Bacon number”
    (the number of links between it and the page for Kevin Bacon, inclusive) of 6
    or less:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下将存储在维基百科上具有“Bacon 数”（与凯文·贝肯页面之间的链接数，包括）小于或等于 6 的所有页面：
- en: '[PRE33]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Three functions here use PyMySQL to interface with the database:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的三个函数使用 PyMySQL 与数据库交互：
- en: '`insertPageIfNotExists`'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`insertPageIfNotExists`'
- en: As its name indicates, this function inserts a new page record if it does not
    exist already. This, along with the running list of all collected pages stored
    in `pages`, ensures that page records are not duplicated. It also serves to look
    up `pageId` numbers in order to create new links.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，如果页面记录尚不存在，此函数将插入一个新的页面记录。这与存储在 `pages` 中的所有收集页面的运行列表一起，确保页面记录不会重复。它还用于查找
    `pageId` 数字以创建新的链接。
- en: '`insertLink`'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`insertLink`'
- en: This creates a new link record in the database. It will not create a link if
    that link already exists. Even if two or more identical links *do* exist on the
    page, for our purposes, they are the same link, represent the same relationship,
    and should be counted as only one record. This also helps maintain the integrity
    of the database if the program is run multiple times, even over the same pages.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这在数据库中创建一个新的链接记录。如果该链接已经存在，它将不会创建一个链接。即使页面上存在两个或多个相同的链接，对于我们的目的来说，它们是同一个链接，代表同一个关系，并且应该被计为一个记录。即使在同一页面上运行多次程序，这也有助于保持数据库的完整性。
- en: '`loadPages`'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`loadPages`'
- en: This loads all current pages from the database into a list, so that it can be
    determined whether a new page should be visited. Pages are also collected during
    runtime, so if this crawler is run only once, starting with an empty database,
    in theory `loadPage` should not be needed. In practice, however, problems may
    arise. The network might go down, or you might want to collect links over several
    periods of time, and it’s important for the crawler to be able to reload itself
    and not lose any ground.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这会将数据库中所有当前页面加载到列表中，以便确定是否应该访问新页面。页面也会在运行时收集，因此如果此爬虫仅运行一次，从空数据库开始理论上不应该需要`loadPage`。然而，实际上可能会出现问题。网络可能会中断，或者您可能希望在几段时间内收集链接，因此爬虫能够重新加载自身并不会失去任何进展是非常重要的。
- en: 'You should be aware of one potentially problematic subtlety of using `loadPages`,
    and the `pages` list it generates, to determine whether or not to visit a page:
    as soon as each page is loaded, all the links on that page are stored as pages,
    even though they have not been visited yet—just their links have been seen. If
    the crawler is stopped and restarted, all of these “seen but not visited” pages
    will never be visited, and links coming from them will not be recorded. This might
    be fixed by adding a boolean `visited` variable to each page record and setting
    it to `True` only if that page has been loaded and its own outgoing links recorded.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该注意使用`loadPages`和它生成的`pages`列表确定是否访问页面时可能出现的一个潜在问题：一旦加载每个页面，该页面上的所有链接都被存储为页面，即使它们尚未被访问——只是它们的链接已被看到。如果爬虫停止并重新启动，所有这些“已看到但未访问”的页面将永远不会被访问，并且来自它们的链接将不会被记录。可以通过向每个页面记录添加布尔变量`visited`并仅在该页面已加载并记录其自身的传出链接时将其设置为`True`来修复此问题。
- en: For our purposes, however, this solution is fine as is. If you can ensure fairly
    long runtimes (or just a single runtime), and it isn’t a necessity to ensure a
    complete set of links (just a large dataset to experiment with), the addition
    of the `visited` variable is not necessary.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于我们的目的来说，目前这个解决方案已经足够了。如果您可以确保相对较长的运行时间（或只需一次运行时间），并且没有必要确保完整的链接集（只需要一个大数据集进行实验），则不需要添加`visited`变量。
- en: 'For the continuation of this problem and the final solution for getting from
    [Kevin Bacon](https://en.wikipedia.org/wiki/Kevin_Bacon) to [Eric Idle](https://en.wikipedia.org/wiki/Eric_Idle),
    see [“Six Degrees of Wikipedia: Conclusion”](ch12.html#six-degrees-conclusion)
    on solving directed graph problems.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于解决从[凯文·贝肯](https://en.wikipedia.org/wiki/Kevin_Bacon)到[埃里克·艾多](https://en.wikipedia.org/wiki/Eric_Idle)的问题的延续以及最终解决方案，请参阅解决有向图问题的[“维基百科的六度：结论”](ch12.html#six-degrees-conclusion)。
- en: Email
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 电子邮件
- en: Just as web pages are sent over HTTP, email is sent over SMTP (Simple Mail Transfer
    Protocol). And just as you use a web server client to handle sending out web pages
    over HTTP, servers use various email clients, such as Sendmail, Postfix, or Mailman,
    to send and receive email.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 就像网页通过HTTP发送一样，电子邮件通过SMTP（简单邮件传输协议）发送。而且就像您使用Web服务器客户端处理通过HTTP发送网页一样，服务器使用各种电子邮件客户端（如Sendmail、Postfix或Mailman）来发送和接收电子邮件。
- en: Although sending email with Python is relatively easy, it does require that
    you have access to a server running SMTP. Setting up an SMTP client on your server
    or local machine is tricky and outside the scope of this book, but many excellent
    resources can help with this task, particularly if you are running Linux or macOS.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用Python发送电子邮件相对简单，但确实需要您可以访问运行SMTP的服务器。在服务器或本地计算机上设置SMTP客户端很棘手，超出了本书的范围，但许多优秀的资源可以帮助完成此任务，特别是如果您正在运行Linux或macOS。
- en: The following code examples assume that you are running an SMTP client locally.
    (To modify this code for a remote SMTP client, change `localhost` to your remote
    server’s address.)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例假设您在本地运行SMTP客户端。（要将此代码修改为远程SMTP客户端，请将`localhost`更改为您的远程服务器地址。）
- en: 'Sending an email with Python requires just nine lines of code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python发送电子邮件仅需九行代码：
- en: '[PRE34]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Python contains two important packages for sending email: *smtplib* and *email*.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Python包含两个重要的包用于发送电子邮件：*smtplib* 和 *email*。
- en: Python’s email module contains useful formatting functions for creating email
    packets to send. The `MIMEText` object, used here, creates an empty email formatted
    for transfer with the low-level MIME (Multipurpose Internet Mail Extensions) protocol,
    across which the higher-level SMTP connections are made. The `MIMEText` object,
    `msg`, contains to/from email addresses, as well as a body and a header, which
    Python uses to create a properly formatted email.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的 email 模块包含用于创建要发送的电子邮件包的有用格式化函数。这里使用的 `MIMEText` 对象创建了一个空的电子邮件，格式化为使用低级
    MIME（多用途互联网邮件扩展）协议进行传输，高级别的 SMTP 连接是在此基础上建立的。`MIMEText` 对象 `msg` 包含了电子邮件的收件人和发件人地址，以及一个主体和一个头部，Python
    使用这些信息来创建一个格式正确的电子邮件。
- en: The smtplib package contains information for handling the connection to the
    server. Just like a connection to a MySQL server, this connection must be torn
    down every time it is created to avoid creating too many connections.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: smtplib 包包含了处理与服务器连接的信息。就像连接到 MySQL 服务器一样，这个连接必须在每次创建时关闭，以避免创建过多的连接。
- en: 'This basic email function can be extended and made more useful by enclosing
    it in a function:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基本的电子邮件功能可以通过将其放在一个函数中来扩展并使其更有用：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This particular script checks the website [*https://isitchristmas.com*](https://isitchristmas.com) (the
    main feature of which is a giant YES or NO, depending on the day of the year)
    once an hour. If it sees anything other than a NO, it will send you an email alerting
    you that it’s Christmas.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定脚本每小时检查一次网站 [*https://isitchristmas.com*](https://isitchristmas.com)（其主要功能是根据一年中的日期显示一个巨大的
    YES 或 NO）。如果它看到的不是 NO，它将发送给您一个警报邮件，提醒您现在是圣诞节。
- en: Although this particular program might not seem much more useful than a calendar
    hanging on your wall, it can be slightly tweaked to do a variety of extremely
    useful things. It can email you alerts in response to site outages, test failures,
    or even the appearance of an out-of-stock product you’re waiting for on Amazon—none
    of which your wall calendar can do.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个特定程序看起来可能比挂在墙上的日历没有多大用处，但它可以稍加调整，做出各种非常有用的事情。它可以在网站停机、测试失败，甚至是你在亚马逊等待的缺货产品出现时向你发送警报邮件——而你的墙挂日历都做不到这些。
- en: ^([1](ch09.html#id556-marker)) Joab Jackson, [“YouTube Scales MySQL with Go
    Code”](http://bit.ly/1LWVmc8), *PCWorld*, December 15, 2012.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09.html#id556-marker)) Joab Jackson，[“YouTube 用 Go 代码扩展 MySQL”](http://bit.ly/1LWVmc8)，*PCWorld*，2012年12月15日。
- en: ^([2](ch09.html#id557-marker)) Jeremy Cole and Davi Arnaut, [“MySQL at Twitter”](http://bit.ly/1KHDKns),
    *The Twitter Engineering Blog*, April 9, 2012.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch09.html#id557-marker)) Jeremy Cole 和 Davi Arnaut，[“Twitter 上的 MySQL”](http://bit.ly/1KHDKns)，*Twitter
    工程博客*，2012年4月9日。
- en: '^([3](ch09.html#id558-marker)) [“MySQL and Database Engineering: Mark Callaghan”](http://on.fb.me/1RFMqvw),
    Facebook Engineering, March 4, 2012.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch09.html#id558-marker)) [“MySQL 和数据库工程：Mark Callaghan”](http://on.fb.me/1RFMqvw)，Facebook
    工程师，2012年3月4日。
