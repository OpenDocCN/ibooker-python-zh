- en: Chapter 5\. Advanced HTML Parsing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章. 高级HTML解析
- en: When Michelangelo was asked how he could sculpt a work of art as masterful as
    his *David*, he is famously reported to have said, “It is easy. You just chip
    away the stone that doesn’t look like David.”
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当有人问到米开朗基罗如何雕刻出像他的*大卫*那样精湛的艺术品时，据说他曾经说过：“很简单。你只需凿掉那些不像大卫的石头。”
- en: Although web scraping is unlike marble sculpting in most other respects, you
    must take a similar attitude when it comes to extracting the information you’re
    seeking from complicated web pages. In this chapter, we’ll explore various techniques
    to chip away any content that doesn’t look like content you want, until you arrive
    at the information you’re seeking. Complicated HTML pages may be look intimidating
    at first, but just keep chipping!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Web抓取在大多数其他方面不像大理石雕刻，但当你试图从复杂的网页中提取你想要的信息时，你必须采取类似的态度。在本章中，我们将探讨各种技术，逐步剔除任何不符合你想要的内容的内容，直到你找到你想要的信息。复杂的HTML页面可能一开始看起来令人生畏，但只要不断地削减！
- en: Another Serving of BeautifulSoup
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BeautifulSoup再次登场
- en: In [Chapter 4](ch04.html#c-4), you took a quick look at installing and running
    BeautifulSoup, as well as selecting objects one at a time. In this section, we’ll
    discuss searching for tags by attributes, working with lists of tags, and navigating
    parse trees.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#c-4)中，您快速了解了安装和运行BeautifulSoup以及逐个选择对象的方法。在本节中，我们将讨论通过属性搜索标记、处理标记列表以及导航解析树。
- en: Nearly every website you encounter contains stylesheets. Stylesheets are created
    so that web browsers can render HTML into colorful and aesthetically pleasing
    designs for humans. You might think of this styling layer as, at the very least,
    perfectly ignorable for web scrapers—but not so fast! CSS is, in fact, a huge
    boon for web scrapers because it requires the differentiation of HTML elements
    in order to style them differently.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您遇到的几乎每个网站都包含样式表。样式表被创建为Web浏览器可以将HTML渲染成丰富多彩和美观的设计。您可能认为这个样式层对于网络爬虫来说至少是可以完全忽略的，但别那么快！实际上，CSS对于网络爬虫来说是一个巨大的助益，因为它要求对HTML元素进行区分，以便以不同的方式对其进行样式设置。
- en: 'CSS provides an incentive for web developers to add tags to HTML elements they
    might have otherwise left with the exact same markup. Some tags might look like
    this:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: CSS为Web开发人员提供了一个激励，让他们为HTML元素添加标签，否则他们可能会使用完全相同的标记。有些标签可能是这样的：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Others look like this:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 其他人可能是这样的：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Web scrapers can easily separate these two tags based on their class; for example,
    they might use BeautifulSoup to grab all the red text but none of the green text.
    Because CSS relies on these identifying attributes to style sites appropriately,
    you are almost guaranteed that these class and id attributes will be plentiful
    on most modern websites.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Web爬虫可以根据它们的类轻松区分这两个标记；例如，它们可以使用BeautifulSoup抓取所有红色文本，但不包括任何绿色文本。由于CSS依赖这些标识属性来适当地设计网站的样式，几乎可以肯定，这些类和id属性在大多数现代网站上都是丰富的。
- en: Let’s create an example web scraper that scrapes the page located at [*http://www.pythonscraping.com/pages/warandpeace.html*](http://www.pythonscraping.com/pages/warandpeace.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个示例网络爬虫，用于爬取位于[*http://www.pythonscraping.com/pages/warandpeace.html*](http://www.pythonscraping.com/pages/warandpeace.html)的页面。
- en: 'On this page, the lines spoken by characters in the story are in red, whereas
    the names of characters are in green. You can see the `span` tags, which reference
    the appropriate CSS classes, in the following sample of the page’s source code:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在此页面上，故事中人物说的台词是红色的，而人物的名字是绿色的。您可以在以下页面源代码示例中看到引用适当CSS类的`span`标记：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can grab the entire page and create a `BeautifulSoup` object with it by
    using a program similar to the one used in [Chapter 4](ch04.html#c-4):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以抓取整个页面并使用它创建一个`BeautifulSoup`对象，方法与[第四章](ch04.html#c-4)中使用的程序类似：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Using this `BeautifulSoup` object, you can use the `find_all` function to extract
    a Python list of proper nouns found by selecting only the text within `<span class="green"></span>`
    tags (`find_all` is an extremely flexible function you’ll be using a lot later
    in this book):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个`BeautifulSoup`对象，您可以使用`find_all`函数提取一个Python列表，其中包含仅选择`<span class="green"></span>`标记内文本的专有名词（`find_all`是一个非常灵活的函数，您将在本书后面经常使用它）：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When run, it should list all the proper nouns in the text, in the order they
    appear in *War and Peace*. How does it work? Previously, you’ve called `bs.tagName`
    to get the first occurrence of that tag on the page. Now, you’re calling `bs.find_all(tagName,
    tagAttributes)` to get a list of all of the tags on the page, rather than just
    the first.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行时，它应该按照 *战争与和平* 中的顺序列出文本中的所有专有名词。它是如何工作的？之前，你调用过 `bs.tagName` 来获取页面上该标签的第一个出现。现在，你调用
    `bs.find_all(tagName, tagAttributes)` 来获取页面上所有该标签的列表，而不仅仅是第一个。
- en: After getting a list of names, the program iterates through all names in the
    list and prints `name.get_text()` in order to separate the content from the tags.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 获取名称列表后，程序遍历列表中的所有名称，并打印 `name.get_text()` 以便将内容与标签分开。
- en: When to get_text() and When to Preserve Tags
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用 get_text() 和何时保留标签
- en: '`.get_text()` strips all tags from the document you are working with and returns
    a Unicode string containing the text only. For example, if you are working with
    a large block of text that contains many hyperlinks, paragraphs, and other tags,
    all those will be stripped away, and you’ll be left with a tagless block of text.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`.get_text()` 从你正在处理的文档中去除所有标签，并返回一个只包含文本的 Unicode 字符串。例如，如果你正在处理一个包含许多超链接、段落和其他标签的大块文本，那么所有这些内容都将被去除，你将得到一个没有标签的文本块。'
- en: Keep in mind that it’s much easier to find what you’re looking for in a BeautifulSoup
    object than in a block of text. Calling `.get_text()` should always be the last
    thing you do, immediately before you print, store, or manipulate your final data.
    In general, you should try to preserve the tag structure of a document as long
    as possible.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在 BeautifulSoup 对象中查找你要找的内容比在一块文本中要容易得多。调用 `.get_text()` 应该总是在最后一步操作之前，即在打印、存储或操作最终数据之前。一般来说，你应该尽量保持文档的标签结构尽可能长时间地存在。
- en: find() and find_all() with BeautifulSoup
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 BeautifulSoup 的 find() 和 find_all()
- en: BeautifulSoup’s `find()` and `find_all()` are the two functions you will likely
    use the most. With them, you can easily filter HTML pages to find lists of desired
    tags, or a single tag, based on their various attributes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: BeautifulSoup 的 `find()` 和 `find_all()` 是你可能会经常使用的两个函数。使用它们可以轻松过滤 HTML 页面，找到所需标签的列表，或者根据它们的不同属性找到单个标签。
- en: 'The two functions are extremely similar, as evidenced by their definitions
    in the BeautifulSoup documentation:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数在 BeautifulSoup 文档中的定义非常相似：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In all likelihood, 95% of the time you will need to use only the first two
    arguments: `tag` and `attrs`. However, let’s take a look at all the parameters
    in greater detail.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，95% 的情况下你只需要使用前两个参数：`tag` 和 `attrs`。然而，我们来更详细地看一下所有参数。
- en: The `tag` parameter is one that you’ve seen before; you can pass a string name
    of a tag or even a Python  list of string tag names. For example, the following
    returns a list of all the header tags in a document:^([1](ch05.html#id413))
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`tag` 参数是你之前见过的；你可以传递一个标签的字符串名称，甚至是一个 Python 列表，其中包含多个标签名。例如，以下代码返回文档中所有标题标签的列表：^([1](ch05.html#id413))'
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Unlike the `tag` parameter, which can be either a string or an iterable, the
    `attrs` parameter must be a Python dictionary of attributes and values. It matches
    tags that contain any one of those attributes. For example, the following function
    would return *both* the green and red `span` tags in the HTML document:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `tag` 参数不同，`attrs` 参数必须是一个 Python 字典，包含属性和值。它匹配包含任何一个这些属性的标签。例如，以下函数将返回 HTML
    文档中的 *绿色* 和 *红色* `span` 标签：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `recursive` parameter is a boolean. How deeply into the document do you
    want to go? If `recursive` is set to `True`, the `find_all` function looks into
    children, and children’s children, etc., for tags that match the parameters. If
    it is `False`, it will look only at the top-level tags in your document. By default,
    `find_all` works recursively (`recursive` is set to `True`). In general, it’s
    a good idea to leave this as is, unless you really know what you need to do and
    performance is an issue.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`recursive` 参数是一个布尔值。你想要深入文档多深？如果将 `recursive` 设置为 `True`，`find_all` 函数将深入到子级、子级的子级等，查找符合参数的标签。如果设置为
    `False`，它将仅查找文档中的顶级标签。默认情况下，`find_all` 递归地工作（`recursive` 设置为 `True`）。通常情况下，除非你确切知道需要做什么并且性能是个问题，否则最好保持这个设置不变。'
- en: 'The `text` parameter is unusual in that it matches based on the text content
    of the tags, rather than properties of the tags themselves. For instance, if you
    want to find the number of times “the prince” is surrounded by tags on the example
    page, you could replace your `.find_all()` function in the previous example with
    the following lines:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`text`参数不同之处在于它基于标签的文本内容进行匹配，而不是标签本身的属性。例如，如果您想要找到“王子”被标签包围的次数，在示例页面上，您可以用以下代码替换之前示例中的`.find_all()`函数：'
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The output of this is 7.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果为7。
- en: The `limit` parameter, of course, is used only in the `find_all` method; `find` is
    equivalent to the same `find_all` call, with a limit of 1.  You might set this
    if you’re interested in retrieving only the first *x* items from the page. Be
    aware that this gives you the first items on the page in the order they occur
    in the document, not necessarily the first ones you want.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，`limit`参数仅在`find_all`方法中使用；`find`等同于使用限制为1的相同`find_all`调用。如果您只对从页面中检索的前*x*个项目感兴趣，则可以设置这个参数。请注意，这会按照文档中它们出现的顺序返回页面上的第一个项目，而不一定是您想要的第一个项目。
- en: 'The additional `kwargs` parameter allows you to pass any additional named arguments
    you want into the method. Any extra arguments that `find` or `find_all` doesn’t
    recognize will be used as tag attribute matchers. For example:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 附加的`kwargs`参数允许您将任何其他命名参数传递给方法。`find`或`find_all`不识别的任何额外参数将用作标签属性匹配器。例如：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This returns the first tag with the word “text” in the `class` attribute and
    “title” in the `id` attribute. Note that, by convention, each value for an `id`
    should be used only once on the page. Therefore, in practice, a line like this
    may not be particularly useful and should be equivalent to using the `find` function:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 返回第一个标签，其`class`属性中包含“text”和`id`属性中包含“title”。请注意，按照惯例，每个`id`值在页面上应该只使用一次。因此，在实践中，像这样的一行可能并不特别有用，并且应等同于使用`find`函数：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You might have noticed that BeautifulSoup already has a way to find tags based
    on their attributes and values: the `attr` parameter. Indeed, the following two
    lines are identical:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，BeautifulSoup已经有了一种根据它们的属性和值查找标签的方法：`attr`参数。实际上，以下两行是相同的：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, the syntax of the first line is shorter and arguably easier to work
    with for quick filters where you need tags by a particular attribute. When filters
    get more complex, or when you need to pass attribute value options as a list in
    the arguments, you may want to use the `attrs` parameter:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，第一行的语法更短，且在需要按特定属性获取标签的快速过滤器时更易于使用。当过滤器变得更复杂，或者当您需要将属性值选项作为参数列表传递时，可能需要使用`attrs`参数：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Other BeautifulSoup Objects
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他BeautifulSoup对象
- en: 'So far in the book, you’ve seen two types of objects in the BeautifulSoup library:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书中，您已经看到BeautifulSoup库中的两种对象类型：
- en: '`BeautifulSoup` objects'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`BeautifulSoup`对象'
- en: Instances seen in previous code examples as the variable `bs`
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码示例中作为变量`bs`出现的实例
- en: '`Tag` objects'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tag`对象'
- en: 'Retrieved in lists, or retrieved individually by calling `find` and `find_all`
    on a `BeautifulSoup` object, or drilling down:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在`BeautifulSoup`对象上调用`find`和`find_all`或深入挖掘，以列表形式检索，或单独检索：
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'However, two more objects in the library, although less commonly used, are
    still important to know about:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，库中还有两个对象，虽然使用较少，但仍然很重要：
- en: '`NavigableString` objects'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`NavigableString`对象'
- en: Used to represent text within tags, rather than the tags themselves (some functions
    operate on and produce `NavigableStrings`, rather than tag objects).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用于表示标签内的文本，而不是标签本身（某些函数操作并生成`NavigableStrings`，而不是标签对象）。
- en: '`Comment` object'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`Comment`对象'
- en: Used to find HTML comments in comment tags, `<!--like this one-->`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 用于查找HTML注释中的注释标签，`<!--like this one-->`。
- en: These are the only four objects in the BeautifulSoup package at the time of
    this writing. These were also the only four objects in the BeautifulSoup package
    when it was released in 2004, so the number of available objects is unlikely to
    change in the near future.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，这些是BeautifulSoup包中唯一的四个对象。当BeautifulSoup包于2004年发布时，这些也是唯一的四个对象，因此在不久的将来可用对象的数量不太可能改变。
- en: Navigating Trees
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导航树
- en: 'The `find_all` function is responsible for finding tags based on their name
    and attributes. But what if you need to find a tag based on its location in a
    document? That’s where tree navigation comes in handy. In [Chapter 4](ch04.html#c-4),
    you looked at navigating a BeautifulSoup tree in a single direction:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`find_all`函数负责根据名称和属性查找标签。但是，如果你需要根据文档中的位置查找标签呢？这就是树导航派上用场的地方。在[第4章](ch04.html#c-4)中，你看过如何在BeautifulSoup树中单向导航：'
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now let’s look at navigating up, across, and diagonally through HTML trees.
    You’ll use our highly questionable online shopping site at *http://www.pythonscraping.com/pages/page3.html*
    as an example page for scraping, as shown in [Figure 5-1](#shopping_screenshot).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在HTML树中向上、横向和斜向导航。你将使用我们极具争议性的在线购物网站[*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html)作为抓取的示例页面，如[图5-1](#shopping_screenshot)所示。
- en: '![Alt Text](assets/wsp3_0501.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![Alt Text](assets/wsp3_0501.png)'
- en: Figure 5-1\. Screenshot from [*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html)
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 来自[*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html)的屏幕截图
- en: 'The HTML for this page, mapped out as a tree (with some tags omitted for brevity),
    looks like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此页面的HTML，作为树形结构映射出来（为简洁起见，某些标签被省略），看起来像这样：
- en: HTML
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML
- en: '`body`'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`body`'
- en: '`div.wrapper`'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`div.wrapper`'
- en: '`h1`'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`h1`'
- en: '`div.content`'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`div.content`'
- en: '`table#giftList`'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table#giftList`'
- en: '`tr`'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tr`'
- en: '`th`'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`th`'
- en: '`th`'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`th`'
- en: '`th`'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`th`'
- en: '`th`'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`th`'
- en: '`tr.gift#gift1`'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tr.gift#gift1`'
- en: '`td`'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`td`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`span.excitingNote`'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`span.excitingNote`'
- en: '`td`'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`td`'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`img`'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img`'
- en: '...table rows continue...'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '...表行继续...'
- en: '`div.footer`'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`div.footer`'
- en: You will use this same HTML structure as an example in the next few sections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你将会在接下来的几节中使用这个相同的HTML结构作为示例。
- en: Dealing with children and other descendants
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理儿童和其他后代
- en: 'In computer science and some branches of mathematics, you often hear about
    horrible things done to children: moving them, storing them, removing them, and
    even killing them. Fortunately, this section focuses only on selecting them!'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学和某些数学分支中，你经常会听说对子代进行的可怕操作：移动它们、存储它们、移除它们，甚至杀死它们。幸运的是，本节仅专注于选择它们！
- en: 'In the BeautifulSoup library, as well as many other libraries, there is a distinction
    drawn between *children* and *descendants*: much like in a human family tree,
    children are always exactly one tag below a parent, whereas descendants can be
    at any level in the tree below a parent. For example, the `tr` tags are children
    of the `table` tag, whereas `tr`, `th`, `td`, `img`, and `span` are all descendants
    of the `table` tag (at least in our example page). All children are descendants,
    but not all descendants are children.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在BeautifulSoup库以及许多其他库中，都区分*子代*和*后代*：就像人类家谱中的情况一样，子代始终位于父代的正下方，而后代可以位于树中父代的任何级别。例如，`tr`标签是`table`标签的子代，而`tr`、`th`、`td`、`img`和`span`都是`table`标签的后代（至少在我们的示例页面中是这样）。所有子代都是后代，但并非所有后代都是子代。
- en: In general, BeautifulSoup functions always deal with the descendants of the
    current tag selected. For instance, `bs.body.h1` selects the first `h1` tag that
    is a descendant of the `body` tag. It will not find tags located outside the body.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，BeautifulSoup函数总是处理当前标签选定的后代。例如，`bs.body.h1`选择的是`body`标签的第一个`h1`标签后代。它不会找到位于body之外的标签。
- en: Similarly, `bs.div.find_all('img')` will find the first `div` tag in the document,
    and then retrieve a list of all `img` tags that are descendants of that `div`
    tag.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，`bs.div.find_all('img')`将会找到文档中第一个`div`标签，然后检索该`div`标签的所有后代`img`标签列表。
- en: 'If you want to find only descendants that are children, you can use the `.children`
    tag:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想找到作为子代的后代，你可以使用`.children`标签：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code prints the list of product rows in the `giftList` table, including
    the initial row of column labels. If you were to write it using the `descendants()`
    function instead of the `children()` function, about two dozen tags would be found
    within the table and printed, including `img` tags, `span` tags, and individual
    `td` tags. It’s definitely important to differentiate between children and descendants!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码打印出`giftList`表中的产品行列表，包括列标签的初始行。如果你使用`descendants()`函数而不是`children()`函数来编写它，将会在表中找到并打印大约二十多个标签，包括`img`标签、`span`标签和单独的`td`标签。区分子代和后代显然非常重要！
- en: Dealing with siblings
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理兄弟节点
- en: 'The BeautifulSoup `next_siblings()` function makes it trivial to collect data
    from tables, especially ones with title rows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: BeautifulSoup的`next_siblings()`函数使得从表格中收集数据变得轻松，特别是带有标题行的表格：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The output of this code is to print all rows of products from the product table,
    except for the first title row. Why does the title row get skipped? Objects cannot
    be siblings with themselves. Anytime you get siblings of an object, the object
    itself will not be included in the list. As the name of the function implies,
    it calls *next* siblings only. If you were to select a row in the middle of the
    list, for example, and call `next_siblings` on it, only the subsequent siblings
    would be returned. So, by selecting the title row and calling `next_siblings`,
    you can select all the rows in the table without selecting the title row itself.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的输出是打印产品表中除第一行标题行之外的所有产品行。为什么标题行被跳过了呢？对象不能与自身为兄弟。每当您获取对象的兄弟时，该对象本身不会包含在列表中。正如函数名称所示，它仅调用
    *next* 兄弟。例如，如果您选择列表中间的一行，并在其上调用 `next_siblings`，那么只会返回随后的兄弟。因此，通过选择标题行并调用 `next_siblings`，您可以选择表中的所有行，而不选择标题行本身。
- en: Make Selections Specific
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使选择更加具体
- en: 'The preceding code will work just as well if you select `bs.table.tr` or even
    just `bs.tr` to select the first row of the table. However, in the code, I go
    to the trouble of writing everything out in a longer form:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要选择表的第一行，上述代码同样有效，无论是选择 `bs.table.tr` 还是仅选择 `bs.tr`。但在代码中，我费力地以更长的形式写出了所有内容：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Even if it looks like there’s just one table (or other target tag) on the page,
    it’s easy to miss things. In addition, page layouts change all the time. What
    was once the first of its kind on the page might someday be the second or third
    tag of that type found on the page. To make your scrapers more robust, it’s best
    to be as specific as possible when making tag selections. Take advantage of tag
    attributes when they are available.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 即使看起来页面上只有一个表（或其他目标标签），也很容易忽略事物。此外，页面布局随时都在变化。曾经是页面上第一个的东西，有一天可能成为页面上第二或第三种类型的标签。为了使您的爬虫更加健壮，最好在进行标签选择时尽可能具体。利用标签属性时要尽量具体。
- en: As a complement to `next_siblings`, the `previous_siblings` function often can
    be helpful if there is an easily selectable tag at the end of a list of sibling
    tags that you would like to get.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 `next_siblings` 的补充，`previous_siblings` 函数通常在您希望获取兄弟标签列表末尾的易于选择的标签时非常有用。
- en: And, of course, there are the `next_sibling` and `previous_sibling` functions,
    which perform nearly the same function as `next_siblings` and `previous_siblings`,
    except they return a single tag rather than a list of them.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有`next_sibling`和`previous_sibling`函数，它们执行的功能几乎与`next_siblings`和`previous_siblings`相同，只是它们返回单个标签而不是列表。
- en: Dealing with parents
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理父元素
- en: 'When scraping pages, you will likely discover that you need to find parents
    of tags less frequently than you need to find their children or siblings. Typically,
    when you look at HTML pages with the goal of crawling them, you start by looking
    at the top layer of tags, and then figure out how to drill your way down into
    the exact piece of data that you want. Occasionally, however, you can find yourself
    in odd situations that require BeautifulSoup’s parent-finding functions, `.parent`
    and `.parents`. For example:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在抓取页面时，您可能会发现需要查找标签的父标签的频率比需要查找它们的子标签或兄弟标签的频率要少。通常，当您查看具有爬行目标的HTML页面时，您首先查看顶层标签，然后想办法深入到您想要的确切数据部分。然而，偶尔可能会遇到需要
    BeautifulSoup 的父查找函数 `.parent` 和 `.parents` 的奇怪情况。例如：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This code will print the price of the object represented by the image at the
    location *../img/gifts/img1.jpg* (in this case, the price is $15.00).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将打印由位置 *../img/gifts/img1.jpg* 表示的图像所代表的对象的价格（在本例中，价格为 $15.00）。
- en: 'How does this work? The following diagram represents the tree structure of
    the portion of the HTML page you are working with, with numbered steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何工作的？以下图示表示您正在处理的HTML页面部分的树形结构，带有编号步骤：
- en: <tr>
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <tr>
- en: '`td`'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`td`'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td`'
- en: '`td` [![3](assets/3.png)](#c03)'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td` [![3](assets/3.png)](#c03)'
- en: '`"$15.00"` **[![4](assets/4.png)](#c04)**'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"$15.00"` **[![4](assets/4.png)](#c04)**'
- en: '`td` [![2](assets/2.png)](#c02)'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`td` [![2](assets/2.png)](#c02)'
- en: '`<img src="../img/gifts/img1.jpg">` [![1](assets/1.png)](#c01)'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<img src="../img/gifts/img1.jpg">` [![1](assets/1.png)](#c01)'
- en: '[![1](assets/1.png)](#comarker1)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#comarker1)'
- en: The image tag where `src="../img/gifts/img1.jpg"` is first selected.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个选择了 `src="../img/gifts/img1.jpg"` 的图像标签。
- en: '[![2](assets/2.png)](#comarker2)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#comarker2)'
- en: You select the parent of that tag (in this case, the `td` tag).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您选择了该标签的父标签（在本例中为 `td` 标签）。
- en: '[![3](assets/3.png)](#comarker3)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#comarker3)'
- en: You select the `previous_sibling` of the `td` tag (in this case, the `td` tag
    that contains the dollar value of the product).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择`td`标签的`previous_sibling`（在这种情况下，包含产品价格的`td`标签）。
- en: '[![4](assets/4.png)](#comarker4)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#comarker4)'
- en: You select the text within that tag `"$15.00"`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择标签内的文本 `"$15.00"`。
- en: Regular Expressions
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式
- en: 'As the old computer science joke goes: “Let’s say you have a problem, and you
    decide to solve it with regular expressions. Well, now you have two problems.”'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 正如一个老的计算机科学笑话所说：“假设你有一个问题，并且你决定用正则表达式来解决它。好吧，现在你有两个问题。”
- en: Unfortunately, regular expressions (often shortened to *regex*) are often taught
    using large tables of random symbols, strung together to look like a lot of nonsense.
    This tends to drive people away, and later they get out into the workforce and
    write needlessly complicated searching and filtering functions in order to avoid
    regex.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，正则表达式（通常缩写为*regex*）通常是用大量随机符号组成的大表格来教授的，看起来像是一堆无意义的东西。这种方法往往会让人望而却步，后来他们进入职场时会编写不必要复杂的搜索和过滤函数以避免使用正则表达式。
- en: Regular expressions are an invaluable tool when it comes to web scraping. Fortunately
    for you, regular expressions are not all that difficult to get up and running
    with quickly, and they can be learned by looking at and experimenting with a few
    simple examples.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到网页抓取时，正则表达式是一个非常宝贵的工具。幸运的是，你不必花费太多时间就能迅速掌握并且可以通过几个简单的例子来学习它们。
- en: '*Regular expressions* are so called because they are used to identify strings
    belonging to a *regular language*. The word “language” here doesn’t mean a language
    in the sense of a programming language or even a natural language (like English
    or French). Instead it is the mathematical sense meaning “a set of strings that
    follow some rules.”'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*正则表达式*之所以被这样称呼，是因为它们用于识别属于*正则语言*的字符串。这里的“语言”并不是指编程语言或者自然语言（比如英语或法语），而是数学上的意义，意味着“一组遵循某些规则的字符串”。'
- en: 'A regular language is the set of strings that can be generated by a set of
    linear rules that can be followed simply while moving along the candidate string
    and matching it to the rules as you go.^([2](ch05.html#id438))  For example:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 正则语言是一组可以通过一组线性规则生成的字符串，简单地沿着候选字符串移动并匹配规则。^([2](ch05.html#id438)) 例如：
- en: Write the letter *a* at least once.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少写下字母*a*。
- en: Append the letter *b* exactly five times.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在末尾添加字母*b*正好五次。
- en: Append to this the letter *c* an even number of times.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在末尾追加字母*c*，偶数次。
- en: Write either the letter *d* or *e* at the end.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在末尾写下字母*d*或*e*。
- en: 'A regular expression can definitively determine: “Yes, this string you’ve given
    me follows the rules,” or “This string does not follow the rules.” This can be
    exceptionally handy for quickly scanning large documents to look for strings that
    look like phone numbers or email addresses.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式可以明确地确定：“是的，这个字符串符合规则”，或者“这个字符串不符合规则”。这对于快速扫描大文档以查找看起来像电话号码或电子邮件地址的字符串非常方便。
- en: Strings that follow the rules above are strings like *aaaabbbbbccccd*, *aabbbbbcce*,
    and so on. There are, mathematically speaking, an infinite number of strings matching
    this pattern.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 符合上述规则的字符串，例如*aaaabbbbbccccd*，*aabbbbbcce*等等，数学上来说，有无限多个符合这种模式的字符串。
- en: 'Regular expressions are merely a shorthand way of expressing these sets of
    rules. For instance, here’s the regular expression for the series of steps just
    described:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式只是一种简写方式来表达这些规则集合。例如，这里就是刚才描述的一系列步骤的正则表达式：
- en: '[PRE19]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This string might seem a little daunting at first, but it becomes clearer when
    you break it into its components:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个字符串一开始可能看起来有点吓人，但当你把它分解成其组成部分时就变得更清晰了：
- en: '*`aa*`*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*`aa*`*'
- en: The letter *a* is written, followed by *a** (read as *a star*), which means
    “any number of a’s, including 0 of them.” In this way, you can guarantee that
    the letter *a* is written at least once.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先写下字母*a*，然后是*a**（读作星号*），意思是“任意数量的a，包括0个”。通过这种方式，你可以确保至少写下字母*a*。
- en: '*`bbbbb`*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*`bbbbb`*'
- en: No special effects here—just five b’s in a row.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有特效，只是连续五个b。
- en: '*`(cc)*`*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*`(cc)*`*'
- en: Any even number of things can be grouped into pairs, so to enforce this rule
    about even things, you can write two c’s, surround them with parentheses, and
    write an asterisk after it, meaning that you can have any number of *pairs* of
    c’s (note that this can mean zero pairs, as well).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 任何偶数个事物都可以成对分组，因此为了强制执行这个关于偶数事物的规则，你可以写两个c，用括号括起来，并在其后写一个星号，表示你可以有任意数量的*c*对（注意这也可以意味着零对）。
- en: '*`(d|e)`*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*`(d|e)`*'
- en: Adding a bar in the middle of two expressions means that it can be “this thing
    *or* that thing.” In this case, you are saying “add a *d* *or* an *e*.” In this
    way, you can guarantee that there is exactly one of either of these two characters.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个表达式中间添加一条竖线意味着它可以是“这个东西*或者*那个东西”。在这种情况下，你是在说“添加一个*d*或者一个*e*”。通过这种方式，你可以确保这两个字符中确切地有一个。
- en: Experimenting with RegEx
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 试验正则表达式
- en: When learning how to write regular expressions, it’s critical to play around
    with them and get a feel for how they work. If you don’t feel like firing up a
    code editor, writing a few lines, and running your program to see whether a regular
    expression works as expected, you can go to a website such as [RegEx Pal](http://regexpal.com/) and
    test your regular expressions on the fly.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当学习如何编写正则表达式时，重要的是要尝试并了解它们的工作原理。如果你不想启动代码编辑器、写几行代码并运行你的程序来查看正则表达式是否按预期工作，你可以去[RegEx
    Pal](http://regexpal.com/)等网站上实时测试你的正则表达式。
- en: '[Table 5-1](#table_2.1) lists commonly used regular expression symbols, with
    brief explanations and examples. This list is by no means complete, and, as mentioned
    before, you might encounter slight variations from language to language. However,
    these 12 symbols are the most commonly used regular expressions in Python and
    can be used to find and collect almost any string type.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-1](#table_2.1) 列出了常用的正则表达式符号及简要解释和示例。这个列表并不完整，正如前面提到的，你可能会在不同的编程语言中遇到略有不同。然而，这12个符号是Python中最常用的正则表达式，几乎可以用来查找和收集任何类型的字符串。'
- en: Table 5-1\. Commonly used regular expression symbols
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-1\. 常用正则表达式符号
- en: '| Symbol(s) | Meaning | Example | Example matches |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 含义 | 示例 | 示例匹配 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| * | Matches the preceding character, subexpression, or bracketed character,
    0 or more times. | a*b* | aaaaaaaa, aaabbbbb, bbbbbb |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| * | 匹配前一个字符、子表达式或括号中的字符，0次或更多次。 | a*b* | aaaaaaaa, aaabbbbb, bbbbbb |'
- en: '| + | Matches the preceding character, subexpression, or bracketed character,
    1 or more times. | a+b+ | aaaaaaaab, aaabbbbb, abbbbbb |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| + | 匹配前一个字符、子表达式或括号中的字符，1次或更多次。 | a+b+ | aaaaaaaab, aaabbbbb, abbbbbb |'
- en: '| [] | Matches any character within the brackets (i.e., “Pick any one of these
    things”). | [A-Z]* | APPLE, CAPITALS,'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '| [] | 匹配括号中的任何字符（即“从这些内容中挑选任意一个”）。 | [A-Z]* | APPLE, CAPITALS,'
- en: QWERTY |
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: QWERTY |
- en: '| () | A grouped subexpression (these are evaluated first, in the “order of
    operations” of regular expressions). | (a*b)* | aaabaab, abaaab, ababaaaaab |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| () | 分组的子表达式（这些按照正则表达式的“运算顺序”首先进行计算）。 | (a*b)* | aaabaab, abaaab, ababaaaaab
    |'
- en: '| {m, n} | Matches the preceding character, subexpression, or bracketed character
    between *m* and *n* times (inclusive). | a{2,3}b{2,3} | aabbb, aaabbb, aabb |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| {m, n} | 匹配前一个字符、子表达式或括号中的字符*m*到*n*次（包括*m*和*n*）。 | a{2,3}b{2,3} | aabbb,
    aaabbb, aabb |'
- en: '| [^] | Matches any single character that is *not* in the brackets. | [^A-Z]*
    | apple, lowercase,'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '| [^] | 匹配不在括号中的任何单个字符。 | [^A-Z]* | apple, lowercase,'
- en: qwerty |
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: qwerty |
- en: '| &#124; | Matches any character, string of characters, or subexpression separated
    by the `I` (note that this is a vertical bar, or *pipe*, not a capital i). | b(a&#124;i&#124;e)d
    | bad, bid, bed |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| &#124; | 匹配任何字符、字符串或由`I`（注意这是一条竖线，或称为*管道*，而不是大写字母i）分隔的子表达式。 | b(a&#124;i&#124;e)d
    | bad, bid, bed |'
- en: '| . | Matches any single character (including symbols, numbers, a space, etc.).
    | b.d | bad, bzd, b$d, b d |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| . | 匹配任何单个字符（包括符号、数字、空格等）。 | b.d | bad, bzd, b$d, b d |'
- en: '| ^ | Indicates that a character or subexpression occurs at the beginning of
    a string. | ^a | apple, asdf, a |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| ^ | 表示字符或子表达式出现在字符串的开头。 | ^a | apple, asdf, a |'
- en: '| \ | An escape character (this allows you to use special characters as their
    literal meanings). | \^ \&#124; \\ | ^ &#124; \ |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| \ | 转义字符（这允许你将特殊字符用作它们的字面意义）。 | \^ \&#124; \\ | ^ &#124; \ |'
- en: '| $ | Often used at the end of a regular expression, it means “match this up
    to the end of the string.” Without it, every regular expression has a de facto
    “.*” at the end of it, accepting strings where only the first part of the string
    matches. This can be thought of as analogous to the ^ symbol. | [A-Z]*[a-z]*$
    | ABCabc, zzzyx, Bob |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| $ | 常用于正则表达式的末尾，表示“匹配直到字符串末尾”。如果没有它，每个正则表达式默认会以“.*”结尾，接受只匹配字符串第一部分的字符串。这可以类比为
    ^ 符号的作用。 | [A-Z]*[a-z]*$ | ABCabc, zzzyx, Bob |'
- en: '| ?! | “Does not contain.” This odd pairing of symbols, immediately preceding
    a character (or regular expression), indicates that that character should not
    be found in that specific place in the larger string. This can be tricky to use;
    after all, the character might be found in a different part of the string. If
    trying to eliminate a character entirely, use in conjunction with a ^ and $ at
    either end. | ^((?![A-Z]).)*$ | no-caps-here, $ymb0ls a4e f!ne |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| ?! | “不包含”。这对奇怪的符号，紧跟在一个字符（或正则表达式）之前，表示在更大的字符串中，该特定位置不应出现该字符。这可能会有些棘手；毕竟，该字符可能出现在字符串的其他部分。如果想要完全排除某个字符，可以与开头的
    ^ 和末尾的 $ 结合使用。 | ^((?![A-Z]).)*$ | no-caps-here, $ymb0ls a4e f!ne |'
- en: 'One classic example of regular expressions can be found in the practice of
    identifying email addresses. Although the exact rules governing email addresses
    vary slightly from mail server to mail server, we can create a few general rules.
    The corresponding regular expression for each of these rules is shown in the second
    column:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式的一个经典示例是识别电子邮件地址的实践。尽管确切的电子邮件地址规则略有不同，但我们可以制定几个通用规则。每个规则对应的正则表达式如下所示：
- en: '|'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rule 1
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 规则 1
- en: 'The first part of an email address contains at least one of the following:
    uppercase letters, lowercase letters, the numbers 0–9, periods (.), plus signs
    (+), or underscores (_).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件地址的第一部分至少包含以下内容之一：大写字母、小写字母、数字 0–9、句点（.）、加号（+）或下划线（_）。
- en: '|'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**[A-Za-z0-9._+]+**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**[A-Za-z0-9._+]+**'
- en: The regular expression shorthand is pretty smart. For example, it knows that
    “A-Z” means “any uppercase letter, A through Z.” By putting all these possible
    sequences and symbols in brackets (as opposed to parentheses), you are saying,
    “This symbol can be any one of these things we’ve listed in the brackets.” Note
    also that the + sign means “these characters can occur as many times as they want
    to but must occur at least once.”
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式的简写是非常聪明的。例如，它知道“A-Z”意味着“从 A 到 Z 的任何大写字母”。通过将所有可能的序列和符号放在方括号中（而不是圆括号中），您在说：“这个符号可以是我们在方括号中列出的任何一个。”还要注意，加号（+）号表示“这些字符可以出现任意次数，但必须至少出现一次。”
- en: '|'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rule 2
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 规则 2
- en: After this, the email address contains the @ symbol.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，电子邮件地址包含 @ 符号。
- en: '|'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**@**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**@**'
- en: 'This is fairly straightforward: the @ symbol must occur in the middle, and
    it must occur exactly once.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当简单：@ 符号必须出现在中间，并且必须恰好出现一次。
- en: '|'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rule 3
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 规则 3
- en: The email address then must contain at least one uppercase or lowercase letter.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 邮件地址必须包含至少一个大写或小写字母。
- en: '|'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**[A-Za-z]+**'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**[A-Za-z]+**'
- en: You may use only letters in the first part of the domain name, after the @ symbol.
    Also, there must be at least one character.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在 @ 符号后的域名的第一部分中只能使用字母，并且必须至少有一个字符。
- en: '|'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rule 4
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 规则 4
- en: This is followed by a period (.).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这之后跟着一个句点（.）。
- en: '|'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**.**'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**.**'
- en: You must include a period (.) before the top-level domain.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶级域名前必须包含一个句点（.）。
- en: '|'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rule 5
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 规则 5
- en: Finally, the email address ends with *com*, *org*, *edu*, or *net* (in reality,
    there are many possible top-level domains, but these four should suffice for the
    sake of example).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，电子邮件地址以 *com*, *org*, *edu* 或 *net* 结尾（实际上，顶级域名有很多可能，但这四个例子足够说明问题）。
- en: '|'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**(com&#124;org&#124;edu&#124;net)**'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '**(com&#124;org&#124;edu&#124;net)**'
- en: This lists the possible sequences of letters that can occur after the period
    in the second part of an email address.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这列出了电子邮件地址第二部分中句点后可能出现的字母序列。
- en: '|'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'By concatenating all of the rules, you arrive at this regular expression:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有规则连接起来，可以得到这个正则表达式：
- en: '[PRE20]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When attempting to write any regular expression from scratch, it’s best to first
    make a list of steps that concretely outlines what your target string looks like.
    Pay attention to edge cases. For instance, if you’re identifying phone numbers,
    are you considering country codes and extensions?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当试图从头开始编写任何正则表达式时，最好首先列出一系列具体步骤，明确说明你的目标字符串的样子。注意边缘情况。例如，如果你正在识别电话号码，你是否考虑了国家代码和分机号码？
- en: 'Regular Expressions: Not Always Regular!'
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式：并非总是规则的！
- en: The standard version of regular expressions (the one covered in this book and
    used by Python and BeautifulSoup) is based on syntax used by Perl. Most modern
    programming languages use this or one similar to it. Be aware, however, that if
    you are using regular expressions in another language, you might encounter problems.
    Even some modern languages, such as Java, have slight differences in the way they
    handle regular expressions. When in doubt, read the docs!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式的标准版本（本书涵盖的版本并由 Python 和 BeautifulSoup 使用）基于 Perl 使用的语法。大多数现代编程语言使用这个或类似的语法。然而，请注意，如果您在另一种语言中使用正则表达式，可能会遇到问题。甚至一些现代语言，如
    Java，在处理正则表达式时也有细微差异。如果有疑问，请阅读文档！
- en: Regular Expressions and BeautifulSoup
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则表达式和 BeautifulSoup
- en: If the previous section on regular expressions seemed a little disjointed from
    the mission of this book, here’s where it all ties together. BeautifulSoup and
    regular expressions go hand in hand when it comes to scraping the web. In fact,
    most functions that take in a string argument (e.g., `find(id="aTagIdHere")`)
    will also take in a regular expression just as well.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前一节关于正则表达式的内容似乎与本书的任务有些脱节，那么这就是它们之间的联系。BeautifulSoup 和正则表达式在网页抓取方面是密不可分的。事实上，大多数接受字符串参数的函数（例如
    `find(id="aTagIdHere")`）同样也可以接受正则表达式。
- en: Let’s take a look at some examples, scraping the page found at [*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些例子，抓取[*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html)
    所找到的页面。
- en: 'Notice that the site has many product images, which take the following form:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，该网站有许多产品图片，其形式如下：
- en: '[PRE21]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'If you wanted to grab URLs of all of the product images, it might seem fairly
    straightforward at first: just grab all the image tags by using `.find_all("img")`,
    right? But there’s a problem. In addition to the obvious “extra” images (e.g.,
    logos), modern websites often have hidden images, blank images used for spacing
    and aligning elements, and other random image tags you might not be aware of.
    Certainly, you can’t count on the only images on the page being product images.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要抓取所有产品图片的 URL，一开始似乎相当简单：只需使用 `.find_all("img")` 来抓取所有图像标签，对吗？但是有一个问题。除了明显的“额外”图像（例如标志），现代网站经常还有隐藏的图像，用于间隔和对齐元素的空白图像，以及其他您可能不知道的随机图像标签。当然，你不能指望页面上唯一的图像是产品图像。
- en: Let’s also assume that the layout of the page might change, or that, for whatever
    reason, you don’t want to depend on the *position* of the image in the page in
    order to find the correct tag. This might be the case when you are trying to grab
    specific elements or pieces of data that are scattered randomly throughout a website.
    For instance, a featured product image might appear in a special layout at the
    top of some pages but not others.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 假设页面的布局可能会发生变化，或者出于某种原因，你不想依赖于图像在页面中的*位置*来找到正确的标签。当你试图抓取分散在网站各处的特定元素或数据片段时，情况可能是这样的。例如，一个特色产品图片可能会出现在某些页面顶部的特殊布局中，但在其他页面中则不会。
- en: 'The solution is to look for something identifying about the tag itself. In
    this case, you can look at the file path of the product images:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是查找标签本身的某些特征。在这种情况下，你可以查看产品图片的文件路径：
- en: '[PRE22]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This prints only the relative image paths that start with *../img/gifts/img*
    and end in *.jpg*, the output of which is:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅打印以*../img/gifts/img*开头并以*.jpg*结尾的相对图像路径，其输出为：
- en: '[PRE23]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: A regular expression can be inserted as any argument in a BeautifulSoup expression,
    allowing you a great deal of flexibility in finding target elements.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式可以作为 BeautifulSoup 表达式中的任何参数插入，从而允许你以很大的灵活性来找到目标元素。
- en: Accessing Attributes
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问属性
- en: So far, you’ve looked at how to access and filter tags and access content within
    them. However, often in web scraping you’re not looking for the content of a tag;
    you’re looking for its attributes. This becomes especially useful for tags such
    as `a`, where the URL it is pointing to is contained within the `href` attribute;
    or the `img` tag, where the target image is contained within the `src` attribute.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学会了如何访问和过滤标签以及访问其中的内容。然而，在网页抓取中，通常你不是在寻找标签的内容，而是在寻找它们的属性。这对于诸如`a`标签特别有用，它指向的URL包含在`href`属性中；或者`img`标签，其中目标图像包含在`src`属性中。
- en: 'With tag objects, a Python list of attributes can be automatically accessed
    by calling this:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标签对象，可以通过调用这个来自动访问Python列表的属性：
- en: '[PRE24]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Keep in mind that this literally returns a Python dictionary object, which
    makes retrieval and manipulation of these attributes trivial. The source location
    for an image, for example, can be found using the following line:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这实际上返回一个Python字典对象，这使得检索和操作这些属性变得轻而易举。例如，可以使用以下行找到图像的源位置：
- en: '[PRE25]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Lambda Expressions
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lambda表达式
- en: '*Lambda* is a fancy academic term that, in programming, simply means “a shorthand
    way of writing a function.” In Python, we might write a function that returns
    the square of a number as:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '*Lambda*是一个花哨的学术术语，在编程中，它简单地意味着“一种编写函数的简便方法”。在Python中，我们可以编写一个返回一个数的平方的函数如下：'
- en: '[PRE26]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We could use a lambda expression to do the same thing in one line:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用lambda表达式在一行内完成同样的事情：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This assigns the variable `square` directly to a function that takes in a single
    argument `n` and returns `n**2`. But there’s no rule that says functions have
    to be “named” or assigned to variables at all. We can simply write them as values:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 此处将变量`square`直接分配给一个函数，该函数接受一个参数`n`并返回`n**2`。但并没有规定函数必须“命名”或者根本不分配给变量。我们可以将它们作为值来编写：
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Essentially, a *lambda expression* is a function that exists alone, without
    being named or assigned to a variable. In Python, a lambda function cannot have
    more than one line of code (this is a matter of style and good taste on Python’s
    part, rather than some fundamental rule of computer science, however).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，*lambda表达式*是一个独立存在的函数，没有被命名或分配给变量。在Python中，lambda函数不能超过一行代码（这是Python风格和良好品味的问题，而不是计算机科学的一项基本规则）。
- en: The most common use of lambda expressions is an argument passed in to other
    functions. BeautifulSoup allows you to pass certain types of functions as parameters
    into the `find_all` function.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: lambda表达式最常见的用途是作为传递给其他函数的参数。BeautifulSoup允许你将某些类型的函数作为参数传递到`find_all`函数中。
- en: The only restriction is that these functions must take a tag object as an argument
    and return a boolean. Every tag object that BeautifulSoup encounters is evaluated
    in this function, and tags that evaluate to `True` are returned, while the rest
    are discarded.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的限制是这些函数必须接受一个标签对象作为参数，并返回一个布尔值。BeautifulSoup遇到的每个标签对象都在此函数中评估，评估为`True`的标签被返回，其余被丢弃。
- en: 'For example, the following retrieves all tags that have exactly two attributes:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码检索所有具有恰好两个属性的标签：
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here, the function that you are passing as the argument is `len(tag.attrs)
    == 2`. Where this is `True`, the  `find_all` function will return the tag. That
    is, it will find tags with two attributes, such as:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，作为参数传递的函数是`len(tag.attrs) == 2`。当这个条件成立时，`find_all`函数将返回该标签。也就是说，它会找到具有两个属性的标签，例如：
- en: '[PRE30]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Lambda functions are so useful you can even use them to replace existing BeautifulSoup
    functions:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数非常有用，你甚至可以使用它们来替换现有的BeautifulSoup函数：
- en: '[PRE31]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This also can be accomplished without a lambda function:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以不使用lambda函数来完成：
- en: '[PRE32]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: However, if you remember the syntax for the lambda function, and how to access
    tag properties, you may never need to remember any other BeautifulSoup syntax
    again!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你记得lambda函数的语法以及如何访问标签属性，你可能再也不需要记住任何其他BeautifulSoup语法了！
- en: Because the provided lambda function can be any function that returns a `True`
    or `False` value, you can even combine them with regular expressions to find tags
    with an attribute matching a certain string pattern.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 因为提供的lambda函数可以是返回`True`或`False`值的任何函数，你甚至可以将它们与正则表达式结合起来，以找到具有匹配特定字符串模式的属性的标签。
- en: You Don’t Always Need a Hammer
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你不总是需要一把锤子
- en: It can be tempting, when faced with a Gordian knot of tags, to dive right in
    and use multiline statements to try to extract your information. However, keep
    in mind that layering the techniques used in this chapter with reckless abandon
    can lead to code that is difficult to debug, fragile, or both. Let’s look at some
    of the ways you can avoid altogether the need for advanced HTML parsing.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 当面对一团复杂的标签时，直接潜入并使用多行语句来提取信息是很诱人的。然而，请记住，放任这一章节中使用的技术层叠可能会导致难以调试或脆弱的代码。让我们看看一些可以避免需要高级
    HTML 解析的方法。
- en: 'Let’s say you have some target content. Maybe it’s a name, statistic, or block
    of text. Maybe it’s buried 20 tags deep in an HTML mush with no helpful tags or
    HTML attributes to be found. You may decide to throw caution to the wind and write
    something like the following line to attempt extraction:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一些目标内容。也许是一个名字、统计数据或者一段文字。也许它被深深埋在 HTML 混乱中，没有有用的标签或者 HTML 属性。你可能会决定冒险一试，写下像以下这样的代码尝试提取：
- en: '[PRE33]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: That doesn’t look so great. In addition to the aesthetics of the line, even
    the slightest change to the website by a site administrator might break your web
    scraper altogether. What if the site’s web developer decides to add another table
    or another column of data? What if the developer adds another component (with
    a few `div` tags) to the top of the page? The preceding line is precarious and
    depends on the structure of the site never changing.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不太好。除了行的美观度之外，即使网站管理员对网站进行了微小的更改，也可能会完全破坏你的网络爬虫。如果站点的 Web 开发人员决定添加另一个表或另一列数据，该怎么办？如果开发人员在页面顶部添加了另一个组件（带有几个`div`标签），前面的行就会变得岌岌可危，依赖于网站结构永远不会改变。
- en: So what are your options?
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你有哪些选择？
- en: Look for any “landmarks” that you can use to jump right into the middle of the
    document, closer to the content that you actually want. Convenient CSS attributes
    are an obvious landmark, but you can also get creative and grab tags by their
    content using `.find_all(text='some tag content')` in a pinch.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找任何可以用来直接跳到文档中间位置的“地标”，更接近你实际想要的内容。方便的 CSS 属性是一个明显的地标，但你也可以创造性地通过`.find_all(text='some
    tag content')`来获取标签的内容。
- en: If there’s no easy way to isolate the tag you want or any of its parents, can
    you find a sibling? Use the `.parent` method and then drill back down to the target
    tag.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有简单的方法来分离你想要的标签或其任何父级，你能找到一个兄弟节点吗？使用`.parent`方法，然后再深入到目标标签。
- en: Abandon this document altogether and look for a “Print This Page” link, or perhaps
    a mobile version of the site that has better-formatted HTML (more on presenting
    yourself as a mobile device—and receiving mobile site versions—in [Chapter 17](ch17.html#c-17)).
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全放弃这个文档，寻找“打印本页”链接，或者可能有更好格式的移动版网站（关于如何呈现自己为移动设备，并接收移动网站版本，请参见[第17章](ch17.html#c-17)）。
- en: Don’t ignore the content in the `<script>` tags or separately loaded JavaScript
    files. JavaScript often contains the data that you’re looking for and in a nicer
    format! For example, I once collected nicely formatted street addresses from a
    website by examining the JavaScript for an embedded Google Maps application. For
    more information about this technique, see [Chapter 11](ch11.html#c-11).
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忽视`<script>`标签中的内容或单独加载的 JavaScript 文件。JavaScript 通常包含你正在寻找的数据，并且格式更好！例如，我曾通过检查嵌入的
    Google 地图应用程序的 JavaScript，从一个网站收集了格式良好的街道地址。有关此技术的更多信息，请参阅[第11章](ch11.html#c-11)。
- en: Information might be available in the URL of the page itself. For example, page
    titles and product IDs can often be found there.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息可能可以在页面的 URL 中找到。例如，页面标题和产品 ID 通常可以在那里找到。
- en: If the information you are looking for is unique to this website for some reason,
    you’re out of luck. If not, try to think of other sources you could get this information
    from. Is there another website with the same data? Is this website displaying
    data that it scraped or aggregated from another website?
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在寻找的信息由于某种原因只在这个网站上唯一，那你就没戏了。如果不是，请考虑其他可能来源的信息。是否有另一个网站有相同的数据？这个网站是否展示了从另一个网站抓取或聚合的数据？
- en: Especially when you are faced with buried or poorly formatted data, it’s important
    not to just start digging and write yourself into a hole that you might not be
    able to get out of. Take a deep breath and think of alternatives.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是当面对埋藏或格式混乱的数据时，重要的是不要只是开始挖掘并把自己写入一个可能无法走出的困境中。深呼吸，考虑一些替代方案。
- en: The techniques presented here, when used correctly, will go a long way toward
    writing more stable and reliable web crawlers.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 当正确使用时，这里介绍的技术将在很大程度上有助于编写更稳定可靠的网络爬虫。
- en: ^([1](ch05.html#id413-marker)) If you’re looking to get a list of all `h<*some_level*>`
    tags in the document, there are more succinct ways of writing this code to accomplish
    the same thing. We’ll take a look at other ways of approaching these types of
    problems in the section [“Regular Expressions and BeautifulSoup”](#reg_expressions).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.html#id413-marker)) 如果你想要获取文档中所有`h<*some_level*>`标签的列表，有更简洁的编写这段代码以完成相同任务的方法。我们将在[“正则表达式和BeautifulSoup”](#reg_expressions)一节中看看其他解决这类问题的方法。
- en: ^([2](ch05.html#id438-marker)) You might be asking yourself, “Are there ‘irregular’
    languages and irregular expressions?” Nonregular expressions are beyond the scope
    of this book, but they encompass strings such as “write a prime number of a’s,
    followed by exactly twice that number of b’s” or “write a palindrome.” It’s impossible
    to identify strings of this type with a regular expression. Fortunately, I’ve
    never been in a situation where my web scraper needed to identify these kinds
    of strings.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch05.html#id438-marker)) 也许你会问自己，“有‘不规则’的语言和不规则表达式吗？” 非正则表达式超出了本书的范围，但它们包括诸如“写下一串a的质数，然后是正好两倍于该数的b”的字符串或“写下一个回文”。
    使用正则表达式无法识别这种类型的字符串。 幸运的是，我从未遇到过我的网络爬虫需要识别这种字符串的情况。
