- en: Chapter 11\. Working with Dirty Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章\. 处理脏数据
- en: So far in this book, I’ve ignored the problem of badly formatted data by using
    generally well-formatted data sources, dropping data entirely if it deviated from
    what was expected. But, in web scraping, you often can’t be too picky about where
    you get your data, or what it looks like.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我通过使用通常格式良好的数据源，如果数据偏离预期，则完全删除数据，忽略了格式不良的数据问题。但是，在网络抓取中，您通常无法太挑剔数据的来源或其外观。
- en: Because of errant punctuation, inconsistent capitalization, line breaks, and
    misspellings, dirty data can be a big problem on the web. This chapter covers
    a few tools and techniques to help you prevent the problem at the source by changing
    the way you write code and cleaning the data after it’s in the database.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于错误的标点符号、不一致的大写、换行和拼写错误，脏数据在网络上可能是一个大问题。本章介绍了一些工具和技术，帮助您通过更改编码方式和在数据进入数据库后清理数据，从根源上预防问题。
- en: This is the chapter where web scraping intersects with its close relative, data
    science. While the job title of “data scientist” might conjure mental images of
    cutting-edge programming techniques and advanced mathematics, the truth is that
    a lot of it is grunt work. Someone has to clean and normalize these millions of
    records before they can be used to build a machine learning model, and that person
    is the data scientist.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是网络抓取与其近亲数据科学交汇的章节。虽然“数据科学家”这个职称可能让人联想到先进的编程技术和高级数学，但事实上，大部分工作是苦工活。在能够用于构建机器学习模型之前，某人必须清理和规范这些数百万条记录，这就是数据科学家的工作。
- en: Cleaning Text
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本清理
- en: 'Python is a programming language that lends itself very well to text processing.
    It’s easy to write clean, functional, modular code to do even complex text processing
    projects. With the following code, we can scrape text from the Wikipedia article
    on Python at [*http://en.wikipedia.org/wiki/Python_(programming_language)*](http://en.wikipedia.org/wiki/Python_(programming_language)):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种非常适合文本处理的编程语言。您可以轻松编写干净、功能性、模块化的代码，甚至处理复杂的文本处理项目。使用以下代码，我们可以从维基百科关于
    Python 的文章中获取文本[*http://en.wikipedia.org/wiki/Python_(programming_language)*](http://en.wikipedia.org/wiki/Python_(programming_language))：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This content begins:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此内容开始：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will perform several actions on this text:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对这段文本执行几项操作：
- en: Remove citations, of the form “[123]”
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除形式为“[123]”的引用
- en: Remove newline characters
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除换行符
- en: Split the text into sentences
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本分割为句子
- en: Remove any parenthesized text containing an aside in the middle of a sentence
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除句子中含有旁注的括号文本
- en: Remove descriptions of illustrations not included in the text
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除文本中未包含的插图描述
- en: Make text lowercase
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本转换为小写
- en: Remove all punctuation
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除所有标点符号
- en: It’s important to note that these functions must be applied in a particular
    order. For instance, removing punctuation (including square brackets) would make
    it difficult to identify and remove citations later on. Removing punctuation and
    making all text lowercase would also make it impossible to split the text into
    sentences.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这些函数必须按特定顺序应用。例如，如果删除标点符号（包括方括号），将难以识别和删除后续的引用。删除标点符号并将所有文本转换为小写后，也将无法将文本拆分为句子。
- en: 'The functions for removing newline characters and making the text lowercase
    are fairly straightforward:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 删除换行符和将文本转换为小写的函数非常简单：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here the newlines are replaced with a space character (“ ”) rather than removed
    altogether to avoid text like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里换行用空格字符（“ ”）替换，而不是完全删除，以避免出现这样的文本：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'being turned into text like this:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 被转换为以下文本：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Inserting the space ensures that all sentences still get a space between them.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 插入空格可以确保所有句子之间仍然有空格。
- en: 'With this in mind, we can write the function for splitting sentences:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个想法，我们可以编写分割句子的函数：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Rather than splitting simply on the period, we split on the period and a space.
    This prevents decimals, for instance in the ubiquitous “Python 2.5,” or code examples
    like:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是简单地在句号上进行拆分，而是在句号和空格上进行拆分。这可以避免出现小数，例如普遍存在的“Python 2.5”，或者代码示例如：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: from being split erroneously into sentences. In addition, we want to make sure
    that any double-spaced or otherwise odd sentences are cleaned by stripping each
    leading or trailing whitespace using the `strip` function before returning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 防止被错误地分割成句子。此外，我们希望确保任何双空格或其他奇怪的句子都通过在返回之前使用`strip`函数去除每个前导或尾随空格来进行清理。
- en: 'However, `split_sentences` can’t be called right away. Many sentences contain
    citations immediately after them:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，不能立即调用 `split_sentences`。许多句子紧随其后引用：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The function for removing citations can be written like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 删除引用的函数可以写成这样：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The variable name `CITATION_REGEX` is written in uppercase, indicating that
    it’s a constant, and pre-compiled outside of the function itself. The function
    could also be written as:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 变量名 `CITATION_REGEX` 采用大写，表示它是一个常量，并且在函数本身之外预先编译。函数也可以写成这样：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: However, this forces Python to recompile this regular expression every time
    the function is run (which could be thousands or millions of times, depending
    on the project), rather than having it pre-compiled and ready to go. While the
    speed of the program is not necessarily a significant bottleneck in web scraping,
    pre-compiling regular expressions outside of functions is easy to do and allows
    you to document the code through an appropriate variable name for the regular
    expression.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这会强制 Python 每次运行函数时重新编译这个正则表达式（这可能是成千上万次，具体取决于项目），而不是预先编译好并准备好使用。虽然程序的速度在网页抓取中并不一定是一个显著的瓶颈，但在函数外预先编译正则表达式非常容易实现，并允许您通过合适的变量名来文档化代码中的正则表达式。
- en: 'Removing parenthesized text, such as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 删除括号文本，例如：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'and:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 和：
- en: '[PRE11]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'is a similar pattern to removing the citations. A good first approach might
    be:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于删除引用也是一种类似的模式。一个很好的初步方法可能是：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Indeed, this does remove parenthesized text in the examples above, but it also
    removes anything in parentheses from sections like:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，这确实从上述示例中删除了括号文本，但它也从像这样的部分中删除了括号内的任何内容：
- en: '[PRE13]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In addition, it presents a danger if there are unmatched parentheses in the
    text. An opening parenthesis may cause large sections of text to be removed the
    next time any sort of closing parenthesis is found.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果文本中存在不匹配的括号，会存在危险。开放括号可能导致在找到任何形式的闭合括号时，大段文本被移除。
- en: 'To solve this, we can examine the types of characters generally seen in parenthesized
    text, look only for them, and limit the length of that parenthesized text:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以检查括号文本中通常见到的字符类型，仅查找它们，并限制括号文本的长度：
- en: '[PRE14]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Occasionally, descriptions of illustrations not extracted in the text might
    be present. For example:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔，文本中可能存在未提取的插图描述。例如：
- en: '[PRE15]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: which precedes a block of code not extracted in text.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 它前面是一段未提取出来的代码块。
- en: 'These descriptions are generally short, start with a newline, contain only
    letters, and end with a colon. We can remove them with a regular expression:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些描述通常很短，以换行符开头，只包含字母，并以冒号结尾。我们可以使用正则表达式删除它们：
- en: '[PRE16]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: At this point, we can remove the punctuation. Because so many of the previous
    steps depend on punctuation to be present in order to identify what text to keep
    and what to remove, stripping the punctuation is generally one of the last steps
    of any text cleaning task.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以删除标点符号。因为许多前面的步骤依赖于标点符号的存在来确定哪些文本保留哪些删除，所以剥离标点符号通常是任何文本清理任务的最后一步。
- en: '[Python’s string module](https://docs.python.org/3/library/string.html) contains
    many handy sets of characters, one of which is `string.punctuation`. This is a
    set of all the ASCII punctuation:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[Python 字符串模块](https://docs.python.org/3/library/string.html) 包含许多方便的字符集合，其中之一是
    `string.punctuation`。这是所有 ASCII 标点符号的集合：'
- en: '[PRE17]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can take this string containing all ASCII punctuation and turn it into a
    regular expression using `re.escape` (which escapes any reserved regular expression
    symbols) and joining everything with a `|` character:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `re.escape`（它转义任何保留的正则表达式符号）和用 `|` 字符连接所有 ASCII 标点的字符串，将其转换为正则表达式：
- en: '[PRE18]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'It’s common, with all this string manipulation, for unicode characters to become
    misrepresented in the string. Especially common is the unicode “nonbreaking space”
    which is represented by a `&nbsp;` in HTML and can be found frequently in text
    on the web. This can be seen in our Wikipedia text printed out as `\xa0`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些字符串操作中，Unicode 字符往往会在字符串中被错误表示。特别常见的是 Unicode 的“不间断空格”，在 HTML 中表示为 `&nbsp;`，在网页文本中经常可以找到。我们在
    Wikipedia 文本中打印出来可以看到它显示为 `\xa0`：
- en: '[PRE19]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Regardless of which strange characters you encounter, you can fix them with
    Python’s `unicodedata` package. Normalizing unicode characters will be the final
    step in cleaning the text:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 无论遇到哪些奇怪的字符，都可以使用 Python 的 `unicodedata` 包来修复它们。规范化 Unicode 字符将是清理文本的最后一步：
- en: '[PRE20]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'At this point, you have a set of short, well-organized functions that perform
    a variety of text cleaning operations. Because we might want to add, remove, or
    change the order that the functions are called in, we can add these functions
    to a list and call them in a general way on our text:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您已经拥有一组短小而精心组织的函数，可以执行各种文本清理操作。因为我们可能希望添加、删除或更改调用函数的顺序，所以我们可以将这些函数添加到列表中，并在文本上以一般方式调用它们：
- en: '[PRE21]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Although Python is not generally thought of as a functional language like JavaScript
    or—as a more extreme example—Haskell, it’s useful to remember that functions can
    be passed around as variables in situations like this!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Python通常不被认为是像JavaScript或更极端的例子中的Haskell那样的函数语言，但要记住，在这种情况下，函数可以像变量一样传递！
- en: Working with Normalized Text
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用标准化文本工作
- en: Once you’ve cleaned the text, what do you do with it? One common technique is
    to break it up into smaller pieces of text that can be more easily quantified
    and analyzed. Computational linguists call these *n-grams*, where n represents
    the number of words in each piece of text. In this example, we’ll be working specifically
    with 2-grams, or 2 word pieces of text.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您清理了文本，接下来该怎么做呢？一个常见的技术是将其分成更容易量化和分析的小块文本。计算语言学家称这些为*n-grams*，其中n表示每个文本块中的单词数。在本例中，我们将专门使用2-gram，即2个单词的文本块。
- en: N-grams typically do not span sentences. So we can use the text obtained in
    the previous section, split into sentences, and create 2-grams with each sentence
    in the list.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: N-gram通常不跨越句子。因此，我们可以使用前一节中获取的文本，将其拆分为句子，并为列表中的每个句子创建2-gram。
- en: 'A Python function for breaking text into n-grams can be written as:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于将文本分解为n-gram的Python函数可以编写为：
- en: '[PRE22]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output of this function on the text “web scraping with python” is:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数在文本“web scraping with python”上的输出是：
- en: '[PRE23]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: One problem with this function is that it returns many duplicate 2-grams. Every
    2-gram it encounters gets added to the list, with no record of its frequency.
    Not only is it interesting to record the frequency of these 2-grams, rather than
    just their existence, but it can be useful in charting the effects of changes
    to the cleaning and data normalization algorithms. If data is normalized successfully,
    the total number of unique n-grams will be reduced, while the total count of n-grams
    found (i.e., the number of unique or nonunique items identified as n-grams) will
    not be reduced. In other words, there will be fewer “buckets” for the same number
    of n-grams.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的一个问题是，它返回了许多重复的2-gram。它遇到的每个2-gram都会被添加到列表中，而没有记录其频率。记录这些2-gram的频率是有趣的，而不仅仅是它们的存在，因为这可以在清理和数据标准化算法变更的效果图中非常有用。如果数据成功标准化，唯一n-gram的总数将减少，而找到的n-gram的总计数（即标识为n-gram的唯一或非唯一项的数量）不会减少。换句话说，相同数量的n-gram将有更少的“桶”。
- en: 'You can do this by modifying the code that collects the n-grams to add them
    to a `Counter` object, rather than a list. Here, the `cleaned` variable is our
    list of cleaned sentences obtained in the previous section:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过修改收集n-gram的代码，将它们添加到`Counter`对象中来完成。在这里，`cleaned`变量是我们在前一节中获取的已清理句子的列表：
- en: '[PRE24]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: There are many other ways to create counts of n-grams, such as adding them to
    a dictionary object in which the value of the list points at a count for the number
    of times it was seen. That has a disadvantage in that it requires a bit more management
    and makes sorting tricky.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他创建n-gram计数的方法，例如将它们添加到字典对象中，其中列表的值指向它被看到的次数的计数。这样做的缺点是它需要更多的管理，并且使排序变得棘手。
- en: 'However, using a `Counter` object also has a disadvantage: it cannot store
    lists, because lists are unhashable. Converting these to tuples (which are hashable)
    would work well and make sense in this context, as would joining the lists to
    strings. In this case, I’ve chosen to convert them to strings by using a `'' ''.join(text[i:i+n])`
    inside the list comprehension for each n-gram.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用`Counter`对象也有一个缺点：它不能存储列表，因为列表是不可散列的。将它们转换为元组（可散列）将很好地解决问题，并且在这种情况下，将它们转换为字符串也是有道理的，通过在列表理解中使用`'
    '.join(text[i:i+n])`将它们转换为字符串。
- en: 'We can call the `countNGramsFromSentences` function with our cleaned text from
    the previous section and use the `most_common` function to get a list of 2-grams
    sorted by the most common ones first:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用前一节中清理的文本调用`countNGramsFromSentences`函数，并使用`most_common`函数获取按最常见排序的2-gram列表：
- en: '[PRE25]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here are the results:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE26]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As of this writing, there are 2,814 unique 2-grams, with the most popular ones
    containing word combinations that are very common in any English text, such as
    “such as.” Depending on your project, you may want to remove n-grams like this
    that do not have much relevance to the page’s actual subject matter. Doing this
    is a topic for [Chapter 12](ch12.html#c-12).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文撰写时，有2814个独特的2-gram，其中最受欢迎的组合包含在任何英文文本中都非常常见的词组，例如“such as”。根据您的项目需求，您可能希望移除类似于这样没有太多关联性的n-gram。如何做到这一点是第[12章](ch12.html#c-12)的一个话题。
- en: Beyond this, it’s usually good to stop and consider how much computing power
    you want to expend normalizing data. There are a number of situations in which
    different spellings of words are equivalent, but to resolve this equivalency,
    you need to run a check on every single word to see whether it matches any of
    your preprogrammed equivalencies.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通常需要停下来考虑要消耗多少计算资源来规范化数据。有许多情况下，不同拼写的单词是等效的，但为了解决这种等效性，您需要检查每个单词，看它是否与您预先编程的等效项匹配。
- en: For example, “Python 1st” and “Python first” both appear in the list of 2-grams.
    However, to make a blanket rule that says, “All first, second, third, etc., will
    be resolved to 1st, 2nd, 3rd, etc. (or vice versa)” would result in an additional
    10 or so checks per word.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，“Python 1st”和“Python first”都出现在2-gram列表中。然而，如果要制定一个一刀切的规则，即“所有的first、second、third等都将被解析为1st、2nd、3rd等（反之亦然）”，那么每个单词将额外增加约10次检查。
- en: Similarly, the inconsistent use of hyphens (“co-ordinated” versus “coordinated”),
    misspellings, and other natural language incongruities will affect the groupings
    of n-grams and might muddy the results of the output if the incongruities are
    common enough.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，连字符的不一致使用（例如“co-ordinated”与“coordinated”）、拼写错误以及其他自然语言的不一致性将影响n-gram的分组，并可能使输出的结果变得模糊，如果这些不一致性足够普遍的话。
- en: One solution, in the case of hyphenated words, might be to remove hyphens entirely
    and treat the word as a single string, which would require only a single operation.
    However, this would also mean that hyphenated phrases (an all-too-common occurrence)
    will be treated  as a single word. Going the other route and treating hyphens
    as spaces might be a better option. Just be prepared for the occasional “co ordinated”
    and “ordinated attack” to slip in!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理连字符词的情况下，一种解决方法可能是完全删除连字符，并将该词视为一个字符串，这只需要进行一次操作。然而，这也意味着连字符短语（这种情况实在是太常见了）将被视为一个单词。采取另一种方法，将连字符视为空格可能是一个更好的选择。只是要做好准备，偶尔会有“co
    ordinated”和“ordinated attack”这样的情况出现！
- en: Cleaning Data with Pandas
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Pandas清理数据
- en: This section is not about the endearing bears native to China, but the Python
    data analysis package: *pandas*. If you’ve done any work with data science and
    machine learning, you’ve likely encountered it before, as it is ubiquitous in
    the field.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本节不是关于中国的可爱熊猫，而是关于Python数据分析软件包*pandas*。如果您有过数据科学和机器学习的工作经验，那么很可能在此之前就已经接触过它，因为它在该领域中无处不在。
- en: Pandas was created as a solo project for work in 2008 by programmer Wes McKinney.
    In 2009, he made the project public and it quickly took off. The package filled
    a particular niche in data wrangling. It functioned much like a spreadsheet in
    some ways, with pretty printing and easy reshaping pivot functions. It also harnessed
    the power and flexibility of the underlying Python code and data science libraries
    that it was built on.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是由程序员Wes McKinney在2008年独立开发的项目。2009年，他将该项目公开，并迅速获得了广泛认可。该软件包填补了数据整理中的一个特定空白。在某些方面，它的功能类似于电子表格，具有良好的打印效果和易于重塑的数据透视功能。它还充分利用了底层Python代码和数据科学库的强大和灵活性。
- en: 'Some might recommend the [Anaconda package management system](https://www.anaconda.com) when
    installing data science libraries like numpy, pandas, and scikit-learn. Although
    there is excellent support for these packages with Anaconda, pandas is also straightforward
    to install with pip:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人在安装像numpy、pandas和scikit-learn这样的数据科学库时，可能会推荐使用[安装包管理系统Anaconda](https://www.anaconda.com)。虽然Anaconda对这些包有很好的支持，但使用pip也可以轻松安装pandas：
- en: '[PRE27]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The package is, by convention, imported as `pd` rather than the full name `pandas`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 习惯上，该软件包被导入为`pd`而不是完整名称`pandas`：
- en: '[PRE28]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Don’t Import Individual Methods and Classes from Pandas
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不要从Pandas中导入单独的方法和类
- en: 'The pandas ecosystem is large, complex, and often overlaps the namespace of
    built-in Python functions and packages. For this reason, pandas functions should
    almost always be referenced starting from `pd` rather than importing them directly,
    such as:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: pandas生态系统庞大、复杂，并且经常与内置Python函数和软件包的命名空间重叠。因此，几乎总是应该从`pd`开始引用pandas函数，而不是直接导入它们，例如：
- en: '[PRE29]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In these cases, the above imports might cause confusion with the built-in Python `array` module
    and `min` function.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，上述导入可能会与内置Python `array`模块和`min`函数造成混淆。
- en: 'One accepted exception may be for the DataFrame class, imported as:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一个已接受的例外可能是对作为DataFrame类导入的：
- en: '[PRE30]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In this case, `DataFrame` is not found in the Python standard library and is
    easily-recognized as a pandas class. However, this is the one exception you are
    likely to see, and many still prefer to reference the DataFrame class as `pd.DataFrame`.
    Because the library is so-often referenced in code, this is one reason why the
    convention is to import pandas as `pd` rather than the full name!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`DataFrame`不在Python标准库中，并且很容易被识别为pandas类。然而，这是您可能会看到的一个例外，并且许多人仍然喜欢将DataFrame类称为`pd.DataFrame`。因为库在代码中经常被引用，这是为什么惯例是将pandas导入为`pd`而不是全名的一个原因！
- en: 'The object you will be working with most often in the pandas library is the
    DataFrame. These are similar to spreadsheets or tables, and can be constructed
    in a variety of ways. For example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您在pandas库中最常使用的对象是数据框架。这些类似于电子表格或表格，可以通过多种方式构建。例如：
- en: '[PRE31]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `head` method produces a pretty-printed DataFrame of the data and its columns
    and headers, as shown in [Figure 11-1](#fig1101).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`head`方法生成一个漂亮打印的数据框架，显示数据及其列和标题，如[图 11-1](#fig1101)所示。'
- en: '![](assets/wsp3_1101.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_1101.png)'
- en: Figure 11-1\. A simple pandas DataFrame
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1。一个简单的pandas数据框架
- en: DataFrames are required to always have an index and column names. If those are
    not provided, as in this case, where only a simple matrix of data is supplied,
    they will be automatically generated. The DataFrame’s index (0, 1, 2) can be seen
    in bold to the left, and the column names (0, 1) are at the top in bold.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框架始终需要索引和列名。如果未提供这些信息，如本例中仅提供简单的数据矩阵，它们将被自动生成。数据框架的索引（0, 1, 2）可以在左侧以粗体显示，列名（0,
    1）在顶部以粗体显示。
- en: Rather than working with raw Python lists and dictionaries, DataFrames provide
    an enormous variety convenient helper functions to sort, clean, manipulate, arrange,
    and display your data. If you are working with larger data sets, they also provide
    a speed and memory advantage over lists and dictionaries.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用原始的Python列表和字典不同，数据框提供了大量方便的辅助函数，用于对数据进行排序、清理、操作、排列和显示。如果您处理较大的数据集，它们还比列表和字典提供了速度和内存优势。
- en: Cleaning
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理
- en: 'In the following examples, you’ll use data scraped from [Wikipedia’s List of
    Countries with McDonald’s Restaurants](https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants).
    We can use the `pd.read_csv` function to read data directly from a CSV file to
    a dataframe:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，您将使用从[Wikipedia的《麦当劳餐厅分布国家列表》](https://en.wikipedia.org/wiki/List_of_countries_with_McDonald%27s_restaurants)抓取的数据。我们可以使用`pd.read_csv`函数直接从CSV文件读取数据到数据框架：
- en: '[PRE32]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Optionally, an integer can be passed to the `head` method to print out a number
    of rows other than the default of 5\. This gives a nice view of the CSV data scraped
    from earlier, as shown in [Figure 11-2](#1102).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，可以传递一个整数给`head`方法，以打印出除默认值5之外的行数。这样可以很好地查看早期抓取的CSV数据，如[图 11-2](#1102)所示。
- en: '![](assets/wsp3_1102.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_1102.png)'
- en: Figure 11-2\. Displaying a list of countries with lds
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-2。显示具有餐厅的国家列表
- en: 'The column names here are somewhat wordy and not well-formatted. We can rename
    them using the `rename` method:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的列名有些冗长且格式不佳。我们可以使用`rename`方法对它们进行重命名：
- en: '[PRE33]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we pass in a dictionary to the `columns` keyword argument, where the keys
    are the original column names and the value is the new column name. The boolean
    argument `inplace` means that the columns are renamed in-place in the original
    DataFrame, rather than a new DataFrame being returned.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们向`columns`关键字参数传递一个字典，其中键是原始列名，值是新列名。布尔参数`inplace`意味着列会在原始数据框架中就地重命名，而不是返回一个新的数据框架。
- en: 'Next, we can isolate only the columns that we want to work with by passing
    in a list of those column names to a sort of slicing syntax using `[]` brackets:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以通过将要处理的列名列表传递给切片语法`[]`，来隔离我们想要处理的列：
- en: '[PRE34]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Now that we have the relabeled DataFrame columns we want, we can look at the
    data. There are a few things we will want to fix up. First, the dates in the “Date
    of first store” or “Date” column are usually well-formatted, but they also contain
    extra text or even other dates. As a simple strategy, we may decide to keep the
    first thing that matches the “date” format and discard the rest.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了我们想要的重新标记的DataFrame列，我们可以查看数据了。有几件事情我们需要修复。首先，“首次店铺日期”或“日期”列中的日期通常格式良好，但它们也包含额外的文本甚至其他日期。作为一个简单的策略，我们可以决定保留匹配“日期”格式的第一个内容，并丢弃其余内容。
- en: 'Functions can be applied to an entire column in a DataFrame by first selecting
    that column using the same “slicing” syntax used above. A single selected column
    a pandas `Series` instance. The `Series` class has an `apply` method which applies
    a single function to each value in the Series:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 函数可以通过首先使用与上述相同的“切片”语法选择整个DataFrame列来应用于DataFrame中的整个列。一个单独选择的列是一个 pandas `Series` 实例。`Series` 类有一个 `apply` 方法，它可以将一个函数应用到Series中的每个值上：
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Here, I am using a lambda operator to apply a function that gets all `date_regex` matches
    and returns the first one as the date.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我正在使用 lambda 运算符来应用一个函数，该函数获取所有 `date_regex` 的匹配项，并将第一个匹配项作为日期返回。
- en: 'After cleaning, these dates can be converted to actual pandas datetime values
    using the `to_datetime` function:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 清理后，这些日期可以使用 `to_datetime` 函数转换为实际的 pandas datetime 值：
- en: '[PRE36]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Often, there is a delicate balance between the fast and efficient production
    of “clean” data, and the preservation of completely accurate and nuanced data.
    For instance, our date cleaning reduced the following text in the United Kingdom
    row:  "*England: November 13, 1974[21] Wales: December 3, 1984 Scotland: November
    23, 1987[22] Northern Ireland: October 12, 1991*" into the single date: "*1974-11-13*“.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 往往，在快速高效生成“干净”数据与保留完全准确和细微数据之间存在微妙的平衡。例如，我们的日期清理将英国行的以下文本减少到单个日期：“*英格兰：1974年11月13日[21]
    威尔士：1984年12月3日 苏格兰：1987年11月23日[22] 北爱尔兰：1991年10月12日*”，变成了单个日期：“*1974-11-13*”。
- en: Technically, this is correct. If the country of the United Kingdom as a whole
    is considered, then 1974-11-13 is the first date a McDonald’s appeared in it.
    However, it is simply happenstance that the dates were written in the cell in
    chronological order, and that we decided to take the first one, and also that
    the earliest date was the right one to choose. One might imagine many other circumstances
    where we might not be so lucky.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，这是正确的。如果整个英国作为一个整体来考虑，那么1974年11月13日是麦当劳首次出现的日期。然而，很巧合的是，日期按照时间顺序写在单元格中，并且我们决定选择第一个日期，并且最早的日期是正确选择的。我们可以想象许多其他情况，在那些情况下我们可能就没有那么幸运。
- en: In some cases, you may do a survey of the data and decide that your chosen cleaning
    method is good enough. Perhaps it is correct in most of the cases you look at.
    Perhaps it’s incorrect in one direction half the time, incorrect in the other
    direction the other half of the time, and things balance out for your purposes
    over large datasets. Or you may decide you need another method to clean or capture
    the data more accurately.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，您可以对数据进行调查，并决定您选择的清理方法是否足够好。也许在您查看的大多数情况下都是正确的。也许在一半的时间里，向一个方向不正确，在另一半时间里，向另一个方向不正确，对于您的目的来说，在大型数据集上平衡是可以接受的。或者您可能决定需要另一种方法来更准确地清理或捕捉数据。
- en: 'The “Outlets” column of the dataset presents similar challenges. This column
    contains text such as "*13,515[10][failed verification][11]*" and " *(excl. seasonal
    restaurants) 43 (including seasonal and mobile restaurants)*" which are not the
    clean integers that we might like for further analysis. Again, we can use a simple
    approach to get the first integer available in the dataset:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的“出口”列也存在类似的挑战。此列包含文本，如“*13,515[10][验证失败][11]*”和“ *(不包括季节性餐厅) 43（包括季节性和移动餐厅）*”，这些都不是我们希望进行进一步分析的干净整数。同样，我们可以使用简单的方法获取数据集中可用的第一个整数：
- en: '[PRE37]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Although this could also be written as a lambda function, you may consider
    breaking the logic out into a separate function if several steps are required.
    This also has the advantage of allowing you to easily print out any exceptions
    found during exploratory data processing, for further consideration:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这也可以写成一个 lambda 函数，但如果需要多个步骤，可以考虑将逻辑拆分到一个单独的函数中。这样做的好处是在探索性数据处理过程中，可以轻松打印出任何发现的异常，以便进一步考虑：
- en: '[PRE38]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Finally, the DataFrame is cleaned and ready for further analysis, as shown in
    [Figure 11-3](#1103).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，DataFrame 已经清理好，准备进行进一步的分析，如 [图 11-3](#1103) 所示。
- en: '![](assets/wsp3_1103.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_1103.png)'
- en: Figure 11-3\. DataFrame with clean column headers, formatted dates, and integer
    data
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. 具有清洁列标题、格式化日期和整数数据的 DataFrame
- en: Indexing, Sorting, and Filtering
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引、排序和过滤
- en: 'Remember from earlier that all DataFrames have an index, whether you explicitly
    provide one or not. The McDonald’s data itself has a convenient index: the “Order”
    column, which signifies the chronological order in which the countries received
    their first McDonald’s restaurant. We can set the index using the `set_index`
    method:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，所有的 DataFrame 都有一个索引，无论您是否明确提供了一个。麦当劳的数据本身有一个方便的索引：”Order“ 列，表示国家接收第一家麦当劳餐厅的时间顺序。我们可以使用 `set_index` 方法设置索引：
- en: '[PRE39]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This discards the old index and moves the “Order” column into the index. Again,
    the `inplace` keyword argument means that this is done in-place on the original
    DataFrame, rather than have a copy of the DataFrame returned.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这会丢弃旧索引并将 ”Order“ 列移到索引中。同样，`inplace` 关键字参数意味着这是在原始 DataFrame 上进行的就地操作，而不是返回
    DataFrame 的副本。
- en: 'The `sort_values` method can be used to sort data by one or many columns. The `inplace` keyword
    can be used in this method as well. However, because sorting is usually done for
    exploratory analysis and a permanent sort is not desired, it may be more useful
    to return the DataFrame for printing:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`sort_values` 方法可用于按一个或多个列排序数据。在这个方法中也可以使用 `inplace` 关键字。然而，因为排序通常用于探索性分析，不需要永久排序，所以将
    DataFrame 返回用于打印可能更有用：'
- en: '[PRE40]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This shows that the countries with the most McDonald’s are the United States,
    followed by China, and then Japan. France,  I’m sure it will be pleased to know,
    comes in fourth place, with the greatest number of McDonald’s of any European
    country!
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了拥有最多麦当劳的国家是美国，其次是中国，然后是日本。法国，我相信会很高兴知道，排名第四，是欧洲国家中麦当劳最多的国家！
- en: 'Filtering DataFrames is easy with the `query` method. It takes, as an argument,
    a query string:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `query` 方法很容易过滤 DataFrame。它的参数是一个查询字符串：
- en: '[PRE41]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This returns a DataFrame containing only records where the number of Outlets
    is less than 100\. Most of the usual Python comparison operators work for DataFrame
    filtering using the query method, however this query language is not Python syntax.
    For instance, this will raise an Exception:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个 DataFrame，其中仅包含 Outlets 数量小于 100 的记录。大多数常规的 Python 比较运算符在使用查询方法进行 DataFrame
    过滤时都有效，但是这种查询语言不是 Python 语法。例如，这将引发异常：
- en: '[PRE42]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'If you want to test for the presence or absence of any empty values, the correct
    pandas way to do it is using the `isnull` and `notnull` query functions:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想测试任何空值的存在或不存在，正确的 pandas 方法是使用 `isnull` 和 `notnull` 查询函数：
- en: '[PRE43]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: As you might guess, these statements capture both `None` values as well as `NaN` objects
    from the underlying numpy package that pandas is built on top of.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能猜到的那样，这些语句同时捕获了 `None` 值以及来自底层 numpy 包的 `NaN` 对象。
- en: 'If we want to add another logic clause, you can separate them by a single ampersand:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要添加另一个逻辑子句，可以用一个单与号分隔它们：
- en: '[PRE44]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'An `or` statement is represented with a single pipe:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单管道表示一个 `or` 语句：
- en: '[PRE45]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note that the entire date (`"1990-01-01"`) is not required here, but will also
    work with just the year `"1990"`. Pandas is fairly forgiving about interpreting
    strings as dates, although you should always double-check that the data coming
    back is what you expect it to be.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这里不需要整个日期 (`"1990-01-01"`)，只写年份 `"1990"` 也可以。Pandas 在解释字符串为日期时相当宽容，尽管你应该始终仔细检查返回的数据是否符合你的期望。
- en: More About Pandas
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多关于 Pandas 的信息
- en: 'I sincerely hope that your journey with pandas does not end here. We are fortunate
    that Wes McKinney, the creator and [Benevolent Dictator for Life](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life) of
    pandas, has also written a book about it: [*Python for Data Analysis*](https://www.oreilly.com/library/view/python-for-data/9781098104023/).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我真诚地希望你与 pandas 的旅程不会就此结束。我们很幸运，pandas 的创造者和终身[仁慈独裁者](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life)
    Wes McKinney，也写了一本关于它的书：[*Python for Data Analysis*](https://www.oreilly.com/library/view/python-for-data/9781098104023/)。
- en: If you plan to do more with data science, or simply want a good tool to clean
    and analyze data occasionally in Python, I recommend that you check it out.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划在数据科学领域做更多的事情，或者只是想在 Python 中偶尔清理和分析数据的好工具，我建议你去了解一下。
