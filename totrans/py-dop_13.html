<html><head></head><body><section data-pdf-bookmark="Chapter 13. Serverless Technologies" data-type="chapter" epub:type="chapter"><div class="chapter" id="serverless">&#13;
<h1><span class="label">Chapter 13. </span>Serverless Technologies</h1>&#13;
&#13;
&#13;
<p><a data-primary="serverless technologies" data-type="indexterm" id="ix_ch13-asciidoc0"/><em>Serverless</em> <a data-primary="serverless technologies" data-secondary="about" data-type="indexterm" id="ix_ch13-asciidoc1"/>is a term that generates a lot of buzz in the IT industry these days. As often happens with these kinds of terms, people have different opinions about what they actually mean. At face value, <em>serverless</em> implies a world where you do not need to worry about managing servers anymore. To some extent, this is true, but only for the developers who are using the functionality offered by <em>serverless</em> technologies. This chapter shows there is a <em>lot</em> of work that needs to happen behind the scenes for this magical world of no servers to come into being.</p>&#13;
&#13;
<p>Many people equate the term <em>serverless</em> with <a data-primary="Function as a Service (FaaS)" data-type="indexterm" id="idm46691321268360"/>Function as a Service (FaaS). This is partially true, and it mostly came about when AWS launched the Lambda service in 2015. AWS Lambdas are functions that can be run in the cloud without deploying a traditional server to host the functions. Hence the word <em>serverless</em>.</p>&#13;
&#13;
<p>However, FaaS is not the only service that can be dubbed serverless. These days the Big Three public cloud providers (Amazon, Microsoft, and Google) all offer Containers as a Service (CaaS), which allows you to deploy full-blown Docker containers to their clouds without provisioning servers to host those containers. These services can also be called serverless. Examples of such services are AWS Fargate, Microsoft Azure Container Instances, and Google Cloud Run.</p>&#13;
&#13;
<p>What are some use cases for serverless technologies? For FaaS technologies such as AWS Lambda, especially due to the event-driven manner in which Lambda functions can be triggered by other cloud services, use cases include:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Extract-Transform-Load (ETL) data processing, where, as an example, a file is uploaded to S3, which triggers the execution of a Lambda function that does ETL processing on the data and sends it to a queue or a backend database</p>&#13;
</li>&#13;
<li>&#13;
<p>ETL processing on logs sent by other services to CloudWatch</p>&#13;
</li>&#13;
<li>&#13;
<p>Scheduling tasks in a cron-like manner based on CloudWatch Events triggering Lambda functions</p>&#13;
</li>&#13;
<li>&#13;
<p>Real-time notifications based on Amazon SNS triggering Lambda functions</p>&#13;
</li>&#13;
<li>&#13;
<p>Email processing using Lambda and Amazon SES</p>&#13;
</li>&#13;
<li>&#13;
<p>Serverless website hosting, with the static web resources such as Javascript, CSS, and HTML stored in S3 and fronted by the CloudFront CDN service, and a REST API handled by an API Gateway routing the API requests to Lambda functions, which communicate with a backend such as Amazon RDS or Amazon DynamoDB</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Many serverless use cases are identified in each of the cloud service providers’ online documentation. For example, in the Google Cloud serverless ecosystem, web applications are handled best by Google AppEngine, APIs are handled best by Google Functions, and CloudRun is preferred for running processes in Docker containers. For a concrete example, consider a service that needs to perform machine learning tasks such as object detection with the TensorFlow framework. Due to the compute, memory, and disk resource limitations of FaaS, combined with the limited availability of libraries in a FaaS setup, it is probably better to run such a service using a CaaS service such as Google Cloud Run, as opposed to a FaaS service such as Google Cloud Functions.</p>&#13;
&#13;
<p>The Big Three cloud providers also offer a rich DevOps toolchain around their FaaS platforms. For example, when you use AWS Lambda, with little effort, you can also add these services from AWS:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>AWS X-Ray for tracing/observability</p>&#13;
</li>&#13;
<li>&#13;
<p>Amazon CloudWatch for logging, alerting, and event scheduling</p>&#13;
</li>&#13;
<li>&#13;
<p>AWS Step Functions for serverless workflow coordination</p>&#13;
</li>&#13;
<li>&#13;
<p>AWS Cloud9 for an in-browser development environment</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>How do you choose between FaaS and CaaS? In one dimension, it depends on the unit of deployment. If you only care about short-lived functions, with few dependencies and small amounts of data processing, then FaaS can work for you. If, on the other hand, you have long-running processes with lots of dependencies and heavy computing power requirements, then you may be better off using CaaS. Most FaaS services have severe limits for running time (15 minutes maximum for Lambda), computing power, memory size, disk space, and HTTP request and response limits. The upside to FaaS’ short execution times is that you only pay for the duration of the function.</p>&#13;
&#13;
<p>If you remember the discussion at the beginning of <a data-type="xref" href="ch12.html#containers-kubernetes">Chapter 12</a> on pets versus cattle versus insects, functions can truly be considered ephemeral insects that briefly come into existence, perform some processing, and disappear. Because of their ephemeral nature, functions in FaaS are also stateless, which is an important fact to keep in mind as you architect your application.</p>&#13;
&#13;
<p>Another dimension for choosing between FaaS and CaaS is the number and type of interactions that your service has with other services. For example, an AWS Lambda function can be triggered asynchronously by no less than eight other AWS services, including S3, Simple Notification Service (SNS), Simple Email Service (SES), and CloudWatch. This richness of interactions makes it easier to write functions that respond to events, so FaaS wins in this case.</p>&#13;
&#13;
<p>As you’ll see in this chapter, many FaaS services are actually based on Kubernetes, which these days is the de facto container orchestration standard. Even though your unit of deployment is a function, behind the scenes the FaaS tooling creates and pushes Docker containers to a Kubernetes cluster that you might or might not manage. OpenFaas and OpenWhisk are examples of such Kubernetes-based FaaS technologies. When you self-host these FaaS platforms, you very quickly become aware that <em>server</em> makes up most of the word serverless. All of a sudden you have to worry a lot about the care and feeding of your Kubernetes clusters.</p>&#13;
&#13;
<p>When we split the word DevOps into its parts, Dev and Ops, serverless technologies are targeted more toward the Dev side. They help developers feel less friction when it comes to deploying their code. The burden, especially in a self-hosted scenario, is on Ops to provision the infrastructure (sometimes very complex) that will support the FaaS or CaaS platforms. However, even if the Dev side might feel there is little need for Ops when it comes to serverless (which happens, although by definition this split makes it a non-DevOps situation), there are still plenty of Ops-related issues to worry about when it comes to using a Serverless platform: security, scalability, resource limitations and capacity planning, monitoring, logging, and observability. These have traditionally been considered the domain of Ops, but in the brave new DevOps world we are talking about, they need to be tackled by both Dev and Ops in tandem and with cooperation. A Dev team should not feel that its task is done when it finishes writing the code. Instead, it should take ownership and yes, pride, in getting the service all the way to production, with good monitoring, logging, and tracing built in.</p>&#13;
&#13;
<p>We start this chapter with examples of how to deploy the same Python function, representing a simple HTTP endpoint, to the Big Three cloud providers using their FaaS offerings.</p>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Some of the commands used in the following examples produce large amounts of output. Except for cases where it is critical to the understanding of the command, we will omit the majority of the output lines to save trees and enable the reader to focus better on the text.<a data-startref="ix_ch13-asciidoc1" data-type="indexterm" id="idm46691321244312"/></p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying the Same Python Function to the “Big Three” Cloud Providers" data-type="sect1"><div class="sect1" id="idm46691321243448">&#13;
<h1>Deploying the Same Python Function to the <span class="keep-together">“Big Three” Cloud Providers</span></h1>&#13;
&#13;
<p><a data-primary="serverless technologies" data-secondary="deploying the same Python function to the Big Three cloud providers" data-type="indexterm" id="ix_ch13-asciidoc2"/>For AWS and Google, we use the Serverless platform, which simplifies these deployments by abstracting the creation of cloud resources that are involved in the FaaS runtime environments. The Serverless platform does not yet support Python functions for Microsoft Azure, so in that case we show how to use Azure-specific CLI tooling.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Installing Serverless Framework" data-type="sect2"><div class="sect2" id="idm46691321239672">&#13;
<h2>Installing Serverless Framework</h2>&#13;
&#13;
<p><a data-primary="serverless technologies" data-secondary="installing the Serverless framework" data-type="indexterm" id="idm46691321238536"/><a href="https://serverless.com">The Serverless platform</a> is based on nodejs. To install it, use <code>npm</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ npm install -g serverless</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying Python Function to AWS Lambda" data-type="sect2"><div class="sect2" id="idm46691321235336">&#13;
<h2>Deploying Python Function to AWS Lambda</h2>&#13;
&#13;
<p><a data-primary="AWS Lambda" data-type="indexterm" id="ix_ch13-asciidoc3"/><a data-primary="serverless technologies" data-secondary="deploying Python function to AWS Lambda" data-type="indexterm" id="ix_ch13-asciidoc4"/>Start by cloning the Serverless platform examples GitHub repository:</p>&#13;
&#13;
<pre data-type="programlisting">$ git clone https://github.com/serverless/examples.git&#13;
$ cd aws-python-simple-http-endpoint&#13;
$ export AWS_PROFILE=gheorghiu-net</pre>&#13;
&#13;
<p>The Python HTTP endpoint is defined in the file <em>handler.py</em>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">handler</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">import</code> <code class="nn">json</code>&#13;
<code class="kn">import</code> <code class="nn">datetime</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">endpoint</code><code class="p">(</code><code class="n">event</code><code class="p">,</code> <code class="n">context</code><code class="p">):</code>&#13;
    <code class="n">current_time</code> <code class="o">=</code> <code class="n">datetime</code><code class="o">.</code><code class="n">datetime</code><code class="o">.</code><code class="n">now</code><code class="p">()</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>&#13;
    <code class="n">body</code> <code class="o">=</code> <code class="p">{</code>&#13;
        <code class="s2">"message"</code><code class="p">:</code> <code class="s2">"Hello, the current time is "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">current_time</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="n">response</code> <code class="o">=</code> <code class="p">{</code>&#13;
        <code class="s2">"statusCode"</code><code class="p">:</code> <code class="mi">200</code><code class="p">,</code>&#13;
        <code class="s2">"body"</code><code class="p">:</code> <code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">(</code><code class="n">body</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">return</code> <code class="n">response</code></pre>&#13;
&#13;
<p>The Serverless platform uses a declarative approach for specifying the resources it needs to create with a YAML file called <em>serverless.yaml</em>. Here is file that declares a function called <code>currentTime</code>, corresponding to the Python function <code>endpoint</code> from the <code>handler</code> module defined previously:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat serverless.yml</code>&#13;
<code class="l-Scalar-Plain">service</code><code class="p-Indicator">:</code> <code class="l-Scalar-Plain">aws-python-simple-http-endpoint</code>&#13;
&#13;
<code class="nt">frameworkVersion</code><code class="p">:</code> <code class="s">"&gt;=1.2.0</code><code class="nv"> </code><code class="s">&lt;2.0.0"</code>&#13;
&#13;
<code class="nt">provider</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">aws</code>&#13;
  <code class="nt">runtime</code><code class="p">:</code> <code class="l-Scalar-Plain">python2.7</code> <code class="c1"># or python3.7, supported as of November 2018</code>&#13;
&#13;
<code class="nt">functions</code><code class="p">:</code>&#13;
  <code class="nt">currentTime</code><code class="p">:</code>&#13;
    <code class="nt">handler</code><code class="p">:</code> <code class="l-Scalar-Plain">handler.endpoint</code>&#13;
    <code class="nt">events</code><code class="p">:</code>&#13;
      <code class="p-Indicator">-</code> <code class="nt">http</code><code class="p">:</code>&#13;
          <code class="nt">path</code><code class="p">:</code> <code class="l-Scalar-Plain">ping</code>&#13;
          <code class="nt">method</code><code class="p">:</code> <code class="l-Scalar-Plain">get</code></pre>&#13;
&#13;
<p>Modify the Python version to 3.7 in <em>serverless.yaml</em>:</p>&#13;
&#13;
<pre data-type="programlisting">provider:&#13;
  name: aws&#13;
  runtime: python3.7</pre>&#13;
&#13;
<p>Deploy the function to AWS Lambda by running the <a data-primary="serverless deploy command" data-type="indexterm" id="idm46691321078968"/><code>serverless deploy</code> command:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless deploy&#13;
Serverless: Packaging service...&#13;
Serverless: Excluding development dependencies...&#13;
Serverless: Uploading CloudFormation file to S3...&#13;
Serverless: Uploading artifacts...&#13;
Serverless:&#13;
Uploading service aws-python-simple-http-endpoint.zip file to S3 (1.95 KB)...&#13;
Serverless: Validating template...&#13;
Serverless: Updating Stack...&#13;
Serverless: Checking Stack update progress...&#13;
..............&#13;
Serverless: Stack update finished...&#13;
Service Information&#13;
service: aws-python-simple-http-endpoint&#13;
stage: dev&#13;
region: us-east-1&#13;
stack: aws-python-simple-http-endpoint-dev&#13;
resources: 10&#13;
api keys:&#13;
  None&#13;
endpoints:&#13;
  GET - https://3a88jzlxm0.execute-api.us-east-1.amazonaws.com/dev/ping&#13;
functions:&#13;
  currentTime: aws-python-simple-http-endpoint-dev-currentTime&#13;
layers:&#13;
  None&#13;
Serverless:&#13;
Run the "serverless" command to setup monitoring, troubleshooting and testing.</pre>&#13;
&#13;
<p class="pagebreak-before">Test the deployed AWS Lambda function by hitting its endpoint with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl https://3a88jzlxm0.execute-api.us-east-1.amazonaws.com/dev/ping&#13;
{"message": "Hello, the current time is 23:16:30.479690"}%</pre>&#13;
&#13;
<p>Invoke the Lambda function directly with the <a data-primary="serverless invoke command" data-type="indexterm" id="idm46691321073864"/><code>serverless invoke</code> command:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless invoke --function currentTime&#13;
{&#13;
    "statusCode": 200,&#13;
    "body": "{\"message\": \"Hello, the current time is 23:18:38.101006\"}"&#13;
}</pre>&#13;
&#13;
<p>Invoke the Lambda function directly and inspect the log (which is sent to AWS CloudWatch Logs) at the same time:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless invoke --function currentTime --log&#13;
{&#13;
    "statusCode": 200,&#13;
    "body": "{\"message\": \"Hello, the current time is 23:17:11.182463\"}"&#13;
}&#13;
--------------------------------------------------------------------&#13;
START RequestId: 5ac3c9c8-f8ca-4029-84fa-fcf5157b1404 Version: $LATEST&#13;
END RequestId: 5ac3c9c8-f8ca-4029-84fa-fcf5157b1404&#13;
REPORT RequestId: 5ac3c9c8-f8ca-4029-84fa-fcf5157b1404&#13;
Duration: 1.68 ms Billed Duration: 100 ms   Memory Size: 1024 MB&#13;
Max Memory Used: 56 MB</pre>&#13;
&#13;
<p>Note how the <code>Billed Duration</code> in the preceding output is 100 ms. This shows one of the advantages of using FaaS—being billed in very short increments of time.</p>&#13;
&#13;
<p>One other thing we want to draw your attention to is the heavy lifting behind the scenes by the Serverless platform in the creation of AWS resources that are part of the Lambda setup. Serverless creates a CloudFormation stack called, in this case, <code>aws-python-simple-http-endpoint-dev</code>. You can inspect it with the <code>aws</code> CLI tool:</p>&#13;
&#13;
<pre data-type="programlisting">$ aws cloudformation describe-stack-resources \&#13;
  --stack-name aws-python-simple-http-endpoint-dev&#13;
  --region us-east-1 | jq '.StackResources[].ResourceType'&#13;
"AWS::ApiGateway::Deployment"&#13;
"AWS::ApiGateway::Method"&#13;
"AWS::ApiGateway::Resource"&#13;
"AWS::ApiGateway::RestApi"&#13;
"AWS::Lambda::Function"&#13;
"AWS::Lambda::Permission"&#13;
"AWS::Lambda::Version"&#13;
"AWS::Logs::LogGroup"&#13;
"AWS::IAM::Role"&#13;
"AWS::S3::Bucket"</pre>&#13;
&#13;
<p>Note how this CloudFormation stack contains no less than 10 AWS resource types that you would have had to otherwise create or associate with one another manually.<a data-startref="ix_ch13-asciidoc4" data-type="indexterm" id="idm46691321065880"/><a data-startref="ix_ch13-asciidoc3" data-type="indexterm" id="idm46691321065176"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying Python Function to Google Cloud Functions" data-type="sect2"><div class="sect2" id="idm46691321234392">&#13;
<h2>Deploying Python Function to Google Cloud Functions</h2>&#13;
&#13;
<p><a data-primary="Google Cloud Functions" data-type="indexterm" id="ix_ch13-asciidoc5"/><a data-primary="serverless technologies" data-secondary="deploying Python function to Google Cloud Functions" data-type="indexterm" id="ix_ch13-asciidoc6"/>In this section, we will take as an example the code from the <code>google-python-simple-http-endpoint</code> directory from the Serverless platform examples GitHub repository:</p>&#13;
&#13;
<pre data-type="programlisting">$ gcloud projects list&#13;
PROJECT_ID                  NAME                        PROJECT_NUMBER&#13;
pulumi-gke-testing          Pulumi GKE Testing          705973980178&#13;
pythonfordevops-gke-pulumi  pythonfordevops-gke-pulumi  787934032650</pre>&#13;
&#13;
<p>Create a new GCP project:</p>&#13;
&#13;
<pre data-type="programlisting">$ gcloud projects create pythonfordevops-cloudfunction</pre>&#13;
&#13;
<p>Initialize the local <code>gcloud</code> environment:</p>&#13;
&#13;
<pre data-type="programlisting">$ gcloud init&#13;
Welcome! This command will take you through the configuration of gcloud.&#13;
&#13;
Settings from your current configuration [pythonfordevops-gke-pulumi] are:&#13;
compute:&#13;
  region: us-west1&#13;
  zone: us-west1-c&#13;
core:&#13;
  account: grig.gheorghiu@gmail.com&#13;
  disable_usage_reporting: 'True'&#13;
  project: pythonfordevops-gke-pulumi&#13;
&#13;
Pick configuration to use:&#13;
[1] Re-initialize this configuration with new settings&#13;
[2] Create a new configuration&#13;
[3] Switch to and re-initialize existing configuration: [default]&#13;
Please enter your numeric choice:  2&#13;
&#13;
Enter configuration name. Names start with a lower case letter and&#13;
contain only lower case letters a-z, digits 0-9, and hyphens '-':&#13;
pythonfordevops-cloudfunction&#13;
Your current configuration has been set to: [pythonfordevops-cloudfunction]&#13;
&#13;
Choose the account you would like to use to perform operations for&#13;
this configuration:&#13;
 [1] grig.gheorghiu@gmail.com&#13;
 [2] Log in with a new account&#13;
Please enter your numeric choice:  1&#13;
&#13;
You are logged in as: [grig.gheorghiu@gmail.com].&#13;
&#13;
Pick cloud project to use:&#13;
 [1] pulumi-gke-testing&#13;
 [2] pythonfordevops-cloudfunction&#13;
 [3] pythonfordevops-gke-pulumi&#13;
 [4] Create a new project&#13;
Please enter numeric choice or text value (must exactly match list&#13;
item):  2&#13;
&#13;
Your current project has been set to: [pythonfordevops-cloudfunction].</pre>&#13;
&#13;
<p>Authorize local shell with GCP:</p>&#13;
&#13;
<pre data-type="programlisting">$ gcloud auth login</pre>&#13;
&#13;
<p>Use the Serverless framework to deploy the same Python HTTP endpoint as in the AWS Lambda example, but this time as a Google Cloud Function:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless deploy&#13;
&#13;
  Serverless Error ---------------------------------------&#13;
&#13;
  Serverless plugin "serverless-google-cloudfunctions"&#13;
  initialization errored: Cannot find module 'serverless-google-cloudfunctions'&#13;
Require stack:&#13;
- /usr/local/lib/node_modules/serverless/lib/classes/PluginManager.js&#13;
- /usr/local/lib/node_modules/serverless/lib/Serverless.js&#13;
- /usr/local/lib/node_modules/serverless/lib/utils/autocomplete.js&#13;
- /usr/local/lib/node_modules/serverless/bin/serverless.js&#13;
&#13;
  Get Support --------------------------------------------&#13;
     Docs:          docs.serverless.com&#13;
     Bugs:          github.com/serverless/serverless/issues&#13;
     Issues:        forum.serverless.com&#13;
&#13;
  Your Environment Information ---------------------------&#13;
     Operating System:          darwin&#13;
     Node Version:              12.9.0&#13;
     Framework Version:         1.50.0&#13;
     Plugin Version:            1.3.8&#13;
     SDK Version:               2.1.0</pre>&#13;
&#13;
<p>The error we just encountered is due to the fact that the dependencies specified in <em>package.json</em> have not been installed yet:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat package.json&#13;
{&#13;
  "name": "google-python-simple-http-endpoint",&#13;
  "version": "0.0.1",&#13;
  "description":&#13;
  "Example demonstrates how to setup a simple HTTP GET endpoint with python",&#13;
  "author": "Sebastian Borza &lt;sebito91@gmail.com&gt;",&#13;
  "license": "MIT",&#13;
  "main": "handler.py",&#13;
  "scripts": {&#13;
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1"&#13;
  },&#13;
  "dependencies": {&#13;
    "serverless-google-cloudfunctions": "^2.1.0"&#13;
  }&#13;
}</pre>&#13;
&#13;
<p>The Serverless platform is written in node.js, so its packages need to be installed with <code>npm install</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ npm install</pre>&#13;
&#13;
<p>Try deploying again:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless deploy&#13;
&#13;
  Error --------------------------------------------------&#13;
&#13;
  Error: ENOENT: no such file or directory,&#13;
  open '/Users/ggheo/.gcloud/keyfile.json'</pre>&#13;
&#13;
<p>To generate a credentials key, create a new service account named <code>sa</code> on the GCP IAM service account page. In this case, the email for the new service account was set to <code>sa-255@pythonfordevops-cloudfunction.iam.gserviceaccount.com</code>.</p>&#13;
&#13;
<p>Create a credentials key and download it as <code>~/.gcloud/pythonfordevops-cloudfunction.json</code>.</p>&#13;
&#13;
<p>Specify the project and the path to the key in <em>serverless.yml</em>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">serverless</code><code class="o">.</code><code class="n">yml</code>&#13;
&#13;
<code class="n">service</code><code class="p">:</code> <code class="n">python</code><code class="o">-</code><code class="n">simple</code><code class="o">-</code><code class="n">http</code><code class="o">-</code><code class="n">endpoint</code>&#13;
&#13;
<code class="n">frameworkVersion</code><code class="p">:</code> <code class="s2">"&gt;=1.2.0 &lt;2.0.0"</code>&#13;
&#13;
<code class="n">package</code><code class="p">:</code>&#13;
  <code class="n">exclude</code><code class="p">:</code>&#13;
    <code class="o">-</code> <code class="n">node_modules</code><code class="o">/**</code>&#13;
    <code class="o">-</code> <code class="o">.</code><code class="n">gitignore</code>&#13;
    <code class="o">-</code> <code class="o">.</code><code class="n">git</code><code class="o">/**</code>&#13;
&#13;
<code class="n">plugins</code><code class="p">:</code>&#13;
  <code class="o">-</code> <code class="n">serverless</code><code class="o">-</code><code class="n">google</code><code class="o">-</code><code class="n">cloudfunctions</code>&#13;
&#13;
<code class="n">provider</code><code class="p">:</code>&#13;
  <code class="n">name</code><code class="p">:</code> <code class="n">google</code>&#13;
  <code class="n">runtime</code><code class="p">:</code> <code class="n">python37</code>&#13;
  <code class="n">project</code><code class="p">:</code> <code class="n">pythonfordevops</code><code class="o">-</code><code class="n">cloudfunction</code>&#13;
  <code class="n">credentials</code><code class="p">:</code> <code class="o">~/.</code><code class="n">gcloud</code><code class="o">/</code><code class="n">pythonfordevops</code><code class="o">-</code><code class="n">cloudfunction</code><code class="o">.</code><code class="n">json</code>&#13;
&#13;
<code class="n">functions</code><code class="p">:</code>&#13;
  <code class="n">currentTime</code><code class="p">:</code>&#13;
    <code class="n">handler</code><code class="p">:</code> <code class="n">endpoint</code>&#13;
    <code class="n">events</code><code class="p">:</code>&#13;
      <code class="o">-</code> <code class="n">http</code><code class="p">:</code> <code class="n">path</code></pre>&#13;
&#13;
<p>Go to the GCP Deployment Manager page and enable the Cloud Deployment Manager API; then also enable billing for Google Cloud Storage.</p>&#13;
&#13;
<p>Try deploying again:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless deploy&#13;
Serverless: Packaging service...&#13;
Serverless: Excluding development dependencies...&#13;
Serverless: Compiling function "currentTime"...&#13;
Serverless: Uploading artifacts...&#13;
&#13;
  Error --------------------------------------------------&#13;
&#13;
  Error: Not Found&#13;
  at createError&#13;
  (/Users/ggheo/code/mycode/examples/google-python-simple-http-endpoint/&#13;
  node_modules/axios/lib/core/createError.js:16:15)&#13;
  at settle (/Users/ggheo/code/mycode/examples/&#13;
  google-python-simple-http-endpoint/node_modules/axios/lib/&#13;
  core/settle.js:18:12)&#13;
  at IncomingMessage.handleStreamEnd&#13;
  (/Users/ggheo/code/mycode/examples/google-python-simple-http-endpoint/&#13;
  node_modules/axios/lib/adapters/http.js:202:11)&#13;
  at IncomingMessage.emit (events.js:214:15)&#13;
  at IncomingMessage.EventEmitter.emit (domain.js:476:20)&#13;
  at endReadableNT (_stream_readable.js:1178:12)&#13;
  at processTicksAndRejections (internal/process/task_queues.js:77:11)&#13;
&#13;
  For debugging logs, run again after setting the "SLS_DEBUG=*"&#13;
  environment variable.</pre>&#13;
&#13;
<p>Read through <a href="https://oreil.ly/scsRg">the Serverless platform documentation on GCP credentials and roles</a>.</p>&#13;
&#13;
<p>The following roles need to be assigned to the service account used for the <span class="keep-together">deployment:</span></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Deployment Manager Editor</p>&#13;
</li>&#13;
<li>&#13;
<p>Storage Admin</p>&#13;
</li>&#13;
<li>&#13;
<p>Logging Admin</p>&#13;
</li>&#13;
<li>&#13;
<p>Cloud Functions Developer roles</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Also read through <a href="https://oreil.ly/rKiHg">the Serverless platform documentation on the GCP APIs that need to be enabled</a>.</p>&#13;
&#13;
<p>The following APIs need to be enabled in the GCP console:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Google Cloud Functions</p>&#13;
</li>&#13;
<li>&#13;
<p>Google Cloud Deployment Manager</p>&#13;
</li>&#13;
<li>&#13;
<p>Google Cloud Storage</p>&#13;
</li>&#13;
<li>&#13;
<p>Stackdriver Logging</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Go to Deployment Manager in the GCP console and the inspect error messages:</p>&#13;
&#13;
<pre data-type="programlisting">sls-python-simple-http-endpoint-dev failed to deploy&#13;
&#13;
sls-python-simple-http-endpoint-dev has resource warnings&#13;
sls-python-simple-http-endpoint-dev-1566510445295:&#13;
{"ResourceType":"storage.v1.bucket",&#13;
"ResourceErrorCode":"403",&#13;
"ResourceErrorMessage":{"code":403,&#13;
"errors":[{"domain":"global","location":"Authorization",&#13;
"locationType":"header",&#13;
"message":"The project to be billed is associated&#13;
with an absent billing account.",&#13;
"reason":"accountDisabled"}],&#13;
"message":"The project to be billed is associated&#13;
 with an absent billing account.",&#13;
 "statusMessage":"Forbidden",&#13;
 "requestPath":"https://www.googleapis.com/storage/v1/b",&#13;
 "httpMethod":"POST"}}</pre>&#13;
&#13;
<p>Delete the <code>sls-python-simple-http-endpoint-dev</code> deployment in the GCP console and run <code>serverless deploy</code> again:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless deploy&#13;
&#13;
Deployed functions&#13;
first&#13;
  https://us-central1-pythonfordevops-cloudfunction.cloudfunctions.net/http</pre>&#13;
&#13;
<p>The <code>serverless deploy</code> command kept failing because initially we did not enable billing for Google Cloud Storage. The deployment was marked as failed for the service specified in <em>serverless.yml</em>, and subsequent <code>serverless deploy</code> commands failed even after enabling Cloud Storage billing. Once the failed deployment was deleted in the GCP console, the <code>serverless deploy</code> command started to work.</p>&#13;
&#13;
<p>Invoke the deployed Google Cloud Function directly:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless invoke --function currentTime&#13;
Serverless: v1os7ptg9o48 {&#13;
    "statusCode": 200,&#13;
    "body": {&#13;
        "message": "Received a POST request at 03:46:39.027230"&#13;
    }&#13;
}</pre>&#13;
&#13;
<p>Use the <code>serverless logs</code> command to inspect the logs:</p>&#13;
&#13;
<pre data-type="programlisting">$ serverless logs --function currentTime&#13;
Serverless: Displaying the 4 most recent log(s):&#13;
&#13;
2019-08-23T03:35:12.419846316Z: Function execution took 20 ms,&#13;
finished with status code: 200&#13;
2019-08-23T03:35:12.400499207Z: Function execution started&#13;
2019-08-23T03:34:27.133107221Z: Function execution took 11 ms,&#13;
finished with status code: 200&#13;
2019-08-23T03:34:27.122244864Z: Function execution started</pre>&#13;
&#13;
<p>Test the function endpoint with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl \&#13;
https://undefined-pythonfordevops-cloudfunction.cloudfunctions.net/endpoint&#13;
&lt;!DOCTYPE html&gt;&#13;
&lt;html lang=en&gt;&#13;
  &lt;p&gt;&lt;b&gt;404.&lt;/b&gt; &lt;ins&gt;That’s an error.&lt;/ins&gt;&#13;
  &lt;p&gt;The requested URL was not found on this server.&#13;
  &lt;ins&gt;That’s all we know.&lt;/ins&gt;</pre>&#13;
&#13;
<p>Since we didn’t define a region in <em>serverless.yml</em>, the endpoint URL starts with <code>undefined</code> and returns an error.</p>&#13;
&#13;
<p>Set the region to <code>us-central1</code> in <em>serverless.yml</em>:</p>&#13;
&#13;
<pre data-type="programlisting">provider:&#13;
  name: google&#13;
  runtime: python37&#13;
  region: us-central1&#13;
  project: pythonfordevops-cloudfunction&#13;
  credentials: /Users/ggheo/.gcloud/pythonfordevops-cloudfunction.json</pre>&#13;
&#13;
<p>Deploy the new version with <code>serverless deploy</code> and test the function endpoint <a data-startref="ix_ch13-asciidoc6" data-type="indexterm" id="idm46691320921208"/><a data-startref="ix_ch13-asciidoc5" data-type="indexterm" id="idm46691320920504"/>with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl \&#13;
https://us-central1-pythonfordevops-cloudfunction.cloudfunctions.net/endpoint&#13;
{&#13;
    "statusCode": 200,&#13;
    "body": {&#13;
        "message": "Received a GET request at 03:51:02.560756"&#13;
    }&#13;
}%</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying Python Function to Azure" data-type="sect2"><div class="sect2" id="idm46691321062952">&#13;
<h2>Deploying Python Function to Azure</h2>&#13;
&#13;
<p><a data-primary="Azure" data-type="indexterm" id="ix_ch13-asciidoc7"/><a data-primary="serverless technologies" data-secondary="deploying Python function to Azure" data-type="indexterm" id="ix_ch13-asciidoc8"/>The Serverless platform does not yet support <a href="https://oreil.ly/4WQKG">Azure Functions</a> based on Python. We will demonstrate how to deploy Azure Python Functions using Azure-native tools.</p>&#13;
&#13;
<p>Sign up for a Microsoft Azure account and install the Azure Functions runtime for your specific operating system, following the <a href="https://oreil.ly/GHS4c">official Microsoft documentation</a>. If you are on a macOS, use <code>brew</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ brew tap azure/functions&#13;
$ brew install azure-functions-core-tools</pre>&#13;
&#13;
<p>Create a new directory for the Python function code:</p>&#13;
&#13;
<pre data-type="programlisting">$ mkdir azure-functions-python&#13;
$ cd azure-functions-python</pre>&#13;
&#13;
<p>Install Python 3.6 because 3.7 is not supported by Azure Functions. Create and activate <code>virtualenv</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ brew unlink python&#13;
$ brew install \&#13;
https://raw.githubusercontent.com/Homebrew/homebrew-core/&#13;
f2a764ef944b1080be64bd88dca9a1d80130c558/Formula/python.rb \&#13;
--ignore-dependencies&#13;
&#13;
$ python3 -V&#13;
Python 3.6.5&#13;
&#13;
$ python3 -m venv .venv&#13;
$ source .venv/bin/activate</pre>&#13;
&#13;
<p>Using the <code>Azure func</code> utility, create a local Functions project called <code>python-simple-http-endpoint</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ func init python-simple-http-endpoint&#13;
Select a worker runtime:&#13;
1. dotnet&#13;
2. node&#13;
3. python&#13;
4. powershell (preview)&#13;
Choose option: 3</pre>&#13;
&#13;
<p>Change directories to the newly created <em>python-simple-http-endpoint</em> directory and create an Azure HTTP Trigger Function with the <code>func new</code> command:</p>&#13;
&#13;
<pre data-type="programlisting">$ cd python-simple-http-endpoint&#13;
$ func new&#13;
Select a template:&#13;
1. Azure Blob Storage trigger&#13;
2. Azure Cosmos DB trigger&#13;
3. Azure Event Grid trigger&#13;
4. Azure Event Hub trigger&#13;
5. HTTP trigger&#13;
6. Azure Queue Storage trigger&#13;
7. Azure Service Bus Queue trigger&#13;
8. Azure Service Bus Topic trigger&#13;
9. Timer trigger&#13;
Choose option: 5&#13;
HTTP trigger&#13;
Function name: [HttpTrigger] currentTime&#13;
Writing python-simple-http-endpoint/currentTime/__init__.py&#13;
Writing python-simple-http-endpoint/currentTime/function.json&#13;
The function "currentTime" was created successfully&#13;
from the "HTTP trigger" template.</pre>&#13;
&#13;
<p>Inspect the Python code created:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">currentTime</code><code class="o">/</code><code class="nf-Magic">__init__</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">import</code> <code class="nn">logging</code>&#13;
&#13;
<code class="kn">import</code> <code class="nn">azure.functions</code> <code class="kn">as</code> <code class="nn">func</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">main</code><code class="p">(</code><code class="n">req</code><code class="p">:</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpRequest</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">:</code>&#13;
    <code class="n">logging</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="s1">'Python HTTP trigger function processed a request.'</code><code class="p">)</code>&#13;
&#13;
    <code class="n">name</code> <code class="o">=</code> <code class="n">req</code><code class="o">.</code><code class="n">params</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'name'</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="ow">not</code> <code class="n">name</code><code class="p">:</code>&#13;
        <code class="k">try</code><code class="p">:</code>&#13;
            <code class="n">req_body</code> <code class="o">=</code> <code class="n">req</code><code class="o">.</code><code class="n">get_json</code><code class="p">()</code>&#13;
        <code class="k">except</code> <code class="ne">ValueError</code><code class="p">:</code>&#13;
            <code class="k">pass</code>&#13;
        <code class="k">else</code><code class="p">:</code>&#13;
            <code class="n">name</code> <code class="o">=</code> <code class="n">req_body</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'name'</code><code class="p">)</code>&#13;
&#13;
    <code class="k">if</code> <code class="n">name</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">(</code><code class="n">f</code><code class="s2">"Hello {name}!"</code><code class="p">)</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">(</code>&#13;
             <code class="s2">"Please pass a name on the query string or in the request body"</code><code class="p">,</code>&#13;
             <code class="n">status_code</code><code class="o">=</code><code class="mi">400</code>&#13;
        <code class="p">)</code></pre>&#13;
&#13;
<p>Run the function locally:</p>&#13;
&#13;
<pre data-type="programlisting">$ func host start&#13;
&#13;
[8/24/19 12:21:35 AM] Host initialized (299ms)&#13;
[8/24/19 12:21:35 AM] Host started (329ms)&#13;
[8/24/19 12:21:35 AM] Job host started&#13;
[8/24/19 12:21:35 AM]  INFO: Starting Azure Functions Python Worker.&#13;
[8/24/19 12:21:35 AM]  INFO: Worker ID: e49c429d-9486-4167-9165-9ecd1757a2b5,&#13;
Request ID: 2842271e-a8fe-4643-ab1a-f52381098ae6, Host Address: 127.0.0.1:53952&#13;
Hosting environment: Production&#13;
Content root path: python-simple-http-endpoint&#13;
Now listening on: http://0.0.0.0:7071&#13;
Application started. Press Ctrl+C to shut down.&#13;
[8/24/19 12:21:35 AM] INFO: Successfully opened gRPC channel to 127.0.0.1:53952&#13;
&#13;
Http Functions:&#13;
&#13;
  currentTime: [GET,POST] http://localhost:7071/api/currentTime</pre>&#13;
&#13;
<p>Test from another terminal:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl http://127.0.0.1:7071/api/currentTime\?name\=joe&#13;
Hello joe!%</pre>&#13;
&#13;
<p class="pagebreak-before">Change HTTP handler in <em>currentTime/init.py</em> to include the current time in its response:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">datetime</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">main</code><code class="p">(</code><code class="n">req</code><code class="p">:</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpRequest</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">:</code>&#13;
    <code class="n">logging</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="s1">'Python HTTP trigger function processed a request.'</code><code class="p">)</code>&#13;
&#13;
    <code class="n">name</code> <code class="o">=</code> <code class="n">req</code><code class="o">.</code><code class="n">params</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'name'</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="ow">not</code> <code class="n">name</code><code class="p">:</code>&#13;
        <code class="k">try</code><code class="p">:</code>&#13;
            <code class="n">req_body</code> <code class="o">=</code> <code class="n">req</code><code class="o">.</code><code class="n">get_json</code><code class="p">()</code>&#13;
        <code class="k">except</code> <code class="ne">ValueError</code><code class="p">:</code>&#13;
            <code class="k">pass</code>&#13;
        <code class="k">else</code><code class="p">:</code>&#13;
            <code class="n">name</code> <code class="o">=</code> <code class="n">req_body</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'name'</code><code class="p">)</code>&#13;
&#13;
    <code class="n">current_time</code> <code class="o">=</code> <code class="n">datetime</code><code class="o">.</code><code class="n">datetime</code><code class="o">.</code><code class="n">now</code><code class="p">()</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>&#13;
    <code class="k">if</code> <code class="n">name</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">(</code><code class="n">f</code><code class="s2">"Hello {name},</code>&#13;
        <code class="n">the</code> <code class="n">current</code> <code class="n">time</code> <code class="ow">is</code> <code class="p">{</code><code class="n">current_time</code><code class="p">}</code><code class="err">!</code><code class="s2">")</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="n">func</code><code class="o">.</code><code class="n">HttpResponse</code><code class="p">(</code>&#13;
             <code class="s2">"Please pass a name on the query string or in the request body"</code><code class="p">,</code>&#13;
             <code class="n">status_code</code><code class="o">=</code><code class="mi">400</code>&#13;
        <code class="p">)</code></pre>&#13;
&#13;
<p>Test the new function with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl http://127.0.0.1:7071/api/currentTime\?name\=joe&#13;
Hello joe, the current time is 17:26:54.256060!%</pre>&#13;
&#13;
<p>Install the Azure CLI with <code>pip</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ pip install azure.cli</pre>&#13;
&#13;
<p>Create an Azure Resource Group, Storage Account, and Function App using the <code>az</code> CLI utility in interactive mode.&#13;
This mode places you in an interactive shell with auto-completion, command descriptions, and examples. Note that if&#13;
you want to follow along, you will need to specify a different and unique <code>functionapp</code> name. You might also need to specify a different Azure region, such as <code>eastus</code>, that supports free trial accounts:</p>&#13;
&#13;
<pre data-type="programlisting">$ az interactive&#13;
az&gt;&gt; login&#13;
az&gt;&gt; az group create --name myResourceGroup --location westus2&#13;
az&gt;&gt; az storage account create --name griggheorghiustorage --location westus2 \&#13;
--resource-group myResourceGroup --sku Standard_LRS&#13;
az&gt;&gt; az functionapp create --resource-group myResourceGroup --os-type Linux \&#13;
--consumption-plan-location westus2 --runtime python \&#13;
--name pyazure-devops4all \&#13;
--storage-account griggheorghiustorage&#13;
az&gt;&gt; exit</pre>&#13;
&#13;
<p>Deploy the <code>functionapp</code> project to Azure using the <code>func</code> utility:</p>&#13;
&#13;
<pre data-type="programlisting">$ func azure functionapp publish pyazure-devops4all --build remote&#13;
Getting site publishing info...&#13;
Creating archive for current directory...&#13;
Perform remote build for functions project (--build remote).&#13;
Uploading 2.12 KB&#13;
&#13;
OUTPUT OMITTED&#13;
&#13;
Running post deployment command(s)...&#13;
Deployment successful.&#13;
App container will begin restart within 10 seconds.&#13;
Remote build succeeded!&#13;
Syncing triggers...&#13;
Functions in pyazure-devops4all:&#13;
    currentTime - [httpTrigger]&#13;
      Invoke url:&#13;
      https://pyazure-devops4all.azurewebsites.net/api/&#13;
      currenttime?code=b0rN93O04cGPcGFKyX7n9HgITTPnHZiGCmjJN/SRsPX7taM7axJbbw==</pre>&#13;
&#13;
<p>Test the deployed function in Azure by hitting its endpoint with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl "https://pyazure-devops4all.azurewebsites.net/api/currenttime\&#13;
?code\=b0rN93O04cGPcGFKyX7n9HgITTPnHZiGCmjJN/SRsPX7taM7axJbbw\=\=\&amp;name\=joe"&#13;
Hello joe, the current time is 01:20:32.036097!%</pre>&#13;
&#13;
<p>It is always a good idea to remove any cloud resources you don’t need anymore. In this case, you can run<a data-startref="ix_ch13-asciidoc8" data-type="indexterm" id="idm46691320605768"/><a data-startref="ix_ch13-asciidoc7" data-type="indexterm" id="idm46691320605064"/>:<a data-startref="ix_ch13-asciidoc2" data-type="indexterm" id="idm46691320604264"/></p>&#13;
&#13;
<pre data-type="programlisting">$ az group delete --name myResourceGroup</pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying a Python Function to Self-Hosted FaaS Platforms" data-type="sect1"><div class="sect1" id="idm46691320918104">&#13;
<h1>Deploying a Python Function to Self-Hosted <span class="keep-together">FaaS Platforms</span></h1>&#13;
&#13;
<p><a data-primary="function as a service (FaaS)" data-secondary="self-hosted" data-type="indexterm" id="ix_ch13-asciidoc9"/><a data-primary="serverless technologies" data-secondary="deploying Python function to self-hosted Faas platforms" data-type="indexterm" id="ix_ch13-asciidoc10"/>As mentioned earlier in this chapter, many FaaS platforms are running on top of Kubernetes clusters. One advantage of this approach is that the functions you deploy run as regular Docker containers inside Kubernetes, so you can use your existing Kubernetes tooling, especially when it comes to observability (monitoring, logging, and tracing). Another advantage is potential cost savings. By running your serverless functions as containers inside an existing Kubernetes cluster, you can use the existing capacity of the cluster and not pay per function call as you would if you deployed your functions to a third-party FaaS platform.</p>&#13;
&#13;
<p>In this section, we consider one of these platforms: <a href="https://www.openfaas.com">OpenFaaS</a>. Some other examples of similar FaaS platforms running on Kubernetes include the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://kubeless.io">Kubeless</a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://fnproject.io">Fn Project</a> (the underlying technology powering the Oracle FaaS offering called Oracle Functions)</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://fission.io">Fission</a></p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://openwhisk.apache.org">Apache OpenWhisk</a></p>&#13;
</li>&#13;
</ul>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Deploying Python Function to OpenFaaS" data-type="sect2"><div class="sect2" id="idm46691320590840">&#13;
<h2>Deploying Python Function to OpenFaaS</h2>&#13;
&#13;
<p><a data-primary="function as a service (FaaS)" data-secondary="openFaas" data-type="indexterm" id="ix_ch13-asciidoc11"/><a data-primary="openFaas" data-type="indexterm" id="ix_ch13-asciidoc12"/><a data-primary="serverless technologies" data-secondary="deploying Python function to OpenFaas" data-type="indexterm" id="ix_ch13-asciidoc13"/>For this example, we use a “Kubernetes-lite” distribution from Rancher called <code>k3s</code>. We use <code>k3s</code> instead of <code>minikube</code> to showcase the wide variety of tools available in the Kubernetes ecosystem.</p>&#13;
&#13;
<p>Start by running the <a href="https://oreil.ly/qK0xJ"><code>k3sup</code></a> utility to provision a <code>k3s</code> Kubernetes cluster on an Ubuntu EC2 instance.</p>&#13;
&#13;
<p>Download and install <code>k3sup</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -sLS https://get.k3sup.dev | sh&#13;
$ sudo cp k3sup-darwin /usr/local/bin/k3sup</pre>&#13;
&#13;
<p>Verify SSH connectivity into the remote EC2 instance:</p>&#13;
&#13;
<pre data-type="programlisting">$ ssh ubuntu@35.167.68.86 date&#13;
Sat Aug 24 21:38:57 UTC 2019</pre>&#13;
&#13;
<p>Install <code>k3s</code> via <code>k3sup install</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ k3sup install --ip 35.167.68.86 --user ubuntu&#13;
OUTPUT OMITTED&#13;
Saving file to: kubeconfig</pre>&#13;
&#13;
<p>Inspect the <em>kubeconfig</em> file:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat kubeconfig&#13;
apiVersion: v1&#13;
clusters:&#13;
- cluster:&#13;
    certificate-authority-data: BASE64_FIELD&#13;
    server: https://35.167.68.86:6443&#13;
  name: default&#13;
contexts:&#13;
- context:&#13;
    cluster: default&#13;
    user: default&#13;
  name: default&#13;
current-context: default&#13;
kind: Config&#13;
preferences: {}&#13;
users:&#13;
- name: default&#13;
  user:&#13;
    password: OBFUSCATED&#13;
    username: admin</pre>&#13;
&#13;
<p>Point the <code>KUBECONFIG</code> environment variable to the local <em>kubeconfig</em> file and test <code>kubectl</code> commands against the remote k3s cluster:</p>&#13;
&#13;
<pre data-type="programlisting">$ export KUBECONFIG=./kubeconfig&#13;
&#13;
$ kubectl cluster-info&#13;
Kubernetes master is running at https://35.167.68.86:6443&#13;
CoreDNS is running at&#13;
https://35.167.68.86:6443/api/v1/namespaces/kube-system/&#13;
services/kube-dns:dns/proxy&#13;
&#13;
To further debug and diagnose cluster problems, use&#13;
'kubectl cluster-info dump'.&#13;
&#13;
$ kubectl get nodes&#13;
NAME            STATUS   ROLES    AGE   VERSION&#13;
ip-10-0-0-185   Ready    master   10m   v1.14.6-k3s.1</pre>&#13;
&#13;
<p>The next step is to install the OpenFaas Serverless platform on the k3s Kubernetes cluster.</p>&#13;
&#13;
<p>Install <code>faas-cli</code> on the local macOS:</p>&#13;
&#13;
<pre data-type="programlisting">$ brew install faas-cli</pre>&#13;
&#13;
<p>Create RBAC permissions for Tiller, which is the server component of Helm:</p>&#13;
&#13;
<pre data-type="programlisting">$ kubectl -n kube-system create sa tiller \&#13;
  &amp;&amp; kubectl create clusterrolebinding tiller \&#13;
  --clusterrole cluster-admin \&#13;
  --serviceaccount=kube-system:tiller&#13;
serviceaccount/tiller created&#13;
clusterrolebinding.rbac.authorization.k8s.io/tiller created</pre>&#13;
&#13;
<p>Install Tiller via <code>helm init</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ helm init --skip-refresh --upgrade --service-account tiller</pre>&#13;
&#13;
<p>Download, configure, and install the Helm chart for OpenFaaS:</p>&#13;
&#13;
<pre data-type="programlisting">$ wget \&#13;
https://raw.githubusercontent.com/openfaas/faas-netes/master/namespaces.yml&#13;
&#13;
$ cat namespaces.yml&#13;
apiVersion: v1&#13;
kind: Namespace&#13;
metadata:&#13;
  name: openfaas&#13;
  labels:&#13;
    role: openfaas-system&#13;
    access: openfaas-system&#13;
    istio-injection: enabled&#13;
---&#13;
apiVersion: v1&#13;
kind: Namespace&#13;
metadata:&#13;
  name: openfaas-fn&#13;
  labels:&#13;
    istio-injection: enabled&#13;
    role: openfaas-fn&#13;
&#13;
$ kubectl apply -f namespaces.yml&#13;
namespace/openfaas created&#13;
namespace/openfaas-fn created&#13;
&#13;
$ helm repo add openfaas https://openfaas.github.io/faas-netes/&#13;
"openfaas" has been added to your repositories</pre>&#13;
&#13;
<p>Generate a random password for basic authentication to the OpenFaaS gateway:</p>&#13;
&#13;
<pre data-type="programlisting">$ PASSWORD=$(head -c 12 /dev/urandom | shasum| cut -d' ' -f1)&#13;
&#13;
$ kubectl -n openfaas create secret generic basic-auth \&#13;
--from-literal=basic-auth-user=admin \&#13;
--from-literal=basic-auth-password="$PASSWORD"&#13;
secret/basic-auth created</pre>&#13;
&#13;
<p>Deploy OpenFaaS by installing the Helm chart:</p>&#13;
&#13;
<pre data-type="programlisting">$ helm repo update \&#13;
 &amp;&amp; helm upgrade openfaas --install openfaas/openfaas \&#13;
    --namespace openfaas  \&#13;
    --set basic_auth=true \&#13;
    --set serviceType=LoadBalancer \&#13;
    --set functionNamespace=openfaas-fn&#13;
&#13;
OUTPUT OMITTED&#13;
&#13;
NOTES:&#13;
To verify that openfaas has started, run:&#13;
kubectl --namespace=openfaas get deployments -l "release=openfaas,app=openfaas"</pre>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The <code>basic_auth</code> setup used here without TLS should ONLY be used for experimenting/learning. Any environment of consquence should be configured to ensure that credentials are passed over a secure TLS connection.</p>&#13;
</div>&#13;
&#13;
<p>Verify the services running in the <code>openfaas</code> namespace:</p>&#13;
&#13;
<pre data-type="programlisting">$ kubectl get service -nopenfaas&#13;
NAME                TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)&#13;
alertmanager        ClusterIP      10.43.193.61    &lt;none&gt;        9093/TCP&#13;
basic-auth-plugin   ClusterIP      10.43.83.12     &lt;none&gt;        8080/TCP&#13;
gateway             ClusterIP      10.43.7.46      &lt;none&gt;        8080/TCP&#13;
gateway-external    LoadBalancer   10.43.91.91     10.0.0.185    8080:31408/TCP&#13;
nats                ClusterIP      10.43.33.153    &lt;none&gt;        4222/TCP&#13;
prometheus          ClusterIP      10.43.122.184   &lt;none&gt;        9090/TCP</pre>&#13;
&#13;
<p>Forward port 8080 from the remote instance to port 8080 locally:</p>&#13;
&#13;
<pre data-type="programlisting">$ kubectl port-forward -n openfaas svc/gateway 8080:8080 &amp;&#13;
[1] 29183&#13;
Forwarding from 127.0.0.1:8080 -&gt; 8080</pre>&#13;
&#13;
<p>Go to the OpenFaaS web UI at <a href="http://localhost:8080"><em class="hyperlink">http://localhost:8080</em></a> and log in using username <code>admin</code> and password <code>$PASSWORD</code>.</p>&#13;
&#13;
<p>Continue by creating an OpenFaaS Python function. Use the <code>faas-cli</code> tool to create a new OpenFaaS function called <a data-primary="hello python function" data-type="indexterm" id="idm46691320553144"/><code>hello-python</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli new --lang python hello-python&#13;
Folder: hello-python created.&#13;
Function created in folder: hello-python&#13;
Stack file written: hello-python.yml</pre>&#13;
&#13;
<p>Inspect the configuration file for the <code>hello-python</code> function:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat hello-python.yml</code>&#13;
<code class="l-Scalar-Plain">version</code><code class="p-Indicator">:</code> <code class="l-Scalar-Plain">1.0</code>&#13;
<code class="nt">provider</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">openfaas</code>&#13;
  <code class="nt">gateway</code><code class="p">:</code> <code class="l-Scalar-Plain">http://127.0.0.1:8080</code>&#13;
<code class="nt">functions</code><code class="p">:</code>&#13;
  <code class="nt">hello-python</code><code class="p">:</code>&#13;
    <code class="nt">lang</code><code class="p">:</code> <code class="l-Scalar-Plain">python</code>&#13;
    <code class="nt">handler</code><code class="p">:</code> <code class="l-Scalar-Plain">./hello-python</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">hello-python:latest</code></pre>&#13;
&#13;
<p>Inspect the automatically created directory <em>hello-python</em>:</p>&#13;
&#13;
<pre data-type="programlisting">$ ls -la hello-python&#13;
total 8&#13;
drwx------  4 ggheo  staff  128 Aug 24 15:16 .&#13;
drwxr-xr-x  8 ggheo  staff  256 Aug 24 15:16 ..&#13;
-rw-r--r--  1 ggheo  staff  123 Aug 24 15:16 handler.py&#13;
-rw-r--r--  1 ggheo  staff    0 Aug 24 15:16 requirements.txt&#13;
&#13;
$ cat hello-python/handler.py&#13;
def handle(req):&#13;
    """handle a request to the function&#13;
    Args:&#13;
        req (str): request body&#13;
    """&#13;
&#13;
    return req</pre>&#13;
&#13;
<p class="pagebreak-before">Edit <em>handler.py</em> and bring over the code that prints the current time from the Serverless platform’s simple-http-example:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">hello</code><code class="o">-</code><code class="n">python</code><code class="o">/</code><code class="n">handler</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">import</code> <code class="nn">json</code>&#13;
<code class="kn">import</code> <code class="nn">datetime</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">handle</code><code class="p">(</code><code class="n">req</code><code class="p">):</code>&#13;
    <code class="sd">"""handle a request to the function</code>&#13;
<code class="sd">    Args:</code>&#13;
<code class="sd">        req (str): request body</code>&#13;
<code class="sd">    """</code>&#13;
&#13;
    <code class="n">current_time</code> <code class="o">=</code> <code class="n">datetime</code><code class="o">.</code><code class="n">datetime</code><code class="o">.</code><code class="n">now</code><code class="p">()</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>&#13;
    <code class="n">body</code> <code class="o">=</code> <code class="p">{</code>&#13;
        <code class="s2">"message"</code><code class="p">:</code> <code class="s2">"Received a {} at {}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">req</code><code class="p">,</code> <code class="nb">str</code><code class="p">(</code><code class="n">current_time</code><code class="p">))</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="n">response</code> <code class="o">=</code> <code class="p">{</code>&#13;
        <code class="s2">"statusCode"</code><code class="p">:</code> <code class="mi">200</code><code class="p">,</code>&#13;
        <code class="s2">"body"</code><code class="p">:</code> <code class="n">body</code>&#13;
    <code class="p">}</code>&#13;
    <code class="k">return</code> <code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">(</code><code class="n">response</code><code class="p">,</code> <code class="n">indent</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code></pre>&#13;
&#13;
<p>The next step is to build the OpenFaaS Python function. Use the <a data-primary="faas-cli build command" data-type="indexterm" id="idm46691320474632"/><code>faas-cli build</code> command, which will build a Docker image based on an autogenerated Dockerfile:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli build -f ./hello-python.yml&#13;
[0] &gt; Building hello-python.&#13;
Clearing temporary build folder: ./build/hello-python/&#13;
Preparing ./hello-python/ ./build/hello-python//function&#13;
Building: hello-python:latest with python template. Please wait..&#13;
Sending build context to Docker daemon  8.192kB&#13;
Step 1/29 : FROM openfaas/classic-watchdog:0.15.4 as watchdog&#13;
&#13;
DOCKER BUILD OUTPUT OMITTED&#13;
&#13;
Successfully tagged hello-python:latest&#13;
Image: hello-python:latest built.&#13;
[0] &lt; Building hello-python done.&#13;
[0] worker done.</pre>&#13;
&#13;
<p>Check that the Docker image is present locally:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker images | grep hello-python&#13;
hello-python                          latest&#13;
05b2c37407e1        29 seconds ago      75.5MB</pre>&#13;
&#13;
<p>Tag and push the Docker image to Docker Hub registry so it can be used on the remote Kubernetes cluster:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker tag hello-python:latest griggheo/hello-python:latest</pre>&#13;
&#13;
<p class="pagebreak-before">Edit <em>hello-python.yml</em> and change:</p>&#13;
&#13;
<pre data-type="programlisting">image: griggheo/hello-python:latest</pre>&#13;
&#13;
<p>Use the <a data-primary="faas-cli push command" data-type="indexterm" id="idm46691320351256"/><code>faas-cli push</code> command to push the image to Docker Hub:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli push -f ./hello-python.yml&#13;
[0] &gt; Pushing hello-python [griggheo/hello-python:latest].&#13;
The push refers to repository [docker.io/griggheo/hello-python]&#13;
latest: digest:&#13;
sha256:27e1fbb7f68bb920a6ff8d3baf1fa3599ae92e0b3c607daac3f8e276aa7f3ae3&#13;
size: 4074&#13;
[0] &lt; Pushing hello-python [griggheo/hello-python:latest] done.&#13;
[0] worker done.</pre>&#13;
&#13;
<p>Next, deploy the OpenFaaS Python function to the remote <code>k3s</code> cluster. Use the <code>faas-cli deploy</code> command to deploy the function:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli deploy -f ./hello-python.yml&#13;
Deploying: hello-python.&#13;
WARNING! Communication is not secure, please consider using HTTPS.&#13;
Letsencrypt.org offers free SSL/TLS certificates.&#13;
Handling connection for 8080&#13;
&#13;
unauthorized access, run "faas-cli login"&#13;
to setup authentication for this server&#13;
&#13;
Function 'hello-python' failed to deploy with status code: 401</pre>&#13;
&#13;
<p>Use the <a data-primary="faas-cli login command" data-type="indexterm" id="idm46691320346280"/><code>faas-cli login</code> command to obtain authenication credentials:</p>&#13;
&#13;
<pre data-type="programlisting">$ echo -n $PASSWORD | faas-cli login -g http://localhost:8080 \&#13;
-u admin --password-stdin&#13;
Calling the OpenFaaS server to validate the credentials...&#13;
Handling connection for 8080&#13;
WARNING! Communication is not secure, please consider using HTTPS.&#13;
Letsencrypt.org offers free SSL/TLS certificates.&#13;
credentials saved for admin http://localhost:8080</pre>&#13;
&#13;
<p>Edit <em>hello-python.yml</em> and change:</p>&#13;
&#13;
<pre data-type="programlisting">gateway: http://localhost:8080</pre>&#13;
&#13;
<p>Because we are returning JSON from our handler, add these lines to <em>hello-python.yml</em>:</p>&#13;
&#13;
<pre data-type="programlisting">    environment:&#13;
      content_type: application/json</pre>&#13;
&#13;
<p class="pagebreak-before">Contents of <em>hello-python.yml</em>:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat hello-python.yml</code>&#13;
<code class="l-Scalar-Plain">version</code><code class="p-Indicator">:</code> <code class="l-Scalar-Plain">1.0</code>&#13;
<code class="nt">provider</code><code class="p">:</code>&#13;
  <code class="nt">name</code><code class="p">:</code> <code class="l-Scalar-Plain">openfaas</code>&#13;
  <code class="nt">gateway</code><code class="p">:</code> <code class="l-Scalar-Plain">http://localhost:8080</code>&#13;
<code class="nt">functions</code><code class="p">:</code>&#13;
  <code class="nt">hello-python</code><code class="p">:</code>&#13;
    <code class="nt">lang</code><code class="p">:</code> <code class="l-Scalar-Plain">python</code>&#13;
    <code class="nt">handler</code><code class="p">:</code> <code class="l-Scalar-Plain">./hello-python</code>&#13;
    <code class="nt">image</code><code class="p">:</code> <code class="l-Scalar-Plain">griggheo/hello-python:latest</code>&#13;
    <code class="nt">environment</code><code class="p">:</code>&#13;
      <code class="nt">content_type</code><code class="p">:</code> <code class="l-Scalar-Plain">application/json</code></pre>&#13;
&#13;
<p>Run the <code>faas-cli deploy</code> command again:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli deploy -f ./hello-python.yml&#13;
Deploying: hello-python.&#13;
WARNING! Communication is not secure, please consider using HTTPS.&#13;
Letsencrypt.org offers free SSL/TLS certificates.&#13;
Handling connection for 8080&#13;
Handling connection for 8080&#13;
&#13;
Deployed. 202 Accepted.&#13;
URL: http://localhost:8080/function/hello-python</pre>&#13;
&#13;
<p>If a code change is needed, use the following commands to rebuild and redeploy the function. Note that the <code>faas-cli remove</code> command will delete the current version of the function:</p>&#13;
&#13;
<pre data-type="programlisting">$ faas-cli build -f ./hello-python.yml&#13;
$ faas-cli push -f ./hello-python.yml&#13;
$ faas-cli remove -f ./hello-python.yml&#13;
$ faas-cli deploy -f ./hello-python.yml</pre>&#13;
&#13;
<p>Now test the deployed function with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl localhost:8080/function/hello-python --data-binary 'hello'&#13;
Handling connection for 8080&#13;
{&#13;
    "body": {&#13;
        "message": "Received a hello at 22:55:05.225295"&#13;
    },&#13;
    "statusCode": 200&#13;
}</pre>&#13;
&#13;
<p>Test by invoking the function directly with <code>faas-cli</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ echo -n "hello" | faas-cli invoke hello-python&#13;
Handling connection for 8080&#13;
{&#13;
    "body": {&#13;
        "message": "Received a hello at 22:56:23.549509"&#13;
    },&#13;
    "statusCode": 200&#13;
}</pre>&#13;
&#13;
<p>The next example will be more full featured. We will demonstrate how to use the AWS CDK to provision several Lambda functions behind an API Gateway for create/read/update/delete (CRUD) REST access to <code>todo</code> items stored in a DynamoDB table. We will also show how to load test our REST API with containers deployed in AWS Fargate and running the Locust load-testing tool against the API. The Fargate containers will also be provisioned with the AWS CDK<a data-startref="ix_ch13-asciidoc13" data-type="indexterm" id="idm46691320260808"/><a data-startref="ix_ch13-asciidoc12" data-type="indexterm" id="idm46691320260104"/><a data-startref="ix_ch13-asciidoc11" data-type="indexterm" id="idm46691320259432"/>.<a data-startref="ix_ch13-asciidoc10" data-type="indexterm" id="idm46691320258632"/><a data-startref="ix_ch13-asciidoc9" data-type="indexterm" id="idm46691320257928"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Provisioning DynamoDB Table, Lambda Functions, and API Gateway Methods Using the AWS CDK" data-type="sect1"><div class="sect1" id="idm46691320589256">&#13;
<h1>Provisioning DynamoDB Table, Lambda Functions, and API Gateway Methods Using the AWS CDK</h1>&#13;
&#13;
<p><a data-primary="API Gateway methods" data-type="indexterm" id="ix_ch13-asciidoc14"/><a data-primary="AWS (Amazon Web Services)" data-secondary="CDK" data-type="indexterm" id="ix_ch13-asciidoc15"/><a data-primary="DynamoDB table" data-type="indexterm" id="ix_ch13-asciidoc16"/><a data-primary="Lambda functions" data-type="indexterm" id="ix_ch13-asciidoc17"/><a data-primary="serverless technologies" data-secondary="provisioning DynamoDB table/Lambda functions/API Gateway methods using the AWS CDK" data-type="indexterm" id="ix_ch13-asciidoc18"/>We briefly mentioned the AWS CDK in <a data-type="xref" href="ch10.html#infra-as-code">Chapter 10</a>. AWS CDK is a product that allows you to define the desired state of the infrastructure using real code (currently supported languages are TypeScript and Python), as opposed to using a YAML definition file (as the Serverless platform does).</p>&#13;
&#13;
<p>Install CDK CLI with <code>npm</code> at the global level (depending on your operating system, you may need to run the following command with <code>sudo</code>):</p>&#13;
&#13;
<pre data-type="programlisting">$ npm install cdk -g</pre>&#13;
&#13;
<p>Create a directory for the CDK application:</p>&#13;
&#13;
<pre data-type="programlisting">$ mkdir cdk-lambda-dynamodb-fargate&#13;
$ cd cdk-lambda-dynamodb-fargate</pre>&#13;
&#13;
<p>Create a sample Python application with <code>cdk init</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk init app --language=python&#13;
Applying project template app for python&#13;
Executing Creating virtualenv...&#13;
&#13;
# Welcome to your CDK Python project!&#13;
&#13;
This is a blank project for Python development with CDK.&#13;
The `cdk.json` file tells the CDK Toolkit how to execute your app.</pre>&#13;
&#13;
<p>List the files created:</p>&#13;
&#13;
<pre data-type="programlisting">$ ls -la&#13;
total 40&#13;
drwxr-xr-x   9 ggheo  staff   288 Sep  2 10:10 .&#13;
drwxr-xr-x  12 ggheo  staff   384 Sep  2 10:10 ..&#13;
drwxr-xr-x   6 ggheo  staff   192 Sep  2 10:10 .env&#13;
-rw-r--r--   1 ggheo  staff  1651 Sep  2 10:10 README.md&#13;
-rw-r--r--   1 ggheo  staff   252 Sep  2 10:10 app.py&#13;
-rw-r--r--   1 ggheo  staff    32 Sep  2 10:10 cdk.json&#13;
drwxr-xr-x   4 ggheo  staff   128 Sep  2 10:10 cdk_lambda_dynamodb_fargate&#13;
-rw-r--r--   1 ggheo  staff     5 Sep  2 10:10 requirements.txt&#13;
-rw-r--r--   1 ggheo  staff  1080 Sep  2 10:10 setup.py</pre>&#13;
&#13;
<p>Inspect the main file <em>app.py</em>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">app</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="c1">#!/usr/bin/env python3</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">cdk_lambda_dynamodb_fargate.cdk_lambda_dynamodb_fargate_stack</code> \&#13;
<code class="kn">import</code> <code class="n">CdkLambdaDynamodbFargateStack</code>&#13;
&#13;
<code class="n">app</code> <code class="o">=</code> <code class="n">core</code><code class="o">.</code><code class="n">App</code><code class="p">()</code>&#13;
<code class="n">CdkLambdaDynamodbFargateStack</code><code class="p">(</code><code class="n">app</code><code class="p">,</code> <code class="s2">"cdk-lambda-dynamodb-fargate"</code><code class="p">)</code>&#13;
&#13;
<code class="n">app</code><code class="o">.</code><code class="n">synth</code><code class="p">()</code></pre>&#13;
&#13;
<p>A CDK program is composed of an <em>app</em> that can contain one or more <em>stacks</em>. A stack corresponds to a CloudFormation stack object.</p>&#13;
&#13;
<p>Inspect the module defining the CDK stack:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">cdk_lambda_dynamodb_fargate</code><code class="o">/</code><code class="n">cdk_lambda_dynamodb_fargate_stack</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">CdkLambdaDynamodbFargateStack</code><code class="p">(</code><code class="n">core</code><code class="o">.</code><code class="n">Stack</code><code class="p">):</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">scope</code><code class="p">:</code> <code class="n">core</code><code class="o">.</code><code class="n">Construct</code><code class="p">,</code> <code class="nb">id</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="bp">None</code><code class="p">:</code>&#13;
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="n">scope</code><code class="p">,</code> <code class="nb">id</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># The code that defines your stack goes here</code></pre>&#13;
&#13;
<p>Because we are going to have two stacks, one for the DynamoDB/Lambda/API Gateway resources, and one for the Fargate resources, rename</p>&#13;
&#13;
<p><em>cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_fargate_stack.py</em></p>&#13;
&#13;
<p>to <em>cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py</em></p>&#13;
&#13;
<p>and the class <code>CdkLambdaDynamodbFargateStack</code> to <code>CdkLambdaDynamodbStack</code>.</p>&#13;
&#13;
<p>Also change <em>app.py</em> to refer to the changed module and class names:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">cdk_lambda_dynamodb_fargate.cdk_lambda_dynamodb_stack</code> \&#13;
<code class="kn">import</code> <code class="n">CdkLambdaDynamodbStack</code>&#13;
&#13;
<code class="n">CdkLambdaDynamodbStack</code><code class="p">(</code><code class="n">app</code><code class="p">,</code> <code class="s2">"cdk-lambda-dynamodb"</code><code class="p">)</code></pre>&#13;
&#13;
<p>Activate <code>virtualenv</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ source .env/bin/activate</pre>&#13;
&#13;
<p>We are going to take the <a href="https://oreil.ly/q2dDF">URL shortener CDK example</a> and modify it with code from the <a href="https://oreil.ly/o_gxS">Serverless platform AWS Python REST API example</a> to build a REST API for creating, listing, getting, updating, and deleting <code>todo</code> items. Amazon DynamoDB is used to store the data.</p>&#13;
&#13;
<p>Inspect the <em>serverless.yml</em> file from <em>examples/aws-python-rest-api-with-dynamodb</em> and deploy it with the <code>serverless</code> command to see what AWS resources get created:</p>&#13;
&#13;
<pre data-type="programlisting">$ pwd&#13;
~/code/examples/aws-python-rest-api-with-dynamodb&#13;
&#13;
$ serverless deploy&#13;
Serverless: Stack update finished...&#13;
Service Information&#13;
service: serverless-rest-api-with-dynamodb&#13;
stage: dev&#13;
region: us-east-1&#13;
stack: serverless-rest-api-with-dynamodb-dev&#13;
resources: 34&#13;
api keys:&#13;
  None&#13;
endpoints:&#13;
POST - https://tbst34m2b7.execute-api.us-east-1.amazonaws.com/dev/todos&#13;
GET - https://tbst34m2b7.execute-api.us-east-1.amazonaws.com/dev/todos&#13;
GET - https://tbst34m2b7.execute-api.us-east-1.amazonaws.com/dev/todos/{id}&#13;
PUT - https://tbst34m2b7.execute-api.us-east-1.amazonaws.com/dev/todos/{id}&#13;
DELETE - https://tbst34m2b7.execute-api.us-east-1.amazonaws.com/dev/todos/{id}&#13;
functions:&#13;
  create: serverless-rest-api-with-dynamodb-dev-create&#13;
  list: serverless-rest-api-with-dynamodb-dev-list&#13;
  get: serverless-rest-api-with-dynamodb-dev-get&#13;
  update: serverless-rest-api-with-dynamodb-dev-update&#13;
  delete: serverless-rest-api-with-dynamodb-dev-delete&#13;
layers:&#13;
  None&#13;
Serverless: Run the "serverless" command to setup monitoring, troubleshooting and&#13;
            testing.</pre>&#13;
&#13;
<p>The previous command created five Lambda functions, one API Gateway, and one DynamoDB table.</p>&#13;
&#13;
<p>In the CDK directory, add a DynamoDB table to the stack we are building:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">pwd</code>&#13;
<code class="o">~/</code><code class="n">code</code><code class="o">/</code><code class="n">devops</code><code class="o">/</code><code class="n">serverless</code><code class="o">/</code><code class="n">cdk</code><code class="o">-</code><code class="k">lambda</code><code class="o">-</code><code class="n">dynamodb</code><code class="o">-</code><code class="n">fargate</code>&#13;
&#13;
<code class="err">$</code> <code class="n">cat</code> <code class="n">cdk_lambda_dynamodb_fargate</code><code class="o">/</code><code class="n">cdk_lambda_dynamodb_stack</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">aws_dynamodb</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">CdkLambdaDynamodbStack</code><code class="p">(</code><code class="n">core</code><code class="o">.</code><code class="n">Stack</code><code class="p">):</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">scope</code><code class="p">:</code> <code class="n">core</code><code class="o">.</code><code class="n">Construct</code><code class="p">,</code> <code class="nb">id</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="bp">None</code><code class="p">:</code>&#13;
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="n">scope</code><code class="p">,</code> <code class="nb">id</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define the table stores Todo items</code>&#13;
        <code class="n">table</code> <code class="o">=</code> <code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">Table</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"Table"</code><code class="p">,</code>&#13;
                                    <code class="n">partition_key</code><code class="o">=</code><code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">Attribute</code><code class="p">(</code>&#13;
                                      <code class="n">name</code><code class="o">=</code><code class="s2">"id"</code><code class="p">,</code>&#13;
                                      <code class="nb">type</code><code class="o">=</code><code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">AttributeType</code><code class="o">.</code><code class="n">STRING</code><code class="p">),</code>&#13;
                                    <code class="n">read_capacity</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code>&#13;
                                    <code class="n">write_capacity</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>&#13;
&#13;
<p>Install the required Python modules:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat requirements.txt&#13;
-e .&#13;
aws-cdk.core&#13;
aws-cdk.aws-dynamodb&#13;
&#13;
$ pip install -r requirements.txt</pre>&#13;
&#13;
<p>Inspect the CloudFormation stack that will be created by running <code>cdk synth</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ export AWS_PROFILE=gheorghiu-net&#13;
$ cdk synth</pre>&#13;
&#13;
<p>Pass a variable called <code>variable</code> containing the region value to the constructor <code>CdkLambdaDynamodbStack</code> in <em>app.py</em>:</p>&#13;
&#13;
<pre data-type="programlisting">app_env = {"region": "us-east-2"}&#13;
CdkLambdaDynamodbStack(app, "cdk-lambda-dynamodb", env=app_env)</pre>&#13;
&#13;
<p>Run <code>cdk synth</code> again:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk synth&#13;
Resources:&#13;
  TableCD117FA1:&#13;
    Type: AWS::DynamoDB::Table&#13;
    Properties:&#13;
      KeySchema:&#13;
        - AttributeName: id&#13;
          KeyType: HASH&#13;
      AttributeDefinitions:&#13;
        - AttributeName: id&#13;
          AttributeType: S&#13;
      ProvisionedThroughput:&#13;
        ReadCapacityUnits: 10&#13;
        WriteCapacityUnits: 5&#13;
    UpdateReplacePolicy: Retain&#13;
    DeletionPolicy: Retain&#13;
    Metadata:&#13;
      aws:cdk:path: cdk-lambda-dynamodb-fargate/Table/Resource&#13;
  CDKMetadata:&#13;
    Type: AWS::CDK::Metadata&#13;
    Properties:&#13;
      Modules: aws-cdk=1.6.1,&#13;
      @aws-cdk/aws-applicationautoscaling=1.6.1,&#13;
      @aws-cdk/aws-autoscaling-common=1.6.1,&#13;
      @aws-cdk/aws-cloudwatch=1.6.1,&#13;
      @aws-cdk/aws-dynamodb=1.6.1,&#13;
      @aws-cdk/aws-iam=1.6.1,&#13;
      @aws-cdk/core=1.6.1,&#13;
      @aws-cdk/cx-api=1.6.1,@aws-cdk/region-info=1.6.1,&#13;
      jsii-runtime=Python/3.7.4</pre>&#13;
&#13;
<p>Deploy the CDK stack by running <code>cdk deploy</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk deploy&#13;
cdk-lambda-dynamodb-fargate: deploying...&#13;
cdk-lambda-dynamodb-fargate: creating CloudFormation changeset...&#13;
 0/3 | 11:12:25 AM | CREATE_IN_PROGRESS   | AWS::DynamoDB::Table |&#13;
 Table (TableCD117FA1)&#13;
 0/3 | 11:12:25 AM | CREATE_IN_PROGRESS   | AWS::CDK::Metadata   |&#13;
 CDKMetadata&#13;
 0/3 | 11:12:25 AM | CREATE_IN_PROGRESS   | AWS::DynamoDB::Table |&#13;
 Table (TableCD117FA1) Resource creation Initiated&#13;
 0/3 | 11:12:27 AM | CREATE_IN_PROGRESS   | AWS::CDK::Metadata   |&#13;
 CDKMetadata Resource creation Initiated&#13;
 1/3 | 11:12:27 AM | CREATE_COMPLETE      | AWS::CDK::Metadata   |&#13;
 CDKMetadata&#13;
 2/3 | 11:12:56 AM | CREATE_COMPLETE      | AWS::DynamoDB::Table |&#13;
 Table (TableCD117FA1)&#13;
 3/3 | 11:12:57 AM | CREATE_COMPLETE      | AWS::CloudFormation::Stack |&#13;
 cdk-lambda-dynamodb-fargate&#13;
&#13;
Stack ARN:&#13;
arn:aws:cloudformation:us-east-2:200562098309:stack/&#13;
cdk-lambda-dynamodb/3236a8b0-cdad-11e9-934b-0a7dfa8cb208</pre>&#13;
&#13;
<p>The next step is to add Lambda functions and the API Gateway resource to the stack.</p>&#13;
&#13;
<p>In the CDK code directory, create a <em>lambda</em> directory and copy the Python modules from the <a href="https://oreil.ly/mRSjn">Serverless platform AWS Python REST API example</a>:</p>&#13;
&#13;
<pre data-type="programlisting">$ pwd&#13;
~/code/devops/serverless/cdk-lambda-dynamodb-fargate&#13;
&#13;
$ mkdir lambda&#13;
$ cp ~/code/examples/aws-python-rest-api-with-dynamodb/todos/* lambda&#13;
$ ls -la lambda&#13;
total 48&#13;
drwxr-xr-x   9 ggheo  staff   288 Sep  2 10:41 .&#13;
drwxr-xr-x  10 ggheo  staff   320 Sep  2 10:19 ..&#13;
-rw-r--r--   1 ggheo  staff     0 Sep  2 10:41 __init__.py&#13;
-rw-r--r--   1 ggheo  staff   822 Sep  2 10:41 create.py&#13;
-rw-r--r--   1 ggheo  staff   288 Sep  2 10:41 decimalencoder.py&#13;
-rw-r--r--   1 ggheo  staff   386 Sep  2 10:41 delete.py&#13;
-rw-r--r--   1 ggheo  staff   535 Sep  2 10:41 get.py&#13;
-rw-r--r--   1 ggheo  staff   434 Sep  2 10:41 list.py&#13;
-rw-r--r--   1 ggheo  staff  1240 Sep  2 10:41 update.py</pre>&#13;
&#13;
<p class="pagebreak-before">Add the required modules to <em>requirements.txt</em> and install them with <code>pip</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cat requirements.txt&#13;
-e .&#13;
aws-cdk.core&#13;
aws-cdk.aws-dynamodb&#13;
aws-cdk.aws-lambda&#13;
aws-cdk.aws-apigateway&#13;
&#13;
$ pip install -r requirements.txt</pre>&#13;
&#13;
<p>Create Lambda and API Gateway constructs in the stack module:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">cdk_lambda_dynamodb_fargate</code><code class="o">/</code><code class="n">cdk_lambda_dynamodb_stack</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk.core</code> <code class="kn">import</code> <code class="n">App</code><code class="p">,</code> <code class="n">Construct</code><code class="p">,</code> <code class="n">Duration</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">aws_dynamodb</code><code class="p">,</code> <code class="n">aws_lambda</code><code class="p">,</code> <code class="n">aws_apigateway</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">CdkLambdaDynamodbStack</code><code class="p">(</code><code class="n">core</code><code class="o">.</code><code class="n">Stack</code><code class="p">):</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">scope</code><code class="p">:</code> <code class="n">core</code><code class="o">.</code><code class="n">Construct</code><code class="p">,</code> <code class="nb">id</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="bp">None</code><code class="p">:</code>&#13;
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="n">scope</code><code class="p">,</code> <code class="nb">id</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define the table stores Todo todos</code>&#13;
        <code class="n">table</code> <code class="o">=</code> <code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">Table</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"Table"</code><code class="p">,</code>&#13;
            <code class="n">partition_key</code><code class="o">=</code><code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">Attribute</code><code class="p">(</code>&#13;
                <code class="n">name</code><code class="o">=</code><code class="s2">"id"</code><code class="p">,</code>&#13;
                <code class="nb">type</code><code class="o">=</code><code class="n">aws_dynamodb</code><code class="o">.</code><code class="n">AttributeType</code><code class="o">.</code><code class="n">STRING</code><code class="p">),</code>&#13;
            <code class="n">read_capacity</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code>&#13;
            <code class="n">write_capacity</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define the Lambda functions</code>&#13;
        <code class="n">list_handler</code> <code class="o">=</code> <code class="n">aws_lambda</code><code class="o">.</code><code class="n">Function</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoListFunction"</code><code class="p">,</code>&#13;
            <code class="n">code</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Code</code><code class="o">.</code><code class="n">asset</code><code class="p">(</code><code class="s2">"./lambda"</code><code class="p">),</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="s2">"list.list"</code><code class="p">,</code>&#13;
            <code class="n">timeout</code><code class="o">=</code><code class="n">Duration</code><code class="o">.</code><code class="n">minutes</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code>&#13;
            <code class="n">runtime</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Runtime</code><code class="o">.</code><code class="n">PYTHON_3_7</code><code class="p">)</code>&#13;
&#13;
        <code class="n">create_handler</code> <code class="o">=</code> <code class="n">aws_lambda</code><code class="o">.</code><code class="n">Function</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoCreateFunction"</code><code class="p">,</code>&#13;
            <code class="n">code</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Code</code><code class="o">.</code><code class="n">asset</code><code class="p">(</code><code class="s2">"./lambda"</code><code class="p">),</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="s2">"create.create"</code><code class="p">,</code>&#13;
            <code class="n">timeout</code><code class="o">=</code><code class="n">Duration</code><code class="o">.</code><code class="n">minutes</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code>&#13;
            <code class="n">runtime</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Runtime</code><code class="o">.</code><code class="n">PYTHON_3_7</code><code class="p">)</code>&#13;
&#13;
        <code class="n">get_handler</code> <code class="o">=</code> <code class="n">aws_lambda</code><code class="o">.</code><code class="n">Function</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoGetFunction"</code><code class="p">,</code>&#13;
            <code class="n">code</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Code</code><code class="o">.</code><code class="n">asset</code><code class="p">(</code><code class="s2">"./lambda"</code><code class="p">),</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="s2">"get.get"</code><code class="p">,</code>&#13;
            <code class="n">timeout</code><code class="o">=</code><code class="n">Duration</code><code class="o">.</code><code class="n">minutes</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code>&#13;
            <code class="n">runtime</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Runtime</code><code class="o">.</code><code class="n">PYTHON_3_7</code><code class="p">)</code>&#13;
&#13;
        <code class="n">update_handler</code> <code class="o">=</code> <code class="n">aws_lambda</code><code class="o">.</code><code class="n">Function</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoUpdateFunction"</code><code class="p">,</code>&#13;
            <code class="n">code</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Code</code><code class="o">.</code><code class="n">asset</code><code class="p">(</code><code class="s2">"./lambda"</code><code class="p">),</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="s2">"update.update"</code><code class="p">,</code>&#13;
            <code class="n">timeout</code><code class="o">=</code><code class="n">Duration</code><code class="o">.</code><code class="n">minutes</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code>&#13;
            <code class="n">runtime</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Runtime</code><code class="o">.</code><code class="n">PYTHON_3_7</code><code class="p">)</code>&#13;
&#13;
        <code class="n">delete_handler</code> <code class="o">=</code> <code class="n">aws_lambda</code><code class="o">.</code><code class="n">Function</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoDeleteFunction"</code><code class="p">,</code>&#13;
            <code class="n">code</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Code</code><code class="o">.</code><code class="n">asset</code><code class="p">(</code><code class="s2">"./lambda"</code><code class="p">),</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="s2">"delete.delete"</code><code class="p">,</code>&#13;
            <code class="n">timeout</code><code class="o">=</code><code class="n">Duration</code><code class="o">.</code><code class="n">minutes</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code>&#13;
            <code class="n">runtime</code><code class="o">=</code><code class="n">aws_lambda</code><code class="o">.</code><code class="n">Runtime</code><code class="o">.</code><code class="n">PYTHON_3_7</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># pass the table name to each handler through an environment variable</code>&#13;
        <code class="c1"># and grant the handler read/write permissions on the table.</code>&#13;
        <code class="n">handler_list</code> <code class="o">=</code> <code class="p">[</code>&#13;
            <code class="n">list_handler</code><code class="p">,</code>&#13;
            <code class="n">create_handler</code><code class="p">,</code>&#13;
            <code class="n">get_handler</code><code class="p">,</code>&#13;
            <code class="n">update_handler</code><code class="p">,</code>&#13;
            <code class="n">delete_handler</code>&#13;
        <code class="p">]</code>&#13;
        <code class="k">for</code> <code class="n">handler</code> <code class="ow">in</code> <code class="n">handler_list</code><code class="p">:</code>&#13;
            <code class="n">handler</code><code class="o">.</code><code class="n">add_environment</code><code class="p">(</code><code class="s1">'DYNAMODB_TABLE'</code><code class="p">,</code> <code class="n">table</code><code class="o">.</code><code class="n">table_name</code><code class="p">)</code>&#13;
            <code class="n">table</code><code class="o">.</code><code class="n">grant_read_write_data</code><code class="p">(</code><code class="n">handler</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define the API endpoint</code>&#13;
        <code class="n">api</code> <code class="o">=</code> <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaRestApi</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s2">"TodoApi"</code><code class="p">,</code>&#13;
            <code class="n">handler</code><code class="o">=</code><code class="n">list_handler</code><code class="p">,</code>&#13;
            <code class="n">proxy</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define LambdaIntegrations</code>&#13;
        <code class="n">list_lambda_integration</code> <code class="o">=</code> \&#13;
            <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaIntegration</code><code class="p">(</code><code class="n">list_handler</code><code class="p">)</code>&#13;
        <code class="n">create_lambda_integration</code> <code class="o">=</code> \&#13;
            <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaIntegration</code><code class="p">(</code><code class="n">create_handler</code><code class="p">)</code>&#13;
        <code class="n">get_lambda_integration</code> <code class="o">=</code> \&#13;
            <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaIntegration</code><code class="p">(</code><code class="n">get_handler</code><code class="p">)</code>&#13;
        <code class="n">update_lambda_integration</code> <code class="o">=</code> \&#13;
            <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaIntegration</code><code class="p">(</code><code class="n">update_handler</code><code class="p">)</code>&#13;
        <code class="n">delete_lambda_integration</code> <code class="o">=</code> \&#13;
            <code class="n">aws_apigateway</code><code class="o">.</code><code class="n">LambdaIntegration</code><code class="p">(</code><code class="n">delete_handler</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define REST API model and associate methods with LambdaIntegrations</code>&#13;
        <code class="n">api</code><code class="o">.</code><code class="n">root</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'ANY'</code><code class="p">)</code>&#13;
&#13;
        <code class="n">todos</code> <code class="o">=</code> <code class="n">api</code><code class="o">.</code><code class="n">root</code><code class="o">.</code><code class="n">add_resource</code><code class="p">(</code><code class="s1">'todos'</code><code class="p">)</code>&#13;
        <code class="n">todos</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'GET'</code><code class="p">,</code> <code class="n">list_lambda_integration</code><code class="p">)</code>&#13;
        <code class="n">todos</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'POST'</code><code class="p">,</code> <code class="n">create_lambda_integration</code><code class="p">)</code>&#13;
&#13;
        <code class="n">todo</code> <code class="o">=</code> <code class="n">todos</code><code class="o">.</code><code class="n">add_resource</code><code class="p">(</code><code class="s1">'{id}'</code><code class="p">)</code>&#13;
        <code class="n">todo</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'GET'</code><code class="p">,</code> <code class="n">get_lambda_integration</code><code class="p">)</code>&#13;
        <code class="n">todo</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'PUT'</code><code class="p">,</code> <code class="n">update_lambda_integration</code><code class="p">)</code>&#13;
        <code class="n">todo</code><code class="o">.</code><code class="n">add_method</code><code class="p">(</code><code class="s1">'DELETE'</code><code class="p">,</code> <code class="n">delete_lambda_integration</code><code class="p">)</code></pre>&#13;
&#13;
<p class="pagebreak-before">It is worth noting several features of the code we just reviewed:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>We were able to use the <code>add_environment</code> method on each <code>handler</code> object to pass the environment variable <code>DYNAMODB_TABLE</code> used in the Python code for the Lambda functions and set it to <code>table.table_name</code>. The name of the DynamoDB table is not known at construction time, so the CDK will replace it with a token and will set the token to the correct name of the table when it deploys the stack (see the <a href="https://oreil.ly/XfdEU">Tokens</a> documentation for more details).</p>&#13;
</li>&#13;
<li>&#13;
<p>We made full use of a simple programming language construct, the <code>for</code> loop, when we iterated over the list of all Lambda handlers. While this may seem natural, it is still worth pointing out because loops and variable passing are features that are awkwardly implemented, if at all, in YAML-based Infrastructure as Code tools such as Terraform.</p>&#13;
</li>&#13;
<li>&#13;
<p>We defined the HTTP methods (GET, POST, PUT, DELETE) associated with various endpoints of the API Gateway and associated the correct Lambda function with each of them.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Deploy the stack with <code>cdk deploy</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk deploy&#13;
cdk-lambda-dynamodb-fargate failed: Error:&#13;
This stack uses assets, so the toolkit stack must be deployed&#13;
to the environment&#13;
(Run "cdk bootstrap aws://unknown-account/us-east-2")</pre>&#13;
&#13;
<p>Fix by running <code>cdk bootstrap</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk bootstrap&#13;
Bootstrapping environment aws://ACCOUNTID/us-east-2...&#13;
CDKToolkit: creating CloudFormation changeset...&#13;
Environment aws://ACCOUNTID/us-east-2 bootstrapped.</pre>&#13;
&#13;
<p>Deploy the CDK stack again:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk deploy&#13;
OUTPUT OMITTED&#13;
&#13;
Outputs:&#13;
cdk-lambda-dynamodb.TodoApiEndpointC1E16B6C =&#13;
https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/&#13;
&#13;
Stack ARN:&#13;
arn:aws:cloudformation:us-east-2:ACCOUNTID:stack/cdk-lambda-dynamodb/&#13;
15a66bb0-cdba-11e9-aef9-0ab95d3a5528</pre>&#13;
&#13;
<p>The next step is to test the REST API with <code>curl</code>.</p>&#13;
&#13;
<p class="pagebreak-before">First create a new <code>todo</code> item:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -X \&#13;
POST https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos \&#13;
--data '{ "text": "Learn CDK" }'&#13;
{"id": "19d55d5a-cdb4-11e9-9a8f-9ed29c44196e", "text": "Learn CDK",&#13;
"checked": false,&#13;
"createdAt": "1567450902.262834",&#13;
"updatedAt": "1567450902.262834"}%</pre>&#13;
&#13;
<p>Create a second <code>todo</code> item:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -X \&#13;
POST https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos \&#13;
--data '{ "text": "Learn CDK with Python" }'&#13;
{"id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e", "text": "Learn CDK with Python",&#13;
"checked": false,&#13;
"createdAt": "1567451007.680936",&#13;
"updatedAt": "1567451007.680936"}%</pre>&#13;
&#13;
<p>Try getting the details for the item just created by specifying its ID:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl \&#13;
https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/&#13;
prod/todos/58a992c6-cdb4-11e9-9a8f-9ed29c44196e&#13;
{"message": "Internal server error"}%</pre>&#13;
&#13;
<p>Investigate by inspecting the CloudWatch Logs for the Lambda function <span class="keep-together"><code>TodoGetFunction:</code></span></p>&#13;
&#13;
<pre data-type="programlisting">[ERROR] Runtime.ImportModuleError:&#13;
Unable to import module 'get': No module named 'todos'</pre>&#13;
&#13;
<p>To fix, change the line in <em>lambda/get.py</em> from:</p>&#13;
&#13;
<pre data-type="programlisting">from todos import decimalencoder</pre>&#13;
&#13;
<p>to:</p>&#13;
&#13;
<pre data-type="programlisting">import decimalencoder</pre>&#13;
&#13;
<p>Redeploy the stack with <code>cdk deploy</code>.</p>&#13;
&#13;
<p>Try getting the <code>todo</code> item details with <code>curl</code> again:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl \&#13;
https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/&#13;
prod/todos/58a992c6-cdb4-11e9-9a8f-9ed29c44196e&#13;
{"checked": false, "createdAt": "1567451007.680936",&#13;
"text": "Learn CDK with Python",&#13;
"id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e",&#13;
"updatedAt": "1567451007.680936"}</pre>&#13;
&#13;
<p>Make the <code>import decimalencoder</code> change to all modules in the <em>lambda</em> directory that need the decimalencoder module and redeploy with <code>cdk deploy</code>.</p>&#13;
&#13;
<p>List all <code>todos</code> and format the output with the <code>jq</code> utility:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl \&#13;
https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos | jq&#13;
[&#13;
  {&#13;
    "checked": false,&#13;
    "createdAt": "1567450902.262834",&#13;
    "text": "Learn CDK",&#13;
    "id": "19d55d5a-cdb4-11e9-9a8f-9ed29c44196e",&#13;
    "updatedAt": "1567450902.262834"&#13;
  },&#13;
  {&#13;
    "checked": false,&#13;
    "createdAt": "1567451007.680936",&#13;
    "text": "Learn CDK with Python",&#13;
    "id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e",&#13;
    "updatedAt": "1567451007.680936"&#13;
  }&#13;
]</pre>&#13;
&#13;
<p>Delete a <code>todo</code> and verify that the list does not contain it anymore:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -X DELETE \&#13;
https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos/&#13;
19d55d5a-cdb4-11e9-9a8f-9ed29c44196e&#13;
&#13;
$ curl https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos | jq&#13;
[&#13;
  {&#13;
    "checked": false,&#13;
    "createdAt": "1567451007.680936",&#13;
    "text": "Learn CDK with Python",&#13;
    "id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e",&#13;
    "updatedAt": "1567451007.680936"&#13;
  }&#13;
]</pre>&#13;
&#13;
<p>Now test updating an existing <code>todo</code> item with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -X \&#13;
PUT https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos/&#13;
58a992c6-cdb4-11e9-9a8f-9ed29c44196e \&#13;
--data '{ "text": "Learn CDK with Python by reading the PyForDevOps book" }'&#13;
{"message": "Internal server error"}%</pre>&#13;
&#13;
<p>Inspecting the CloudWatch logs for the Lambda function associated with this endpoint shows:</p>&#13;
&#13;
<pre data-type="programlisting">[ERROR] Exception: Couldn't update the todo item.&#13;
Traceback (most recent call last):&#13;
  File "/var/task/update.py", line 15, in update&#13;
    raise Exception("Couldn't update the todo item.")</pre>&#13;
&#13;
<p>Change the validation test in <em>lambda/update.py</em> to:</p>&#13;
&#13;
<pre data-type="programlisting">    data = json.loads(event['body'])&#13;
    if 'text' not in data:&#13;
        logging.error("Validation Failed")&#13;
        raise Exception("Couldn't update the todo item.")</pre>&#13;
&#13;
<p>Also change the value for <code>checked</code> to <code>True</code>, since we have already seen a post that we are trying to update:</p>&#13;
&#13;
<pre data-type="programlisting">ExpressionAttributeValues={&#13;
         ':text': data['text'],&#13;
         ':checked': True,&#13;
         ':updatedAt': timestamp,&#13;
       },</pre>&#13;
&#13;
<p>Redeploy the stack with <code>cdk deploy_</code>.</p>&#13;
&#13;
<p>Test updating the <code>todo</code> item with <code>curl</code>:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl -X \&#13;
PUT https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos/&#13;
58a992c6-cdb4-11e9-9a8f-9ed29c44196e \&#13;
--data '{ "text": "Learn CDK with Python by reading the PyForDevOps book"}'&#13;
{"checked": true, "createdAt": "1567451007.680936",&#13;
"text": "Learn CDK with Python by reading the PyForDevOps book",&#13;
"id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e", "updatedAt": 1567453288764}%</pre>&#13;
&#13;
<p>List the <code>todo</code> items to verify the update:</p>&#13;
&#13;
<pre data-type="programlisting">$ curl https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/todos | jq&#13;
[&#13;
  {&#13;
    "checked": true,&#13;
    "createdAt": "1567451007.680936",&#13;
    "text": "Learn CDK with Python by reading the PyForDevOps book",&#13;
    "id": "58a992c6-cdb4-11e9-9a8f-9ed29c44196e",&#13;
    "updatedAt": 1567453288764&#13;
  }&#13;
]</pre>&#13;
&#13;
<p>The next step is to provision AWS Fargate containers that will run a load test against the REST API we just deployed. Each container will run a Docker image that uses <a href="https://gettaurus.org">the Taurus test automation framework</a> to run the <a href="https://oreil.ly/OGDne">Molotov load-testing tool</a>. We introduced Molotov in <a data-type="xref" href="ch05.html#package_management">Chapter 5</a> as a simple and very useful Python-based load-testing tool.</p>&#13;
&#13;
<p>Start by creating a Dockerfile for running Taurus and Molotov in a directory called <em>loadtest</em>:</p>&#13;
&#13;
<pre data-code-language="docker" data-type="programlisting"><code class="nv">$ </code>mkdir loadtest<code class="p">;</code> <code class="nb">cd </code>loadtest&#13;
<code class="nv">$ </code>cat Dockerfile&#13;
<code class="k">FROM</code><code class="s"> blazemeter/taurus</code>&#13;
&#13;
COPY scripts /scripts&#13;
COPY taurus.yaml /bzt-configs/&#13;
&#13;
<code class="k">WORKDIR</code><code class="s"> /bzt-configs</code>&#13;
<code class="k">ENTRYPOINT</code><code class="s"> ["sh", "-c", "bzt -l /tmp/artifacts/bzt.log /bzt-configs/taurus.yaml"]</code></pre>&#13;
&#13;
<p>The Dockerfile runs the Taurus <code>bzt</code> command line using the <em>taurus.yaml</em> configuration file:</p>&#13;
&#13;
<pre data-code-language="yaml" data-type="programlisting"><code class="l-Scalar-Plain">$ cat taurus.yaml</code>&#13;
<code class="l-Scalar-Plain">execution</code><code class="p-Indicator">:</code>&#13;
<code class="p-Indicator">-</code> <code class="nt">executor</code><code class="p">:</code> <code class="l-Scalar-Plain">molotov</code>&#13;
  <code class="nt">concurrency</code><code class="p">:</code> <code class="l-Scalar-Plain">10</code>  <code class="c1"># number of Molotov workers</code>&#13;
  <code class="nt">iterations</code><code class="p">:</code> <code class="l-Scalar-Plain">5</code>  <code class="c1"># iteration limit for the test</code>&#13;
  <code class="nt">ramp-up</code><code class="p">:</code> <code class="l-Scalar-Plain">30s</code>&#13;
  <code class="nt">hold-for</code><code class="p">:</code> <code class="l-Scalar-Plain">5m</code>&#13;
  <code class="nt">scenario</code><code class="p">:</code>&#13;
    <code class="nt">script</code><code class="p">:</code> <code class="l-Scalar-Plain">/scripts/loadtest.py</code>  <code class="c1"># has to be valid Molotov script</code></pre>&#13;
&#13;
<p>In this configuration file, the value for <code>concurrency</code> is set to 10, which means that we are simulating 10 concurrent users or virtual users (VUs). The <code>executor</code> is defined as a <code>molotov</code> test based on a script called <em>loadtest.py</em> in the <em>scripts</em> directory. Here is the script, which is a Python module:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">scripts</code><code class="o">/</code><code class="n">loadtest</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">import</code> <code class="nn">os</code>&#13;
<code class="kn">import</code> <code class="nn">json</code>&#13;
<code class="kn">import</code> <code class="nn">random</code>&#13;
<code class="kn">import</code> <code class="nn">molotov</code>&#13;
<code class="kn">from</code> <code class="nn">molotov</code> <code class="kn">import</code> <code class="n">global_setup</code><code class="p">,</code> <code class="n">scenario</code>&#13;
&#13;
<code class="nd">@global_setup</code><code class="p">()</code>&#13;
<code class="k">def</code> <code class="nf">init_test</code><code class="p">(</code><code class="n">args</code><code class="p">):</code>&#13;
    <code class="n">BASE_URL</code><code class="o">=</code><code class="n">os</code><code class="o">.</code><code class="n">getenv</code><code class="p">(</code><code class="s1">'BASE_URL'</code><code class="p">,</code> <code class="s1">''</code><code class="p">)</code>&#13;
    <code class="n">molotov</code><code class="o">.</code><code class="n">set_var</code><code class="p">(</code><code class="s1">'base_url'</code><code class="p">,</code> <code class="n">BASE_URL</code><code class="p">)</code>&#13;
&#13;
<code class="nd">@scenario</code><code class="p">(</code><code class="n">weight</code><code class="o">=</code><code class="mi">50</code><code class="p">)</code>&#13;
<code class="n">async</code> <code class="k">def</code> <code class="nf">_test_list_todos</code><code class="p">(</code><code class="n">session</code><code class="p">):</code>&#13;
    <code class="n">base_url</code><code class="o">=</code> <code class="n">molotov</code><code class="o">.</code><code class="n">get_var</code><code class="p">(</code><code class="s1">'base_url'</code><code class="p">)</code>&#13;
    <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos'</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
        <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code><code class="p">,</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code>&#13;
&#13;
<code class="nd">@scenario</code><code class="p">(</code><code class="n">weight</code><code class="o">=</code><code class="mi">30</code><code class="p">)</code>&#13;
<code class="n">async</code> <code class="k">def</code> <code class="nf">_test_create_todo</code><code class="p">(</code><code class="n">session</code><code class="p">):</code>&#13;
    <code class="n">base_url</code><code class="o">=</code> <code class="n">molotov</code><code class="o">.</code><code class="n">get_var</code><code class="p">(</code><code class="s1">'base_url'</code><code class="p">)</code>&#13;
    <code class="n">todo_data</code> <code class="o">=</code> <code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">({</code><code class="s1">'text'</code><code class="p">:</code>&#13;
      <code class="s1">'Created new todo during Taurus/molotov load test'</code><code class="p">})</code>&#13;
    <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos'</code><code class="p">,</code>&#13;
      <code class="n">data</code><code class="o">=</code><code class="n">todo_data</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
        <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code>&#13;
&#13;
<code class="nd">@scenario</code><code class="p">(</code><code class="n">weight</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
<code class="n">async</code> <code class="k">def</code> <code class="nf">_test_update_todo</code><code class="p">(</code><code class="n">session</code><code class="p">):</code>&#13;
    <code class="n">base_url</code><code class="o">=</code> <code class="n">molotov</code><code class="o">.</code><code class="n">get_var</code><code class="p">(</code><code class="s1">'base_url'</code><code class="p">)</code>&#13;
    <code class="c1"># list all todos</code>&#13;
    <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos'</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
        <code class="n">res</code> <code class="o">=</code> <code class="n">await</code> <code class="n">resp</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>&#13;
        <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code><code class="p">,</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code>&#13;
        <code class="c1"># choose random todo and update it with PUT request</code>&#13;
        <code class="n">todo_id</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">choice</code><code class="p">(</code><code class="n">res</code><code class="p">)[</code><code class="s1">'id'</code><code class="p">]</code>&#13;
        <code class="n">todo_data</code> <code class="o">=</code> <code class="n">json</code><code class="o">.</code><code class="n">dumps</code><code class="p">({</code><code class="s1">'text'</code><code class="p">:</code>&#13;
          <code class="s1">'Updated existing todo during Taurus/molotov load test'</code><code class="p">})</code>&#13;
        <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos/'</code> <code class="o">+</code> <code class="n">todo_id</code><code class="p">,</code>&#13;
          <code class="n">data</code><code class="o">=</code><code class="n">todo_data</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
            <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code>&#13;
&#13;
<code class="nd">@scenario</code><code class="p">(</code><code class="n">weight</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
<code class="n">async</code> <code class="k">def</code> <code class="nf">_test_delete_todo</code><code class="p">(</code><code class="n">session</code><code class="p">):</code>&#13;
    <code class="n">base_url</code><code class="o">=</code> <code class="n">molotov</code><code class="o">.</code><code class="n">get_var</code><code class="p">(</code><code class="s1">'base_url'</code><code class="p">)</code>&#13;
    <code class="c1"># list all todos</code>&#13;
    <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos'</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
        <code class="n">res</code> <code class="o">=</code> <code class="n">await</code> <code class="n">resp</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>&#13;
        <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code><code class="p">,</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code>&#13;
        <code class="c1"># choose random todo and delete it with DELETE request</code>&#13;
        <code class="n">todo_id</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">choice</code><code class="p">(</code><code class="n">res</code><code class="p">)[</code><code class="s1">'id'</code><code class="p">]</code>&#13;
        <code class="n">async</code> <code class="k">with</code> <code class="n">session</code><code class="o">.</code><code class="n">delete</code><code class="p">(</code><code class="n">base_url</code> <code class="o">+</code> <code class="s1">'/todos/'</code> <code class="o">+</code> <code class="n">todo_id</code><code class="p">)</code> <code class="k">as</code> <code class="n">resp</code><code class="p">:</code>&#13;
            <code class="k">assert</code> <code class="n">resp</code><code class="o">.</code><code class="n">status</code> <code class="o">==</code> <code class="mi">200</code></pre>&#13;
&#13;
<p>The script has four functions decorated as <code>scenarios</code> to be run by Molotov. They exercise various endpoints of the CRUD REST API. The weights indicate the approximate percentage of the time of the overall test duration that each scenario will be invoked. For example, the <a data-primary="test_list_todos() function" data-type="indexterm" id="idm46691319167240"/><code>_test_list_todos</code> function will be invoked in this example&#13;
approximately 50% of the time,&#13;
<code>_test_create_todo</code> will run approximately 30% of the time, and <code>_test_update_todo</code> and <code>_test_delete_todo</code> will each run approximately 10% of the time.</p>&#13;
&#13;
<p>Build the local Docker image:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker build -t cdk-loadtest .</pre>&#13;
&#13;
<p>Create the local <em>artifacts</em> directory:</p>&#13;
&#13;
<pre data-type="programlisting">$ mkdir artifacts</pre>&#13;
&#13;
<p>Run the local Docker image and mount the local <em>artifacts</em> directory as <em>/tmp/artifacts</em> inside the Docker container:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker run --rm -d \&#13;
--env BASE_URL=https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod \&#13;
-v `pwd`/artifacts:/tmp/artifacts cdk-loadtest</pre>&#13;
&#13;
<p>Debug the Molotov script by inspecting the <em>artifacts/molotov.out</em> file.</p>&#13;
&#13;
<p>Taurus results can be inspected either with <code>docker logs CONTAINER_ID</code> or by inspecting the file <em>artifacts/bzt.log</em>.</p>&#13;
&#13;
<p>Results obtained by inspecting the Docker logs:</p>&#13;
&#13;
<pre data-type="programlisting">$ docker logs -f a228f8f9a2bc&#13;
19:26:26 INFO: Taurus CLI Tool v1.13.8&#13;
19:26:26 INFO: Starting with configs: ['/bzt-configs/taurus.yaml']&#13;
19:26:26 INFO: Configuring...&#13;
19:26:26 INFO: Artifacts dir: /tmp/artifacts&#13;
19:26:26 INFO: Preparing...&#13;
19:26:27 INFO: Starting...&#13;
19:26:27 INFO: Waiting for results...&#13;
19:26:32 INFO: Changed data analysis delay to 3s&#13;
19:26:32 INFO: Current: 0 vu  1 succ  0 fail  0.546 avg rt  /&#13;
Cumulative: 0.546 avg rt, 0% failures&#13;
19:26:39 INFO: Current: 1 vu  1 succ  0 fail  1.357 avg rt  /&#13;
Cumulative: 0.904 avg rt, 0% failures&#13;
ETC&#13;
19:41:00 WARNING: Please wait for graceful shutdown...&#13;
19:41:00 INFO: Shutting down...&#13;
19:41:00 INFO: Post-processing...&#13;
19:41:03 INFO: Test duration: 0:14:33&#13;
19:41:03 INFO: Samples count: 1857, 0.00% failures&#13;
19:41:03 INFO: Average times: total 6.465, latency 0.000, connect 0.000&#13;
19:41:03 INFO: Percentiles:&#13;
+---------------+---------------+&#13;
| Percentile, % | Resp. Time, s |&#13;
+---------------+---------------+&#13;
|           0.0 |          0.13 |&#13;
|          50.0 |          1.66 |&#13;
|          90.0 |        14.384 |&#13;
|          95.0 |         26.88 |&#13;
|          99.0 |        27.168 |&#13;
|          99.9 |        27.584 |&#13;
|         100.0 |        27.792 |&#13;
+---------------+---------------+</pre>&#13;
&#13;
<p>Create CloudWatch dashboards for the Lambda duration (<a data-type="xref" href="#Figure-13-1">Figure 13-1</a>) and DynamoDB provisioned and consumed read and write capacity units (<a data-type="xref" href="#Figure-13-2">Figure 13-2</a>).</p>&#13;
&#13;
<figure><div class="figure" id="Figure-13-1">&#13;
<img alt="pydo 1301" src="assets/pydo_1301.png"/>&#13;
<h6><span class="label">Figure 13-1. </span>Lambda duration</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="Figure-13-2">&#13;
<img alt="pydo 1302" src="assets/pydo_1302.png"/>&#13;
<h6><span class="label">Figure 13-2. </span>DynamoDB provisioned and consumed read and write capacity units</h6>&#13;
</div></figure>&#13;
&#13;
<p>The DynamoDB metrics show that we underprovisioned the DynamoDB read capacity units. This introduced latency, especially for the List function (shown in the Lambda duration graph as the red line going to 14.7 seconds), which retrieves all <code>todo</code> items from the DynamoDB table, and thus is heavy on read operations. We set the value of the provisioned read capacity units to 10 when we created the DynamoDB table, and the CloudWatch graph shows it going to 25.</p>&#13;
&#13;
<p>Let’s change the DynamoDB table type from <code>PROVISIONED</code> to <code>PAY_PER_REQUEST</code>. Make the change in <em>cdk_lambda_dynamodb_fargate/cdk_lambda_dynamodb_stack.py</em>:</p>&#13;
&#13;
<pre data-type="programlisting">        table = aws_dynamodb.Table(self, "Table",&#13;
            partition_key=aws_dynamodb.Attribute(&#13;
                name="id",&#13;
                type=aws_dynamodb.AttributeType.STRING),&#13;
            billing_mode = aws_dynamodb.BillingMode.PAY_PER_REQUEST)</pre>&#13;
&#13;
<p>Run <code>cdk deploy</code> and then run the local Docker load-testing container.</p>&#13;
&#13;
<p>This time the results are much better:</p>&#13;
&#13;
<pre data-type="programlisting">+---------------+---------------+&#13;
| Percentile, % | Resp. Time, s |&#13;
+---------------+---------------+&#13;
|           0.0 |         0.136 |&#13;
|          50.0 |         0.505 |&#13;
|          90.0 |         1.296 |&#13;
|          95.0 |         1.444 |&#13;
|          99.0 |         1.806 |&#13;
|          99.9 |         2.226 |&#13;
|         100.0 |          2.86 |&#13;
+---------------+---------------+</pre>&#13;
&#13;
<p>The graphs for Lambda duration (<a data-type="xref" href="#Figure-13-3">Figure 13-3</a>) and DynamoDB consumed read and write capacity units (<a data-type="xref" href="#Figure-13-4">Figure 13-4</a>) look much better as well.</p>&#13;
&#13;
<figure><div class="figure" id="Figure-13-3">&#13;
<img alt="pydo 1303" src="assets/pydo_1303.png"/>&#13;
<h6><span class="label">Figure 13-3. </span>Lambda duration</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="Figure-13-4">&#13;
<img alt="pydo 1304" src="assets/pydo_1304.png"/>&#13;
<h6><span class="label">Figure 13-4. </span>DynamoDB consumed read and write capacity units</h6>&#13;
</div></figure>&#13;
&#13;
<p>Note that the DynamoDB consumed read capacity units are automatically allocated&#13;
on demand by DynamoDB, and are scaling up to sustain the increased number of&#13;
read requests from the Lambda functions. The function that contributes the most to the read requests is the List function that is called&#13;
in the list, update, and delete scenarios in&#13;
the Molotov <em>loadtest.py</em> script via <code>session.get(base_url + /todos)</code>.</p>&#13;
&#13;
<p>Next, we will create a Fargate CDK stack that will run containers based on the Docker image created previously:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">cdk_lambda_dynamodb_fargate</code><code class="o">/</code><code class="n">cdk_fargate_stack</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">aws_ecs</code><code class="p">,</code> <code class="n">aws_ec2</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">FargateStack</code><code class="p">(</code><code class="n">core</code><code class="o">.</code><code class="n">Stack</code><code class="p">):</code>&#13;
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">scope</code><code class="p">:</code> <code class="n">core</code><code class="o">.</code><code class="n">Construct</code><code class="p">,</code> <code class="nb">id</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="bp">None</code><code class="p">:</code>&#13;
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="n">scope</code><code class="p">,</code> <code class="nb">id</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>&#13;
&#13;
        <code class="n">vpc</code> <code class="o">=</code> <code class="n">aws_ec2</code><code class="o">.</code><code class="n">Vpc</code><code class="p">(</code>&#13;
            <code class="bp">self</code><code class="p">,</code> <code class="s2">"MyVpc"</code><code class="p">,</code>&#13;
            <code class="n">cidr</code><code class="o">=</code> <code class="s2">"10.0.0.0/16"</code><code class="p">,</code>&#13;
            <code class="n">max_azs</code><code class="o">=</code><code class="mi">3</code>&#13;
        <code class="p">)</code>&#13;
        <code class="c1"># define an ECS cluster hosted within the requested VPC</code>&#13;
        <code class="n">cluster</code> <code class="o">=</code> <code class="n">aws_ecs</code><code class="o">.</code><code class="n">Cluster</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s1">'cluster'</code><code class="p">,</code> <code class="n">vpc</code><code class="o">=</code><code class="n">vpc</code><code class="p">)</code>&#13;
&#13;
        <code class="c1"># define our task definition with a single container</code>&#13;
        <code class="c1"># the image is built &amp; published from a local asset directory</code>&#13;
        <code class="n">task_definition</code> <code class="o">=</code> <code class="n">aws_ecs</code><code class="o">.</code><code class="n">FargateTaskDefinition</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s1">'LoadTestTask'</code><code class="p">)</code>&#13;
        <code class="n">task_definition</code><code class="o">.</code><code class="n">add_container</code><code class="p">(</code><code class="s1">'TaurusLoadTest'</code><code class="p">,</code>&#13;
            <code class="n">image</code><code class="o">=</code><code class="n">aws_ecs</code><code class="o">.</code><code class="n">ContainerImage</code><code class="o">.</code><code class="n">from_asset</code><code class="p">(</code><code class="s2">"loadtest"</code><code class="p">),</code>&#13;
            <code class="n">environment</code><code class="o">=</code><code class="p">{</code><code class="s1">'BASE_URL'</code><code class="p">:</code>&#13;
            <code class="s2">"https://k6ygy4xw24.execute-api.us-east-2.amazonaws.com/prod/"</code><code class="p">})</code>&#13;
&#13;
        <code class="c1"># define our fargate service. TPS determines how many instances we</code>&#13;
        <code class="c1"># want from our task (each task produces a single TPS)</code>&#13;
        <code class="n">aws_ecs</code><code class="o">.</code><code class="n">FargateService</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s1">'service'</code><code class="p">,</code>&#13;
            <code class="n">cluster</code><code class="o">=</code><code class="n">cluster</code><code class="p">,</code>&#13;
            <code class="n">task_definition</code><code class="o">=</code><code class="n">task_definition</code><code class="p">,</code>&#13;
            <code class="n">desired_count</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code></pre>&#13;
&#13;
<p>A few things to note in the code for the <code>FargateStack</code> class:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A new VPC is created by using the <code>aws_ec2.Vpc</code> CDK construct.</p>&#13;
</li>&#13;
<li>&#13;
<p>An ECS cluster is created in the new VPC.</p>&#13;
</li>&#13;
<li>&#13;
<p>A Fargate task definition is created based on the Dockerfile from the <em>loadtest</em> directory; the CDK is smart enough to build a Docker image based on this Dockerfile and then push it to the ECR Docker registry.</p>&#13;
</li>&#13;
<li>&#13;
<p>An ECS service is created to run Fargate containers based on the image pushed to ECR; the <code>desired_count</code> parameter specifies how many containers we want to run.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Call the <code>FargateStack</code> constructor in <em>app.py</em>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="err">$</code> <code class="n">cat</code> <code class="n">app</code><code class="o">.</code><code class="n">py</code>&#13;
<code class="c1">#!/usr/bin/env python3</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">aws_cdk</code> <code class="kn">import</code> <code class="n">core</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">cdk_lambda_dynamodb_fargate.cdk_lambda_dynamodb_stack</code> \&#13;
<code class="kn">import</code> <code class="n">CdkLambdaDynamodbStack</code>&#13;
<code class="kn">from</code> <code class="nn">cdk_lambda_dynamodb_fargate.cdk_fargate_stack</code> <code class="kn">import</code> <code class="n">FargateStack</code>&#13;
&#13;
<code class="n">app</code> <code class="o">=</code> <code class="n">core</code><code class="o">.</code><code class="n">App</code><code class="p">()</code>&#13;
<code class="n">app_env</code> <code class="o">=</code> <code class="p">{</code>&#13;
    <code class="s2">"region"</code><code class="p">:</code> <code class="s2">"us-east-2"</code><code class="p">,</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="n">CdkLambdaDynamodbStack</code><code class="p">(</code><code class="n">app</code><code class="p">,</code> <code class="s2">"cdk-lambda-dynamodb"</code><code class="p">,</code> <code class="n">env</code><code class="o">=</code><code class="n">app_env</code><code class="p">)</code>&#13;
<code class="n">FargateStack</code><code class="p">(</code><code class="n">app</code><code class="p">,</code> <code class="s2">"cdk-fargate"</code><code class="p">,</code> <code class="n">env</code><code class="o">=</code><code class="n">app_env</code><code class="p">)</code>&#13;
&#13;
<code class="n">app</code><code class="o">.</code><code class="n">synth</code><code class="p">()</code></pre>&#13;
&#13;
<p>Deploy the <code>cdk-fargate</code> stack:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk deploy cdk-fargate</pre>&#13;
&#13;
<p>Go to the AWS console and inspect the ECS cluster with the running Fargate container (<a data-type="xref" href="#Figure-13-5">Figure 13-5</a>).</p>&#13;
&#13;
<figure><div class="figure" id="Figure-13-5">&#13;
<img alt="pydo 1305" src="assets/pydo_1305.png"/>&#13;
<h6><span class="label">Figure 13-5. </span>ECS cluster with running Fargate container</h6>&#13;
</div></figure>&#13;
&#13;
<p>Inspect the CloudWatch dashboards for Lambda duration (<a data-type="xref" href="#Figure-13-6">Figure 13-6</a>) and DynamoDB consumed read and write capacity units (<a data-type="xref" href="#Figure-13-7">Figure 13-7</a>), noting that latency looks good.</p>&#13;
&#13;
<figure><div class="figure" id="Figure-13-6">&#13;
<img alt="pydo 1306" src="assets/pydo_1306.png"/>&#13;
<h6><span class="label">Figure 13-6. </span>Lambda duration</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="Figure-13-7">&#13;
<img alt="pydo 1307" src="assets/pydo_1307.png"/>&#13;
<h6><span class="label">Figure 13-7. </span>DynamoDB consumed read and write capacity units</h6>&#13;
</div></figure>&#13;
&#13;
<p>Increase the Fargate container count to 5 in <em>cdk_lambda_dynamodb_fargate/cdk_fargate_stack.py</em>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">       <code class="n">aws_ecs</code><code class="o">.</code><code class="n">FargateService</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="s1">'service'</code><code class="p">,</code>&#13;
           <code class="n">cluster</code><code class="o">=</code><code class="n">cluster</code><code class="p">,</code>&#13;
           <code class="n">task_definition</code><code class="o">=</code><code class="n">task_definition</code><code class="p">,</code>&#13;
           <code class="n">desired_count</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>&#13;
&#13;
<p>Redeploy the <code>cdk-fargate</code> stack:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk deploy cdk-fargate</pre>&#13;
&#13;
<p>Inspect the CloudWatch dashboards for Lambda duration (<a data-type="xref" href="#Figure-13-8">Figure 13-8</a>) and DynamoDB consumed read and write capacity units (<a data-type="xref" href="#Figure-13-9">Figure 13-9</a>).</p>&#13;
&#13;
<figure><div class="figure" id="Figure-13-8">&#13;
<img alt="pydo 1308" src="assets/pydo_1308.png"/>&#13;
<h6><span class="label">Figure 13-8. </span>Lambda duration</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="Figure-13-9">&#13;
<img alt="pydo 1309" src="assets/pydo_1309.png"/>&#13;
<h6><span class="label">Figure 13-9. </span>DynamoDB consumed read and write capacity units</h6>&#13;
</div></figure>&#13;
&#13;
<p>Both DynamoDB read capacity units and Lambda duration metrics increased as expected because we are now simulating 5 × 10 = 50 concurrent users.</p>&#13;
&#13;
<p>To simulate more users, we can both increase the <code>concurrency</code> value in the <em>taurus.yaml</em> configuration file, and increase the <code>desired_count</code> for the Fargate containers. Between these two values, we can easily increase the load on our REST API endpoints.</p>&#13;
&#13;
<p>Delete the CDK stacks:</p>&#13;
&#13;
<pre data-type="programlisting">$ cdk destroy cdk-fargate&#13;
$ cdk destroy cdk-lambda-dynamodb</pre>&#13;
&#13;
<p>It is worth noting that the serverless architecture we deployed (API Gateway + five Lambda functions + DynamoDB table) turned out to be a good fit for our CRUD REST API application. We also followed best practices and defined all our infrastructure in Python code by using the AWS CDK.<a data-startref="ix_ch13-asciidoc18" data-type="indexterm" id="idm46691318573320"/><a data-startref="ix_ch13-asciidoc17" data-type="indexterm" id="idm46691318572616"/><a data-startref="ix_ch13-asciidoc16" data-type="indexterm" id="idm46691318571944"/><a data-startref="ix_ch13-asciidoc15" data-type="indexterm" id="idm46691318571272"/><a data-startref="ix_ch13-asciidoc14" data-type="indexterm" id="idm46691318570600"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exercises" data-type="sect1"><div class="sect1" id="idm46691320254424">&#13;
<h1>Exercises</h1>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Run a simple HTTP endpoint using Google’s CaaS platform: <a href="https://cloud.google.com/run">Cloud Run</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Run a simple HTTP endpoint on the other FaaS platforms we mentioned that are based on Kubernetes: <a href="https://kubeless.io">Kubeless</a>, <a href="https://fnproject.io">Fn Project</a>, and <a href="https://fission.io">Fission</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Install and configure <a href="https://openwhisk.apache.org">Apache OpenWhisk</a> inside a production-grade Kubernetes cluster such as Amazon EKS, Google GKE, or Azure AKS.</p>&#13;
</li>&#13;
<li>&#13;
<p>Port the AWS REST API example to GCP and Azure. GCP offers <a href="https://cloud.google.com/endpoints">Cloud Endpoints</a> to manage multiple APIs. Similarly, Azure offers <a href="https://oreil.ly/tmDh7">API Management</a>.<a data-startref="ix_ch13-asciidoc0" data-type="indexterm" id="idm46691318589000"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>