- en: Chapter 2\. Getting Started with Dask
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 开始使用 Dask
- en: We are so happy that you’ve decided to explore whether Dask is the system for
    you by trying it out. In this chapter, we will focus on getting started with Dask
    in its local mode. Using this, we’ll explore a few more straightforward parallel
    computing tasks (including everyone’s favorite, word count).^([1](ch02.xhtml#id330))
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常高兴您决定通过尝试来探索是否 Dask 是适合您的系统。在本章中，我们将专注于在本地模式下启动 Dask。使用这种方式，我们将探索一些更为简单的并行计算任务（包括大家喜爱的单词统计）。^([1](ch02.xhtml#id330))
- en: Installing Dask Locally
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地安装 Dask
- en: Installing Dask locally is reasonably straightforward. If you want to begin
    running on multiple machines, doing so is often easier when you start with a conda
    environment (or virtualenv). This lets you figure out what packages you depend
    on by running `pip freeze` to make sure they’re on all of the workers when it’s
    time to scale.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地安装 Dask 相对来说是比较简单的。如果您想要在多台机器上运行，当您从 conda 环境（或 virtualenv）开始时，通常会更容易。这使得您可以通过运行
    `pip freeze` 来确定您依赖的软件包，在扩展时确保它们位于所有工作节点上。
- en: While you can just run `pip install -U dask`, we prefer using a conda environment
    since it’s easier to match the version of Python to that on a cluster, which allows
    us to connect a local machine to the cluster directly.^([2](ch02.xhtml#id333))
    If you don’t already have conda on your machine, [Miniforge](https://oreil.ly/qVDa7)
    is a good and quick way to get conda installed across multiple platforms. The
    installation of Dask into a new conda environment is shown in [Example 2-1](#install_conda_env_with_dask).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以直接运行 `pip install -U dask`，但我们更倾向于使用 conda 环境，因为这样更容易匹配集群上的 Python 版本，这使得您可以直接连接本地机器到集群。^([2](ch02.xhtml#id333))
    如果您的机器上还没有 conda，[Miniforge](https://oreil.ly/qVDa7) 是一个快速好用的方式来在多个平台上安装 conda。在新的
    conda 环境中安装 Dask 的过程显示在 [Example 2-1](#install_conda_env_with_dask) 中。
- en: Example 2-1\. Installing Dask into a new conda environment
  id: totrans-5
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-1\. 在新的 conda 环境中安装 Dask
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here we install a specific version of Dask rather than just the latest version.
    If you’re planning to connect to a cluster later on, it will be useful to pick
    the same version of Dask as is installed on the cluster.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们安装的是特定版本的 Dask，而不仅仅是最新版本。如果您计划稍后连接到集群，选择与集群上安装的相同版本的 Dask 将非常有用。
- en: Note
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You don’t have to install Dask locally. There is a [BinderHub example with Dask](https://oreil.ly/EK5n5)
    and distributed options, including [one from the creators of Dask](https://oreil.ly/3UEq-),
    that you can use to run Dask, as well as other providers such as [SaturnCloud](https://oreil.ly/_6SyV).
    That being said, we recommend having Dask installed locally even if you end up
    using one of these services.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您不必在本地安装 Dask。有一个带有 Dask 的 [BinderHub 示例](https://oreil.ly/EK5n5) 和分布式选项，包括
    [Dask 的创建者提供的一个](https://oreil.ly/3UEq-)，您可以使用这些选项来运行 Dask，以及其他提供者如 [SaturnCloud](https://oreil.ly/_6SyV)。尽管如此，即使最终使用了这些服务之一，我们还是建议在本地安装
    Dask。
- en: Hello Worlds
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hello Worlds
- en: Now that you have Dask installed locally, it’s time to try the versions of “Hello
    World” available through its various APIs. There are many different options for
    starting Dask. For now, you should use LocalCluster, as shown in [Example 2-2](#make_dask_client).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经在本地安装了 Dask，是时候通过其各种 API 版本的“Hello World”来尝试了。开始 Dask 的选项有很多。目前，您应该使用 LocalCluster，如
    [Example 2-2](#make_dask_client) 中所示。
- en: Example 2-2\. Using LocalCluster to start Dask
  id: totrans-12
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 2-2\. 使用 LocalCluster 启动 Dask
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Task Hello World
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务 Hello World
- en: One of the core building blocks of Dask is `dask.delayed`, which allows you
    to run functions in parallel. If you are running Dask on multiple machines, these
    functions can also be distributed (or spread out) on the different machines. When
    you wrap a function with `dask.delayed` and call it, you get back a “delayed”
    object representing the desired computation. When you created a delayed object,
    Dask is just making a note of what you might want it to do. As with a lazy teenager,
    you need to be explicit. You can force Dask to start computing the value with
    `dask.submit`, which produces a “future.” You can use `dask.compute` both to start
    computing the delayed objects and futures and to return their values.^([3](ch02.xhtml#id344))
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的核心构建块之一是 `dask.delayed`，它允许您并行运行函数。如果您在多台机器上运行 Dask，这些函数也可以分布（或者说散布）到不同的机器上。当您用
    `dask.delayed` 包装一个函数并调用它时，您会得到一个代表所需计算的“延迟”对象。当您创建了一个延迟对象时，Dask 只是记下了您可能希望它执行的操作。就像懒惰的青少年一样，您需要明确告知它。您可以通过
    `dask.submit` 强制 Dask 开始计算值，这会产生一个“future”。您可以使用 `dask.compute` 来启动计算延迟对象和 futures，并返回它们的值。^([3](ch02.xhtml#id344))
- en: Sleepy task
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 睡眠任务
- en: An easy way to see the performance difference is by writing an intentionally
    slow function, like `slow_task`, which calls `sleep`. Then you can compare the
    performance of Dask to “regular” Python by mapping the function over a few elements
    with and without `dask.delayed`, as shown in [Example 2-3](#sleepy_task_ch02_1688747609671).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过编写一个意图上慢的函数，比如调用`sleep`的`slow_task`，可以轻松地看到性能差异。然后，您可以通过在几个元素上映射该函数，使用或不使用`dask.delayed`，来比较Dask与“常规”Python的性能，如[示例 2-3](#sleepy_task_ch02_1688747609671)所示。
- en: Example 2-3\. Sleepy task
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-3\. 睡眠任务
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When we run this example, we get `In sequence 20.01662155520171, in parallel
    6.259156636893749`, which shows that Dask can run some of the tasks in parallel,
    but not all of them.^([4](ch02.xhtml#id350))
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个例子时，我们得到了`In sequence 20.01662155520171, in parallel 6.259156636893749`，这显示了Dask可以并行运行部分任务，但并非所有任务。^([4](ch02.xhtml#id350))
- en: Nested tasks
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嵌套任务
- en: One of the neat things about `dask.delayed` is that you can launch tasks inside
    of other tasks.^([5](ch02.xhtml#id351)) A straightforward real-world example of
    this is a web crawler, with which, when you visit a web page, you want to fetch
    all of the links from that page, as shown in [Example 2-4](#web_crawler_ch02_1688747981454).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`dask.delayed`的一个很好的特点是您可以在其他任务内启动任务。^([5](ch02.xhtml#id351))这的一个简单的现实世界例子是网络爬虫，在这个例子中，当您访问一个网页时，您希望从该页面获取所有链接，如[示例 2-4](#web_crawler_ch02_1688747981454)所示。'
- en: Example 2-4\. Web crawler
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\. 网络爬虫
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In practice, some central co-ordination is still involved behind the scenes
    (including the scheduler), but the freedom to write your code in this nested way
    is quite powerful.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，幕后仍然涉及一些中央协调（包括调度器），但以这种嵌套方式编写代码的自由性非常强大。
- en: We cover other kinds of task dependencies in [“Task Dependencies”](ch03.xhtml#task_deps).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[“任务依赖关系”](ch03.xhtml#task_deps)中涵盖了其他类型的任务依赖关系。
- en: Distributed Collections
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式集合
- en: In addition to the low-level task APIs, Dask also has distributed collections.
    These collections enable you to work with data that would be too large to fit
    on a single machine and to naturally distribute work on it, which is called *data
    parallelism*. Dask has both an unordered collection called a *bag*, and an ordered
    collection called an *array*. Dask arrays aim to implement some of the ndarray
    interface, whereas bags focus more on functional programming (e.g., things like
    `map` and `filter`). You can load Dask collections from files, take local collections
    and distribute them, or take the results of `dask.delayed` tasks and turn them
    into a collection.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了低级任务API之外，Dask还有分布式集合。这些集合使您能够处理无法放入单台计算机的数据，并在其上自然分发工作，这被称为*数据并行性*。Dask既有称为*bag*的无序集合，也有称为*array*的有序集合。Dask数组旨在实现一些ndarray接口，而bags则更专注于函数式编程（例如`map`和`filter`）。您可以从文件加载Dask集合，获取本地集合并进行分发，或者将`dask.delayed`任务的结果转换为集合。
- en: In distributed collections, Dask splits the data up using partitions. Partitions
    are used to decrease the scheduling cost compared to operating on individual rows,
    which is covered in more detail in [“Partitioning/Chunking Collections”](ch03.xhtml#basic_partitioning).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式集合中，Dask使用分区来拆分数据。分区用于降低与操作单个行相比的调度成本，详细信息请参见[“分区/分块集合”](ch03.xhtml#basic_partitioning)。
- en: Dask arrays
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dask数组
- en: Dask arrays allow you to go beyond what can fit in memory, or even on disk,
    on a single computer. Many of the standard NumPy operations are supported out
    of the box, including aggregates such as average and standard deviation. The `from_array`
    function in Dask arrays converts a local array-like collection into a distributed
    collection. [Example 2-5](#ex_dask_array) shows how to create a distributed array
    from a local one and then compute the average.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Dask数组允许您超越单个计算机内存或磁盘容量的限制。Dask数组支持许多标准NumPy操作，包括平均值和标准差等聚合操作。Dask数组中的`from_array`函数将类似本地数组的集合转换为分布式集合。[示例 2-5](#ex_dask_array)展示了如何从本地数组创建分布式数组，然后计算平均值。
- en: Example 2-5\. Creating a distributed array and computing the average
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-5\. 创建分布式数组并计算平均值
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As with all distributed collections, what is expensive on a Dask array is not
    the same as what is expensive on a local array. In the next chapter you’ll learn
    a bit more about how Dask arrays are implemented and hopefully gain a better intuition
    around their performance.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有分布式集合一样，Dask 数组上的昂贵操作与本地数组上的操作并不相同。在下一章中，您将更多地了解Dask数组的实现方式，并希望能更好地直觉到它们的性能。
- en: Creating a distributed collection from a local collection uses the two fundamental
    building blocks of distributed computing, called the *scatter-gather pattern*.
    While the originating dataset must be from a local computer, fitting into a single
    machine, this already expands the number of processors you have at your disposal,
    as well as the intermediate memory you can utilize, enabling you to better exploit
    modern cloud infrastructure and scale. A practical use case would be a distributed
    web crawler, where the list of seed URLs to crawl might be a small dataset, but
    the memory you need to hold while crawling might be an order of magnitude larger,
    requiring distributed computing.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个分布式集合从本地集合使用分布式计算的两个基本构建块，称为*分散-聚集模式*。虽然原始数据集必须来自本地计算机，适合单台机器，但这已经扩展了您可以使用的处理器数量，以及您可以利用的中间内存，使您能够更好地利用现代云基础设施和扩展。一个实际的用例可能是分布式网络爬虫，其中要爬行的种子URL列表可能是一个小数据集，但在爬行时需要保存的内存可能是数量级更大，需要分布式计算。
- en: Dask bags and a word count
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dask包和词频统计
- en: Dask bags implement more of the functional programming interfaces than Dask
    arrays. The “Hello World” of big data is word count, which is easier to implement
    with functional programming interfaces. Since you’ve already made a crawler function,
    you can turn its output into a Dask bag using the `from_delayed` function in [Example 2-6](#make_bag_of_crawler).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Dask包实现了比Dask数组更多的函数式编程接口。大数据的“Hello World”是词频统计，使用函数式编程接口更容易实现。由于您已经编写了一个爬虫函数，您可以使用`from_delayed`函数将其输出转换为Dask包（参见[示例 2-6](#make_bag_of_crawler)）。
- en: Example 2-6\. Turning the crawler function’s output into a Dask bag
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-6\. 将爬虫函数的输出转换为Dask包
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now that you have a Dask bag collection, you can build everyone’s favorite word
    count example on top of it. The first step is to turn your bag of text into a
    bag of words, which you do by using `map` (see [Example 2-7](#make_a_bag_of_words)).
    Once you have the bag of words, you can either use Dask’s built-in `frequency`
    method (see [Example 2-8](#wc_freq)) or write your own `frequency` method using
    functional transformations (see [Example 2-9](#wc_func)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有了一个Dask包集合，您可以在其上构建每个人最喜欢的词频示例。第一步是将您的文本包转换为词袋，您可以通过使用`map`来实现（参见[示例 2-7](#make_a_bag_of_words)）。一旦您有了词袋，您可以使用Dask的内置`frequency`方法（参见[示例 2-8](#wc_freq)），或者使用函数转换编写自己的`frequency`方法（参见[示例 2-9](#wc_func)）。
- en: Example 2-7\. Turning a bag of text into a bag of words
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-7\. 将文本包转换为词袋
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Example 2-8\. Using Dask’s built-in `frequency` method
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-8\. 使用Dask的内置`frequency`方法
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Example 2-9\. Using functional transformations to write a custom `frequency`
    method
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-9\. 使用函数转换编写自定义`frequency`方法
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: On Dask bags, `foldby`, `frequency`, and many other reductions return a single
    partition bag, meaning the data after reduction needs to fit in a single computer.
    Dask DataFrames handle reductions differently and don’t have that same restriction.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在Dask包上，`foldby`，`frequency`和许多其他的归约返回一个单分区包，这意味着归约后的数据需要适合单台计算机。Dask DataFrame处理归约方式不同，没有同样的限制。
- en: Dask DataFrame (Pandas/What People Wish Big Data Was)
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dask DataFrame（Pandas/人们希望大数据是什么）
- en: Pandas is one of the most popular Python data libraries, and Dask has a DataFrame
    library that implements much of the pandas API. Thanks to Python’s duck-typing,
    you can often use Dask’s distributed DataFrame library in place of pandas. Not
    all of the API will work exactly the same, and some parts are not implemented,
    so be sure you have good test coverage.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是最流行的Python数据库之一，而Dask有一个DataFrame库，实现了大部分Pandas API。由于Python的鸭子类型，您通常可以在Pandas的位置使用Dask的分布式DataFrame库。不是所有的API都会完全相同，有些部分没有实现，所以请确保您有良好的测试覆盖。
- en: Warning
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Your intuition around what’s slow and fast with pandas does not carry over.
    We will explore this more in [“Dask DataFrames”](ch03.xhtml#dask_df).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您在使用Pandas时的慢和快的直觉并不适用。我们将在[“Dask DataFrames”](ch03.xhtml#dask_df)中进一步探讨。
- en: To illustrate how you can use Dask DataFrame, we’ll rework Examples [2-6](#make_bag_of_crawler)
    through [2-8](#wc_freq) to use it. As with Dask’s other collections, you can create
    DataFrames from local collections, futures, or distributed files. Since you’ve
    already made a crawler function, you can turn its output into a Dask bag using
    the `from_delayed` function from [Example 2-6](#make_bag_of_crawler). Instead
    of using `map` and `foldby`, you can use pandas APIs such as `explode` and `value_counts`,
    as shown in [Example 2-10](#wc_dataframe).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示您如何使用 Dask DataFrame，我们将重新编写示例 [2-6](#make_bag_of_crawler) 到 [2-8](#wc_freq)
    来使用它。与 Dask 的其他集合一样，您可以从本地集合、未来数据或分布式文件创建 DataFrame。由于您已经创建了一个爬虫函数，您可以使用 `from_delayed`
    函数将其输出转换为 Dask bag。您可以使用像 `explode` 和 `value_counts` 这样的 pandas API，而不是使用 `map`
    和 `foldby`，如 [示例 2-10](#wc_dataframe) 所示。
- en: Example 2-10\. DataFrame word count
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-10\. DataFrame 单词计数
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter you got Dask working on your local machine, as well as had a
    tour of the different “Hello World” (or getting started) examples with most of
    Dask’s different built-in libraries. Subsequent chapters will dive into these
    different tools in more detail.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经在本地机器上成功运行了 Dask，并且看到了大部分 Dask 内置库的不同“Hello World”（或入门）示例。随后的章节将更详细地探讨这些不同的工具。
- en: Now that you’ve got Dask working on your local machine, you might want to jump
    on over to [Chapter 12](ch12.xhtml#ch12) and look at the different deployment
    mechanisms. For the most part, you can run the examples in local mode, albeit
    sometimes a little slower or at a smaller scale. However, the next chapter will
    look at the core concepts of Dask, and one of the upcoming examples emphasizes
    the benefits of having Dask running on multiple machines and is also generally
    easier to explore on a cluster. If you don’t have a cluster available, you may
    wish to set up a simulated one using something like [MicroK8s](https://microk8s.io).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经在本地机器上成功运行了 Dask，您可能想跳转到 [第12章](ch12.xhtml#ch12) 并查看不同的部署机制。在大多数情况下，您可以在本地模式下运行示例，尽管有时速度可能会慢一些或规模较小。然而，下一章将讨论
    Dask 的核心概念，即将要介绍的一个示例强调了在多台机器上运行 Dask 的好处，并且在集群上探索通常更容易。如果您没有可用的集群，您可能希望使用类似 [MicroK8s](https://microk8s.io)
    的工具设置一个模拟集群。
- en: ^([1](ch02.xhtml#id330-marker)) Word count may be a somewhat tired example,
    but it is an important example, since it covers both work that can be done with
    minimal co-ordination (splitting up the text into words) and work requiring co-ordination
    between computers (summing the words).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.xhtml#id330-marker)) 单词计数可能是一个有些陈旧的例子，但它是一个重要的例子，因为它涵盖了既可以通过最小的协调完成的工作（将文本分割成单词），也可以通过多台计算机之间的协调完成的工作（对单词求和）。
- en: ^([2](ch02.xhtml#id333-marker)) There are downsides to deploying your Dask application
    in this way, as discussed in [Chapter 12](ch12.xhtml#ch12), but it can be an excellent
    debugging technique.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.xhtml#id333-marker)) 以这种方式部署您的 Dask 应用程序存在一些缺点，如 [第12章](ch12.xhtml#ch12)
    中所讨论的，但它可以是一种极好的调试技术。
- en: ^([3](ch02.xhtml#id344-marker)) Provided they fit in memory.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch02.xhtml#id344-marker)) 只要它们适合内存。
- en: ^([4](ch02.xhtml#id350-marker)) When we run this on a cluster, we get worse
    performance, as there is overhead to distributing a task to a remote computer
    compared to the small delay.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch02.xhtml#id350-marker)) 当我们在集群上运行时，性能会变差，因为与小延迟相比，将任务分发到远程计算机存在一定的开销。
- en: ^([5](ch02.xhtml#id351-marker)) This is very different from Apache Spark, where
    only the driver/head node can launch tasks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch02.xhtml#id351-marker)) 这与 Apache Spark 十分不同，后者只有驱动程序/主节点可以启动任务。
