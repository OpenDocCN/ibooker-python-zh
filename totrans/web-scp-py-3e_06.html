<html><head></head><body><section data-pdf-bookmark="Chapter 5. Advanced HTML Parsing" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-5">&#13;
<h1><span class="label">Chapter 5. </span>Advanced HTML Parsing</h1>&#13;
&#13;
<p>When Michelangelo was asked how he could sculpt a work of art as masterful as his <em>David</em>, he is famously reported to have said, “It is easy. You just chip away the stone that doesn’t look like David.”</p>&#13;
&#13;
<p>Although web scraping is unlike marble sculpting in most other respects, you must take a similar attitude when it comes to extracting the information you’re seeking from complicated web pages. In this chapter, we’ll explore various techniques to chip away any content that doesn’t look like content you want, until you arrive at the information you’re seeking. Complicated HTML pages may be look intimidating at first, but just keep chipping!</p>&#13;
&#13;
<section data-pdf-bookmark="Another Serving of BeautifulSoup" data-type="sect1"><div class="sect1" id="id35">&#13;
<h1>Another Serving of BeautifulSoup</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch04.html#c-4">Chapter 4</a>, you took a quick look at installing and running BeautifulSoup, as well as selecting objects one at a time. In this section, we’ll discuss searching for tags by attributes, working with lists of tags, and navigating parse trees.</p>&#13;
&#13;
<p>Nearly every website you encounter <a contenteditable="false" data-primary="stylesheets" data-seealso="CSS (Cascading Style Sheets)" data-type="indexterm" id="id406"/>contains stylesheets. Stylesheets are created so that web browsers can render HTML into colorful and aesthetically pleasing designs for humans. You might think of this styling layer as, at the very least, perfectly ignorable for web scrapers—but not so fast! CSS is, in fact, a huge <a contenteditable="false" data-primary="CSS (Cascading Style Sheets)" data-type="indexterm" id="id407"/>boon for web scrapers because it requires the differentiation of HTML elements in order to style them <span class="keep-together">differently.</span></p>&#13;
&#13;
<p>CSS provides an incentive for web developers to add tags to HTML elements they might have otherwise left <a contenteditable="false" data-primary="tags" data-secondary="CSS and" data-type="indexterm" id="id408"/><a contenteditable="false" data-primary="tags" data-seealso="CSS (Cascading Style Sheets); HTML" data-type="indexterm" id="id409"/>with the exact same markup. Some tags might look like this:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">span</code> <code class="na">class</code><code class="o">=</code><code class="s">"green"</code><code class="p">&gt;&lt;/</code><code class="nt">span</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p class="pagebreak-before">Others look like this:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">span</code> <code class="na">class</code><code class="o">=</code><code class="s">"red"</code><code class="p">&gt;&lt;/</code><code class="nt">span</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>Web scrapers can easily separate these two tags based on their class; for example, they might use BeautifulSoup to grab all the red text but none of the green text. Because CSS relies on these identifying attributes to style sites appropriately, you are almost guaranteed that these class and id attributes will be plentiful on most modern <span class="keep-together">websites.</span></p>&#13;
&#13;
<p>Let’s create an example web scraper that scrapes the page located at <a href="http://www.pythonscraping.com/pages/warandpeace.html"><em>http://www.pythonscraping.com/pages/warandpeace.html</em></a>.</p>&#13;
&#13;
<p>On this page, the lines spoken by characters <a contenteditable="false" data-primary="tags" data-secondary="span" data-type="indexterm" id="id410"/>in the story are in red, whereas the names of characters are in green. You can see the <code>span</code> tags, which reference the appropriate CSS classes, in the following sample of the page’s source code:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">span</code> <code class="na">class</code><code class="o">=</code><code class="s">"red"</code><code class="p">&gt;</code>Heavens! what a virulent attack!<code class="p">&lt;/</code><code class="nt">span</code><code class="p">&gt;</code> replied&#13;
<code class="p">&lt;</code><code class="nt">span</code> <code class="na">class</code><code class="o">=</code><code class="s">"green"</code><code class="p">&gt;</code>the prince<code class="p">&lt;/</code><code class="nt">span</code><code class="p">&gt;</code>, not in the least disconcerted&#13;
by this reception.</pre>&#13;
&#13;
<p>You can grab the entire page and <a contenteditable="false" data-primary="BeautifulSoup object" data-type="indexterm" id="id411"/>create a <code>BeautifulSoup</code> object with it by using a program similar to the one used in <a data-type="xref" href="ch04.html#c-4">Chapter 4</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/warandpeace.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Using this <code>BeautifulSoup</code> object, you can use the <code>find_all</code> function to extract a Python list of proper nouns found by selecting only the text within <code> &lt;span class="green"&gt;&lt;/span&gt;</code> tags (<code>find_all</code> is an extremely flexible function you’ll be using a lot later in this book):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">nameList</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'span'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'class'</code><code class="p">:</code><code class="s1">'green'</code><code class="p">})</code>&#13;
<code class="k">for</code> <code class="n">name</code> <code class="ow">in</code> <code class="n">nameList</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">name</code><code class="o">.</code><code class="n">get_text</code><code class="p">())</code></pre>&#13;
&#13;
<p>When run, it should list all the proper nouns in the text, in the order they appear in <em>War and Peace</em>. How does it work? Previously, you’ve called <code>bs.tagName</code> to get the first occurrence of that tag on the page. Now, you’re calling <code>bs.find_all(tagName, tagAttributes)</code> to get a list of all of the tags on the page, rather than just the first.</p>&#13;
&#13;
<p>After getting a list of names, the program iterates through all names in the list and prints <code>name.get_text()</code> in order to separate the content from the tags.</p>&#13;
&#13;
<div data-type="note" epub:type="note">&#13;
<h1>When to get_text() and When to Preserve Tags</h1>&#13;
&#13;
<p><code>.get_text()</code> strips all tags from the document you are working with and returns a Unicode string containing the text only. For example, if you are working with a large block of text that contains many hyperlinks, paragraphs, and other tags, all those will be stripped away, and you’ll be left with a tagless block of text.</p>&#13;
&#13;
<p>Keep in mind that it’s much easier to find what you’re looking for in a BeautifulSoup object than <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="BeautifulSoup objects" data-type="indexterm" id="id412"/>in a block of text. Calling <code>.get_text()</code> should always be the last thing you do, immediately before you print, store, or manipulate your final data. In general, you should try to preserve the tag structure of a document as long as possible.</p>&#13;
</div>&#13;
&#13;
<section data-pdf-bookmark="find() and find_all() with BeautifulSoup" data-type="sect2"><div class="sect2" id="id36">&#13;
<h2>find() and find_all() with BeautifulSoup</h2>&#13;
&#13;
<p>BeautifulSoup’s <code>find()</code> and <code>find_all()</code> are the two functions you will likely use the most. With <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="find()" data-type="indexterm" id="bspbfd"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="find_all()" data-type="indexterm" id="bfpb"/>them, you can easily filter HTML pages to find lists of desired tags, or a single tag, based on their various attributes.</p>&#13;
&#13;
<p>The two functions are extremely similar, as evidenced by their definitions in the BeautifulSoup documentation:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">find_all</code><code class="p">(</code><code class="n">tag</code><code class="p">,</code> <code class="n">attrs</code><code class="p">,</code> <code class="n">recursive</code><code class="p">,</code> <code class="n">text</code><code class="p">,</code> <code class="n">limit</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>&#13;
<code class="n">find</code><code class="p">(</code><code class="n">tag</code><code class="p">,</code> <code class="n">attrs</code><code class="p">,</code> <code class="n">recursive</code><code class="p">,</code> <code class="n">text</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code></pre>&#13;
&#13;
<p>In all likelihood, 95% of the time you will need to use only the first two arguments: <code>tag</code> and <code>attrs</code>. However, let’s take a look at all the parameters in greater detail.</p>&#13;
&#13;
<p>The <code>tag</code> parameter is one that you’ve seen before; you can pass a string name of a tag or even a Python  list of string tag names. For example, the following returns a list of all the header tags in a document:<sup><a data-type="noteref" href="ch05.html#id413" id="id413-marker">1</a></sup></p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="o">.</code><code class="n">find_all</code><code class="p">([</code><code class="s1">'h1'</code><code class="p">,</code><code class="s1">'h2'</code><code class="p">,</code><code class="s1">'h3'</code><code class="p">,</code><code class="s1">'h4'</code><code class="p">,</code><code class="s1">'h5'</code><code class="p">,</code><code class="s1">'h6'</code><code class="p">])</code></pre>&#13;
&#13;
<p>Unlike the <code>tag</code> parameter, which can be either a string or an iterable, the <code>attrs</code> parameter must be a Python dictionary of attributes and values. It matches tags that contain any one of those attributes. For example, the following function would return <em>both</em> the green and red <code>span</code> tags in the HTML document:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'span'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'class'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'green'</code><code class="p">,</code> <code class="s1">'red'</code><code class="p">]})</code></pre>&#13;
&#13;
<p>The <code>recursive</code> parameter is a boolean. How <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="recursive parameter" data-type="indexterm" id="id414"/><a contenteditable="false" data-primary="recursive parameter" data-type="indexterm" id="id415"/>deeply into the document do you want to go? If <code>recursive</code> is set to <code>True</code>, the <code>find_all</code> function looks into children, and children’s children, etc., for tags that match the parameters. If it is <code>False</code>, it will look only at the top-level tags in your document. By default, <code>find_all</code> works recursively (<code>recursive</code> is set to <code>True</code>). In general, it’s a good idea to leave this as is, unless you really know what you need to do and performance is an issue.</p>&#13;
&#13;
<p>The <code>text</code> parameter is unusual in that it matches based on the text content of the tags, rather than properties of the tags themselves. For instance, if you want to find the number of times “the prince” is surrounded by tags on the example page, you could replace your <code>.find_all()</code> function in the previous example with the following lines:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">nameList</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="n">text</code><code class="o">=</code><code class="s1">'the prince'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">nameList</code><code class="p">))</code></pre>&#13;
&#13;
<p>The output of this is 7.</p>&#13;
&#13;
<p>The <code>limit</code> parameter, of course, is used only in the <code>find_all</code> method; <code>find</code> is equivalent to the same <code>find_all</code> call, with a limit of 1.  You might set this if you’re interested in retrieving only the first <em>x</em> items from the page. Be aware that this gives you the first items on the page in the order they occur in the document, not necessarily the first ones you want.</p>&#13;
&#13;
<p>The additional <code>kwargs</code> parameter allows you to pass any additional named arguments you want into the method. Any extra arguments that <code>find</code> or <code>find_all</code> doesn’t recognize will be used as tag attribute matchers. For example:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">title</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="nb">id</code><code class="o">=</code><code class="s1">'title'</code><code class="p">,</code> <code class="n">class_</code><code class="o">=</code><code class="s1">'text'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>This returns the first tag with the word “text” in the <code>class</code> attribute and “title” in the <code>id</code> attribute. Note that, by convention, each value for an <code>id</code> should be used only once on the page. Therefore, in practice, a line like this may not be particularly useful and should be equivalent to using the <code>find</code> function:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">title</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="nb">id</code><code class="o">=</code><code class="s1">'title'</code><code class="p">)</code></pre>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id416">&#13;
<h1>Keyword Arguments and Class</h1>&#13;
&#13;
<p><code>class</code> is a reserved word <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="keyword arguments" data-type="indexterm" id="id417"/>in Python <a contenteditable="false" data-primary="classes" data-type="indexterm" id="id418"/><a contenteditable="false" data-primary="Python" data-secondary="classes" data-type="indexterm" id="id419"/>that cannot be used as a variable or argument name. For example, if you try the following call, you’ll get a syntax error due to the nonstandard use of <code>class</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="n">class</code><code class="o">=</code><code class="s1">'green'</code><code class="p">)</code></pre>&#13;
&#13;
<p>For this reason, BeautifulSoup requires that you use the keyword argument <code>_class</code> instead of <code>class</code>.</p>&#13;
</div></aside>&#13;
&#13;
<p>You might have noticed that BeautifulSoup already has a way to find tags based on their attributes and values: the <code>attr</code> parameter. Indeed, the following two lines are identical:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="nb">id</code><code class="o">=</code><code class="s1">'text'</code><code class="p">)</code>&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="n">attrs</code><code class="o">=</code><code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'text'</code><code class="p">})</code></pre>&#13;
&#13;
<p>However, the syntax of the first line is shorter and arguably easier to work with for quick filters where you need tags by a particular attribute. When filters get more complex, or when you need to pass attribute value options as a list in the arguments, you may want to use <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="find()" data-startref="bspbfd" data-type="indexterm" id="id420"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="find_all()" data-startref="bfpb" data-type="indexterm" id="id421"/>the <code>attrs</code> parameter:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs.find(attrs={'class':['red', 'blue', 'green']})&#13;
</pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Other BeautifulSoup Objects" data-type="sect2"><div class="sect2" id="id136">&#13;
<h2>Other BeautifulSoup Objects</h2>&#13;
&#13;
<p>So far in the book, you’ve seen two types <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="BeautifulSoup objects" data-type="indexterm" id="id422"/>of objects in the BeautifulSoup library:</p>&#13;
&#13;
<dl>&#13;
	<dt><code>BeautifulSoup</code> objects</dt>&#13;
	<dd>Instances seen in previous code examples as the variable <code>bs</code></dd>&#13;
	<dt><code>Tag</code> objects</dt>&#13;
	<dd>Retrieved in lists, or retrieved individually by calling <code>find</code> and <code>find_all</code> on a <code>BeautifulSoup</code> object, or drilling down:</dd>&#13;
	<dd>&#13;
	<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">div</code><code class="o">.</code><code class="n">h1</code></pre>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>However, two more objects in the library, although less commonly used, are still important to know about:</p>&#13;
&#13;
<dl>&#13;
	<dt><code>NavigableString</code> objects</dt>&#13;
	<dd>Used to represent text within tags, rather than <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="NavigableString objects" data-type="indexterm" id="id423"/>the tags themselves (some functions operate on and produce <code>NavigableStrings</code>, rather than tag objects).</dd>&#13;
	<dt><code>Comment</code> object</dt>&#13;
	<dd>Used to find HTML comments in comment tags, <code>&lt;!--like this one--&gt;</code>.</dd>&#13;
</dl>&#13;
&#13;
<p>These are the only four objects in the BeautifulSoup package at the time of this writing. These were also the only four objects in the BeautifulSoup package when it was released in 2004, so the number of available objects is unlikely to change in the near future.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Navigating Trees" data-type="sect2"><div class="sect2" id="id37">&#13;
<h2 class="pagebreak-before less_space">Navigating Trees</h2>&#13;
&#13;
<p>The <code>find_all</code> function is responsible <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="trees" data-type="indexterm" id="bspbrrt"/><a contenteditable="false" data-primary="trees" data-type="indexterm" id="trsees"/>for finding tags based on their name and attributes. But what if you need to find a tag based on its location in a document? That’s where tree navigation comes in handy. In <a data-type="xref" href="ch04.html#c-4">Chapter 4</a>, you looked at navigating a BeautifulSoup tree in a single direction:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">tag</code><code class="o">.</code><code class="n">subTag</code><code class="o">.</code><code class="n">anotherSubTag</code></pre>&#13;
&#13;
<p>Now let’s look at navigating up, across, and diagonally through HTML trees. You’ll use our highly questionable online shopping site at <em>http://www.pythonscraping.com/pages/page3.html</em> as an example page for scraping, as shown in <a data-type="xref" href="#shopping_screenshot">Figure 5-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="shopping_screenshot"><img alt="Alt Text" class="iimagesillustrationspage4png" src="assets/wsp3_0501.png"/>&#13;
<h6><span class="label">Figure 5-1. </span>Screenshot from <a href="http://www.pythonscraping.com/pages/page3.html"><em class="hyperlink">http://www.pythonscraping.com/pages/page3.html</em></a></h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">The HTML for this page, mapped out as a tree (with some tags omitted for brevity), looks like this:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>HTML</p>&#13;
&#13;
	<ul>&#13;
		<li>&#13;
		<p><code>body</code></p>&#13;
&#13;
		<ul>&#13;
			<li>&#13;
			<p><code>div.wrapper</code></p>&#13;
&#13;
			<ul>&#13;
				<li><code>h1</code></li>&#13;
				<li><code>div.content</code></li>&#13;
				<li>&#13;
				<p><code>table#giftList</code></p>&#13;
&#13;
				<ul>&#13;
					<li>&#13;
					<p><code>tr</code></p>&#13;
&#13;
					<ul>&#13;
						<li><code>th</code></li>&#13;
						<li><code>th</code></li>&#13;
						<li><code>th</code></li>&#13;
						<li><code>th</code></li>&#13;
					</ul>&#13;
					</li>&#13;
					<li>&#13;
					<p><code>tr.gift#gift1</code></p>&#13;
&#13;
					<ul>&#13;
						<li><code>td</code></li>&#13;
						<li>&#13;
						<p> <code>td</code></p>&#13;
&#13;
						<ul>&#13;
							<li><code>span.excitingNote</code></li>&#13;
						</ul>&#13;
						</li>&#13;
						<li><code>td</code></li>&#13;
						<li>&#13;
						<p> <code>td</code></p>&#13;
&#13;
						<ul>&#13;
							<li><code>img</code></li>&#13;
						</ul>&#13;
						</li>&#13;
					</ul>&#13;
					</li>&#13;
					<li>...table rows continue...</li>&#13;
				</ul>&#13;
				</li>&#13;
				<li><code>div.footer</code></li>&#13;
			</ul>&#13;
			</li>&#13;
		</ul>&#13;
		</li>&#13;
	</ul>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>You will use this same HTML structure as an <a contenteditable="false" data-primary="trees" data-startref="trsees" data-type="indexterm" id="id424"/>example in the next few sections.</p>&#13;
&#13;
<section data-pdf-bookmark="Dealing with children and other descendants" data-type="sect3"><div class="sect3" id="id137">&#13;
<h3>Dealing with children and other descendants</h3>&#13;
&#13;
<p>In computer science and some branches <a contenteditable="false" data-primary="trees" data-secondary="children" data-type="indexterm" id="tcldn"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="trees" data-tertiary="descendants" data-type="indexterm" id="bstdd"/>of mathematics, you often hear about horrible things done to children: moving them, storing them, removing them, and even killing them. Fortunately, this section focuses only on selecting them!</p>&#13;
&#13;
<p>In the BeautifulSoup library, as well as many other libraries, there is a distinction drawn between <em>children</em> and <em>descendants</em>: much like in a human family tree, children are always exactly one tag below a parent, whereas descendants can be at any level in the tree below a parent. For example, the <code>tr</code> tags are children of the <code>table</code> tag, whereas <code>tr</code>, <code>th</code>, <code>td</code>, <code>img</code>, and <code>span</code> are all descendants of the <code>table</code> tag (at least in our example page). All children are descendants, but not all descendants are children.</p>&#13;
&#13;
<p>In general, BeautifulSoup functions always deal with the descendants of the current tag selected. For instance, <code>bs.body.h1</code> selects the first <code>h1</code> tag that is a descendant of the <code>body</code> tag. It will not find tags located outside the body.</p>&#13;
&#13;
<p>Similarly, <code>bs.div.find_all('img')</code> will find the first <code>div</code> tag in the document, and then retrieve a list of all <code>img</code> tags that are descendants of that <code>div</code> tag.</p>&#13;
&#13;
<p>If you want to find only descendants that are children, you can use the <code class="keep-together">.children</code> tag:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page3.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">child</code> <code class="ow">in</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'table'</code><code class="p">,{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'giftList'</code><code class="p">})</code><code class="o">.</code><code class="n">children</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">child</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>This code prints the list of product rows in the <code>giftList</code> table, including the initial row of column labels. If you were to write it using the <code>descendants()</code> function instead of the <code>children()</code> function, about two dozen tags would be found within the table and printed, including <code>img</code> tags, <code>span</code> tags, and individual <code>td</code> tags. It’s definitely important <a contenteditable="false" data-primary="trees" data-secondary="children" data-startref="tcldn" data-type="indexterm" id="id425"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="trees" data-startref="bstdd" data-tertiary="descendants" data-type="indexterm" id="id426"/>to differentiate between children and descendants!</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Dealing with siblings" data-type="sect3"><div class="sect3" id="id138">&#13;
<h3>Dealing with siblings</h3>&#13;
&#13;
<p>The BeautifulSoup <code>next_siblings()</code> function makes it trivial to collect data from tables, especially <a contenteditable="false" data-primary="trees" data-secondary="siblings" data-type="indexterm" id="id427"/>ones with title rows:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page3.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">sibling</code> <code class="ow">in</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'table'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'giftList'</code><code class="p">})</code><code class="o">.</code><code class="n">tr</code><code class="o">.</code><code class="n">next_siblings</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">sibling</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The output of this code is to print all rows of products from the product table, except for the first title row. Why does the title row get skipped? Objects cannot be siblings with themselves. Anytime you get siblings of an object, the object itself will not be included in the list. As the name of the function implies, it calls <em>next</em> siblings only. If you were to select a row in the middle of the list, for example, and call <code>next_siblings</code> on it, only the subsequent siblings would be returned. So, by selecting the title row and calling <code>next_siblings</code>, you can select all the rows in the table without selecting the title row itself.</p>&#13;
&#13;
<div data-type="note" epub:type="note">&#13;
<h1>Make Selections Specific</h1>&#13;
&#13;
<p>The preceding code will work just as well if you select <code>bs.table.tr</code> or even just <code>bs.tr</code> to select the first row of the table. However, in the code, I go to the trouble of writing everything out in a longer form:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'table'</code><code class="p">,{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'giftList'</code><code class="p">})</code><code class="o">.</code><code class="n">tr</code></pre>&#13;
&#13;
<p>Even if it looks like there’s just one table (or other target tag) on the page, it’s easy to miss things. In addition, page layouts change all the time. What was once the first of its kind on the page might someday be the second or third tag of that type found on the page. To make your scrapers more robust, it’s best to be as specific as possible when making tag selections. Take advantage of tag attributes when they are available.</p>&#13;
</div>&#13;
&#13;
<p>As a complement to <code>next_siblings</code>, the <code>previous_siblings</code> function often can be helpful if there is an easily selectable tag at the end of a list of sibling tags that you would like to get.</p>&#13;
&#13;
<p>And, of course, there are the <code>next_sibling</code> and <code>previous_sibling</code> functions, which perform nearly the same function as <code>next_siblings</code> and <code>previous_siblings</code>, except <a contenteditable="false" data-primary="trees" data-secondary="siblings" data-startref="tsrblg" data-type="indexterm" id="id428"/><a contenteditable="false" data-primary="trees" data-secondary="siblings" data-startref="trsblg" data-type="indexterm" id="id429"/>they return a single tag rather than a list of them.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Dealing with parents" data-type="sect3"><div class="sect3" id="id139">&#13;
<h3>Dealing with parents</h3>&#13;
&#13;
<p>When scraping pages, you will likely discover <a contenteditable="false" data-primary="trees" data-secondary="parents" data-type="indexterm" id="id430"/>that you need to find parents of tags less frequently than you need to find their children or siblings. Typically, when you look at HTML pages with the goal of crawling them, you start by looking at the top layer of tags, and then figure out how to drill your way down into the exact piece of data that you want. Occasionally, however, you can find yourself in odd situations that require BeautifulSoup’s parent-finding functions, <code>.parent</code> and <code>.parents</code>. For example:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page3.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'img'</code><code class="p">,</code>&#13;
              <code class="p">{</code><code class="s1">'src'</code><code class="p">:</code><code class="s1">'../img/gifts/img1.jpg'</code><code class="p">})</code>&#13;
      <code class="o">.</code><code class="n">parent</code><code class="o">.</code><code class="n">previous_sibling</code><code class="o">.</code><code class="n">get_text</code><code class="p">())</code>&#13;
</pre>&#13;
&#13;
<p>This code will print the price of the object represented by the image at the location <em>../img/gifts/img1.jpg</em> (in this case, the price is $15.00).</p>&#13;
&#13;
<p>How does this work? The following diagram represents the tree structure of the portion of the HTML page you are working with, with numbered steps:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>&lt;tr&gt;</p>&#13;
&#13;
	<ul>&#13;
		<li><code>td</code></li>&#13;
		<li><code>td</code></li>&#13;
		<li><code>td</code> <a class="co" href="#c03" id="comarker3"><img alt="3" src="assets/3.png"/></a>&#13;
		<ul>&#13;
			<li><code>"$15.00"</code><strong> <a class="co" href="#c04" id="comarker4"><img alt="4" src="assets/4.png"/></a></strong></li>&#13;
		</ul>&#13;
		</li>&#13;
		<li><code>td</code> <a class="co" href="#c02" id="comarker2"><img alt="2" src="assets/2.png"/></a>&#13;
		<ul>&#13;
			<li><code>&lt;img src="../img/gifts/img1.jpg"&gt;</code> <a class="co" href="#c01" id="comarker1"><img alt="1" src="assets/1.png"/></a></li>&#13;
		</ul>&#13;
		</li>&#13;
	</ul>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<dl class="calloutlist">&#13;
	<dt><a class="co" href="#comarker1" id="c01"><img alt="1" src="assets/1.png"/></a></dt>&#13;
	<dd>&#13;
	<p>The image tag where <code>src="../img/gifts/img1.jpg"</code> is first selected.</p>&#13;
	</dd>&#13;
	<dt><a class="co" href="#comarker2" id="c02"><img alt="2" src="assets/2.png"/></a></dt>&#13;
	<dd>&#13;
	<p>You select the parent of that tag (in this case, the <code>td</code> tag).</p>&#13;
	</dd>&#13;
	<dt><a class="co" href="#comarker3" id="c03"><img alt="3" src="assets/3.png"/></a></dt>&#13;
	<dd>&#13;
	<p>You select the <code>previous_sibling</code> of the <code>td</code> tag (in this case, the <code>td</code> tag that contains the dollar value of the product).</p>&#13;
	</dd>&#13;
	<dt><a class="co" href="#comarker4" id="c04"><img alt="4" src="assets/4.png"/></a></dt>&#13;
	<dd>&#13;
	<p>You select the text within <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="trees" data-startref="bspbrrt" data-type="indexterm" id="id431"/><a contenteditable="false" data-primary="trees" data-secondary="parents" data-startref="tsprt" data-type="indexterm" id="id432"/><a contenteditable="false" data-primary="trees" data-secondary="parents" data-startref="tseepr" data-type="indexterm" id="id433"/>that tag <code>"$15.00"</code>.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Regular Expressions" data-type="sect1"><div class="sect1" id="regular_express">&#13;
<h1>Regular Expressions</h1>&#13;
&#13;
<p>As the old computer science joke goes: “Let’s say you have a problem, and you decide to solve it with regular <a contenteditable="false" data-primary="regular expressions" data-type="indexterm" id="id434"/><a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-type="indexterm" id="id435"/>expressions. Well, now you have two problems.”</p>&#13;
&#13;
<p>Unfortunately, regular expressions (often shortened to <em>regex</em>) are often taught using large tables <a contenteditable="false" data-primary="regular expressions" data-secondary="regex" data-type="indexterm" id="id436"/><a contenteditable="false" data-primary="regex" data-type="indexterm" id="id437"/>of random symbols, strung together to look like a lot of nonsense. This tends to drive people away, and later they get out into the workforce and write needlessly complicated searching and filtering functions in order to avoid regex.</p>&#13;
&#13;
<p>Regular expressions are an invaluable tool when it comes to web scraping. Fortunately for you, regular expressions are not all that difficult to get up and running with quickly, and they can be learned by looking at and experimenting with a few simple examples.</p>&#13;
&#13;
<p><em>Regular expressions</em> are so called because they are used to identify strings belonging to a <em>regular language</em>. The word “language” here doesn’t mean a language in the sense of a programming language or even a natural language (like English or French). Instead it is the mathematical sense meaning “a set of strings that follow some rules.”</p>&#13;
&#13;
<p>A regular language is the set of <a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-tertiary="strings" data-type="indexterm" id="rgxptg"/><a contenteditable="false" data-primary="strings, regular expressions" data-type="indexterm" id="stggx"/>strings that can be generated by a set of linear rules that can be followed simply while moving along the candidate string and matching it to the rules as you go.<sup><a data-type="noteref" href="ch05.html#id438" id="id438-marker">2</a></sup>  For example:</p>&#13;
&#13;
<ol>&#13;
	<li>&#13;
	<p>Write the letter <em>a</em> at least once.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Append the letter <em>b</em> exactly five times.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Append to this the letter <em>c</em> an even number of times.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Write either the letter <em>d</em> or <em>e</em> at the end.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>A regular expression can definitively determine: “Yes, this string you’ve given me follows the rules,” or “This string does not follow the rules.” This can be exceptionally handy for quickly scanning large documents to look for strings that look like phone numbers or email addresses.</p>&#13;
&#13;
<p>Strings that follow the rules above are strings like <em>aaaabbbbbccccd</em>, <em>aabbbbbcce</em>, and so on. There are, mathematically speaking, an infinite number of strings matching this pattern.</p>&#13;
&#13;
<p>Regular expressions are merely a shorthand way of expressing these sets of rules. For instance, here’s the regular expression for the series of steps just described:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
aa*bbbbb(cc)*(d|e)</pre>&#13;
&#13;
<p>This string might seem a little daunting at first, but it becomes clearer when you break it into its components:</p>&#13;
&#13;
<dl>&#13;
	<dt><em><code>aa*</code></em></dt>&#13;
	<dd>The letter <em>a</em> is written, followed by <em>a*</em> (read as <em>a star</em>), which means “any number of a’s, including 0 of them.” In this way, you can guarantee that the letter <em>a</em> is written at least once.</dd>&#13;
	<dt><em><code>bbbbb</code></em></dt>&#13;
	<dd>No special effects here—just five b’s in a row.</dd>&#13;
	<dt><em><code>(cc)*</code></em></dt>&#13;
	<dd>Any even number of things can be grouped into pairs, so to enforce this rule about even things, you can write two c’s, surround them with parentheses, and write an asterisk after it, meaning that you can have any number of <em>pairs</em> of c’s (note that this can mean zero pairs, as well).</dd>&#13;
	<dt><em><code>(d|e)</code></em></dt>&#13;
	<dd>Adding a bar in the middle of two expressions means that it can be “this thing <em>or </em>that thing.” In this case, you are saying “add a <em>d</em> <em>or</em> an <em>e</em>.” In this way, you <a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-startref="rgxptg" data-tertiary="strings" data-type="indexterm" id="id439"/><a contenteditable="false" data-primary="strings, regular expressions" data-startref="stggx" data-type="indexterm" id="id440"/>can guarantee that there is exactly one of either of these two characters.</dd>&#13;
</dl>&#13;
&#13;
<div data-type="note" epub:type="note">&#13;
<h1>Experimenting with RegEx</h1>&#13;
&#13;
<p>When learning how to write regular expressions, it’s <a contenteditable="false" data-primary="regular expressions" data-secondary="RegEx Pal" data-type="indexterm" id="rgxxp"/><a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-tertiary="RegEx Pal" data-type="indexterm" id="xxgxp"/><a contenteditable="false" data-primary="RegEx Pal" data-type="indexterm" id="rgxpl"/>critical to play around with them and get a feel for how they work. If you don’t feel like firing up a code editor, writing a few lines, and running your program to see whether a regular expression works as expected, you can go to a website such as <a href="http://regexpal.com/">RegEx Pal</a> and test your regular expressions on the fly.</p>&#13;
</div>&#13;
&#13;
<p><a data-type="xref" href="#table_2.1">Table 5-1</a> lists commonly used regular expression symbols, with brief explanations and examples. This list is by no means complete, and, as mentioned before, you might encounter slight variations from language to language. However, these 12 symbols are the most commonly used regular expressions in Python and can be used to find and collect almost any string type.</p>&#13;
&#13;
<table id="table_2.1">&#13;
	<caption><span class="label">Table 5-1. </span>Commonly used regular expression symbols</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th>Symbol(s)</th>&#13;
			<th>Meaning</th>&#13;
			<th>Example</th>&#13;
			<th>Example matches</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>*</td>&#13;
			<td>Matches the preceding character, subexpression, or bracketed character, 0 or more times.</td>&#13;
			<td>a*b*</td>&#13;
			<td>&#13;
			<p>aaaaaaaa, aaabbbbb, bbbbbb</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>+</td>&#13;
			<td>Matches the preceding character, subexpression, or bracketed character, 1 or more times.</td>&#13;
			<td>a+b+</td>&#13;
			<td>&#13;
			<p>aaaaaaaab, aaabbbbb, abbbbbb</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>[]</td>&#13;
			<td>Matches any character within the brackets (i.e., “Pick any one of these things”).</td>&#13;
			<td>[A-Z]*</td>&#13;
			<td>APPLE,<br/>&#13;
			CAPITALS,<br/>&#13;
			QWERTY</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>()</td>&#13;
			<td>&#13;
			<p>A grouped subexpression (these are evaluated first, in the “order of operations” of regular expressions).</p>&#13;
			</td>&#13;
			<td>(a*b)*</td>&#13;
			<td>aaabaab, abaaab,<br/>&#13;
			ababaaaaab</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>{m, n}</td>&#13;
			<td>Matches the preceding character, subexpression, or bracketed character between <em>m</em> and <em>n</em> times (inclusive).</td>&#13;
			<td>a{2,3}b{2,3}</td>&#13;
			<td>aabbb, aaabbb, aabb</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>[^]</td>&#13;
			<td>Matches any single character that is <em>not</em> in the brackets.</td>&#13;
			<td>[^A-Z]*</td>&#13;
			<td>apple,<br/>&#13;
			lowercase,<br/>&#13;
			qwerty</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>|</td>&#13;
			<td>Matches any character, string of characters, or subexpression separated by the <code>I</code> (note that this is a vertical bar, or <em>pipe</em>, not a capital i).</td>&#13;
			<td>b(a|i|e)d</td>&#13;
			<td>bad, bid, bed</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>.</td>&#13;
			<td>Matches any single character (including symbols, numbers, a space, etc.).</td>&#13;
			<td>b.d</td>&#13;
			<td>bad, bzd, b$d, b d</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>^</td>&#13;
			<td>Indicates that a character or subexpression occurs at the beginning of a string.</td>&#13;
			<td>^a</td>&#13;
			<td>&#13;
			<p>apple, asdf, a</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>\</td>&#13;
			<td>An escape character (this allows you to use special characters as their literal meanings).</td>&#13;
			<td>\^ \| \\</td>&#13;
			<td>^ | \</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>$</td>&#13;
			<td>Often used at the end of a regular expression, it means “match this up to the end of the string.” Without it, every regular expression has a de facto “.*” at the end of it, accepting strings where only the first part of the string matches. This can be thought of as analogous to the ^ symbol.</td>&#13;
			<td>[A-Z]*[a-z]*$</td>&#13;
			<td>ABCabc, zzzyx, Bob</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>?!</td>&#13;
			<td>“Does not contain.” This odd pairing of symbols, immediately preceding a character (or regular expression), indicates that that character should not be found in that specific place in the larger string. This can be tricky to use; after all, the character might be found in a different part of the string. If trying to eliminate a character entirely, use in conjunction with a ^ and $ at either end.</td>&#13;
			<td>^((?![A-Z]).)*$</td>&#13;
			<td>no-caps-here, $ymb0ls a4e f!ne</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>One classic example of regular expressions can be found in the practice of identifying email addresses. Although the exact rules governing email addresses vary slightly from mail server to mail server, we can create a few general rules. The corresponding regular expression for each of these rules is shown in the second column:</p>&#13;
&#13;
<table id="email_rules">&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>&#13;
			<dl>&#13;
				<dt>Rule 1</dt>&#13;
				<dd>The first part of an email address contains at least one of the following: uppercase letters, lowercase letters, the numbers 0–9, periods (.), plus signs (+), or underscores (_).</dd>&#13;
			</dl>&#13;
			</td>&#13;
			<td>&#13;
			<dl>&#13;
				<dt><strong>[A-Za-z0-9._+]+</strong></dt>&#13;
				<dd>The regular expression shorthand is pretty smart. For example, it knows that “A-Z” means “any uppercase letter, A through Z.” By putting all these possible sequences and symbols in brackets (as opposed to parentheses), you are saying, “This symbol can be any one of these things we’ve listed in the brackets.” Note also that the + sign means “these characters can occur as many times as they want to but must occur at least once.”</dd>&#13;
			</dl>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<dl>&#13;
				<dt>Rule 2</dt>&#13;
				<dd>After this, the email address contains the @ symbol.</dd>&#13;
			</dl>&#13;
			</td>&#13;
			<td>&#13;
			<dl>&#13;
				<dt><strong>@</strong></dt>&#13;
				<dd>This is fairly straightforward: the @ symbol must occur in the middle, and it must occur exactly once.</dd>&#13;
			</dl>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<dl>&#13;
				<dt>Rule 3</dt>&#13;
				<dd>The email address then must contain at least one uppercase or lowercase letter.</dd>&#13;
			</dl>&#13;
			</td>&#13;
			<td>&#13;
			<dl>&#13;
				<dt><strong>[A-Za-z]+</strong></dt>&#13;
				<dd>You may use only letters in the first part of the domain name, after the @ symbol. Also, there must be at least one character.</dd>&#13;
			</dl>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<dl>&#13;
				<dt>Rule 4</dt>&#13;
				<dd>This is followed by a period (.).</dd>&#13;
			</dl>&#13;
			</td>&#13;
			<td>&#13;
			<dl>&#13;
				<dt><strong>.</strong></dt>&#13;
				<dd>You must include a period (.) before the top-level domain.</dd>&#13;
			</dl>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<dl>&#13;
				<dt>Rule 5</dt>&#13;
				<dd>Finally, the email address ends with <em>com</em>, <em>org</em>, <em>edu</em>, or <em>net</em> (in reality, there are many possible top-level domains, but these four should suffice for the sake of example).</dd>&#13;
			</dl>&#13;
			</td>&#13;
			<td>&#13;
			<dl>&#13;
				<dt><strong>(com|org|edu|net)</strong></dt>&#13;
				<dd>This lists the possible sequences of letters that can occur after the period in the second part of an email address.</dd>&#13;
			</dl>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>By concatenating all of the rules, you arrive at this regular expression:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
[A-Za-z0-9._+]+@[A-Za-z]+.(com|org|edu|net)</pre>&#13;
&#13;
<p>When attempting to write any regular expression from scratch, it’s best to first make a list of steps that concretely outlines what your target string looks like. Pay attention to edge cases. For instance, if you’re identifying phone numbers, are you considering <a contenteditable="false" data-primary="regular expressions" data-secondary="RegEx Pal" data-startref="rgxxp" data-type="indexterm" id="id441"/><a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-startref="xxgxp" data-tertiary="RegEx Pal" data-type="indexterm" id="id442"/><a contenteditable="false" data-primary="RegEx Pal" data-startref="rgxpl" data-type="indexterm" id="id443"/>country codes and extensions?</p>&#13;
&#13;
<div data-type="warning" epub:type="warning">&#13;
<h1>Regular Expressions: Not Always Regular!</h1>&#13;
&#13;
<p>The standard version of regular expressions (the one covered in this book and used by Python and BeautifulSoup) is based on syntax used by Perl. Most modern programming languages use this or one similar to it. Be aware, however, that if you are using regular expressions in another language, you might encounter problems. Even some modern languages, such as Java, have slight differences in the way they handle regular expressions. When in doubt, read the docs!</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Regular Expressions and BeautifulSoup" data-type="sect1"><div class="sect1" id="reg_expressions">&#13;
<h1>Regular Expressions and BeautifulSoup</h1>&#13;
&#13;
<p>If the previous section on regular <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="regular expressions" data-type="indexterm" id="btfpbgx"/><a contenteditable="false" data-primary="regular expressions" data-secondary="BeautifulSoup" data-type="indexterm" id="rgxpbsp"/><a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-tertiary="BeautifulSoup" data-type="indexterm" id="xpssxsu"/>expressions seemed a little disjointed from the mission of this book, here’s where it all ties together. BeautifulSoup and regular expressions go hand in hand when it comes to scraping the web. In fact, most functions that take in a string argument (e.g., <code>find(id="aTagIdHere")</code>) will also take in a regular expression just as well.</p>&#13;
&#13;
<p>Let’s take a look at some examples, scraping the page found at <a href="http://www.pythonscraping.com/pages/page3.html"><em>http://www.pythonscraping.com/pages/page3.html</em></a>.</p>&#13;
&#13;
<p>Notice that the site has many product images, which take the following form:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
&lt;img src="../img/gifts/img3.jpg"&gt;</pre>&#13;
&#13;
<p>If you wanted to grab URLs of all of the product images, it might seem fairly straightforward at first: just grab all the image tags by using <code>.find_all("img")</code>, right? But there’s a problem. In addition to the obvious “extra” images (e.g., logos), modern websites often have hidden images, blank images used for spacing and aligning elements, and other random image tags you might not be aware of. Certainly, you can’t count on the only images on the page being product images.</p>&#13;
&#13;
<p>Let’s also assume that the layout of the page might change, or that, for whatever reason, you don’t want to depend on the <em>position</em> of the image in the page in order to find the correct tag. This might be the case when you are trying to grab specific elements or pieces of data that are scattered randomly throughout a website. For instance, a featured product image might appear in a special layout at the top of some pages but not others.</p>&#13;
&#13;
<p>The solution is to look for something identifying about the tag itself. In this case, you can look at the file path of the product images:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
<code class="kn">import</code> <code class="nn">re</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page3.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
<code class="n">images</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'img'</code><code class="p">,</code>&#13;
    <code class="p">{</code><code class="s1">'src'</code><code class="p">:</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'..\/img\/gifts/img.*.jpg'</code><code class="p">)})</code>&#13;
<code class="k">for</code> <code class="n">image</code> <code class="ow">in</code> <code class="n">images</code><code class="p">:</code> &#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">image</code><code class="p">[</code><code class="s1">'src'</code><code class="p">])</code>&#13;
</pre>&#13;
&#13;
<p>This prints only the relative image paths that start with <em>../img/gifts/img</em> and end in <em>.jpg</em>, the output of which is:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
../img/gifts/img1.jpg&#13;
../img/gifts/img2.jpg&#13;
../img/gifts/img3.jpg&#13;
../img/gifts/img4.jpg&#13;
../img/gifts/img6.jpg&#13;
</pre>&#13;
&#13;
<p>A regular expression can be inserted as any argument in a BeautifulSoup expression, allowing you a great deal of <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="regular expressions" data-startref="btfpbgx" data-type="indexterm" id="id444"/><a contenteditable="false" data-primary="regular expressions" data-secondary="BeautifulSoup" data-startref="rgxpbsp" data-type="indexterm" id="id445"/><a contenteditable="false" data-primary="expressions" data-secondary="regular expressions" data-startref="xpssxsu" data-tertiary="BeautifulSoup" data-type="indexterm" id="id446"/>flexibility in finding target elements.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Accessing Attributes" data-type="sect1"><div class="sect1" id="id141">&#13;
<h1>Accessing Attributes</h1>&#13;
&#13;
<p>So far, you’ve looked at how to access and filter tags and access content within them. However, often in web scraping you’re not looking for the content of a tag; you’re looking for its attributes. This becomes especially useful for tags such as <code>a</code>, where the URL it is pointing to is contained within the <code>href</code> attribute; or the <code>img</code> tag, where the target image is contained within the <code>src</code> attribute.</p>&#13;
&#13;
<p>With tag objects, a Python list of <a contenteditable="false" data-primary="Python" data-secondary="attributes" data-type="indexterm" id="id447"/>attributes can be automatically accessed by calling this:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
myTag.attrs&#13;
</pre>&#13;
&#13;
<p>Keep in mind that this literally returns a Python <a contenteditable="false" data-primary="Python" data-secondary="dictionary object" data-type="indexterm" id="id448"/>dictionary object, which makes retrieval and manipulation of these attributes trivial. The source location for an image, for example, can be found using the following line:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
myImgTag.attrs['src']</pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Lambda Expressions" data-type="sect1"><div class="sect1" id="lambda_express">&#13;
<h1>Lambda Expressions</h1>&#13;
&#13;
<p><em>Lambda</em> is a fancy academic <a contenteditable="false" data-primary="expressions" data-secondary="lambda expressions" data-type="indexterm" id="expbdx"/><a contenteditable="false" data-primary="lambda expressions" data-type="indexterm" id="lbdxpss"/>term that, in programming, simply means “a shorthand way of writing a function.” In Python, we might write a function that returns the square of a number as:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
def square(n):&#13;
    return n**2&#13;
</pre>&#13;
&#13;
<p>We could use a lambda expression to do the same thing in one line:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
square = lambda n: n**2</pre>&#13;
&#13;
<p>This assigns the variable <code>square</code> directly to a function that takes in a single argument <code>n</code> and returns <code>n**2</code>. But there’s no rule that says functions have to be “named” or assigned to variables at all. We can simply write them as values:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
&gt;&gt;&gt; lambda r: r**2&#13;
&lt;function &lt;lambda&gt; at 0x7f8f88223a60&gt;&#13;
</pre>&#13;
&#13;
<p>Essentially, a <em>lambda expression</em> is a function that exists alone, without being named or assigned to a variable. In Python, a lambda function cannot have more than one line of code (this is a matter of style and good taste on Python’s part, rather than some fundamental rule of computer science, however).</p>&#13;
&#13;
<p>The most common use of lambda expressions is an argument passed in to other functions. BeautifulSoup allows you to pass certain types of functions as parameters into the <code>find_all</code> function.</p>&#13;
&#13;
<p>The only restriction is that these functions must take a tag object as an argument and return a boolean. Every tag object that BeautifulSoup encounters is evaluated in this function, and tags that evaluate to <code>True</code> are returned, while the rest are discarded.</p>&#13;
&#13;
<p>For example, the following retrieves all tags that have exactly two attributes:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs.find_all(lambda tag: len(tag.attrs) == 2)</pre>&#13;
&#13;
<p>Here, the function that you are passing as the argument is <code>len(tag.attrs) == 2</code>. Where this is <code>True</code>, the  <code>find_all</code> function will return the tag. That is, it will find tags with two attributes, such as:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">div</code> <code class="na">class</code><code class="o">=</code><code class="s">"body"</code> <code class="na">id</code><code class="o">=</code><code class="s">"content"</code><code class="p">&gt;&lt;/</code><code class="nt">div</code><code class="p">&gt;</code>&#13;
<code class="p">&lt;</code><code class="nt">span</code> <code class="na">style</code><code class="o">=</code><code class="s">"color:red"</code> <code class="na">class</code><code class="o">=</code><code class="s">"title"</code><code class="p">&gt;&lt;/</code><code class="nt">span</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>Lambda functions are so useful you can even use them to replace existing BeautifulSoup functions:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs.find_all(lambda tag: tag.get_text() ==&#13;
    'Or maybe he\'s only resting?')</pre>&#13;
&#13;
<p>This also can be accomplished without a lambda function:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs.find_all('', text='Or maybe he\'s only resting?')</pre>&#13;
&#13;
<p>However, if you remember the syntax for the lambda function, and how to access tag properties, you may never need to remember any other BeautifulSoup syntax again!</p>&#13;
&#13;
<p>Because the provided lambda function can be any function that returns a <code>True</code> or <code>False</code> value, you can even combine them with regular expressions to find tags with an <a contenteditable="false" data-primary="expressions" data-secondary="lambda expressions" data-startref="expbdx" data-type="indexterm" id="id449"/><a contenteditable="false" data-primary="lambda expressions" data-startref="lbdxpss" data-type="indexterm" id="id450"/>attribute matching a certain string pattern.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="You Don’t Always Need a Hammer" data-type="sect1"><div class="sect1" id="id243">&#13;
<h1>You Don’t Always Need a Hammer</h1>&#13;
&#13;
<p>It can be tempting, when faced with a Gordian knot of tags, to dive right in and use multiline statements to try to extract your information. However, keep in mind that layering the techniques used in this chapter with reckless abandon can lead to code that is difficult to debug, fragile, or both. Let’s look at some of the ways you can avoid altogether the need for advanced HTML parsing.</p>&#13;
&#13;
<p>Let’s say you have some target content. Maybe it’s a name, statistic, or block of text. Maybe it’s buried 20 tags deep in an HTML mush with no helpful tags or HTML attributes to be found. You may decide to throw caution to the wind and write something like the following line to attempt extraction:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'table'</code><code class="p">)[</code><code class="mi">4</code><code class="p">]</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'tr'</code><code class="p">)[</code><code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'td'</code><code class="p">)</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'div'</code><code class="p">)[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'a'</code><code class="p">)</code></pre>&#13;
&#13;
<p>That doesn’t look so great. In addition to the aesthetics of the line, even the slightest change to the website by a site administrator might break your web scraper altogether. What if the site’s web developer decides to add another table or another column of data? What if the developer adds another component (with a few <code>div</code> tags) to the top of the page? The preceding line is precarious and depends on the structure of the site never changing.</p>&#13;
&#13;
<p>So what are your options?</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Look for any “landmarks” that you can use to jump right into the middle of the document, closer to the content that you actually want. Convenient CSS attributes are an obvious landmark, but you can also get creative and grab tags by their content using <code>.find_all(text='some tag content')</code> in a pinch.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>If there’s no easy way to isolate the tag you want or any of its parents, can you find a sibling? Use the <code>.parent</code> method and then drill back down to the target tag.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Abandon this document altogether and look for a “Print This Page” link, or perhaps a mobile version of the site that has better-formatted HTML (more on presenting yourself as a mobile device—and receiving mobile site versions—in <a data-type="xref" href="ch17.html#c-17">Chapter 17</a>).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Don’t ignore the content in the <code>&lt;script&gt;</code> tags or separately loaded JavaScript files. JavaScript often contains the data that you’re looking for and in a nicer format! For example, I once collected nicely formatted street addresses from a website by examining the JavaScript for an embedded Google Maps application. For more information about this technique, see <a data-type="xref" href="ch11.html#c-11">Chapter 11</a>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Information might be available in the URL of the page itself. For example, page titles and product IDs can often be found there.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>If the information you are looking for is unique to this website for some reason, you’re out of luck. If not, try to think of other sources you could get this information from. Is there another website with the same data? Is this website displaying data that it scraped or aggregated from another website?</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Especially when you are faced with buried or poorly formatted data, it’s important not to just start digging and write yourself into a hole that you might not be able to get out of. Take a deep breath and think of alternatives.</p>&#13;
&#13;
<p>The techniques presented here, when used correctly, will go a long way toward writing more stable and reliable web crawlers.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id413"><sup><a href="ch05.html#id413-marker">1</a></sup> If you’re looking to get a list of all <code>h&lt;<em>some_level</em>&gt;</code> tags in the document, there are more succinct ways of writing this code to accomplish the same thing. We’ll take a look at other ways of approaching these types of problems in the section <a data-type="xref" data-xrefstyle="select:nopage" href="#reg_expressions">“Regular Expressions and BeautifulSoup”</a>.</p><p data-type="footnote" id="id438"><sup><a href="ch05.html#id438-marker">2</a></sup> You might be asking yourself, “Are there ‘irregular’ languages and irregular expressions?” Nonregular expressions are <a contenteditable="false" data-primary="regular expressions" data-secondary="nonregular expressions" data-type="indexterm" id="id451"/><a contenteditable="false" data-primary="expressions" data-secondary="nonregular expressions" data-type="indexterm" id="id452"/><a contenteditable="false" data-primary="nonregular expressions" data-type="indexterm" id="id453"/>beyond the scope of this book, but they encompass strings such as “write a prime number of a’s, followed by exactly twice that number of b’s” or “write a palindrome.” It’s impossible to identify strings of this type with a regular expression. Fortunately, I’ve never been in a situation where my web scraper needed to identify these kinds of strings.</p></div></div></section></body></html>