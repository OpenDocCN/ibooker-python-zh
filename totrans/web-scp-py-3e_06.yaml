- en: Chapter 5\. Advanced HTML Parsing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When Michelangelo was asked how he could sculpt a work of art as masterful as
    his *David*, he is famously reported to have said, “It is easy. You just chip
    away the stone that doesn’t look like David.”
  prefs: []
  type: TYPE_NORMAL
- en: Although web scraping is unlike marble sculpting in most other respects, you
    must take a similar attitude when it comes to extracting the information you’re
    seeking from complicated web pages. In this chapter, we’ll explore various techniques
    to chip away any content that doesn’t look like content you want, until you arrive
    at the information you’re seeking. Complicated HTML pages may be look intimidating
    at first, but just keep chipping!
  prefs: []
  type: TYPE_NORMAL
- en: Another Serving of BeautifulSoup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html#c-4), you took a quick look at installing and running
    BeautifulSoup, as well as selecting objects one at a time. In this section, we’ll
    discuss searching for tags by attributes, working with lists of tags, and navigating
    parse trees.
  prefs: []
  type: TYPE_NORMAL
- en: Nearly every website you encounter contains stylesheets. Stylesheets are created
    so that web browsers can render HTML into colorful and aesthetically pleasing
    designs for humans. You might think of this styling layer as, at the very least,
    perfectly ignorable for web scrapers—but not so fast! CSS is, in fact, a huge
    boon for web scrapers because it requires the differentiation of HTML elements
    in order to style them differently.
  prefs: []
  type: TYPE_NORMAL
- en: 'CSS provides an incentive for web developers to add tags to HTML elements they
    might have otherwise left with the exact same markup. Some tags might look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Others look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Web scrapers can easily separate these two tags based on their class; for example,
    they might use BeautifulSoup to grab all the red text but none of the green text.
    Because CSS relies on these identifying attributes to style sites appropriately,
    you are almost guaranteed that these class and id attributes will be plentiful
    on most modern websites.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create an example web scraper that scrapes the page located at [*http://www.pythonscraping.com/pages/warandpeace.html*](http://www.pythonscraping.com/pages/warandpeace.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'On this page, the lines spoken by characters in the story are in red, whereas
    the names of characters are in green. You can see the `span` tags, which reference
    the appropriate CSS classes, in the following sample of the page’s source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can grab the entire page and create a `BeautifulSoup` object with it by
    using a program similar to the one used in [Chapter 4](ch04.html#c-4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this `BeautifulSoup` object, you can use the `find_all` function to extract
    a Python list of proper nouns found by selecting only the text within `<span class="green"></span>`
    tags (`find_all` is an extremely flexible function you’ll be using a lot later
    in this book):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: When run, it should list all the proper nouns in the text, in the order they
    appear in *War and Peace*. How does it work? Previously, you’ve called `bs.tagName`
    to get the first occurrence of that tag on the page. Now, you’re calling `bs.find_all(tagName,
    tagAttributes)` to get a list of all of the tags on the page, rather than just
    the first.
  prefs: []
  type: TYPE_NORMAL
- en: After getting a list of names, the program iterates through all names in the
    list and prints `name.get_text()` in order to separate the content from the tags.
  prefs: []
  type: TYPE_NORMAL
- en: When to get_text() and When to Preserve Tags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`.get_text()` strips all tags from the document you are working with and returns
    a Unicode string containing the text only. For example, if you are working with
    a large block of text that contains many hyperlinks, paragraphs, and other tags,
    all those will be stripped away, and you’ll be left with a tagless block of text.'
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that it’s much easier to find what you’re looking for in a BeautifulSoup
    object than in a block of text. Calling `.get_text()` should always be the last
    thing you do, immediately before you print, store, or manipulate your final data.
    In general, you should try to preserve the tag structure of a document as long
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: find() and find_all() with BeautifulSoup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BeautifulSoup’s `find()` and `find_all()` are the two functions you will likely
    use the most. With them, you can easily filter HTML pages to find lists of desired
    tags, or a single tag, based on their various attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two functions are extremely similar, as evidenced by their definitions
    in the BeautifulSoup documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In all likelihood, 95% of the time you will need to use only the first two
    arguments: `tag` and `attrs`. However, let’s take a look at all the parameters
    in greater detail.'
  prefs: []
  type: TYPE_NORMAL
- en: The `tag` parameter is one that you’ve seen before; you can pass a string name
    of a tag or even a Python  list of string tag names. For example, the following
    returns a list of all the header tags in a document:^([1](ch05.html#id413))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike the `tag` parameter, which can be either a string or an iterable, the
    `attrs` parameter must be a Python dictionary of attributes and values. It matches
    tags that contain any one of those attributes. For example, the following function
    would return *both* the green and red `span` tags in the HTML document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `recursive` parameter is a boolean. How deeply into the document do you
    want to go? If `recursive` is set to `True`, the `find_all` function looks into
    children, and children’s children, etc., for tags that match the parameters. If
    it is `False`, it will look only at the top-level tags in your document. By default,
    `find_all` works recursively (`recursive` is set to `True`). In general, it’s
    a good idea to leave this as is, unless you really know what you need to do and
    performance is an issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `text` parameter is unusual in that it matches based on the text content
    of the tags, rather than properties of the tags themselves. For instance, if you
    want to find the number of times “the prince” is surrounded by tags on the example
    page, you could replace your `.find_all()` function in the previous example with
    the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The output of this is 7.
  prefs: []
  type: TYPE_NORMAL
- en: The `limit` parameter, of course, is used only in the `find_all` method; `find` is
    equivalent to the same `find_all` call, with a limit of 1.  You might set this
    if you’re interested in retrieving only the first *x* items from the page. Be
    aware that this gives you the first items on the page in the order they occur
    in the document, not necessarily the first ones you want.
  prefs: []
  type: TYPE_NORMAL
- en: 'The additional `kwargs` parameter allows you to pass any additional named arguments
    you want into the method. Any extra arguments that `find` or `find_all` doesn’t
    recognize will be used as tag attribute matchers. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns the first tag with the word “text” in the `class` attribute and
    “title” in the `id` attribute. Note that, by convention, each value for an `id`
    should be used only once on the page. Therefore, in practice, a line like this
    may not be particularly useful and should be equivalent to using the `find` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You might have noticed that BeautifulSoup already has a way to find tags based
    on their attributes and values: the `attr` parameter. Indeed, the following two
    lines are identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the syntax of the first line is shorter and arguably easier to work
    with for quick filters where you need tags by a particular attribute. When filters
    get more complex, or when you need to pass attribute value options as a list in
    the arguments, you may want to use the `attrs` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Other BeautifulSoup Objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far in the book, you’ve seen two types of objects in the BeautifulSoup library:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BeautifulSoup` objects'
  prefs: []
  type: TYPE_NORMAL
- en: Instances seen in previous code examples as the variable `bs`
  prefs: []
  type: TYPE_NORMAL
- en: '`Tag` objects'
  prefs: []
  type: TYPE_NORMAL
- en: 'Retrieved in lists, or retrieved individually by calling `find` and `find_all`
    on a `BeautifulSoup` object, or drilling down:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'However, two more objects in the library, although less commonly used, are
    still important to know about:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NavigableString` objects'
  prefs: []
  type: TYPE_NORMAL
- en: Used to represent text within tags, rather than the tags themselves (some functions
    operate on and produce `NavigableStrings`, rather than tag objects).
  prefs: []
  type: TYPE_NORMAL
- en: '`Comment` object'
  prefs: []
  type: TYPE_NORMAL
- en: Used to find HTML comments in comment tags, `<!--like this one-->`.
  prefs: []
  type: TYPE_NORMAL
- en: These are the only four objects in the BeautifulSoup package at the time of
    this writing. These were also the only four objects in the BeautifulSoup package
    when it was released in 2004, so the number of available objects is unlikely to
    change in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating Trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `find_all` function is responsible for finding tags based on their name
    and attributes. But what if you need to find a tag based on its location in a
    document? That’s where tree navigation comes in handy. In [Chapter 4](ch04.html#c-4),
    you looked at navigating a BeautifulSoup tree in a single direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s look at navigating up, across, and diagonally through HTML trees.
    You’ll use our highly questionable online shopping site at *http://www.pythonscraping.com/pages/page3.html*
    as an example page for scraping, as shown in [Figure 5-1](#shopping_screenshot).
  prefs: []
  type: TYPE_NORMAL
- en: '![Alt Text](assets/wsp3_0501.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. Screenshot from [*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The HTML for this page, mapped out as a tree (with some tags omitted for brevity),
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: HTML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`body`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`div.wrapper`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`h1`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`div.content`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`table#giftList`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tr`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`th`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`th`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`th`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`th`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tr.gift#gift1`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`span.excitingNote`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`img`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '...table rows continue...'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`div.footer`'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You will use this same HTML structure as an example in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with children and other descendants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In computer science and some branches of mathematics, you often hear about
    horrible things done to children: moving them, storing them, removing them, and
    even killing them. Fortunately, this section focuses only on selecting them!'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the BeautifulSoup library, as well as many other libraries, there is a distinction
    drawn between *children* and *descendants*: much like in a human family tree,
    children are always exactly one tag below a parent, whereas descendants can be
    at any level in the tree below a parent. For example, the `tr` tags are children
    of the `table` tag, whereas `tr`, `th`, `td`, `img`, and `span` are all descendants
    of the `table` tag (at least in our example page). All children are descendants,
    but not all descendants are children.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, BeautifulSoup functions always deal with the descendants of the
    current tag selected. For instance, `bs.body.h1` selects the first `h1` tag that
    is a descendant of the `body` tag. It will not find tags located outside the body.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, `bs.div.find_all('img')` will find the first `div` tag in the document,
    and then retrieve a list of all `img` tags that are descendants of that `div`
    tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to find only descendants that are children, you can use the `.children`
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This code prints the list of product rows in the `giftList` table, including
    the initial row of column labels. If you were to write it using the `descendants()`
    function instead of the `children()` function, about two dozen tags would be found
    within the table and printed, including `img` tags, `span` tags, and individual
    `td` tags. It’s definitely important to differentiate between children and descendants!
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with siblings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The BeautifulSoup `next_siblings()` function makes it trivial to collect data
    from tables, especially ones with title rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The output of this code is to print all rows of products from the product table,
    except for the first title row. Why does the title row get skipped? Objects cannot
    be siblings with themselves. Anytime you get siblings of an object, the object
    itself will not be included in the list. As the name of the function implies,
    it calls *next* siblings only. If you were to select a row in the middle of the
    list, for example, and call `next_siblings` on it, only the subsequent siblings
    would be returned. So, by selecting the title row and calling `next_siblings`,
    you can select all the rows in the table without selecting the title row itself.
  prefs: []
  type: TYPE_NORMAL
- en: Make Selections Specific
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preceding code will work just as well if you select `bs.table.tr` or even
    just `bs.tr` to select the first row of the table. However, in the code, I go
    to the trouble of writing everything out in a longer form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Even if it looks like there’s just one table (or other target tag) on the page,
    it’s easy to miss things. In addition, page layouts change all the time. What
    was once the first of its kind on the page might someday be the second or third
    tag of that type found on the page. To make your scrapers more robust, it’s best
    to be as specific as possible when making tag selections. Take advantage of tag
    attributes when they are available.
  prefs: []
  type: TYPE_NORMAL
- en: As a complement to `next_siblings`, the `previous_siblings` function often can
    be helpful if there is an easily selectable tag at the end of a list of sibling
    tags that you would like to get.
  prefs: []
  type: TYPE_NORMAL
- en: And, of course, there are the `next_sibling` and `previous_sibling` functions,
    which perform nearly the same function as `next_siblings` and `previous_siblings`,
    except they return a single tag rather than a list of them.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with parents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When scraping pages, you will likely discover that you need to find parents
    of tags less frequently than you need to find their children or siblings. Typically,
    when you look at HTML pages with the goal of crawling them, you start by looking
    at the top layer of tags, and then figure out how to drill your way down into
    the exact piece of data that you want. Occasionally, however, you can find yourself
    in odd situations that require BeautifulSoup’s parent-finding functions, `.parent`
    and `.parents`. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This code will print the price of the object represented by the image at the
    location *../img/gifts/img1.jpg* (in this case, the price is $15.00).
  prefs: []
  type: TYPE_NORMAL
- en: 'How does this work? The following diagram represents the tree structure of
    the portion of the HTML page you are working with, with numbered steps:'
  prefs: []
  type: TYPE_NORMAL
- en: <tr>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td` [![3](assets/3.png)](#c03)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`"$15.00"` **[![4](assets/4.png)](#c04)**'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`td` [![2](assets/2.png)](#c02)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`<img src="../img/gifts/img1.jpg">` [![1](assets/1.png)](#c01)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![1](assets/1.png)](#comarker1)'
  prefs: []
  type: TYPE_NORMAL
- en: The image tag where `src="../img/gifts/img1.jpg"` is first selected.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#comarker2)'
  prefs: []
  type: TYPE_NORMAL
- en: You select the parent of that tag (in this case, the `td` tag).
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#comarker3)'
  prefs: []
  type: TYPE_NORMAL
- en: You select the `previous_sibling` of the `td` tag (in this case, the `td` tag
    that contains the dollar value of the product).
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#comarker4)'
  prefs: []
  type: TYPE_NORMAL
- en: You select the text within that tag `"$15.00"`.
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As the old computer science joke goes: “Let’s say you have a problem, and you
    decide to solve it with regular expressions. Well, now you have two problems.”'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, regular expressions (often shortened to *regex*) are often taught
    using large tables of random symbols, strung together to look like a lot of nonsense.
    This tends to drive people away, and later they get out into the workforce and
    write needlessly complicated searching and filtering functions in order to avoid
    regex.
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions are an invaluable tool when it comes to web scraping. Fortunately
    for you, regular expressions are not all that difficult to get up and running
    with quickly, and they can be learned by looking at and experimenting with a few
    simple examples.
  prefs: []
  type: TYPE_NORMAL
- en: '*Regular expressions* are so called because they are used to identify strings
    belonging to a *regular language*. The word “language” here doesn’t mean a language
    in the sense of a programming language or even a natural language (like English
    or French). Instead it is the mathematical sense meaning “a set of strings that
    follow some rules.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A regular language is the set of strings that can be generated by a set of
    linear rules that can be followed simply while moving along the candidate string
    and matching it to the rules as you go.^([2](ch05.html#id438))  For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Write the letter *a* at least once.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Append the letter *b* exactly five times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Append to this the letter *c* an even number of times.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write either the letter *d* or *e* at the end.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A regular expression can definitively determine: “Yes, this string you’ve given
    me follows the rules,” or “This string does not follow the rules.” This can be
    exceptionally handy for quickly scanning large documents to look for strings that
    look like phone numbers or email addresses.'
  prefs: []
  type: TYPE_NORMAL
- en: Strings that follow the rules above are strings like *aaaabbbbbccccd*, *aabbbbbcce*,
    and so on. There are, mathematically speaking, an infinite number of strings matching
    this pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regular expressions are merely a shorthand way of expressing these sets of
    rules. For instance, here’s the regular expression for the series of steps just
    described:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This string might seem a little daunting at first, but it becomes clearer when
    you break it into its components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*`aa*`*'
  prefs: []
  type: TYPE_NORMAL
- en: The letter *a* is written, followed by *a** (read as *a star*), which means
    “any number of a’s, including 0 of them.” In this way, you can guarantee that
    the letter *a* is written at least once.
  prefs: []
  type: TYPE_NORMAL
- en: '*`bbbbb`*'
  prefs: []
  type: TYPE_NORMAL
- en: No special effects here—just five b’s in a row.
  prefs: []
  type: TYPE_NORMAL
- en: '*`(cc)*`*'
  prefs: []
  type: TYPE_NORMAL
- en: Any even number of things can be grouped into pairs, so to enforce this rule
    about even things, you can write two c’s, surround them with parentheses, and
    write an asterisk after it, meaning that you can have any number of *pairs* of
    c’s (note that this can mean zero pairs, as well).
  prefs: []
  type: TYPE_NORMAL
- en: '*`(d|e)`*'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a bar in the middle of two expressions means that it can be “this thing
    *or* that thing.” In this case, you are saying “add a *d* *or* an *e*.” In this
    way, you can guarantee that there is exactly one of either of these two characters.
  prefs: []
  type: TYPE_NORMAL
- en: Experimenting with RegEx
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When learning how to write regular expressions, it’s critical to play around
    with them and get a feel for how they work. If you don’t feel like firing up a
    code editor, writing a few lines, and running your program to see whether a regular
    expression works as expected, you can go to a website such as [RegEx Pal](http://regexpal.com/) and
    test your regular expressions on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-1](#table_2.1) lists commonly used regular expression symbols, with
    brief explanations and examples. This list is by no means complete, and, as mentioned
    before, you might encounter slight variations from language to language. However,
    these 12 symbols are the most commonly used regular expressions in Python and
    can be used to find and collect almost any string type.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Commonly used regular expression symbols
  prefs: []
  type: TYPE_NORMAL
- en: '| Symbol(s) | Meaning | Example | Example matches |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| * | Matches the preceding character, subexpression, or bracketed character,
    0 or more times. | a*b* | aaaaaaaa, aaabbbbb, bbbbbb |'
  prefs: []
  type: TYPE_TB
- en: '| + | Matches the preceding character, subexpression, or bracketed character,
    1 or more times. | a+b+ | aaaaaaaab, aaabbbbb, abbbbbb |'
  prefs: []
  type: TYPE_TB
- en: '| [] | Matches any character within the brackets (i.e., “Pick any one of these
    things”). | [A-Z]* | APPLE, CAPITALS,'
  prefs: []
  type: TYPE_NORMAL
- en: QWERTY |
  prefs: []
  type: TYPE_NORMAL
- en: '| () | A grouped subexpression (these are evaluated first, in the “order of
    operations” of regular expressions). | (a*b)* | aaabaab, abaaab, ababaaaaab |'
  prefs: []
  type: TYPE_TB
- en: '| {m, n} | Matches the preceding character, subexpression, or bracketed character
    between *m* and *n* times (inclusive). | a{2,3}b{2,3} | aabbb, aaabbb, aabb |'
  prefs: []
  type: TYPE_TB
- en: '| [^] | Matches any single character that is *not* in the brackets. | [^A-Z]*
    | apple, lowercase,'
  prefs: []
  type: TYPE_NORMAL
- en: qwerty |
  prefs: []
  type: TYPE_NORMAL
- en: '| &#124; | Matches any character, string of characters, or subexpression separated
    by the `I` (note that this is a vertical bar, or *pipe*, not a capital i). | b(a&#124;i&#124;e)d
    | bad, bid, bed |'
  prefs: []
  type: TYPE_TB
- en: '| . | Matches any single character (including symbols, numbers, a space, etc.).
    | b.d | bad, bzd, b$d, b d |'
  prefs: []
  type: TYPE_TB
- en: '| ^ | Indicates that a character or subexpression occurs at the beginning of
    a string. | ^a | apple, asdf, a |'
  prefs: []
  type: TYPE_TB
- en: '| \ | An escape character (this allows you to use special characters as their
    literal meanings). | \^ \&#124; \\ | ^ &#124; \ |'
  prefs: []
  type: TYPE_TB
- en: '| $ | Often used at the end of a regular expression, it means “match this up
    to the end of the string.” Without it, every regular expression has a de facto
    “.*” at the end of it, accepting strings where only the first part of the string
    matches. This can be thought of as analogous to the ^ symbol. | [A-Z]*[a-z]*$
    | ABCabc, zzzyx, Bob |'
  prefs: []
  type: TYPE_TB
- en: '| ?! | “Does not contain.” This odd pairing of symbols, immediately preceding
    a character (or regular expression), indicates that that character should not
    be found in that specific place in the larger string. This can be tricky to use;
    after all, the character might be found in a different part of the string. If
    trying to eliminate a character entirely, use in conjunction with a ^ and $ at
    either end. | ^((?![A-Z]).)*$ | no-caps-here, $ymb0ls a4e f!ne |'
  prefs: []
  type: TYPE_TB
- en: 'One classic example of regular expressions can be found in the practice of
    identifying email addresses. Although the exact rules governing email addresses
    vary slightly from mail server to mail server, we can create a few general rules.
    The corresponding regular expression for each of these rules is shown in the second
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Rule 1
  prefs: []
  type: TYPE_NORMAL
- en: 'The first part of an email address contains at least one of the following:
    uppercase letters, lowercase letters, the numbers 0–9, periods (.), plus signs
    (+), or underscores (_).'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**[A-Za-z0-9._+]+**'
  prefs: []
  type: TYPE_NORMAL
- en: The regular expression shorthand is pretty smart. For example, it knows that
    “A-Z” means “any uppercase letter, A through Z.” By putting all these possible
    sequences and symbols in brackets (as opposed to parentheses), you are saying,
    “This symbol can be any one of these things we’ve listed in the brackets.” Note
    also that the + sign means “these characters can occur as many times as they want
    to but must occur at least once.”
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Rule 2
  prefs: []
  type: TYPE_NORMAL
- en: After this, the email address contains the @ symbol.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**@**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is fairly straightforward: the @ symbol must occur in the middle, and
    it must occur exactly once.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Rule 3
  prefs: []
  type: TYPE_NORMAL
- en: The email address then must contain at least one uppercase or lowercase letter.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**[A-Za-z]+**'
  prefs: []
  type: TYPE_NORMAL
- en: You may use only letters in the first part of the domain name, after the @ symbol.
    Also, there must be at least one character.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Rule 4
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by a period (.).
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**.**'
  prefs: []
  type: TYPE_NORMAL
- en: You must include a period (.) before the top-level domain.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Rule 5
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the email address ends with *com*, *org*, *edu*, or *net* (in reality,
    there are many possible top-level domains, but these four should suffice for the
    sake of example).
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '**(com&#124;org&#124;edu&#124;net)**'
  prefs: []
  type: TYPE_NORMAL
- en: This lists the possible sequences of letters that can occur after the period
    in the second part of an email address.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'By concatenating all of the rules, you arrive at this regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: When attempting to write any regular expression from scratch, it’s best to first
    make a list of steps that concretely outlines what your target string looks like.
    Pay attention to edge cases. For instance, if you’re identifying phone numbers,
    are you considering country codes and extensions?
  prefs: []
  type: TYPE_NORMAL
- en: 'Regular Expressions: Not Always Regular!'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The standard version of regular expressions (the one covered in this book and
    used by Python and BeautifulSoup) is based on syntax used by Perl. Most modern
    programming languages use this or one similar to it. Be aware, however, that if
    you are using regular expressions in another language, you might encounter problems.
    Even some modern languages, such as Java, have slight differences in the way they
    handle regular expressions. When in doubt, read the docs!
  prefs: []
  type: TYPE_NORMAL
- en: Regular Expressions and BeautifulSoup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the previous section on regular expressions seemed a little disjointed from
    the mission of this book, here’s where it all ties together. BeautifulSoup and
    regular expressions go hand in hand when it comes to scraping the web. In fact,
    most functions that take in a string argument (e.g., `find(id="aTagIdHere")`)
    will also take in a regular expression just as well.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at some examples, scraping the page found at [*http://www.pythonscraping.com/pages/page3.html*](http://www.pythonscraping.com/pages/page3.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that the site has many product images, which take the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wanted to grab URLs of all of the product images, it might seem fairly
    straightforward at first: just grab all the image tags by using `.find_all("img")`,
    right? But there’s a problem. In addition to the obvious “extra” images (e.g.,
    logos), modern websites often have hidden images, blank images used for spacing
    and aligning elements, and other random image tags you might not be aware of.
    Certainly, you can’t count on the only images on the page being product images.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s also assume that the layout of the page might change, or that, for whatever
    reason, you don’t want to depend on the *position* of the image in the page in
    order to find the correct tag. This might be the case when you are trying to grab
    specific elements or pieces of data that are scattered randomly throughout a website.
    For instance, a featured product image might appear in a special layout at the
    top of some pages but not others.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution is to look for something identifying about the tag itself. In
    this case, you can look at the file path of the product images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints only the relative image paths that start with *../img/gifts/img*
    and end in *.jpg*, the output of which is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: A regular expression can be inserted as any argument in a BeautifulSoup expression,
    allowing you a great deal of flexibility in finding target elements.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Attributes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you’ve looked at how to access and filter tags and access content within
    them. However, often in web scraping you’re not looking for the content of a tag;
    you’re looking for its attributes. This becomes especially useful for tags such
    as `a`, where the URL it is pointing to is contained within the `href` attribute;
    or the `img` tag, where the target image is contained within the `src` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'With tag objects, a Python list of attributes can be automatically accessed
    by calling this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that this literally returns a Python dictionary object, which
    makes retrieval and manipulation of these attributes trivial. The source location
    for an image, for example, can be found using the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Lambda Expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Lambda* is a fancy academic term that, in programming, simply means “a shorthand
    way of writing a function.” In Python, we might write a function that returns
    the square of a number as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We could use a lambda expression to do the same thing in one line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This assigns the variable `square` directly to a function that takes in a single
    argument `n` and returns `n**2`. But there’s no rule that says functions have
    to be “named” or assigned to variables at all. We can simply write them as values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, a *lambda expression* is a function that exists alone, without
    being named or assigned to a variable. In Python, a lambda function cannot have
    more than one line of code (this is a matter of style and good taste on Python’s
    part, rather than some fundamental rule of computer science, however).
  prefs: []
  type: TYPE_NORMAL
- en: The most common use of lambda expressions is an argument passed in to other
    functions. BeautifulSoup allows you to pass certain types of functions as parameters
    into the `find_all` function.
  prefs: []
  type: TYPE_NORMAL
- en: The only restriction is that these functions must take a tag object as an argument
    and return a boolean. Every tag object that BeautifulSoup encounters is evaluated
    in this function, and tags that evaluate to `True` are returned, while the rest
    are discarded.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following retrieves all tags that have exactly two attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the function that you are passing as the argument is `len(tag.attrs)
    == 2`. Where this is `True`, the  `find_all` function will return the tag. That
    is, it will find tags with two attributes, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Lambda functions are so useful you can even use them to replace existing BeautifulSoup
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This also can be accomplished without a lambda function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: However, if you remember the syntax for the lambda function, and how to access
    tag properties, you may never need to remember any other BeautifulSoup syntax
    again!
  prefs: []
  type: TYPE_NORMAL
- en: Because the provided lambda function can be any function that returns a `True`
    or `False` value, you can even combine them with regular expressions to find tags
    with an attribute matching a certain string pattern.
  prefs: []
  type: TYPE_NORMAL
- en: You Don’t Always Need a Hammer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It can be tempting, when faced with a Gordian knot of tags, to dive right in
    and use multiline statements to try to extract your information. However, keep
    in mind that layering the techniques used in this chapter with reckless abandon
    can lead to code that is difficult to debug, fragile, or both. Let’s look at some
    of the ways you can avoid altogether the need for advanced HTML parsing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say you have some target content. Maybe it’s a name, statistic, or block
    of text. Maybe it’s buried 20 tags deep in an HTML mush with no helpful tags or
    HTML attributes to be found. You may decide to throw caution to the wind and write
    something like the following line to attempt extraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: That doesn’t look so great. In addition to the aesthetics of the line, even
    the slightest change to the website by a site administrator might break your web
    scraper altogether. What if the site’s web developer decides to add another table
    or another column of data? What if the developer adds another component (with
    a few `div` tags) to the top of the page? The preceding line is precarious and
    depends on the structure of the site never changing.
  prefs: []
  type: TYPE_NORMAL
- en: So what are your options?
  prefs: []
  type: TYPE_NORMAL
- en: Look for any “landmarks” that you can use to jump right into the middle of the
    document, closer to the content that you actually want. Convenient CSS attributes
    are an obvious landmark, but you can also get creative and grab tags by their
    content using `.find_all(text='some tag content')` in a pinch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there’s no easy way to isolate the tag you want or any of its parents, can
    you find a sibling? Use the `.parent` method and then drill back down to the target
    tag.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abandon this document altogether and look for a “Print This Page” link, or perhaps
    a mobile version of the site that has better-formatted HTML (more on presenting
    yourself as a mobile device—and receiving mobile site versions—in [Chapter 17](ch17.html#c-17)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t ignore the content in the `<script>` tags or separately loaded JavaScript
    files. JavaScript often contains the data that you’re looking for and in a nicer
    format! For example, I once collected nicely formatted street addresses from a
    website by examining the JavaScript for an embedded Google Maps application. For
    more information about this technique, see [Chapter 11](ch11.html#c-11).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information might be available in the URL of the page itself. For example, page
    titles and product IDs can often be found there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the information you are looking for is unique to this website for some reason,
    you’re out of luck. If not, try to think of other sources you could get this information
    from. Is there another website with the same data? Is this website displaying
    data that it scraped or aggregated from another website?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Especially when you are faced with buried or poorly formatted data, it’s important
    not to just start digging and write yourself into a hole that you might not be
    able to get out of. Take a deep breath and think of alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: The techniques presented here, when used correctly, will go a long way toward
    writing more stable and reliable web crawlers.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch05.html#id413-marker)) If you’re looking to get a list of all `h<*some_level*>`
    tags in the document, there are more succinct ways of writing this code to accomplish
    the same thing. We’ll take a look at other ways of approaching these types of
    problems in the section [“Regular Expressions and BeautifulSoup”](#reg_expressions).
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch05.html#id438-marker)) You might be asking yourself, “Are there ‘irregular’
    languages and irregular expressions?” Nonregular expressions are beyond the scope
    of this book, but they encompass strings such as “write a prime number of a’s,
    followed by exactly twice that number of b’s” or “write a palindrome.” It’s impossible
    to identify strings of this type with a regular expression. Fortunately, I’ve
    never been in a situation where my web scraper needed to identify these kinds
    of strings.
  prefs: []
  type: TYPE_NORMAL
