<html><head></head><body><section data-pdf-bookmark="Chapter 10. Reading Documents" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-10">&#13;
<h1><span class="label">Chapter 10. </span>Reading Documents</h1>&#13;
&#13;
<p>It is tempting to think of the internet primarily as a collection of text-based websites interspersed with newfangled web 2.0 multimedia content that can mostly be ignored for the purposes of web scraping. However, this ignores what the internet most fundamentally is: a content-agnostic vehicle for transmitting files.</p>&#13;
&#13;
<p>Although the internet has been around in some form or another since the late 1960s, HTML didn’t debut until 1992. Until then, the internet consisted mostly of email and file transmission; the concept of web pages as we know them today didn’t exist. In other words, the internet is not a collection of HTML files. It is a collection of many types of documents, with HTML files often being used as a frame to showcase them. Without being able to read a variety of document types, including text, PDF, images, video, email, and more, we are missing out on a huge part of the available data.</p>&#13;
&#13;
<p>This chapter covers dealing with documents, whether you’re downloading them to a local folder or reading them and extracting data. You’ll also take a look at dealing with various types of text encoding, which can make it possible to read even foreign-language HTML pages.</p>&#13;
&#13;
<section data-pdf-bookmark="Document Encoding" data-type="sect1"><div class="sect1" id="id59">&#13;
<h1>Document Encoding</h1>&#13;
&#13;
<p>A document’s encoding tells <a contenteditable="false" data-primary="documents, encoding" data-type="indexterm" id="dcmtcdg"/><a contenteditable="false" data-primary="encoding documents" data-type="indexterm" id="ecdgdm"/>applications—whether they are your computer’s operating system or your own Python code—how to read it. This encoding can usually be deduced from its file extension, although this file extension is not mandated by its encoding. I could, for example, save <em>myImage.jpg</em> as <em>myImage.txt</em> with no problems—at least until my text editor tried to open it. Fortunately, this situation is rare, and a document’s file extension is usually all you need to know to read it correctly.</p>&#13;
&#13;
<p>On a fundamental level, all documents are encoded in 0s and 1s. On top of that, encoding algorithms define things such as “how many bits per character” or “how many bits represent the color for each pixel” (in the case of image files). On top of that, you might have a layer of compression, or some space-reducing algorithm, as is the case with PNG files.</p>&#13;
&#13;
<p>Although dealing with non-HTML files might seem intimidating at first, rest assured that with the right library, Python will be properly equipped to deal with any format of information you want to throw at it. The only difference between a text file, a video file, and an image file is how their 0s and 1s are interpreted. This chapter covers several commonly encountered types of files: text, CSV, PDFs, and Word documents.</p>&#13;
&#13;
<p>Notice that these are all, fundamentally, files that store text. For information about working with images, I recommend that you read through this chapter to get used to working with and storing different types of files, and then head to <a data-type="xref" href="ch16.html#c-16">Chapter 16</a> for more information on image processing!</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Text" data-type="sect1"><div class="sect1" id="id60">&#13;
<h1>Text</h1>&#13;
&#13;
<p>It is somewhat unusual to have files <a contenteditable="false" data-primary="text files" data-type="indexterm" id="id589"/><a contenteditable="false" data-primary="files" data-secondary="text files" data-type="indexterm" id="id590"/>stored as plain text online, but it is popular among bare-bones or old-school sites to have large repositories of text files. For example, the Internet Engineering Task Force (IETF) stores all of <a contenteditable="false" data-primary="text files" data-secondary="IETF (Internet Engineering Task Force)" data-type="indexterm" id="id591"/>its published documents as HTML, PDF, and text files (see <a href="https://www.ietf.org/rfc/rfc1149.txt"><em>https://www.ietf.org/rfc/rfc1149.txt</em></a> as an example). Most browsers will display these text files just fine, and you should be able to scrape them with no problem.</p>&#13;
&#13;
<p>For most basic text documents, such as the practice file located at <a href="http://www.pythonscraping.com/pages/warandpeace/chapter1.txt"><em>http://www.pythonscraping.com/pages/warandpeace/chapter1.txt</em></a>, you can use the following method:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="n">textPage</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/'</code>\&#13;
    <code class="s1">'pages/warandpeace/chapter1.txt'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">textPage</code><code class="o">.</code><code class="n">read</code><code class="p">())</code></pre>&#13;
&#13;
<p>Normally, when you retrieve a page using <code>urlopen</code>, you turn it into a <a data-type="link" href="ch04.html#c-4"><code>BeautifulSoup</code></a> object in order to parse the HTML. In this case, you can read the page directly. Turning it into a BeautifulSoup object, while perfectly possible, would be counterproductive—there’s no HTML to parse, so the library would be useless. Once the text file is read in as a string, you merely have to analyze it as you would any other string read into Python. The disadvantage here, of course, is that you don’t have the ability to use HTML tags as context clues, pointing you in the direction of the text you actually need, versus the text you don’t want. This can present a challenge when you’re trying to extract certain information from text files.</p>&#13;
&#13;
<section data-pdf-bookmark="Text Encoding and the Global Internet" data-type="sect2"><div class="sect2" id="ch10sec2">&#13;
<h2>Text Encoding and the Global Internet</h2>&#13;
&#13;
<p>Most of the time, a file extension is <a contenteditable="false" data-primary="text" data-secondary="encoding" data-type="indexterm" id="xfxcd"/><a contenteditable="false" data-primary="files" data-secondary="text files" data-tertiary="text encoding" data-type="indexterm" id="fxfxc"/><a contenteditable="false" data-primary="text files" data-secondary="encoding" data-type="indexterm" id="txfecd"/>all you need to know how to read a file correctly. Strangely enough though, this rule doesn’t apply to the most basic of all documents: the <em>.txt</em> file.</p>&#13;
&#13;
<p>Reading in text by using the previously described methods will work just fine 9 times out of 10. However, dealing with text on the internet can be a tricky business. Next, we’ll cover the basics of English and foreign-language encoding, from ASCII to Unicode to ISO, and how to deal with them.</p>&#13;
&#13;
<section data-pdf-bookmark="A history of text encoding" data-type="sect3"><div class="sect3" id="id61">&#13;
<h3>A history of text encoding</h3>&#13;
&#13;
<p>ASCII was first developed in the 1960s, when bits <a contenteditable="false" data-primary="text" data-secondary="ASCII" data-type="indexterm" id="xscii"/><a contenteditable="false" data-primary="ASCII text" data-type="indexterm" id="ascxt"/>were expensive and there was no reason to encode anything besides the Latin alphabet and a few punctuation characters. For this reason, only 7 bits were used to encode a total of 128 capital letters, lowercase letters, and punctuation. Even with all that creativity, they were still left with 33 non-printing characters, some of which were used, replaced, and/or became obsolete as technologies changed over the years. Plenty of space for everyone, right?</p>&#13;
&#13;
<p>As any programmer knows, 7 is a strange number. It’s not a nice power of 2, but it’s temptingly close. Computer scientists in the 1960s fought over whether an extra bit should be added for the convenience of having a nice round number versus the practicality of files requiring less storage space. In the end, 7 bits won. However, <span class="keep-together">in modern computing,</span> each 7-bit sequence is padded with an extra 0 at the beginning,<sup><a data-type="noteref" href="ch10.html#id592" id="id592-marker">1</a></sup> leaving us with the worst of both worlds—14% larger files, and the lack of flexibility of only 128 characters.</p>&#13;
&#13;
<p>In the early 1990s, people realized that more languages than just English existed, and that it would be really nice if computers could display them. A nonprofit named The Unicode Consortium <a contenteditable="false" data-primary="text" data-secondary="Unicode Consortium" data-type="indexterm" id="id593"/><a contenteditable="false" data-primary="Unicode Consortium" data-type="indexterm" id="id594"/>attempted to bring about a universal text encoder by establishing encodings for every character that needs to be used in any text document, in any language. The goal was to include everything from the Latin alphabet this book is written in, to Cyrillic (кириллица), Chinese pictograms (象形), math and logic symbols (⨊, ≥), and even emoticons and miscellaneous symbols, such as the biohazard sign (☣) and peace symbol (☮).</p>&#13;
&#13;
<p>The resulting encoder, as you might <a contenteditable="false" data-primary="UTF-8" data-type="indexterm" id="id595"/>already know, was dubbed <em>UTF-8</em>, which stands for, confusingly, “Universal Character Set—Transformation Format 8 bit.” The <em>8 bit</em> here refers not to the size of every character but to the smallest size that a character requires to be displayed.</p>&#13;
&#13;
<p>The actual size of a UTF-8 character is flexible. It can range from 1 byte to 4 bytes, depending on where it is placed in the list of possible characters (more popular characters are encoded with fewer bytes; more obscure ones require more bytes).</p>&#13;
&#13;
<p>How is this flexible encoding achieved? The use of 7 bits with an eventual useless leading 0 looked like a design flaw in ASCII at first but proved to be a huge advantage for UTF-8. Because ASCII was so popular, Unicode decided to take advantage of this leading 0 bit by declaring all bytes starting with a 0 to indicate that only one byte is used in the character, and making the two encoding schemes for ASCII and UTF-8 identical. Therefore, the following characters are valid in both UTF-8 and ASCII:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
01000001 - A&#13;
01000010 - B&#13;
01000011 - C&#13;
</pre>&#13;
&#13;
<p>And the following characters are valid only in UTF-8 and will be rendered as nonprintable if the document is interpreted as an ASCII document:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
11000011 10000000 - À&#13;
11000011 10011111 - ß&#13;
11000011 10100111 - ç</pre>&#13;
&#13;
<p>In addition to UTF-8, other UTF standards exist, such as UTF-16, UTF-24, and UTF-32, although documents encoded in these formats are rarely encountered except in unusual circumstances, which are outside the scope of this book.</p>&#13;
&#13;
<p>​While this original “design flaw” of ASCII had a major advantage for UTF-8, the disadvantage has not entirely gone away. The first 8 bits of information in each character can still encode only 128 characters, not a full 256. In a UTF-8 character requiring multiple bytes, additional leading bits are spent, not on character encoding but on check bits used to prevent corruption. Of the 32 (8 x 4) bits in 4-byte characters, only 21 bits are used for character encoding, for a total of 2,097,152 possible characters, of which, 1,114,112 are currently allocated.</p>&#13;
&#13;
<p>The problem with all universal language-encoding standards, of course, is that any document written in a single foreign language may be much larger than it has to be. Although your language might consist only of 100 or so characters, you will need 16 bits for each character rather than just 8 bits, as is the case for the English-specific ASCII. This makes foreign-language text documents in UTF-8 about twice the size of English-language text documents, at least for foreign languages that don’t use the Latin character set.</p>&#13;
&#13;
<p>ISO solves this problem by <a contenteditable="false" data-primary="ISO character sets" data-type="indexterm" id="id596"/><a contenteditable="false" data-primary="text" data-secondary="ISO character sets" data-type="indexterm" id="id597"/>creating specific encodings for each language. Like Unicode, it has the same encodings that ASCII does, but it uses the padding 0 bit at the beginning of every character to allow it to create 128 special characters for all languages that require them. This works best for European languages that also rely heavily on the Latin alphabet (which remain in positions 0–127 in the encoding), but require additional special characters. This allows ISO-8859-1 (designed for the Latin alphabet) to have symbols such as fractions (e.g., ½) or the copyright sign (©).</p>&#13;
&#13;
<p>Other ISO character sets, such as ISO-8859-9 (Turkish), ISO-8859-2 (German, among other languages), and ISO-8859-15 (French, among other languages) can also be found on the internet with some regularity.</p>&#13;
&#13;
<p>Although the popularity of ISO-encoded documents has been declining in recent years, about 9% of websites on the internet are still encoded with some flavor of ISO,<sup><a data-type="noteref" href="ch10.html#id598" id="id598-marker">2</a></sup> making it essential to know <a contenteditable="false" data-primary="text" data-secondary="ASCII" data-startref="xscii" data-type="indexterm" id="id599"/><a contenteditable="false" data-primary="ASCII text" data-startref="ascxt" data-type="indexterm" id="id600"/>about and check for encodings before scraping a site.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Encodings in action" data-type="sect3"><div class="sect3" id="id62">&#13;
<h3>Encodings in action</h3>&#13;
&#13;
<p>In the previous section, you used the <a contenteditable="false" data-primary="text" data-secondary="encoding" data-tertiary="non-English words" data-type="indexterm" id="xecngl"/>default settings for <code>urlopen</code> to read text documents you might encounter on the internet. This works great for most English text. However, the second you encounter Russian, Arabic, or even a word like “résumé,” you might run into problems.</p>&#13;
&#13;
<p>Take the following code, for example:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="n">textPage</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/'</code>\&#13;
    <code class="s1">'pages/warandpeace/chapter1-ru.txt'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">textPage</code><code class="o">.</code><code class="n">read</code><code class="p">())</code></pre>&#13;
&#13;
<p>This reads in the first chapter of the original <em>War and Peace</em> (written in Russian and French) and prints it to the screen. This screen text reads, in part:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
b"\xd0\xa7\xd0\x90\xd0\xa1\xd0\xa2\xd0\xac \xd0\x9f\xd0\x95\xd0\xa0\xd0\x92\xd0\&#13;
x90\xd0\xaf\n\nI\n\n\xe2\x80\x94 Eh bien, mon prince.</pre>&#13;
&#13;
<p>In addition, visiting this page in most browsers results in gibberish (see <a data-type="xref" href="#text_encoded">Figure 10-1</a>).</p>&#13;
&#13;
<figure><div class="figure" id="text_encoded"><img alt="Alt Text" class="iimageswarandpeace_badencodingpng" src="assets/wsp3_1001.png"/>&#13;
<h6><span class="label">Figure 10-1. </span>French and Cyrillic text encoded in ISO-8859-1, the default text document encoding in many browsers</h6>&#13;
</div></figure>&#13;
&#13;
<p>Even for native Russian speakers, that might be a bit difficult to make sense of. The problem is that Python is attempting to read the document as an ASCII document, whereas the browser is attempting to read it as an ISO-8859-1 encoded document. Neither one, of course, realizes it’s a UTF-8 document.</p>&#13;
&#13;
<p>You can explicitly define the string to be UTF-8, which correctly formats the output into Cyrillic characters:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
&#13;
<code class="n">textPage</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/'</code>\&#13;
    <code class="s1">'pages/warandpeace/chapter1-ru.txt'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">textPage</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'utf-8'</code><code class="p">))</code></pre>&#13;
&#13;
<p>Using this concept with BeautifulSoup looks like this:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://en.wikipedia.org/wiki/Python_(programming_language)'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
<code class="n">content</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'mw-content-text'</code><code class="p">})</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code>&#13;
<code class="n">content</code> <code class="o">=</code> <code class="nb">bytes</code><code class="p">(</code><code class="n">content</code><code class="p">,</code> <code class="s1">'UTF-8'</code><code class="p">)</code>&#13;
<code class="n">content</code> <code class="o">=</code> <code class="n">content</code><code class="o">.</code><code class="n">decode</code><code class="p">(</code><code class="s1">'UTF-8'</code><code class="p">)</code></pre>&#13;
&#13;
<p>Python encodes all characters into UT<a contenteditable="false" data-primary="UTF-8" data-type="indexterm" id="id601"/>F-8 by default. You might be tempted to leave this alone and use UTF-8 encoding for every web scraper you write. After all, UTF-8 will also handle ASCII characters as well as foreign languages smoothly. However, it’s important to remember the 9% of websites out there that use some version of ISO encoding as well, so you can never avoid this problem entirely.</p>&#13;
&#13;
<p>Unfortunately, in the case of text documents, it’s impossible to concretely determine what encoding a document has. Some libraries can examine the document and make a best guess (using a little logic to realize that “Ñ€Ð°ÑÑÐºÐ°Ð·Ñ” is probably not a word), but many times they’re wrong.</p>&#13;
&#13;
<p>Fortunately, in the case of HTML pages, the encoding is usually contained in a tag found in the <code>&lt;head&gt;</code> section of the site. Most sites, particularly English-language sites, have this tag:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">meta</code> <code class="na">charset</code><code class="o">=</code><code class="s">"utf-8"</code> <code class="p">/&gt;</code></pre>&#13;
&#13;
<p>Whereas the <a href="http://www.ecma-international.org">ECMA International’s website</a> has this tag:<sup><a data-type="noteref" href="ch10.html#id602" id="id602-marker">3</a></sup></p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">META</code> <code class="na">HTTP-EQUIV</code><code class="o">=</code><code class="s">"Content-Type"</code> <code class="na">CONTENT</code><code class="o">=</code><code class="s">"text/html; charset=iso-8859-1"</code><code class="p">&gt;</code></pre>&#13;
&#13;
<p>If you plan on doing a lot of web scraping, particularly of international sites, it might be wise to look for this meta tag and use the encoding it recommends when reading the contents <a contenteditable="false" data-primary="documents, encoding" data-startref="dcmtcdg" data-type="indexterm" id="id603"/><a contenteditable="false" data-primary="encoding documents" data-startref="ecdgdm" data-type="indexterm" id="id604"/><a contenteditable="false" data-primary="text" data-secondary="encoding" data-startref="xfxcd" data-type="indexterm" id="id605"/><a contenteditable="false" data-primary="files" data-secondary="text files" data-startref="fxfxc" data-tertiary="text encoding" data-type="indexterm" id="id606"/><a contenteditable="false" data-primary="text" data-secondary="encoding" data-startref="xecngl" data-tertiary="non-English words" data-type="indexterm" id="id607"/><a contenteditable="false" data-primary="text files" data-secondary="encoding" data-startref="txfecd" data-type="indexterm" id="id608"/>of the page.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="CSV" data-type="sect1"><div class="sect1" id="id246">&#13;
<h1>CSV</h1>&#13;
&#13;
<p>When web scraping, you are likely to encounter either a CSV file or a coworker who likes data formatted in this way. Fortunately, Python has a <a href="https://docs.python.org/3.4/library/csv.html">fantastic library</a> for both reading and writing CSV files. Although this library is capable of handling many variations of CSV, this section focuses primarily on the standard format. If you have a special case you need to handle, consult the documentation!</p>&#13;
&#13;
<section data-pdf-bookmark="Reading CSV Files" data-type="sect2"><div class="sect2" id="id63">&#13;
<h2>Reading CSV Files</h2>&#13;
&#13;
<p>Python’s <em>csv</em> library is <a contenteditable="false" data-primary="CSV (comma-separated values)" data-secondary="reading files" data-type="indexterm" id="cspvrd"/><a contenteditable="false" data-primary="files" data-secondary="CSV (comma-separated values), reading" data-type="indexterm" id="flcvrd"/><a contenteditable="false" data-primary="csv library" data-type="indexterm" id="cflbrr"/><a contenteditable="false" data-primary="text" data-secondary="CSV (comma-separated values) file" data-type="indexterm" id="xxvsv"/>geared primarily toward working with local files, on the assumption that the CSV data you need is stored on your machine. Unfortunately, this isn’t always the case, especially when you’re web scraping. There are several ways to work around this:</p>&#13;
&#13;
<ul>&#13;
	<li>Download the file locally by hand and point Python at the local file location.</li>&#13;
	<li>Write a Python script to download the file, read it, and (optionally) delete it after retrieval.</li>&#13;
	<li>Retrieve the file as a string from the web, and wrap the string in a <code>StringIO</code> object so that it behaves like a file.</li>&#13;
</ul>&#13;
&#13;
<p>Although the first two options are workable, taking up hard drive space with files when you could easily keep them in memory is bad practice. It’s much better to read the file in as a string and wrap it in an object that allows Python to treat it as a file, without ever saving the file. The following script retrieves a CSV file from the internet (in this case, a list of Monty Python albums at <a href="http://pythonscraping.com/files/MontyPythonAlbums.csv"><em>http://pythonscraping.com/files/MontyPythonAlbums.csv</em></a>) and prints it, row by row, to the terminal:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">io</code> <code class="kn">import</code> <code class="n">StringIO</code>&#13;
<code class="kn">import</code> <code class="nn">csv</code>&#13;
&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/files/MontyPythonAlbums.csv'</code><code class="p">)</code>&#13;
              <code class="o">.</code><code class="n">read</code><code class="p">()</code><code class="o">.</code><code class="n">decode</code><code class="p">(</code><code class="s1">'ascii'</code><code class="p">,</code> <code class="s1">'ignore'</code><code class="p">)</code>&#13;
<code class="n">dataFile</code> <code class="o">=</code> <code class="n">StringIO</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>&#13;
<code class="n">csvReader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">reader</code><code class="p">(</code><code class="n">dataFile</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">csvReader</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">row</code><code class="p">)</code></pre>&#13;
&#13;
<p>The output looks like this:</p>&#13;
&#13;
<pre data-code-language="text" data-executable="true" data-type="programlisting">&#13;
['Name', 'Year']&#13;
["Monty Python's Flying Circus", '1970']&#13;
['Another Monty Python Record', '1971']&#13;
["Monty Python's Previous Record", '1972']&#13;
...</pre>&#13;
&#13;
<p>As you can see from the code sample, the reader object returned by <code>csv.reader</code> is iterable and composed of Python list objects. Because of this, each row in the <code>csvReader</code> object is accessible in the following way:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">csvReader</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'The album "'</code><code class="o">+</code><code class="n">row</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">+</code><code class="s1">'" was released in '</code><code class="o">+</code><code class="nb">str</code><code class="p">(</code><code class="n">row</code><code class="p">[</code><code class="mi">1</code><code class="p">]))</code></pre>&#13;
&#13;
<p>Here is the output:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
The album "Name" was released in Year&#13;
The album "Monty Python's Flying Circus" was released in 1970&#13;
The album "Another Monty Python Record" was released in 1971&#13;
The album "Monty Python's Previous Record" was released in 1972&#13;
...</pre>&#13;
&#13;
<p>Notice the first line: <code>The album "Name" was released in Year</code>. Although this might be an easy-to-ignore result when writing example code, you don’t want this getting into your data in the real world. A lesser programmer might simply skip the first row in the <code>csvReader</code> object, or write in a special case to handle it. Fortunately, an alternative to the <code>csv.reader</code> function takes care of all of this for you automatically. Enter <code>DictReader</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">io</code> <code class="kn">import</code> <code class="n">StringIO</code>&#13;
<code class="kn">import</code> <code class="nn">csv</code>&#13;
&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/files/MontyPythonAlbums.csv'</code><code class="p">)</code>&#13;
              <code class="o">.</code><code class="n">read</code><code class="p">()</code><code class="o">.</code><code class="n">decode</code><code class="p">(</code><code class="s1">'ascii'</code><code class="p">,</code> <code class="s1">'ignore'</code><code class="p">)</code>&#13;
<code class="n">dataFile</code> <code class="o">=</code> <code class="n">StringIO</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>&#13;
<code class="n">dictReader</code> <code class="o">=</code> <code class="n">csv</code><code class="o">.</code><code class="n">DictReader</code><code class="p">(</code><code class="n">dataFile</code><code class="p">)</code>&#13;
&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">dictReader</code><code class="o">.</code><code class="n">fieldnames</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">row</code> <code class="ow">in</code> <code class="n">dictReader</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">row</code><code class="p">)</code></pre>&#13;
&#13;
<p><code>csv.DictReader</code> returns the values of each row in the CSV file as dictionary objects rather than list objects, with field names stored in the variable <code>dictReader.fieldnames</code> and as keys in each dictionary object:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
['Name', 'Year']&#13;
{'Name': 'Monty Python's Flying Circus', 'Year': '1970'}&#13;
{'Name': 'Another Monty Python Record', 'Year': '1971'}&#13;
{'Name': 'Monty Python's Previous Record', 'Year': '1972'}</pre>&#13;
&#13;
<p>The downside, of course, is that it takes slightly longer to create, process, and print these <code>DictReader</code> objects as opposed to <code>csvReader</code>, but the convenience and usability are often worth the additional overhead. Also keep in mind that, when it comes to web scraping, the overhead required for requesting and retrieving website data from an external server will almost always be the unavoidable limiting <a contenteditable="false" data-primary="CSV (comma-separated values)" data-secondary="reading files" data-startref="cspvrd" data-type="indexterm" id="id609"/><a contenteditable="false" data-primary="files" data-secondary="CSV (comma-separated values), reading" data-startref="flcvrd" data-type="indexterm" id="id610"/><a contenteditable="false" data-primary="csv library" data-startref="cflbrr" data-type="indexterm" id="id611"/><a contenteditable="false" data-primary="text" data-secondary="CSV (comma-separated values) file" data-startref="xxvsv" data-type="indexterm" id="id612"/>factor in any program you write, so worrying about which technique might shave microseconds off your total runtime is often a moot point!</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="PDF" data-type="sect1"><div class="sect1" id="id64">&#13;
<h1>PDF</h1>&#13;
&#13;
<p>As a Linux user, I know the pain of being sent a <em>.docx</em> file that my non-Microsoft software mangles, and struggling <a contenteditable="false" data-primary="text" data-secondary="PDF files" data-type="indexterm" id="txtpdff"/><a contenteditable="false" data-primary="PDF files" data-type="indexterm" id="pdffls"/>trying to find the codecs to interpret some new Apple media format. In some ways, Adobe was revolutionary in creating its Portable Document Format in 1993. PDFs allowed users on different platforms to view image and text documents in exactly the same way, regardless of the platform they were viewing it on.</p>&#13;
&#13;
<p>Although storing PDFs on the web is somewhat passé (why store content in a static, slow-loading format when you could write it up as HTML?), PDFs remain ubiquitous, particularly when dealing with official forms and filings.</p>&#13;
&#13;
<p>In 2009, a Briton named Nick Innes made the news when he requested public student test result information from the Buckinghamshire City Council, which was available under the United Kingdom’s version of the Freedom of Information Act. After some repeated requests and denials, he finally received the information he was looking <span class="keep-together">for—in</span> the form of 184 PDF documents.</p>&#13;
&#13;
<p>Although Innes persisted and eventually received a more properly formatted database, had he been an expert web scraper, he likely could have saved himself a lot of time in the courts and used the PDF documents <a contenteditable="false" data-primary="Python" data-secondary="PDF parsing" data-type="indexterm" id="id613"/>directly, with one of Python’s many PDF-parsing modules.</p>&#13;
&#13;
<p>Unfortunately, because the PDF is a relatively simple and open source document format, the space is crowded when it comes to PDF-parsing libraries. These projects are commonly built, abandoned, revived, and built again as the years go by. The most popular, full-featured, and easy-to-use library is currently <a href="https://pypi.org/project/pypdf/">pypdf</a>.</p>&#13;
&#13;
<p>Pypdf is a free, open source <a contenteditable="false" data-primary="Pypdf" data-type="indexterm" id="id614"/>library that allows users to extract text and images from PDFs. It will also allow you to perform operations on PDF files and generate them directly from Python if you want to make them rather than just read them.</p>&#13;
&#13;
<p>You can install as usual using pip:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>pypdf<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>The documentation is located at <a href="https://pypdf.readthedocs.io/en/latest/index.html"><em>https://pypdf.readthedocs.io/en/latest/index.html</em></a>.</p>&#13;
&#13;
<p>Here is a basic implementation that allows you to read arbitrary PDFs to a string, given a local file object:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlretrieve</code>&#13;
<code class="kn">from</code> <code class="nn">pypdf</code> <code class="kn">import</code> <code class="n">PdfReader</code>&#13;
&#13;
<code class="n">urlretrieve</code><code class="p">(</code>&#13;
    <code class="s1">'http://pythonscraping.com/pages/warandpeace/chapter1.pdf'</code><code class="p">,</code>&#13;
    <code class="s1">'chapter1.pdf'</code>&#13;
<code class="p">)</code>&#13;
<code class="n">reader</code> <code class="o">=</code> <code class="n">PdfReader</code><code class="p">(</code><code class="s1">'chapter1.pdf'</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">page</code> <code class="ow">in</code> <code class="n">reader</code><code class="o">.</code><code class="n">pages</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">page</code><code class="o">.</code><code class="n">extract_text</code><code class="p">())</code>&#13;
</pre>&#13;
&#13;
<p>This gives the familiar plain-text output:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
CHAPTER I&#13;
&#13;
"Well, Prince, so Genoa and Lucca are now just family estates of&#13;
the Buonapartes. But I warn you, if you don't tell me that this&#13;
means war, if you still try to defend the infamies and horrors&#13;
perpetrated by that Antichrist- I really believe he is Antichrist- I will &#13;
</pre>&#13;
&#13;
<p>Note that the PDF file argument must be an actual file object. You must download the file first locally before you can pass it to the <code>Pdfreader</code> class. However, if you’re processing large numbers of PDF files and don’t want to keep the original files around, you can always overwrite the previous file by sending the same filename to <code class="keep-together">urlretrieve</code> after you’ve extracted the text.</p>&#13;
&#13;
<p>The output from pypdf might not be perfect, especially for PDFs with images, oddly formatted text, or text arranged in tables or charts. However, for most text-only PDFs, the output should be no <a contenteditable="false" data-primary="text" data-secondary="PDF files" data-startref="txtpdff" data-type="indexterm" id="id615"/><a contenteditable="false" data-primary="PDF files" data-startref="pdffls" data-type="indexterm" id="id616"/>different than if the PDF were a text file.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Microsoft Word and .docx" data-type="sect1"><div class="sect1" id="id65">&#13;
<h1 class="pagebreak-before">Microsoft Word and .docx</h1>&#13;
&#13;
<p>At the risk of offending my friends at Microsoft: I do not like Microsoft Word. Not because it’s necessarily a bad <a contenteditable="false" data-primary="text" data-secondary="Word (Microsoft)" data-type="indexterm" id="txwcs"/><a contenteditable="false" data-primary="Word (Microsoft)" data-type="indexterm" id="wrdmcf"/><a contenteditable="false" data-primary="Microsoft Word" data-type="indexterm" id="msfwd"/><a contenteditable="false" data-primary=".docx files (Microsoft Word)" data-primary-sortas="docx files" data-type="indexterm" id="dcsfl"/>piece of software, but because of the way its users misuse it. It has a particular talent for turning what should be simple text documents or PDFs into large, slow, difficult-to-open beasts that often lose all formatting from machine to machine, and are, for whatever reason, editable when the content is often meant to be static.</p>&#13;
&#13;
<p>Word files are designed for content creation, not content sharing. Nevertheless, they are ubiquitous on certain sites, containing important documents, information, and even charts and multimedia; in short, everything that can and should be created with HTML.</p>&#13;
&#13;
<p>Before about 2008, Microsoft Office products used the proprietary <em>.doc </em>file format. This binary-file format was difficult to read and poorly supported by other word processors. In an effort to get with the times and adopt a standard that was used by many other pieces of software, Microsoft decided to use the Open Office XML-based standard, which made the files compatible with open source and other software.</p>&#13;
&#13;
<p>Unfortunately, Python’s support for this file format, used by Google Docs, Open Office, and Microsoft Office, still isn’t great. There is the <a href="http://python-docx.readthedocs.org/en/latest/">python-docx library</a>, but this only gives users the ability to create documents and read only basic file data such as the size and title of the file, not the actual contents. To read the contents of a Microsoft Office file, you’ll need to roll your own solution.</p>&#13;
&#13;
<p>The first step is to read the XML from the file:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">zipfile</code> <code class="kn">import</code> <code class="n">ZipFile</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">io</code> <code class="kn">import</code> <code class="n">BytesIO</code>&#13;
&#13;
<code class="n">wordFile</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/pages/AWordDocument.docx'</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">()</code>&#13;
<code class="n">wordFile</code> <code class="o">=</code> <code class="n">BytesIO</code><code class="p">(</code><code class="n">wordFile</code><code class="p">)</code>&#13;
<code class="n">document</code> <code class="o">=</code> <code class="n">ZipFile</code><code class="p">(</code><code class="n">wordFile</code><code class="p">)</code>&#13;
<code class="n">xml_content</code> <code class="o">=</code> <code class="n">document</code><code class="o">.</code><code class="n">read</code><code class="p">(</code><code class="s1">'word/document.xml'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">xml_content</code><code class="o">.</code><code class="n">decode</code><code class="p">(</code><code class="s1">'utf-8'</code><code class="p">))</code></pre>&#13;
&#13;
<p>This reads a remote Word document as a binary file object (<code>BytesIO</code> is analogous to <code>StringIO</code>, used earlier in this chapter), unzips it using Python’s <a contenteditable="false" data-primary="Python" data-secondary="zipfile library" data-type="indexterm" id="id617"/>core zipfile library (all <em>.docx</em> files are zipped to save space), and then reads the unzipped file, which is XML.</p>&#13;
&#13;
<p>The Word document at <a href="http://pythonscraping.com/pages/AWordDocument.docx"><em>http://pythonscraping.com/pages/AWordDocument.docx</em></a> is shown in <a data-type="xref" href="#word_website">Figure 10-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="word_website">&#13;
<img alt="" class="iimageswsp3_1002png" src="assets/wsp3_1002.png"/>&#13;
<h6><span class="label">Figure 10-2. </span>This is a Word document that’s full of content you might want very much, but it’s difficult to access because I’m putting it on my website as a <em>.docx</em> file instead of publishing it as HTML. The word “unfortunatly” is misspelled.</h6>&#13;
</div></figure>&#13;
&#13;
<p>The output of the Python script reading my simple Word document is the following:</p>&#13;
&#13;
<pre data-code-language="xml" data-type="programlisting">&#13;
<code class="nt">&lt;w:document</code><code class="w"> </code><code class="na">xmlns:wpc=</code><code class="s">"http://schemas.microsoft.com/office/word/2010/&#13;
wordprocessingCanvas"</code><code class="w"> </code><code class="na">xmlns:cx=</code><code class="s">"http://schemas.microsoft.com/office/d&#13;
rawing/2014/chartex"</code><code class="w"> </code><code class="na">xmlns:cx1=</code><code class="s">"http://schemas.microsoft.com/office/d&#13;
rawing/2015/9/8/chartex"</code><code class="w"> </code><code class="na">xmlns:cx2=</code><code class="s">"http://schemas.microsoft.com/offi&#13;
ce/drawing/2015/10/21/chartex"</code><code class="w"> </code><code class="na">xmlns:cx3=</code><code class="s">"http://schemas.microsoft.co&#13;
m/office/drawing/2016/5/9/chartex"</code><code class="w"> </code><code class="na">xmlns:cx4=</code><code class="s">"http://schemas.microsof&#13;
&#13;
</code><em><code class="s">...More schema data here...&#13;
</code></em><code class="s">&#13;
&lt;w:body&gt;&lt;w:p w14:paraId="</code><code class="err">1</code><code class="err">9</code><code class="err">A</code><code class="err">1</code><code class="err">8</code><code class="err">0</code><code class="err">2</code><code class="err">5</code><code class="err">"</code><code class="w"> </code><code class="na">w14:textId=</code><code class="s">"54C8E458"</code><code class="w"> </code><code class="na">w:rsidR=</code><code class="s">"007&#13;
45992"</code><code class="w"> </code><code class="na">w:rsidRDefault=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidP=</code><code class="s">"00BF6C9C"</code><code class="nt">&gt;</code><code class="nt">&lt;w:pPr</code><code class="nt">&gt;</code><code class="nt">&lt;w:pStyle</code><code class="w"> &#13;
</code><code class="na">w:val=</code><code class="s">"Heading1"</code><code class="nt">/&gt;</code><code class="nt">&lt;/w:pPr&gt;</code><code class="nt">&lt;w:r</code><code class="nt">&gt;</code><code class="nt">&lt;w:t</code><code class="nt">&gt;</code><code>A</code><code class="w"> </code><code>Word</code><code class="w"> </code><code>Document</code><code class="w"> </code><code>on</code><code class="w"> </code><code>a</code><code class="w"> </code><code>Website</code><code class="nt">&lt;/w:t&#13;
&gt;</code><code class="nt">&lt;/w:r&gt;</code><code class="nt">&lt;/w:p&gt;</code><code class="nt">&lt;w:p</code><code class="w"> </code><code class="na">w14:paraId=</code><code class="s">"501E7A3A"</code><code class="w"> </code><code class="na">w14:textId=</code><code class="s">"77777777"</code><code class="w"> </code><code class="na">w:rsidR&#13;
=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidRDefault=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidP=</code><code class="s">"00BF6C9C"</code><code class="nt">/&gt;</code><code class="nt">&lt;w:p</code><code class="w"> </code><code class="err">w</code><code class="err">1</code><code class="err">4</code><code class="err">:</code><code class="err">p</code><code class="err">a</code><code class="w">&#13;
</code><code class="na">raId=</code><code class="s">"13929BE7"</code><code class="w"> </code><code class="na">w14:textId=</code><code class="s">"20FEDCDB"</code><code class="w"> </code><code class="na">w:rsidR=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidRPr=</code><code class="s">"0&#13;
0BF6C9C"</code><code class="w"> </code><code class="na">w:rsidRDefault=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidP=</code><code class="s">"00BF6C9C"</code><code class="nt">&gt;</code><code class="nt">&lt;w:r</code><code class="nt">&gt;</code><code class="nt">&lt;w:t</code><code class="w"> </code><code class="err">x</code><code class="err">m</code><code class="err">l</code><code class="err">:</code><code class="err">s</code><code class="w">&#13;
</code><code class="na">pace=</code><code class="s">"preserve"</code><code class="nt">&gt;</code><code>This</code><code class="w"> </code><code>is</code><code class="w"> </code><code>a</code><code class="w"> </code><code>Word</code><code class="w"> </code><code>document,</code><code class="w"> </code><code>full</code><code class="w"> </code><code>of</code><code class="w"> </code><code>content</code><code class="w"> </code><code>that</code><code class="w"> </code><code>you</code><code class="w"> </code><code>wan</code><code class="w">&#13;
</code><code>t</code><code class="w"> </code><code>very</code><code class="w"> </code><code>much.</code><code class="w"> </code><code class="nt">&lt;/w:t&gt;</code><code class="nt">&lt;/w:r&gt;</code><code class="nt">&lt;w:proofErr</code><code class="w"> </code><code class="na">w:type=</code><code class="s">"spellStart"</code><code class="nt">/&gt;</code><code class="nt">&lt;w:r</code><code class="nt">&gt;</code><code class="nt">&lt;w:t</code><code class="nt">&gt;</code><code>U</code><code class="w">&#13;
</code><code>nfortuna</code><code class="nt">&lt;/w:t&gt;</code><code class="nt">&lt;/w:r&gt;</code><code class="nt">&lt;w:r</code><code class="w"> </code><code class="na">w:rsidR=</code><code class="s">"00BC14C7"</code><code class="nt">&gt;</code><code class="nt">&lt;w:t</code><code class="nt">&gt;</code><code>t</code><code class="nt">&lt;/w:t&gt;</code><code class="nt">&lt;/w:r&gt;</code><code class="nt">&lt;w:r</code><code class="nt">&gt;</code><code class="nt">&lt;w</code><code class="w">&#13;
</code><code class="err">:</code><code class="err">t</code><code class="nt">&gt;</code><code>ly</code><code class="nt">&lt;/w:t&gt;</code><code class="nt">&lt;/w:r&gt;</code><code class="nt">&lt;w:proofErr</code><code class="w"> </code><code class="na">w:type=</code><code class="s">"spellEnd"</code><code class="nt">/&gt;</code><code class="nt">&lt;w:r</code><code class="nt">&gt;</code><code class="nt">&lt;w:t</code><code class="w"> </code><code class="na">xml:space=</code><code class="s">"&#13;
preserve"</code><code class="nt">&gt;</code><code>,</code><code class="w"> </code><code>it’s</code><code class="w"> </code><code>difficult</code><code class="w"> </code><code>to</code><code class="w"> </code><code>access</code><code class="w"> </code><code>because</code><code class="w"> </code><code>I’m</code><code class="w"> </code><code>putting</code><code class="w"> </code><code>it</code><code class="w"> </code><code>on</code><code class="w"> </code><code>my</code><code class="w"> </code><code>web</code><code class="w">&#13;
</code><code>site</code><code class="w"> </code><code>as</code><code class="w"> </code><code>a</code><code class="w"> </code><code>.docx</code><code class="w"> </code><code>file,</code><code class="w"> </code><code>rather</code><code class="w"> </code><code>than</code><code class="w"> </code><code>just</code><code class="w"> </code><code>publishing</code><code class="w"> </code><code>it</code><code class="w"> </code><code>as</code><code class="w"> </code><code>HTML.</code><code class="w"> </code><code class="nt">&lt;/w:t&gt;</code><code class="nt">&lt;&#13;
/w:r&gt;</code><code class="nt">&lt;/w:p&gt;</code><code class="nt">&lt;w:sectPr</code><code class="w"> </code><code class="na">w:rsidR=</code><code class="s">"00BF6C9C"</code><code class="w"> </code><code class="na">w:rsidRPr=</code><code class="s">"00BF6C9C"</code><code class="nt">&gt;</code><code class="nt">&lt;w:pgSz</code><code class="w"> &#13;
</code><code class="na">w:w=</code><code class="s">"12240"</code><code class="w"> </code><code class="na">w:h=</code><code class="s">"15840"</code><code class="nt">/&gt;</code><code class="nt">&lt;w:pgMar</code><code class="w"> </code><code class="na">w:top=</code><code class="s">"1440"</code><code class="w"> </code><code class="na">w:right=</code><code class="s">"1440"</code><code class="w"> </code><code class="err">w</code><code class="err">:</code><code class="err">b</code><code class="err">o</code><code class="err">t</code><code class="err">t</code><code class="err">o</code><code class="w">&#13;
</code><code class="na">m=</code><code class="s">"1440"</code><code class="w"> </code><code class="na">w:left=</code><code class="s">"1440"</code><code class="w"> </code><code class="na">w:header=</code><code class="s">"720"</code><code class="w"> </code><code class="na">w:footer=</code><code class="s">"720"</code><code class="w"> </code><code class="na">w:gutter=</code><code class="s">"0"</code><code class="nt">/&gt;</code><code class="nt">&lt;w</code><code class="w">&#13;
</code><code class="err">:</code><code class="err">c</code><code class="err">o</code><code class="err">l</code><code class="err">s</code><code class="w"> </code><code class="na">w:space=</code><code class="s">"720"</code><code class="nt">/&gt;</code><code class="nt">&lt;w:docGrid</code><code class="w"> </code><code class="na">w:linePitch=</code><code class="s">"360"</code><code class="nt">/&gt;</code><code class="nt">&lt;/w:sectPr&gt;</code><code class="err">&lt;</code><code>/w:bod</code><code class="w">&#13;
</code><code>y&gt;</code><code class="nt">&lt;/w:document&gt;</code><code class="w">&#13;
</code></pre>&#13;
&#13;
<p>There’s clearly a lot of metadata here, but the actual text content you want is buried. Fortunately, all of the text in the document, including the title at the top, is contained in <code>w:t</code> tags, which makes it easy to grab:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">zipfile</code> <code class="kn">import</code> <code class="n">ZipFile</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">io</code> <code class="kn">import</code> <code class="n">BytesIO</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">wordFile</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/pages/AWordDocument.docx'</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">()</code>&#13;
<code class="n">wordFile</code> <code class="o">=</code> <code class="n">BytesIO</code><code class="p">(</code><code class="n">wordFile</code><code class="p">)</code>&#13;
<code class="n">document</code> <code class="o">=</code> <code class="n">ZipFile</code><code class="p">(</code><code class="n">wordFile</code><code class="p">)</code>&#13;
<code class="n">xml_content</code> <code class="o">=</code> <code class="n">document</code><code class="o">.</code><code class="n">read</code><code class="p">(</code><code class="s1">'word/document.xml'</code><code class="p">)</code>&#13;
&#13;
<code class="n">wordObj</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">xml_content</code><code class="o">.</code><code class="n">decode</code><code class="p">(</code><code class="s1">'utf-8'</code><code class="p">),</code> <code class="s1">'xml'</code><code class="p">)</code>&#13;
<code class="n">textStrings</code> <code class="o">=</code> <code class="n">wordObj</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'w:t'</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">textElem</code> <code class="ow">in</code> <code class="n">textStrings</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">textElem</code><code class="o">.</code><code class="n">text</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Note that instead of the <em>html.parser</em> parser that you normally use with <code>BeautifulSoup</code>, you’re passing it the <em>xml</em> parser. This is because colons are nonstandard in HTML tag names like <code>w:t</code>, and <em>html.parser</em> does not recognize them.</p>&#13;
&#13;
<p>The output isn’t perfect but it’s getting there, and printing each <code>w:t</code> tag on a new line makes it easy to see how Word is splitting up the text:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
A Word Document on a Website&#13;
This is a Word document, full of content that you want very much.&#13;
Unfortuna&#13;
t&#13;
ly&#13;
, it’s difficult to access because I’m putting it on my website as &#13;
a .docx file, rather than just publishing it as HTML.&#13;
</pre>&#13;
&#13;
<p>Notice that the word “unfortunatly” is split up across multiple lines. In the original XML, it is surrounded with the tag <code>&lt;w:proofErr w:type="spellStart"/&gt;</code>. This is how Word highlights the misspelling with a red squiggly underline.</p>&#13;
&#13;
<p>The title of the document is preceded by the style descriptor tag <code>&lt;w:pstyle w:val="Title"&gt;</code>. Although this doesn’t make it extremely easy for us to identify titles (or other styled text) as such, using BeautifulSoup’s navigation features can be useful:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">textStrings</code> <code class="o">=</code> <code class="n">wordObj</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'w:t'</code><code class="p">)</code>&#13;
&#13;
<code class="k">for</code> <code class="n">textElem</code> <code class="ow">in</code> <code class="n">textStrings</code><code class="p">:</code>&#13;
    <code class="n">style</code> <code class="o">=</code> <code class="n">textElem</code><code class="o">.</code><code class="n">parent</code><code class="o">.</code><code class="n">parent</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'w:pStyle'</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="n">style</code> <code class="ow">is</code> <code class="ow">not</code> <code class="kc">None</code> <code class="ow">and</code> <code class="n">style</code><code class="p">[</code><code class="s1">'w:val'</code><code class="p">]</code> <code class="o">==</code> <code class="s1">'Title'</code><code class="p">:</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="s1">'Title is: </code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">textElem</code><code class="o">.</code><code class="n">text</code><code class="p">))</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="n">textElem</code><code class="o">.</code><code class="n">text</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>This function easily can be expanded to print tags <a contenteditable="false" data-primary="text" data-secondary="Word (Microsoft)" data-startref="txwcs" data-type="indexterm" id="id618"/><a contenteditable="false" data-primary="Word (Microsoft)" data-startref="wrdmcf" data-type="indexterm" id="id619"/><a contenteditable="false" data-primary="Microsoft Word" data-startref="msfwd" data-type="indexterm" id="id620"/><a contenteditable="false" data-primary=".docx files (Microsoft Word)" data-primary-sortas="docx files" data-startref="dcsfl" data-type="indexterm" id="id621"/>around a variety of text styles or label them in some other way.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id592"><sup><a href="ch10.html#id592-marker">1</a></sup> This “padding” bit will come back to haunt us with the ISO standards a little later.</p><p data-type="footnote" id="id598"><sup><a href="ch10.html#id598-marker">2</a></sup> According to <a href="https://w3techs.com/technologies/history_overview/character_encoding">W3Techs</a>, which uses web crawlers to gather these sorts of statistics.</p><p data-type="footnote" id="id602"><sup><a href="ch10.html#id602-marker">3</a></sup> ECMA was one of the original contributors to the ISO standard, so it’s no surprise its website is encoded with a flavor of ISO.</p></div></div></section></body></html>