- en: Appendix A. Key System Concepts for Dask Users
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录A. Dask用户的关键系统概念
- en: We’ve covered a few distributed system concepts briefly as needed in this book,
    but as you get ready to head out on your own, it’s a good idea to review some
    of the core concepts that Dask is built on. In this appendix, you will learn more
    about the key principles used in Dask and how they impact the code you write on
    top of Dask.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们根据需要简要介绍了一些分布式系统概念，但是当你准备独立进行工作时，复习一些Dask构建在其上的核心概念是一个好主意。在这个附录中，你将更多地了解Dask中使用的关键原则，以及它们如何影响你在Dask之上编写的代码。
- en: Testing
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试
- en: Testing is an often overlooked part of data science and data engineering. Some
    of our tools, like SQL and Jupyter notebooks, do not encourage testing or make
    it easy to test—but this does not absolve us of the responsibility to test our
    code. Data privacy concerns can add another layer of challenge, where we don’t
    want to store user data for testing, requiring us to put in the effort to create
    “fake” data for testing or break our code down into testable components where
    we don’t need user data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 测试通常是数据科学和数据工程中经常被忽视的一部分。我们的一些工具，如SQL和Jupyter笔记本，不鼓励测试或者使得测试变得容易——但这并不免除我们测试代码的责任。数据隐私问题可能会增加另一层挑战，我们不希望为测试而存储用户数据，这就要求我们努力创建“虚假”数据进行测试，或者将我们的代码分解为可测试的组件，这些组件不需要用户数据。
- en: Manual Testing
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动测试
- en: We often perform some kind of manual testing while writing software or data
    tools. This can include simply running the tool and eyeballing the results to
    see if they look reasonable. Manual testing is time-consuming and not automatically
    repeatable, so while it is great during development, it is insufficient for long-lived
    projects.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在编写软件或数据工具时经常进行某种形式的手动测试。这可以包括简单地运行工具并眼睛观察结果，看看它们是否合理。手动测试很耗时，而且不会自动重复，所以虽然在开发过程中很棒，但对于长期项目来说是不够的。
- en: Unit Testing
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单元测试
- en: Unit testing refers to testing individual units of code rather than the whole
    system together. This requires having your code be composed in different units,
    like modules or functions. While this is less common with notebooks, we believe
    that structuring your code for testability is a good practice to follow.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试指的是测试单个代码单元，而不是整个系统一起测试。这要求你的代码被组织成不同的单元，如模块或函数。虽然在笔记本上这种做法较少见，但我们认为为了可测试性而结构化你的代码是一个好的实践。
- en: Writing unit tests for notebooks can be challenging; doctests are slightly easier
    to inline within a notebook. If you want to use traditional unit test libraries,
    the [ipython-unittest magics](https://oreil.ly/yUxXy) let you inline your unit
    tests within your notebook.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为笔记本编写单元测试可能会很有挑战；文档测试在笔记本中稍微更容易内联。如果你想使用传统的单元测试库，[ipython-unittest magics](https://oreil.ly/yUxXy)可以让你在笔记本中内联你的单元测试。
- en: Integration Testing
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成测试
- en: Integration testing refers to testing how different parts of a system work together.
    It is often much closer to the real usage of your code, but it can be more complicated,
    as it involves setting up other systems to test against. You can (to an extent)
    use some of the same libraries for integration testing, but these tests tend to
    involve more setup and teardown work.^([1](app01.xhtml#id978)) Integration testing
    is also more likely to be “flaky,” since making sure that all of the different
    components your software needs are present in your test environment before starting
    the tests can be challenging.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试指的是测试系统的不同部分如何一起工作。它通常更接近于代码的实际使用情况，但也可能更复杂，因为它涉及设置其他系统来进行测试。你可以在一定程度上使用一些相同的库进行集成测试，但这些测试往往需要更多的设置和拆卸工作。^([1](app01.xhtml#id978))
    集成测试也更容易出现“不稳定”，因为在开始测试之前确保你的软件需要的所有不同组件在测试环境中都存在是具有挑战性的。
- en: Test-Driven Development
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试驱动开发
- en: Test-driven development involves taking the requirements or expectations of
    your code and writing tests and then writing the code after. For data science
    pipelines this can often be done by creating a sample input (sometimes called
    a golden set) and writing out what you expect the output to be. Test-driven development
    can be complicated, especially when integrating multiple data sources.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 测试驱动开发涉及根据代码的需求或期望编写测试，然后再编写代码。对于数据科学管道来说，这通常可以通过创建样本输入（有时称为黄金集）来完成，并写出你期望的输出。测试驱动开发可能会很复杂，特别是当集成多个数据源时。
- en: While you don’t need to use test-driven development, we believe it’s important
    to make tests alongside the development of your data pipelines. Tests added after
    development are better than no tests, but in our experience the context you have
    during the development helps you create better tests (and validate your assumptions
    early on).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您不需要使用测试驱动开发，但我们认为在开发数据流水线的同时进行测试非常重要。事后添加的测试总比没有测试好，但根据我们的经验，在开发过程中您拥有的上下文帮助您更好地创建测试（并且尽早验证您的假设）。
- en: Property Testing
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 属性测试
- en: Property testing is a potentially great solution to the challenge of coming
    up with test data that covers all of the edge cases in terms of data that your
    code could trip up on. Instead of writing the traditional “for input A, result
    B is expected,” you specify properties, like “if we have 0 customers, we should
    have 0 sales” or “all (valid) customers should have a fraud score after this pipeline.”
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 属性测试可能是应对数据测试挑战的一个潜在的很好的解决方案，该解决方案涵盖了您的代码可能会出错的所有边缘情况的测试数据。与编写传统的“对于输入A，预期结果B”的方法不同，您可以指定属性，比如“如果我们有0个顾客，我们应该有0笔销售”或者“所有（有效的）顾客在此流水线后应该有欺诈评分”。
- en: '[Hypothesis](https://oreil.ly/zQhnh) is the most popular library for property
    testing in Python.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hypothesis](https://oreil.ly/zQhnh) 是Python中最流行的属性测试库。'
- en: Working with Notebooks
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用笔记本
- en: Testing notebooks is painful, which is unfortunate given their immense popularity.
    Generally, you can either have your testing outside of the notebook, which allows
    you the use of existing Python testing libraries, or try to put it inside the
    notebook.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 测试笔记本是令人痛苦的，尽管它们极其受欢迎。一般来说，您可以选择在笔记本外进行测试，这样可以使用现有的Python测试库，或者尝试将测试放在笔记本内部。
- en: Out-of-Notebook Testing
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外部笔记本测试
- en: The traditional option (besides ignoring testing) is to refactor the parts of
    your code you want to test into separate regular Python files and test those using
    normal testing libraries. While the partial refactoring can be painful, rewriting
    to more testable components can bring benefits to debugging as well.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了忽略测试之外，传统选项是将您想要测试的代码部分重构为单独的常规Python文件，并使用正常的测试库对其进行测试。虽然部分重构可能会很痛苦，但将代码重写为更易测试的组件也可以带来调试的好处。
- en: The [testbook project](https://oreil.ly/3_YsK) is an alternative to refactoring
    that takes an interesting approach, allowing you to write your tests outside of
    your notebook, and not requiring you to give up on notebooks. Instead, you use
    the libraries decorator to annotate tests—for example, `@testbook('untitled_7.ipynb',
    execute=True)` will import and execute the notebook before executing the test.
    You can also control which parts of the notebook are executed, but this partial
    execution can be brittle and prone to breakage on updates.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[testbook项目](https://oreil.ly/3_YsK) 是重构的一种替代方法，采用了一种有趣的方法，允许您在笔记本外编写测试，而无需放弃笔记本。相反，您可以使用库装饰器来注释测试，例如，`@testbook(''untitled_7.ipynb'',
    execute=True)` 将在执行测试之前导入和执行笔记本。您还可以控制执行笔记本的哪些部分，但是这种部分执行可能在更新时很脆弱并容易中断。'
- en: 'In-Notebook Testing: In-Line Assertions'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记本内测试：内联断言
- en: Some people like to use in-line assertions in their notebooks as a form of testing.
    In this case, if something fails (e.g., the assertion that there should be some
    customers), the rest of the notebook will not run. While we think that having
    in-line assertions is great, we don’t believe it is a replacement for traditional
    testing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人喜欢在笔记本中使用内联断言作为测试的一种形式。在这种情况下，如果某些断言失败（例如，断言应该有一些顾客），那么笔记本的其余部分将不会运行。虽然我们认为使用内联断言很棒，但我们不认为它能替代传统的测试方法。
- en: Data and Output Validation
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据和输出验证
- en: While good testing can catch many problems, sometimes the real world is more
    creative than we can ever be, and our code will still fail. In many situations,
    the worst case is that our program fails and produces an incorrect output that
    we don’t know is incorrect, and then we (or others) take action based on its results.
    Validation attempts to notify us when our job has failed so that we can take action
    on it before someone else does. In many ways, it is like running spell-check on
    a term paper before submission—if there are a few errors, OK, but if everything
    is red, it’s probably good to double-check. Depending on what your job does, validating
    it will be different.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然良好的测试可以捕捉到许多问题，但有时现实世界比我们想象的更有创造力，我们的代码仍然会失败。在许多情况下，最糟糕的情况是我们的程序失败并生成一个我们不知道是错误的不正确输出，然后我们（或其他人）根据其结果采取行动。验证试图在我们的作业失败时通知我们，以便我们在其他人之前采取行动。在许多方面，这就像在提交学期论文之前运行拼写检查一样——如果有几个错误，那么好，但如果一切都是红色，最好再检查一遍。根据您的工作内容，验证它的方法会有所不同。
- en: There are a number of different tools you can use to validate the output of
    your Dask job, including of course Dask itself. Some tools, like [TFX’s data validation](https://oreil.ly/Vfb1Z),
    attempt to compare previous versions for statistical similarity and schema changes.^([2](app01.xhtml#id992))
    [Pydantic](https://oreil.ly/RN8aI) is relatively new, but it has Dask integration
    and does excellent type and schema validation. You can also do more complex statistical
    assertions using its Hypothesis component (which is different from Python’s Hypothesis).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的工具可以用来验证您的 Dask 作业的输出，当然包括 Dask 本身。一些工具，如 [TFX 的数据验证](https://oreil.ly/Vfb1Z)，尝试比较先前版本的统计相似性和模式更改[^2]。[Pydantic](https://oreil.ly/RN8aI)
    相对较新，但它具有 Dask 集成并且进行了出色的类型和模式验证。您还可以使用其假设组件进行更复杂的统计断言（这与 Python 的假设不同）。
- en: ML models can be more difficult to validate without impacting users, but statistical
    techniques can still help (as can incremental deployments). Since ML models are
    produced from data, a good (partial) step can be validating the data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型在不影响用户的情况下更难验证，但统计技术仍然可以帮助（增量部署也可以）。由于机器学习模型是由数据生成的，验证数据是一个良好（部分）的步骤。
- en: It is useful to think of what the implications could be of your pipeline failing.
    For example, you might want to spend more time validating a pipeline that determines
    dosages of medicine in a clinical trial, compared to a job that predicts which
    version of your ad will be the most successful.^([3](app01.xhtml#id995))
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 想想你的管道失败可能会带来什么影响是有用的。例如，你可能希望花更多时间验证一个管道，该管道决定临床试验中药物剂量，而不是预测哪个广告版本最成功[^3]。
- en: Peer-to-Peer Versus Centralized Distributed
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Peer-to-Peer Versus Centralized Distributed
- en: Even inside of a distributed system, there are various levels of “distributed.”
    Dask is a centralized distributed system, where there is a static leader node
    responsible for various tasks and coordination among the workers. In more distributed
    systems, there is no static leader node, and if the head node goes away, the remaining
    peers can elect a new head node, like with ZooKeeper. In even more distributed
    systems, there is no head node distinction, and all of the nodes in the cluster
    are effectively equally capable (from a software point of view; the hardware may
    be different).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在分布式系统内部，也存在各种级别的“分布式”。Dask 是一个集中式分布式系统，其中有一个静态领导节点负责各种任务和协调工作人员之间的工作。在更分布式的系统中，没有静态领导节点，如果主节点消失，剩余的对等节点可以选举一个新的主节点，就像使用
    ZooKeeper 一样。在更分布式的系统中，没有主节点的区别，集群中的所有节点在软件上（硬件可能不同）都是同等能力的。
- en: Centralized distributed systems tend to be faster, while encountering limitations
    earlier in terms of scaling and challenges around the failure of the centralized
    component.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 集中式分布式系统倾向于更快，但在扩展方面遇到早期限制，并且在集中组件失败的挑战方面也有所挑战。
- en: Methods of Parallelism
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行方法
- en: There are many different ways to split up our work, and in this book we’ve mostly
    looked at task and data parallelism.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多不同的方法来分解我们的工作，在本书中，我们主要讨论了任务并行和数据并行。
- en: Task Parallelism
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务并行
- en: '`dask.delayed` and Python’s multi-processing both represent task parallelism.
    With task parallelism, you are not limited to executing the same code. Task parallelism
    offers the most flexibility but requires more changes to your code to take advan­tage of
    it.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`dask.delayed` 和 Python 的多进程都代表了任务并行。通过任务并行，您不受限于执行相同的代码。任务并行提供了最大的灵活性，但需要更多的代码更改来充分利用它。'
- en: Data Parallelism
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据并行
- en: Data parallelism refers to taking the same operation and running it in parallel
    on different chunks (or partitions) of data. This is a wonderful technique for
    operations on DataFrames and arrays. Data parallelism depends on partitioning
    to split up the work. We cover partitioning in detail in [Chapter 4](ch04.xhtml#ch04).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行指的是对不同数据块（或分区）上的相同操作进行并行运行。这是一种在DataFrame和数组上操作的优秀技术。数据并行依赖于分区来分割工作。我们在[第四章](ch04.xhtml#ch04)详细介绍了分区。
- en: Shuffles and narrow versus wide transformations
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 洗牌和窄与宽转换
- en: '*Narrow* transformations (or data parallelism without any aggregation or shuffle)
    are often much faster than *wide* transformations, which involve shuffles or aggregations.
    While this terminology is borrowed from the Spark community, the distinction (and
    implications for fault tolerance) applies to Dask’s data-parallel operations as
    well.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*窄* 转换（或没有任何聚合或洗牌的数据并行）通常比*宽* 转换快得多，后者涉及洗牌或聚合。虽然这个术语借用自Spark社区，但区分（及其对容错性的影响）同样适用于Dask的数据并行操作。'
- en: Limitations
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 限制
- en: Data parallelism is not well suited to many different kinds of work. Even when
    working on data problems, it is not as well suited to doing many different things
    (non-uniform computation). Data parallelism is often poorly suited to computation
    on small amounts of data—for example, model serving where you may need to evaluate
    a single request at a time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行不太适合各种不同类型的工作。即使在处理数据问题时，也不适合执行多种不同的操作（非均匀计算）。数据并行通常不适合处理少量数据的计算，例如模型服务，可能需要逐个评估单个请求。
- en: Load Balancing
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载均衡
- en: Load balancing is another way of looking at parallelism where a system (or systems)
    routes the requests (or tasks) to different servers. Load balancing can range
    from basic, like round-robin, to “smart,” taking advantage of information about
    the relative load, resources, and data on the workers/servers to schedule the
    task. The more complex the load balancing is, the more work the load balancer
    has to do. In Dask all of this load balancing is handled centrally, which requires
    that the head node has a relatively complete view of most workers’ state to intelligently
    assign tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡是并行性的另一种视角，系统（或系统）将请求（或任务）路由到不同的服务器。负载均衡的范围从基本的轮询到“智能”负载均衡，利用关于相对负载、资源和工作服务器/服务器上数据的信息来调度任务。负载均衡越复杂，负载平衡器的工作量就越大。在Dask中，所有这些负载均衡都由中心处理，这要求主节点相对完整地查看大多数工作节点的状态以智能地分配任务。
- en: The other extreme is “simple” load balancing, where some systems, like DNS round-robin-based
    load balancing (not used in Dask), do not have any information about the system
    loads and just pick the “next” node. When tasks (or requests) are roughly equal
    in complexity, round-robin-based load balancing can work well. This technique
    is most often used for handling web requests or external API requests where you
    don’t have a lot of control over the client making the requests. You are most
    likely to see this in model serving, like translating text or predicting fraudulent
    transactions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个极端是“简单”的负载均衡，例如某些系统，如基于DNS轮询的负载均衡（Dask未使用），没有任何关于系统负载的信息，只是选择“下一个”节点。当任务（或请求）在复杂性上大致相等时，基于轮询的负载均衡可以很好地工作。这种技术最常用于处理Web请求或外部API请求，其中您无法完全控制进行请求的客户端。您最有可能在模型服务中看到这一点，例如翻译文本或预测欺诈交易。
- en: Network Fault Tolerance and CAP Theorem
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络容错和CAP定理
- en: If you search for “distributed computing concepts,” you will likely come across
    the CAP theorem. The CAP theorem is most relevant for distributed data stores,
    but it’s useful to understand regardless. The theorem states that we cannot build
    a distributed system that is consistent, available, and partition-tolerant. Partitions
    can occur from hardware failure or, more commonly, from overloaded network links.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您搜索“分布式计算概念”，您可能会遇到CAP定理。CAP定理对于分布式数据存储最为相关，但无论如何理解它都是有用的。该定理指出，我们无法构建一个既一致（Consistent）、可用（Available）、又分区容忍（Partition-tolerant）的分布式系统。分区可能由硬件故障或更常见的是由于过载的网络链路引起。
- en: Dask itself has already made the trade-off of not being partition-tolerant;
    whichever side of a network partition has the “leader” is the side that continues
    on, and the other side is unable to progress.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Dask本身已经做出了不支持容错分区的折衷；网络分区的任一一侧拥有“领导者”，则该侧将继续运行，而另一侧则无法进展。
- en: It’s important to understand how this applies to the resources that you are
    accessing from Dask. For example, you may find yourself in a case in which a network
    partition means that Dask is unable to write its output. Or—even worse, in our
    opinion—it can result in situations in which the data you store from Dask is discarded.^([4](app01.xhtml#id1017))
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这如何应用于您从Dask访问的资源是很重要的。例如，您可能会发现自己处于一种情况中，即网络分区意味着Dask无法写入其输出。或者更糟糕的是，在我们看来，它可能导致您从Dask存储的数据被丢弃。^([4](app01.xhtml#id1017))
- en: The [Jepsen project](https://jepsen.io), by Kyle Kingsbury, is one of the best
    projects that we know of for testing distributed storage and query systems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由Kyle Kingsbury创建的[Jepsen项目](https://jepsen.io)是我们所知的用于测试分布式存储和查询系统的最佳项目之一。
- en: Recursion (Tail and Otherwise)
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归（尾递归和其他）
- en: Recursion refers to functions that call themselves (either directly or indirectly).
    When it’s indirect, it’s called *co-recursion*, and recursive functions that return
    the final value are called *tail-recursive*.^([5](app01.xhtml#id1019)) Tail-recursive
    functions are similar to loops, and sometimes the language can translate tail-recursive
    calls into loops or maps.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 递归是指调用自身的函数（直接或间接）。当它是间接的时候，被称为*co-recursion*，而返回最终值的递归函数被称为*tail-recursive*。^([5](app01.xhtml#id1019))
    尾递归函数类似于循环，有时语言可以将尾递归调用转换为循环或映射。
- en: Recursive functions are sometimes avoided in languages that cannot optimize
    them, since there is overhead to calling a function. Instead, users will try to
    express the recursive logic using loops.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会避免在无法优化递归的语言中使用递归函数，因为调用函数会有开销。相反，用户会尝试使用循环表达递归逻辑。
- en: Excessive non-optimized recursion can result in a stack overflow error. In C,
    Java, C++, and more, stack memory is allocated separately from the main memory
    (also called heap memory). In Python, the amount of recursion is controlled by
    `set​recur⁠sionlimit`. Python provides a [tail-recursive annotation](https://oreil.ly/QTHYz)
    that you can use to help optimize these recursive calls.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 过度的非优化递归可能导致堆栈溢出错误。在C、Java、C++等语言中，堆栈内存与主内存（也称为堆内存）分开分配。在Python中，递归的数量由`set​recur⁠sionlimit`控制。Python提供了一个[tail-recursive
    annotation](https://oreil.ly/QTHYz)，您可以使用它来帮助优化这些递归调用。
- en: In Dask, while recursive calls don’t have the exact same stack problem, excessive
    recursion can be one of the causes of load on the head node. This is because scheduling
    the recursive call must pass through the head node, and the excessive number of
    recursive functions will cause Dask’s scheduler to slow down long before any stack
    size issues are countered.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在Dask中，虽然递归调用没有完全相同的堆栈问题，但过度递归可能是头节点负载的原因之一。这是因为调度递归调用必须经过头节点，并且过多的递归函数会导致Dask的调度器在遇到任何堆栈大小问题之前变慢。
- en: 'Versioning and Branching: Code and Data'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 版本控制和分支：代码和数据
- en: Versioning is an important computer science concept, and it can be applied to
    both code and data. Ideally, versioning makes it easy to undo errors and go back
    to earlier versions or explore multiple directions simultaneously. Many of the
    items we produce are a combination of both our code and our data; to truly meet
    the goal of being able to quickly roll back and support experimentation, you will
    want to have versioning for both your code and your data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制是一个重要的计算机科学概念，它可以应用于代码和数据。理想情况下，版本控制使得很容易撤销错误并返回到早期版本或同时探索多个方向。我们生产的许多物品都是我们的代码和数据的结合；为了真正实现快速回滚和支持实验的目标，您将希望对代码和数据都进行版本控制。
- en: Version control tools for source code have existed for a long time. For code,
    [Git](https://git-scm.com) has become the most popular open source version control
    system in usage, overtaking tools such as Subversion, Concurrent Version Systems,
    and many others.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码的版本控制工具已经存在很长时间。对于代码来说，[Git](https://git-scm.com)已经成为使用最广泛的开源版本控制系统，超过了诸如Subversion、Concurrent
    Version Systems等工具。
- en: While understanding Git thoroughly can be very complicated,^([6](app01.xhtml#id1022))
    for common usage there are a few [core commands](https://oreil.ly/ZYBJM) that
    often see you through. Teaching Git is beyond the scope of this appendix, but
    there are a great many resources, including [*Head First Git*](https://learning.oreilly.com/library/view/head-first-git/9781492092506/)
    by Raju Gandhi (O’Reilly) and *Oh Shit, Git!* by Julia Evans, as well as free
    online resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深入理解 Git 可能非常复杂，^([6](app01.xhtml#id1022)) 但对于常见用法，有几个 [核心命令](https://oreil.ly/ZYBJM)
    经常能帮助你解决问题。本附录不涵盖 Git 的教学内容，但有许多资源可供参考，包括 Raju Gandhi（O'Reilly）的 [*Head First
    Git*](https://learning.oreilly.com/library/view/head-first-git/9781492092506/)
    和 Julia Evans 的 *Oh Shit, Git!*，还有免费的在线资源。
- en: Unfortunately, software version control tools don’t currently have the best
    notebook integration experience and often require additional tools like [ReviewNB](https://www.reviewnb.com)
    to make the changes understandable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，软件版本控制工具目前的笔记本集成体验并不是最佳的，通常需要额外的工具，比如 [ReviewNB](https://www.reviewnb.com)，以便更好地理解变更。
- en: Now, a natural question is, can you use the same tools for versioning your data
    as your software? Sometimes you can—provided that your data is small enough and
    does not contain any personal information, using source control on data can be
    OK. However, software tends to be stored in text and is normally relatively smaller
    than your data, and many of the source control tools do not work well when files
    start to exceed even a few dozen MBs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一个自然的问题是，你能否使用相同的工具对数据进行版本控制，就像你对软件做的那样？有时候可以——只要你的数据足够小并且不包含任何个人信息，使用源代码控制对数据进行管理是可以接受的。然而，软件通常存储在文本中，通常比你的数据要小，并且在文件开始超过几十
    MB 后，许多源代码控制工具的效果并不理想。
- en: Instead, tools like [LakeFS](https://lakefs.io) add Git-like versioning semantics
    on top of existing external data stores (e.g., S3, HDFS, Iceberg, Delta).^([7](app01.xhtml#id1023))
    Another option is to make copies of your tables manually, but we find this leads
    to the familiar “-final2-really-final” problem with naming notebooks and Word
    docs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，像 [LakeFS](https://lakefs.io) 这样的工具在现有的外部数据存储（例如 S3、HDFS、Iceberg、Delta）之上添加了类似
    Git 的版本控制语义。^([7](app01.xhtml#id1023)) 另一种选择是手动复制你的表格，但我们发现这会导致命名笔记本和 Word 文档时常见的“-final2-really-final”问题。
- en: Isolation and Noisy Neighbors
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隔离和噪音邻居
- en: So far, we’ve talked about isolation in the context of being able to have your
    Python packages, but there are more kinds of isolation. Some other levels of isolation
    include CPU, GPU, memory, and network.^([8](app01.xhtml#id1025)) Many cluster
    managers do not provide full isolation—this means that if your tasks get scheduled
    on the wrong nodes, they might have bad performance. A common solution to this
    is to request the amounts of resources in-line with the full node to avoid having
    other jobs scheduled alongside your own.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了能够拥有自己的 Python 包的隔离性，但还有更多种类的隔离。一些其他层次的隔离包括 CPU、GPU、内存和网络。^([8](app01.xhtml#id1025))
    许多集群管理器并未提供完整的隔离性——这意味着如果你的任务被安排在错误的节点上，它们可能会表现出差劲的性能。解决这个问题的常见方法是按照整个节点的资源量请求资源，以避免在你自己的任务旁边安排其他任务。
- en: Strict isolation can also have downsides, especially if the isolation framework
    doesn’t support bursting. Strict isolation without bursting can result in resource
    waste, but for mission-critical workflows this is often the trade-off.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 严格的隔离也可能存在缺点，特别是如果隔离框架不支持突发性需求。严格的隔离如果没有突发性需求支持，可能会导致资源浪费，但对于关键任务工作流来说，这通常是一种权衡。
- en: Machine Fault Tolerance
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器容错
- en: Fault tolerance is a key concept in distributed computing because the more computers
    you add, the higher the probability of a fault on any given computer. In some
    smaller deployments of Dask, machine fault tolerance is not as important, so if
    you’re running Dask exclusively in local mode or on two or three computers you
    keep under your desk, you might be OK to skip this section.^([9](app01.xhtml#id1028))
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 容错是分布式计算中的一个关键概念，因为你增加的计算机数量越多，每台计算机发生故障的概率就越高。在一些较小的 Dask 部署中，机器容错并不那么重要，因此，如果你仅在本地模式下或在两三台桌子底下的计算机上运行
    Dask，你可能可以跳过本节内容。^([9](app01.xhtml#id1028))
- en: Dask’s core fault tolerance approach is to re-compute lost data. This is the
    approach chosen by many modern data-parallel systems since failures are not super
    common, so making the situation with no failures fast is the priority.^([10](app01.xhtml#id1029))
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的核心容错方法是重新计算丢失的数据。这是许多现代数据并行系统选择的方法，因为故障并不是很常见，因此使没有故障的情况下快速恢复是首要任务。^([10](app01.xhtml#id1029))
- en: It is important to consider, with fault tolerance of Dask, what the fault condition
    possibilities are in the components Dask is connected to. While re-compute is
    a fine approach for distributed computing, distributed storage has different trade-offs.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑 Dask 的容错性时，重要的是考虑 Dask 连接到的各个组件的故障条件可能性。虽然重新计算是分布式计算的一种良好方法，但分布式存储有不同的权衡。
- en: Dask’s approach to re-compute on failure means that the data that Dask used
    for the computation remains present to re-load when needed. In most systems, this
    will be the case, but in some streaming systems you may need to configure longer
    TTLs or otherwise have a buffer on top to provide the reliability that Dask requires.
    Also, if you are deploying your own storage layer (e.g., MinIO), it’s important
    that you deploy it in a way to minimize data loss.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 对于在失败后重新计算的方法意味着用于计算的数据仍然存在以便需要时重新加载。在大多数系统中，这将是情况，但在某些流式系统中，您可能需要配置更长的
    TTL 或者在顶部有一个缓冲区，以提供 Dask 所需的可靠性。另外，如果您正在部署自己的存储层（例如 MinIO），重要的是以一种方式部署它，以最小化数据丢失。
- en: Dask’s fault tolerance does not extend to the leader node. A partial solution
    to this is often called high availability, where a system outside of Dask monitors
    and restarts your Dask leader node.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的容错性不包括领导节点。解决这个问题的部分方案通常称为高可用性，即 Dask 外部的系统监控并重启您的 Dask 领导节点。
- en: Fault tolerance techniques are often also used when scaling down, since fault
    tolerance and scale down both involve the loss of a node.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在缩减规模时常常也会使用容错技术，因为容错和缩减规模都涉及节点的丢失。
- en: Scalability (Up and Down)
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可伸缩性（上升和下降）
- en: Scalability refers to the ability of a distributed system to grow to handle
    larger problems and the sometimes overlooked ability to shrink when the needs
    are reduced (say, after the grad students go to sleep). In computer science, we
    generally categorize scalability as either *horizontal* or *vertical*. Horizontal
    scaling refers to adding more computers, whereas vertical scaling refers to using
    bigger computers.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩性指的是分布式系统处理更大问题并在需要减少时（例如研究生睡觉后）缩小的能力。在计算机科学中，我们通常将可伸缩性分类为*水平*或*垂直*。水平扩展是指添加更多计算机，而垂直扩展是指使用更大的计算机。
- en: Another important consideration is *auto*-scaling versus *manual* scaling. In
    auto-scaling, the execution engine (in our case, Dask) will scale the resources
    for us. Dask’s auto-scaler will horizontally scale by adding your workers when
    needed (provided the deployment supports it). To scale up vertically, you can
    add larger instance types to Dask’s auto-scaler and request those resources with
    your jobs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的考虑因素是自动扩展与手动扩展。在自动扩展中，执行引擎（在我们的情况下是 Dask）将为我们扩展资源。Dask 的自动扩展器将通过在需要时添加工作节点来进行水平扩展（前提是部署支持）。要进行垂直扩展，您可以向
    Dask 的自动扩展器添加较大的实例类型，并在作业中请求这些资源。
- en: Note
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In a way, Dask’s task “stealing” can be viewed as a form of automatic vertical
    scaling. If a node is incapable of (or especially slow at) handling a task, then
    another Dask worker can “steal” the task. In practice, the auto-scaler does not
    allocate higher resource nodes unless you schedule a task that asks for those
    resources.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，Dask 的任务“窃取”可以看作是一种自动垂直扩展的形式。如果一个节点无法（或特别慢）处理一个任务，那么另一个 Dask 工作节点可以“窃取”这个任务。在实践中，除非您安排了一个请求这些资源的任务，否则自动扩展器不会分配更高资源节点。
- en: 'Cache, Memory, Disk, and Networking: How the Performance Changes'
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存、内存、磁盘和网络：性能变化的影响
- en: Dask jobs are frequently data-heavy, and the cost of transferring data to the
    CPU (or GPU) can have a large impact on performance. CPU cache is normally more
    than an order of magnitude faster than reading from memory. Reading data from
    an SSD is roughly 4x slower than memory, and sending data within a data center
    can be ~10 times slower.^([11](app01.xhtml#id1040)) CPU caches can normally contain
    only a few elements.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 作业通常数据密集，将数据传输到 CPU（或 GPU）对性能影响很大。CPU 缓存通常比从内存读取快一个数量级以上。从 SSD 读取数据大约比从内存慢4倍，在数据中心内部发送数据可能慢约10倍。^([11](app01.xhtml#id1040))
    CPU 缓存通常只能包含几个元素。
- en: Transferring data from RAM (or even worse, from disk/network) can result in
    the CPU stalling or not being able to do any useful work. This makes chaining
    operations especially important.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据从 RAM（甚至更糟的是从磁盘/网络）转移可能导致 CPU 停顿或无法执行任何有用的工作。这使得链式操作尤为重要。
- en: The [Computers Are Fast website](https://oreil.ly/Iyzds) does an excellent job
    of illustrating these performance impacts with real code.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[计算机速度很快网站](https://oreil.ly/Iyzds) 通过真实代码很好地说明了这些性能影响。'
- en: Hashing
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哈希
- en: Hashing is an important part not only of Dask but also of computer science in
    general. Dask uses hashing to convert complex data types into integers to assign
    the data to the correct partition. Hashing is generally a “one-way” operation
    that embeds the larger key space into a smaller key space. For many operations,
    like assigning data to the correct partitions, you want hashing to be fast. However,
    for tasks like pseudonymization and passwords, you intentionally choose slower
    hashing algorithms and frequently add more iterations to make it more difficult
    to reverse. It’s important to pick the right hashing algorithm to match your purposes,
    since the different behaviors could be a feature in one use case but a bug in
    the other.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希算法不仅在 Dask 中很重要，在计算机科学中也是如此。Dask 使用哈希算法将复杂的数据类型转换为整数，以便将数据分配给正确的分区。哈希通常是一个“单向”的操作，它将较大的键空间嵌入到较小的键空间中。对于许多操作，比如将数据分配给正确的分区，你希望哈希算法快速执行。然而，对于像假名化和密码这样的任务，你故意选择较慢的哈希算法，并经常增加更多迭代次数，以使其难以逆转。选择正确的哈希算法以匹配你的目的非常重要，因为不同的行为可能在一个用例中是一个特性，但在另一个用例中是一个错误。
- en: Data Locality
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据局部性
- en: Data transfer costs can quickly overwhelm data compute costs for simple computation.
    When possible, scheduling tasks on nodes that already have the data is often much
    faster since the task has to be scheduled somewhere (e.g., you pay the network
    cost of copying the task regardless), but you can avoid moving the data if you
    put the task in the right place. Network copies are also generally slower than
    disk.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的计算，数据传输成本可能会迅速超过数据计算成本。在可能的情况下，在已经具有数据的节点上安排任务通常会快得多，因为任务必须在某处安排（例如，无论如何都要支付复制任务的网络成本），但如果将任务放在正确的位置，则可以避免移动数据。网络复制通常也比磁盘慢。
- en: Dask allows you to specify a desired worker in your `client.submit` with `workers=`.
    Also, if you have data that is going to be accessed everywhere, rather than doing
    a regular scatter, you can broadcast it by adding `broadcast=True` so that all
    workers have a full copy of the collection.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `client.submit` 中，Dask 允许你指定一个期望的工作节点，通过 `workers=`。此外，如果你有数据将在各处访问，而不是进行常规的
    scatter，你可以通过添加 `broadcast=True` 来广播它，以便所有工作节点都有集合的完整副本。
- en: Exactly Once Versus At Least Once
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一次性执行与至少一次执行
- en: In most software development the concept of *exactly once* is so much of a given
    that we don’t even think of it as a requirement. For example, doubly applied debits
    or credits to a bank account could be catastrophic. Exactly-once execution in
    Dask requires the use of external systems because of Dask’s approach to fault
    tolerance. A common approach is to use a database (distributed or non-distributed)
    along with transactions to ensure exactly-once execution.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数软件开发中，“一次性执行”这个概念是如此的普遍，以至于我们甚至不将其视为一个要求。例如，对银行账户的重复应用借记或贷记可能会是灾难性的。在 Dask
    中实现一次性执行需要使用外部系统，因为 Dask 的容错方法。一个常见的方法是使用数据库（分布式或非分布式）以及事务来确保一次性执行。
- en: Not all distributed systems have this challenge. Systems in which the inputs
    and outputs are controlled and fault tolerance is achieved by redundant writes
    have an easier time with exactly-once execution. Some systems that use re-compute
    on failure are still able to offer exactly-once execution by integrating distributed
    locks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的分布式系统都有这个挑战。输入和输出受控制，并通过冗余写入实现容错的系统在执行上一次时更容易。一些使用失败后重新计算的系统仍能通过集成分布式锁提供一次性执行。
- en: Conclusion
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Distributed systems are fun, but as you can see from the distributed systems
    concepts, they add a substantial amount of overhead. If you don’t need distributed
    systems, then using Dask in local mode and using local data stores can greatly
    simplify your life. Regardless of whether you decide on local mode or distributed,
    having an understanding of general systems concepts will help you build better
    Dask pipelines.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统很有趣，但正如你从分布式系统的概念中看到的那样，它们增加了大量的开销。如果你不需要分布式系统，那么在本地模式下使用 Dask 并使用本地数据存储可以极大地简化你的生活。无论你选择本地模式还是分布式模式，对一般系统概念的了解都将帮助你构建更好的
    Dask 流水线。
- en: ^([1](app01.xhtml#id978-marker)) This can include creating a database, filling
    it with data, starting up cluster services, etc.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](app01.xhtml#id978-marker)) 这可以包括创建数据库，填充数据，启动集群服务等。
- en: ^([2](app01.xhtml#id992-marker)) We do not recommend TFX for new environments,
    as it can be challenging to get running.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](app01.xhtml#id992-marker)) 我们不建议在新环境中使用 TFX，因为可能很难启动。
- en: ^([3](app01.xhtml#id995-marker)) We acknowledge that society is often not structured
    this way.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](app01.xhtml#id995-marker)) 我们承认社会通常不是这样构建的。
- en: ^([4](app01.xhtml#id1017-marker)) This is not the most common fault tolerance
    of databases, but some default configurations of common databases can result in
    this.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](app01.xhtml#id1017-marker)) 这不是数据库最常见的容错方式，但一些常见数据库的默认配置可能导致这种情况。
- en: ^([5](app01.xhtml#id1019-marker)) *Indirect* here means with another function
    in between; for example, “A calls B, which calls A” is an example of co-recursion.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](app01.xhtml#id1019-marker)) *间接*在这里意味着在两个函数之间;例如，“A调用B，B调用A”是共递归的一个例子。
- en: ^([6](app01.xhtml#id1022-marker)) One classic [XKCD comic](https://oreil.ly/9zAmg)
    comes surprisingly close to capturing our early experiences with Git.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](app01.xhtml#id1022-marker)) 一部经典的[XKCD漫画](https://oreil.ly/9zAmg)出人意料地接近捕捉我们在Git早期经历中的经验。
- en: '^([7](app01.xhtml#id1023-marker)) Conflict-of-interest disclosure: Holden has
    received a T-shirt and stickers from the LakeFS project. Some alternatives include
    Project Nessie (focused on Iceberg tables).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](app01.xhtml#id1023-marker)) 利益冲突披露：Holden已从LakeFS项目获得T恤衫和贴纸。一些替代方案包括专注于Iceberg表的Nessie项目。
- en: ^([8](app01.xhtml#id1025-marker)) For example, two ML tasks on the same node
    may both try to use all of the CPU resources.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](app01.xhtml#id1025-marker)) 例如，同一个节点上的两个 ML 任务可能都会尝试使用所有的 CPU 资源。
- en: ^([9](app01.xhtml#id1028-marker)) We choose three here since the probability
    of the failure of a worker node that does not have the driver is only 2x that
    of the driver (which we can’t recover from), and this scales linearly as you add
    more machines.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](app01.xhtml#id1028-marker)) 我们在这里选择了三个，因为没有驱动程序的工作节点失败的概率仅为驱动程序的两倍（我们无法恢复），并且随着添加更多机器，这种比例呈线性增长。
- en: ^([10](app01.xhtml#id1029-marker)) You can cache intermediate steps to reduce
    the cost of re-computing, but this only works if the cached location has not failed
    and requires you to clean up any caching.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](app01.xhtml#id1029-marker)) 您可以缓存中间步骤以减少重新计算的成本，但前提是缓存位置未失败，并且需要清理任何缓存。
- en: ^([11](app01.xhtml#id1040-marker)) Exact performance numbers depend on your
    hardware.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](app01.xhtml#id1040-marker)) 精确的性能数字取决于您的硬件。
