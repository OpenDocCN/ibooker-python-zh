<html><head></head><body><div id="sbo-rt-content" class="calibre2"><section data-type="chapter" epub:type="chapter" class="calibre3" data-pdf-bookmark="Chapter 1. Understanding Performant Python"><div class="preface" id="understanding_performant_python">
<h1 class="calibre23"><span class="publishername">Chapter 1. </span>Understanding Performant Python</h1>

<aside data-type="sidebar" epub:type="sidebar" class="calibre40"><div class="sidebar" id="idm46122435857192">
<h5 class="calibre41">Questions You’ll Be Able to Answer After This Chapter</h5>
<ul class="printings">
<li class="calibre21">
<p class="calibre42">What are the elements of a computer’s architecture?</p>
</li>
<li class="calibre21">
<p class="calibre42">What are some common alternate computer architectures?</p>
</li>
<li class="calibre21">
<p class="calibre42">How does Python abstract the underlying computer architecture?</p>
</li>
<li class="calibre21">
<p class="calibre42">What are some of the hurdles to making performant Python code?</p>
</li>
<li class="calibre21">
<p class="calibre42">What strategies can help you become a highly performant programmer?</p>
</li>
</ul>
</div></aside>

<p class="author1"><a data-type="indexterm" data-primary="CPUs (central processing units)" data-secondary="measuring usage" data-see="profiling" id="idm46122428741400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="RAM (random access memory)" data-secondary="measuring usage" data-see="profiling" id="idm46122428739960" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="matrix and vector computation" data-secondary="numpy and" data-see="numpy" id="idm46122428738728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" data-secondary="numpy and" data-see="numpy" id="idm46122428737496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="prime numbers" data-secondary="verifying with interprocess communication (IPC)" data-see="IPC (interprocess communication)" id="idm46122428736264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="DAFSA" data-see="DAWGs (directed acyclic word graphs)" id="idm46122428734936" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="heat equation" data-see="diffusion equation" id="idm46122428733976" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="C compilers" data-see="compiling to C" id="idm46122428733032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="central processing units" data-see="CPUs (central processing units)" id="idm46122428732088" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="computer architectures" data-see="architectures" id="idm46122428948520" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory, measuring usage" data-see="profiling" id="idm46122428947608" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="fragmentation" data-see="memory fragmentation" id="idm46122428946664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="hash table" data-see="dictionaries and sets" id="idm46122428945720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multiprocessing" data-secondary="interprocess communication (IPC)" data-see="IPC (interprocess communication)" id="idm46122428944776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="programming computers" id="idm46122428943528" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="performant Python" id="pp_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Programming computers can be thought of as moving bits of data and transforming
them in special ways to achieve a particular result. However, these
actions have a time cost. Consequently, <em class="hyperlink">high performance programming</em> can be
thought of as the act of minimizing these operations either by reducing the
overhead (i.e., writing more efficient code) or by changing the way that we do
these operations to make each one more meaningful (i.e., finding a more
suitable algorithm).</p>

<p class="author1">Let’s focus on reducing the overhead in code in order to gain more insight into
the actual hardware on which we are moving these bits. This may seem like a
futile exercise, since Python works quite hard to abstract away direct
interactions with the hardware. However, by understanding both the best way
that bits can be moved in the real hardware and the ways that Python’s
abstractions force your bits to move, you can make progress toward writing high
performance programs in Python.</p>






<section data-type="sect1" data-pdf-bookmark="The Fundamental Computer System" class="calibre3"><div class="preface" id="idm46122428940024">
<h1 class="calibre25">The Fundamental Computer System</h1>

<p class="author1"><a data-type="indexterm" data-primary="architectures" id="a_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The underlying components that make up a computer can be simplified into three
basic parts: the computing units, the memory units, and the connections between
them. In addition, each of these units has different properties that we can use
to understand them. The computational unit has the property of how many
computations it can do per second, the memory unit has the properties of how much
data it can hold and how fast we can read from and write to it, and finally, the
connections have the property of how fast they can move data from one place to
another.</p>

<p class="author1">Using these building blocks, we can talk about a standard workstation at
multiple levels of sophistication. For example, the standard workstation can be
thought of as having a <a data-type="indexterm" data-primary="CPUs (central processing units)" data-secondary="about" id="idm46122428936360" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>central processing unit (CPU) as the computational unit,
connected to both the <a data-type="indexterm" data-primary="RAM (random access memory)" data-secondary="about" id="idm46122428935192" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>random access memory (RAM) and the hard drive as two
separate <a data-type="indexterm" data-primary="memory units" id="idm46122428934104" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>memory units (each having different capacities and read/write speeds),
and finally a bus that provides the connections between all of these parts.
However, we can also go into more detail and see that the CPU itself has several
memory units in it: the L1, L2, and sometimes even the L3 and L4 cache, which
have small capacities but very fast speeds (from several kilobytes to a dozen
megabytes). Furthermore, new computer architectures generally come with new
configurations (for example, Intel’s SkyLake CPUs replaced the frontside bus
with the Intel Ultra Path Interconnect and restructured many connections).
Finally, in both of these approximations of a workstation we have neglected the
network connection, which is effectively a very slow connection to potentially
many other computing and memory units!</p>

<p class="author1">To help untangle these various intricacies, let’s go over a brief description of
these fundamental blocks.</p>








<section data-type="sect2" data-pdf-bookmark="Computing Units" class="calibre3"><div class="preface" id="computing-units">
<h2 class="calibre43">Computing Units</h2>

<p class="author1"><a data-type="indexterm" data-primary="architectures" data-secondary="computing units" id="a_cu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="computing units" id="cu_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <em class="hyperlink">computing unit</em> of a computer is the centerpiece of its
usefulness—it provides the ability to transform any bits it receives into other
bits or to change the state of the current process. CPUs are the most commonly
used computing unit; however, <a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="about" id="idm46122429268488" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>graphics <span class="publishername">processing</span> units (GPUs) are gaining popularity as
auxiliary computing units. They were originally used to speed up computer
graphics but are becoming more applicable for numerical applications and are
useful thanks to their intrinsically parallel nature, which allows many
calculations to happen simultaneously.  Regardless of its type, a computing unit
takes in a series of bits (for example, bits representing numbers) and outputs
another set of bits (for example, bits representing the sum of those numbers). In
addition to the basic arithmetic operations on integers and real numbers and
bitwise operations on binary numbers, some computing units also provide very
specialized operations, such as the “fused multiply add” operation, which takes
in three numbers, <code class="calibre26">A</code>, <code class="calibre26">B</code>, and <code class="calibre26">C</code>, and returns the value <code class="calibre26">A * B + C</code>.</p>

<p class="author1">The main properties of interest in a computing unit are the number of operations
it can do in one cycle and the number of cycles it can do in one second. The first
value is measured by its <a data-type="indexterm" data-primary="IPC (instructions per cycle)" id="idm46122429263688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>instructions per cycle (IPC),<sup class="calibre44"><a data-type="noteref" id="idm46122429262840-marker" href="ch01_split_001.xhtml#idm46122429262840" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> while the latter value
is measured by its <a data-type="indexterm" data-primary="clock speed" id="idm46122429261224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>clock speed. These two measures are always competing with
each other when new computing units are being made. For example, the Intel Core
series has a very high IPC but a lower clock speed, while the Pentium 4 chip has
the reverse. GPUs, on the other hand, have a very high IPC and clock speed,
but they suffer from other problems like the slow communications that we discuss
in <a data-type="xref" href="ch01_split_000.xhtml#understanding_pp_communication" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Communications Layers”</a>.</p>

<p class="author1">Furthermore, although increasing clock speed almost immediately speeds up all
programs running on that computational unit (because they are able to do more
calculations per second), having a higher IPC can also drastically affect
computing by changing the level of <em class="hyperlink">vectorization</em> that is possible.
<a data-type="indexterm" data-primary="vectorization" id="idm46122436160840" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Vectorization occurs when a CPU is provided with multiple pieces of data at a time
and is able to operate on all of them at once. This sort of CPU instruction is
known as <a data-type="indexterm" data-primary="SIMD (single instruction, multiple data)" id="idm46122436159784" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>single instruction, multiple data (SIMD).</p>

<p class="author1">In general, computing units have advanced quite slowly over the past
decade (see <a data-type="xref" href="ch01_split_000.xhtml#FIG-performant-historical-clock" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 1-1</a>). Clock speeds and IPC have both
been stagnant because of the physical limitations of making transistors smaller
and smaller. As a result, chip manufacturers have been relying on other methods
to gain more speed, including simultaneous multithreading (where multiple
threads can run at once), more clever out-of-order execution, and multicore
architectures.</p>

<p class="author1"><a data-type="indexterm" data-primary="hyperthreads" id="idm46122436157032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Hyperthreading presents a virtual second CPU to the host operating system (OS), and
clever hardware logic tries to interleave two threads of instructions into the
execution units on a single CPU. When successful, gains of up to 30% over a
single thread can be achieved. Typically, this works well when the units of work
across both threads use different types of execution units—for example, one performs
floating-point operations and the other performs integer operations.</p>

<p class="author1"><a data-type="indexterm" data-primary="Out-of-order execution" id="idm46122436155448" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Out-of-order execution enables a compiler to spot that some parts of a linear
program sequence do not depend on the results of a previous piece of work, and therefore that both pieces of work could occur in any order or at the
same time. As long as sequential results are presented at the right time, the
program continues to execute correctly, even though pieces of work are computed
out of their programmed order. This enables some instructions to execute when others
might be blocked (e.g., waiting for a memory access), allowing greater overall
utilization of the available 
<span class="publishername">resources</span>.</p>

<p class="author1">Finally, and most important for the higher-level programmer, there is the prevalence
of<a data-type="indexterm" data-primary="architectures" data-secondary="multi-core" id="idm46122436152920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multi-core architectures" id="idm46122436151944" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> multicore architectures. These architectures include multiple CPUs
within the same unit, which increases the total capability without running into
barriers to making each individual unit faster. This is why it is currently
hard to find any machine with fewer than two cores—in this case, the computer
has two physical computing units that are connected to each other. While this
increases the total number of operations that <em class="hyperlink">can</em> be done per second, it
can make writing code more difficult!</p>

<figure class="calibre46"><div id="FIG-performant-historical-clock" class="figure">
<h6 class="calibre47"><span class="publishername">Figure 1-1. </span>Clock speed of CPUs over time (from <a href="https://oreil.ly/JnJt2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">CPU DB</a>)</h6>
</div></figure>

<p class="author1">Simply adding more cores to a CPU does not always speed up a
program’s execution time. This is because of something known as<a data-type="indexterm" data-primary="Amdahl's law" id="idm46122436146824" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/GC2CK" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">Amdahl’s
law</em></a>. Simply stated, Amdahl’s law is this: if a program designed to run on
multiple cores has some subroutines that must run on one core, this will be the
limitation for the maximum speedup that can be achieved by allocating more cores.</p>

<p class="author1">For example, if we had a survey we wanted one hundred people to fill out, and that
survey took 1 minute to complete, we could complete this task in 100 minutes if
we had one person asking the questions (i.e., this person goes to participant 1, asks
the questions, waits for the responses, and then moves to participant 2). This
method of having one person asking the questions and waiting for responses is
similar to a serial process. In serial processes, we have operations being
satisfied one at a time, each one waiting for the previous operation to
complete.</p>

<p class="author1">However, we could perform the survey in parallel if we had two people asking the
questions, which would let us finish the process in only 50 minutes. This can be
done because each individual person asking the questions does not need to know
anything about the other person asking questions. As a result, the task can
easily be split up without having any dependency between the question askers.</p>

<p class="author1">Adding more people asking the questions will give us more speedups,
until we have one hundred people asking questions. At this point, the process would
take 1 minute and would be limited simply by the time it takes a participant to
answer questions. Adding more people asking questions will not result in any further
speedups, because these extra people will have no tasks to perform—all the
participants are already being asked questions!  At this point, the only way to
reduce the overall time to run the survey is to reduce the amount of time it
takes for an individual survey, the serial portion of the problem, to complete.
Similarly, with CPUs, we can add more cores that can perform various chunks of
the computation as necessary until we reach a point where the <a data-type="indexterm" data-primary="bottlenecks" data-seealso="profiling" id="idm46122436141896" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>bottleneck is the
time it takes for a specific core to finish its task. In other words, the
bottleneck in any parallel calculation is always the smaller serial tasks that
are being spread out.</p>

<p class="author1">Furthermore, a major hurdle with utilizing
multiple cores in Python is Python’s use of a<a data-type="indexterm" data-primary="GIL (global interpreter lock)" id="idm46122428706312" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="global interpreter lock (GIL)" id="idm46122428705640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">global interpreter lock</em> (GIL).
The GIL makes sure that a Python process can run only one instruction at a time,
regardless of the number of cores it is currently using. This means that even
though some Python code has access to multiple cores at a time, only one core is
running a Python instruction at any given time. Using the previous example of a
survey, this would mean that even if we had 100 question askers, only one person could
ask a question and listen to a response at a time. This effectively removes any
sort of benefit from having multiple question askers! While this may seem like
quite a hurdle, especially if the current trend in computing is to have multiple
computing units rather than having faster ones, this problem can be avoided by
using other standard library tools, like <code class="calibre26">multiprocessing</code>
(<a data-type="xref" href="ch09_split_000.xhtml#multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 9</a>), technologies like <code class="calibre26">numpy</code> or <code class="calibre26">numexpr</code>
(<a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>), Cython (<a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>), or distributed models
of computing (<a data-type="xref" href="ch10.xhtml#clustering" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 10</a>).<a data-type="indexterm" data-startref="ix_computingunits" id="idm46122428698984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-startref="ix_archcompu" id="idm46122428698280" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<a data-type="indexterm" data-primary="" data-startref="a_cu" id="idm46122428697480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cu_ab" id="idm46122428696504" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Python 3.2 also saw <a href="https://oreil.ly/W2ikf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">a major rewrite of the GIL</a>, which made the system much more
nimble, alleviating many of the concerns around the system for single-thread
performance. Although it still locks Python into running only one instruction at a time, the GIL
now does better at switching between those instructions and doing so with
less overhead.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Memory Units" class="calibre3"><div class="preface" id="idm46122428933176">
<h2 class="calibre43">Memory Units</h2>

<p class="author1"><a data-type="indexterm" data-primary="architectures" data-secondary="memory units" id="a_mu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="memory units" id="mu_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">Memory units</em> in computers are used to store bits. These could be bits
representing variables in your program or bits representing the pixels of an
image. Thus, the abstraction of a memory unit applies to the registers
in your motherboard as well as your <a data-type="indexterm" data-primary="RAM (random access memory)" data-secondary="about" id="idm46122428689496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>RAM and hard drive. The one major
difference between all of these types of memory units is the speed at which they
can read/write data. To make things more complicated, the read/write speed is
heavily dependent on the way that data is being read.</p>

<p class="author1">For example, most memory units perform much better when they read one large
chunk of data as opposed to many small chunks (this is referred to as<a data-type="indexterm" data-primary="sequential read" id="idm46122428687528" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="random data" id="idm46122428778776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">sequential
read</em> versus <em class="hyperlink">random data</em>). If the data in these memory units is thought of as pages
in a large book, this means that most memory units have better <a data-type="indexterm" data-primary="read/write speeds" id="idm46122428776968" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>read/write speeds
when going through the book page by page rather than constantly flipping from
one random page to another. While this fact is generally true across all memory
units, the amount that this affects each type is drastically different.</p>

<p class="author1">In addition to the read/write speeds, memory units also have<a data-type="indexterm" data-primary="latency" id="idm46122428775496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<em class="hyperlink">latency</em>, which can be characterized as the time it takes the device to find
the data that is being used. For a spinning hard drive, this latency can be high
because the disk needs to physically spin up to speed and the read head must
move to the right position. On the
other hand, for RAM, this latency can be quite small because everything is<a data-type="indexterm" data-primary="solid state hard drive" id="idm46122428773896" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> solid state.
Here is a short description of the various memory units that are commonly found
inside a standard workstation, in order of read/write speeds:<sup class="calibre44"><a data-type="noteref" id="idm46122428772888-marker" href="ch01_split_001.xhtml#idm46122428772888" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup></p>
<dl class="calibre28">
<dt class="calibre29"><a data-type="indexterm" data-primary="spinning hard drive" id="idm46122428770440" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Spinning hard drive</dt>
<dd class="calibre30">
<p class="calibre31">Long-term storage that persists even when the computer
is shut down. Generally has slow read/write speeds because the disk must be
physically spun and moved. Degraded performance with random access patterns
but very large capacity (10 terabyte range).</p>
</dd>
<dt class="calibre29">Solid-state hard drive</dt>
<dd class="calibre30">
<p class="calibre31">Similar to a spinning hard drive, with faster
read/write speeds but smaller capacity (1 terabyte range).</p>
</dd>
<dt class="calibre29">RAM</dt>
<dd class="calibre30">
<p class="calibre31">Used to store application code and data (such as any variables being
used). Has fast read/write characteristics and performs well with random
access patterns, but is generally limited in capacity (64 gigabyte range).</p>
</dd>
<dt class="calibre29"><a data-type="indexterm" data-primary="L1/L2 cache" id="idm46122428765192" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>L1/L2 cache</dt>
<dd class="calibre30">
<p class="calibre31">Extremely fast read/write speeds. Data going to the CPU
<em class="hyperlink">must</em> go through here. Very small capacity (megabytes range).</p>
</dd>
</dl>

<p class="author1"><a data-type="xref" href="ch01_split_000.xhtml#FIG-performant-memory-units" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 1-2</a> gives a graphic representation of the differences between these types of memory units by looking at the characteristics of currently available consumer <span class="publishername">hardware.</span></p>

<p class="author1">A clearly visible trend is that read/write speeds and
capacity are inversely proportional—as we try to increase speed, capacity gets
reduced. Because of this, many systems implement a tiered approach to memory:
data starts in its full state in the hard drive, part of it moves to RAM, and
then a much smaller subset moves to the L1/L2 cache. This method of tiering enables
programs to keep memory in different places depending on access speed
requirements. When trying to optimize the memory patterns of a program, we are
simply optimizing which data is placed where, how it is laid out (in order to
increase the number of sequential reads), and how many times it is moved among
the various locations. In addition, methods such as <a data-type="indexterm" data-primary="asynchronous I/O" id="idm46122428760024" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>asynchronous I/O and
<a data-type="indexterm" data-primary="preemptive caching" id="idm46122428759192" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>preemptive caching provide ways to make sure that data is always where it needs
to be without having to waste computing time—most of these processes can
happen independently, while other calculations are being performed!<a data-type="indexterm" data-primary="" data-startref="a_mu" id="idm46122428758120" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mu_ab" id="idm46122428757176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<figure class="calibre46"><div id="FIG-performant-memory-units" class="figure">
<img src="Images/hpp2_0102.png" alt="Memory Characteristics" class="calibre48"/>
<h6 class="calibre47"><span class="publishername">Figure 1-2. </span>Characteristic values for different types of memory units (values from <span class="publishername">February</span> 2014)</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Communications Layers" class="calibre3"><div class="preface" id="understanding_pp_communication">
<h2 class="calibre43">Communications Layers</h2>

<p class="author1"><a data-type="indexterm" data-primary="buses" id="b_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="architectures" data-secondary="communication layers" id="a_cl" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="communication layers" id="cl_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Finally, let’s look at how all of these fundamental blocks communicate with
each other. Many modes of communication exist, but all are
variants on a thing called a <em class="hyperlink">bus</em>.</p>

<p class="author1">The <em class="hyperlink">frontside bus</em>, for example, is the connection between the <a data-type="indexterm" data-primary="RAM (random access memory)" data-secondary="about" id="idm46122428746984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>RAM and the L1/L2 cache. It moves data that is ready to be transformed by the processor into
the staging ground to get ready for calculation, and it moves finished calculations
out. There are other buses, too, such as the external bus that acts as
the main route from hardware devices (such as hard drives and networking cards)
to the CPU and system memory. This external bus is generally slower than the frontside bus.</p>

<p class="author1">In fact, many of the benefits of the L1/L2 cache are attributable to the faster
bus. Being able to queue up data necessary for computation in large chunks on a
slow bus (from RAM to cache) and then having it available at very fast speeds
from the cache lines (from cache to CPU) enables the <a data-type="indexterm" data-primary="CPUs (central processing units)" data-secondary="about" id="idm46122429035704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>CPU to do more calculations
without waiting such a long time.</p>

<p class="author1">Similarly, many of the drawbacks of using a <a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="about" id="idm46122429034136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>GPU come from the bus it is
connected on: since the GPU is generally a peripheral device, it communicates
through the <a data-type="indexterm" data-primary="PCI bus" id="idm46122429032888" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PCI bus, which is much slower than the frontside bus. As a result,
getting data into and out of the GPU can be quite a taxing operation. The advent of heterogeneous computing, or computing blocks that have both a
CPU and a GPU on the frontside bus, aims at <span class="publishername">reducing</span> the data transfer cost and
making GPU computing more of an available option, even when a lot of data must
be transferred.</p>

<p class="author1">In addition to the communication blocks within the computer, the network can be
thought of as yet another communication block. This block, though, is much
more pliable than the ones discussed previously; a network device can be
connected to a memory device, such as a <a data-type="indexterm" data-primary="NAS (network attached storage)" id="idm46122429030312" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>network attached storage (NAS) device or
another computing block, as in a computing node in a cluster. However, network
communications are generally much slower than the other types of communications
mentioned previously. While the frontside bus can transfer dozens of gigabits
per second, the network is limited to the order of several dozen megabits.</p>

<p class="author1">It is clear, then, that the main property of a bus is its speed: how much data
it can move in a given amount of time. This property is given by combining two
quantities: how much data can be moved in one transfer (bus width) and how many
transfers the bus can do per second (bus frequency). It is important to note that
the data moved in one transfer is always sequential: a chunk of data is read off
of the memory and moved to a different place. Thus, the speed of a bus is
broken into these two quantities because individually they can affect
different aspects of computation: a large bus width can help vectorized code (or
any code that sequentially reads through memory) by making it possible to move
all the relevant data in one transfer, while, on the other hand, having a small
bus width but a very high frequency of transfers can help code that must do many
reads from random parts of memory. Interestingly, one of the ways that these
properties are changed by computer designers is by the physical layout of the
motherboard: when chips are placed close to one another, the length of the
physical wires joining them is smaller, which can allow for faster transfer
speeds. In addition, the number of wires itself dictates the width of the bus
(giving real physical meaning to the term!).</p>

<p class="author1">Since interfaces can be tuned to give the right performance for a specific application, it is no surprise that there are hundreds of types. <a data-type="xref" href="ch01_split_000.xhtml#FIG-performant-connection-speed" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 1-3</a> shows the bitrates for a sampling of common interfaces. Note that this doesn’t speak at all about the latency of the connections, which dictates how long it takes for a data request to be responded to (although latency is very computer-dependent, some basic limitations are inherent to the interfaces being used).<a data-type="indexterm" data-primary="" data-startref="a_ch" id="idm46122429025640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="a_cl" id="idm46122429024696" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cl_ab" id="idm46122429023752" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="b_ab" id="idm46122429022808" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<figure class="calibre46"><div id="FIG-performant-connection-speed" class="figure">
<img src="Images/hpp2_0103.png" alt="Connection Speeds" class="calibre49"/>
<h6 class="calibre47"><span class="publishername">Figure 1-3. </span>Connection speeds of various common interfaces<sup class="calibre44"><a data-type="noteref" id="idm46122429019976-marker" href="ch01_split_001.xhtml#idm46122429019976" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup></h6>
</div></figure>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Putting the Fundamental Elements Together" class="calibre3"><div class="preface" id="idm46122428752968">
<h1 class="calibre25">Putting the Fundamental Elements Together</h1>

<p class="author1"><a data-type="indexterm" data-primary="matrix and vector computation" id="mvc_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="vector and matrix computation" id="vmc_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="architectures" data-secondary="constructing" id="a_con" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Understanding the basic components of a computer is not enough to fully
understand the problems of high performance programming. The interplay of all of
these <span class="publishername">components</span> and how they work together to solve a problem introduces
extra levels of complexity. In this section we will
explore some toy problems, illustrating how the ideal solutions would work and
how Python approaches them.</p>

<p class="author1">A warning: this section may seem bleak—most of the remarks in this section seem
to say that Python is natively incapable of dealing with the problems of
performance. This is untrue, for two reasons. First, among all of the
“components of performant computing,” we have neglected one very important
component: the developer. What native Python may lack in performance, it gets
back right away with speed of development. Furthermore, throughout the book we
will introduce modules and philosophies that can help mitigate many of the
problems described here with relative ease. With both of these aspects combined,
we will keep the fast development mindset of Python while removing many of the
performance constraints.</p>








<section data-type="sect2" data-pdf-bookmark="Idealized Computing Versus the Python Virtual Machine" class="calibre3"><div class="preface" id="understanding-performance-idealized-computing">
<h2 class="calibre43">Idealized Computing Versus the Python Virtual Machine</h2>

<p class="author1"><a data-type="indexterm" data-primary="idealized computing" id="ic_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="virtual machine" id="idm46122429008584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Python virtual machine" id="idm46122429007912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>To better understand the components of high performance programming, let’s
look at a simple code sample that checks whether a number is prime:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">import</code> <code class="nn">math</code>

<code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">number</code><code class="p">):</code>
    <code class="n">sqrt_number</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">number</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">sqrt_number</code><code class="p">)</code> <code class="o">+</code> <code class="mi">1</code><code class="p">):</code>
        <code class="kn">if</code> <code class="p">(</code><code class="n">number</code> <code class="o">/</code> <code class="n">i</code><code class="p">)</code><code class="o">.</code><code class="n">is_integer</code><code class="p">():</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code>

<code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"check_prime(10,000,000) = {check_prime(10_000_000)}"</code><code class="p">)</code>
<code class="c"># check_prime(10,000,000) = False</code>
<code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"check_prime(10,000,019) = {check_prime(10_000_019)}"</code><code class="p">)</code>
<code class="c"># check_prime(10,000,019) = True</code></pre>

<p class="author1">Let’s analyze this code using our abstract model of computation and then draw
comparisons to what happens when Python runs this code. As with any
abstraction, we will neglect many of the subtleties in both the idealized
computer and the way that Python runs the code. However, this is generally a
good exercise to perform before solving a problem: think about the general
components of the algorithm and what would be the best way for the computing
components to come together to find a solution. By understanding this
ideal situation and having knowledge of what is actually happening under the
hood in Python, we can iteratively bring our Python code closer to the optimal
code.</p>










<section data-type="sect3" data-pdf-bookmark="Idealized computing" class="calibre3"><div class="preface" id="idm46122435616056">
<h3 class="calibre51">Idealized computing</h3>

<p class="author1">When the code starts, we have the value of <code class="calibre26">number</code> stored in RAM. To
calculate <code class="calibre26">sqrt_number</code>, we need to send the value of <code class="calibre26">number</code> to the CPU.
Ideally, we could send the value once; it would get stored inside the CPU’s
L1/L2 cache, and the CPU would do the calculations and then send the values back
to RAM to get stored. This scenario is ideal because we have minimized the
number of reads of the value of <code class="calibre26">number</code> from RAM, instead opting for reads from
the L1/L2 cache, which are much faster. Furthermore, we have minimized the
number of data transfers through the frontside bus, by using the L1/L2 cache
which is connected directly to the CPU.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">This theme of keeping data where it is needed and moving it as little as
possible is very important when it comes to <span class="publishername">optimization</span>. The concept of <a data-type="indexterm" data-primary="heavy data" id="idm46122435598632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>“heavy data” refers
to the time and effort required to move data around, which is
something we would like to avoid.</p>
</div>

<p class="author1">For the loop in the code, rather than sending one value of <code class="calibre26">i</code> at a time to the
CPU, we would like to send both <code class="calibre26">number</code> and <em class="hyperlink">several</em> values of <code class="calibre26">i</code> to the CPU to
check at the same time. This is possible because the CPU vectorizes operations
with no additional time cost, meaning it can do multiple independent
computations at the same time. So we want to send <code class="calibre26">number</code> to
the CPU cache, in addition to as many values of <code class="calibre26">i</code> as the cache can hold. For
each of the <code class="calibre26">number</code>/<code class="calibre26">i</code> pairs, we will divide them and check if the result is a whole
number; then we will send a signal back indicating whether any of the values was indeed an
integer. If so, the function ends. If not, we repeat. In this way, we need
to communicate back only one result for many values of <code class="calibre26">i</code>, rather than depending on
the slow bus for every value. This takes advantage of a CPU’s ability to
<em class="hyperlink">vectorize</em> a calculation, or run one instruction on multiple data in one clock
cycle.</p>

<p class="author1">This concept of <a data-type="indexterm" data-primary="vectorization" id="idm46122435591720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>vectorization is illustrated by the following code:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">import</code> <code class="nn">math</code>

<code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">number</code><code class="p">):</code>
    <code class="n">sqrt_number</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">number</code><code class="p">)</code>
    <code class="n">numbers</code> <code class="o">=</code> <code class="nb">range</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">sqrt_number</code><code class="p">)</code><code class="o">+</code><code class="mi">1</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">numbers</code><code class="p">),</code> <code class="mi">5</code><code class="p">):</code>
      <code class="c"># the following line is not valid Python code</code>
        <code class="n">result</code> <code class="o">=</code> <code class="p">(</code><code class="n">number</code> <code class="o">/</code> <code class="n">numbers</code><code class="p">[</code><code class="n">i</code><code class="p">:(</code><code class="n">i</code> <code class="o">+</code> <code class="mi">5</code><code class="p">)])</code><code class="o">.</code><code class="n">is_integer</code><code class="p">()</code>
        <code class="kn">if</code> <code class="nb">any</code><code class="p">(</code><code class="n">result</code><code class="p">):</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre>

<p class="author1">Here, we set up the processing such that the division and the checking for
integers are done on a set of five values of <code class="calibre26">i</code> at a time. If properly vectorized,
the CPU can do this line in one step as opposed to doing a separate calculation
for every <code class="calibre26">i</code>. Ideally, the <code class="calibre26">any(result)</code> operation would also happen in the
CPU without having to transfer the results back to RAM. We will talk more
about vectorization, how it works, and when it benefits your code in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>.<a data-type="indexterm" data-primary="" data-startref="ic_ab" id="idm46122435522168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="Python’s virtual machine" class="calibre3"><div class="preface" id="idm46122435521064">
<h3 class="calibre51">Python’s virtual machine</h3>

<p class="author1">The <a data-type="indexterm" data-primary="Python interpreter" id="idm46122435519560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Python virtual machine" id="pvm_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="virtual machine" id="vm_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Python interpreter does a lot of work to try to abstract away the underlying
computing elements that are being used. At no point does a programmer need to
worry about allocating memory for arrays, how to arrange that memory, or in what
sequence it is being sent to the CPU. This is a benefit of Python, since it lets
you focus on the algorithms that are being implemented. However, it comes at a
huge performance cost.</p>

<p class="author1">It is important to realize that at its core, Python is indeed running a set of
very optimized instructions. The trick, however, is getting Python to perform
them in the correct sequence to achieve better performance. For
example, it is quite easy to see that, in the following example, <code class="calibre26">search_fast</code> will
run faster than <code class="calibre26">search_slow</code> simply because it skips the unnecessary
computations that result from not terminating the loop early, even though both solutions have
runtime <code class="calibre26">O(n)</code>. However, things can get complicated when dealing with derived
types, special Python methods, or third-party modules. For example, can you
immediately tell which function will be faster: <code class="calibre26">search_unknown1</code> or
<code class="calibre26">search_unknown2</code>?</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">def</code> <code class="nf">search_fast</code><code class="p">(</code><code class="n">haystack</code><code class="p">,</code> <code class="n">needle</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">haystack</code><code class="p">:</code>
        <code class="kn">if</code> <code class="n">item</code> <code class="o">==</code> <code class="n">needle</code><code class="p">:</code>
            <code class="kn">return</code> <code class="nb">True</code>
    <code class="kn">return</code> <code class="nb">False</code>

<code class="kn">def</code> <code class="nf">search_slow</code><code class="p">(</code><code class="n">haystack</code><code class="p">,</code> <code class="n">needle</code><code class="p">):</code>
    <code class="n">return_value</code> <code class="o">=</code> <code class="nb">False</code>
    <code class="kn">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">haystack</code><code class="p">:</code>
        <code class="kn">if</code> <code class="n">item</code> <code class="o">==</code> <code class="n">needle</code><code class="p">:</code>
            <code class="n">return_value</code> <code class="o">=</code> <code class="nb">True</code>
    <code class="kn">return</code> <code class="n">return_value</code>

<code class="kn">def</code> <code class="nf">search_unknown1</code><code class="p">(</code><code class="n">haystack</code><code class="p">,</code> <code class="n">needle</code><code class="p">):</code>
    <code class="kn">return</code> <code class="nb">any</code><code class="p">((</code><code class="n">item</code> <code class="o">==</code> <code class="n">needle</code> <code class="kn">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">haystack</code><code class="p">))</code>

<code class="kn">def</code> <code class="nf">search_unknown2</code><code class="p">(</code><code class="n">haystack</code><code class="p">,</code> <code class="n">needle</code><code class="p">):</code>
    <code class="kn">return</code> <code class="nb">any</code><code class="p">([</code><code class="n">item</code> <code class="o">==</code> <code class="n">needle</code> <code class="kn">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">haystack</code><code class="p">])</code></pre>

<p class="author1">Identifying slow regions of code through profiling and finding more efficient
ways of doing the same calculations is similar to finding these useless
operations and removing them; the end result is the same, but the number of
computations and data transfers is reduced drastically.</p>

<p class="author1">One of the impacts of this abstraction layer is that vectorization is not
immediately achievable. Our initial prime number routine will run one
iteration of the loop per value of <code class="calibre26">i</code> instead of combining several iterations.
However, looking at the abstracted vectorization example, we see that it is not
valid Python code, since we cannot divide a float by a list. External libraries
such as <code class="calibre26">numpy</code> will help with this situation by adding the ability to do
vectorized mathematical operations.</p>

<p class="author1">Furthermore, Python’s abstraction hurts any optimizations that rely on keeping the
L1/L2 cache filled with the relevant data for the next computation. This comes
from many factors, the first being that Python objects are not laid out in the most
optimal way in memory. This is a consequence of Python being a garbage-collected <span class="publishername">language—memory</span> is automatically allocated and freed when needed.
This creates memory fragmentation that can hurt the transfers to the CPU caches.
In addition, at no point is there an opportunity to change the layout of a data
structure directly in memory, which means that one transfer on the bus may not
contain all the relevant information for a computation, even though it might have
all fit within the bus width.<sup class="calibre44"><a data-type="noteref" id="idm46122435398952-marker" href="ch01_split_001.xhtml#idm46122435398952" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup></p>

<p class="author1">A second, more fundamental problem comes from Python’s dynamic types and the
language not being compiled. As many C programmers have learned throughout the
years, the compiler is often smarter than you are. When compiling code that is
static, the compiler can do many tricks to change the way things are laid out
and how the CPU will run certain instructions in order to optimize them.
Python, however, is not compiled: to make matters worse, it has dynamic types,
which means that inferring any possible opportunities for optimizations
algorithmically is drastically harder since code functionality can be changed
during runtime. There are many ways to mitigate this problem, foremost being the use
of Cython<a data-type="indexterm" data-primary="Cython" data-secondary="about" id="idm46122435396296" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>, which allows Python code to be <a data-type="indexterm" data-primary="compiling" id="idm46122435395224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>compiled and allows the user to create
“hints” to the compiler as to how dynamic the code actually
is.</p>

<p class="author1">Finally, the previously mentioned GIL can
hurt performance if trying to parallelize this code. For example, let’s assume
we change the code to use multiple CPU cores such that each core gets a chunk of
the numbers from 2 to <code class="calibre26">sqrtN</code>. Each core can do its calculation for its chunk
of numbers, and then, when the calculations are all done, the cores can compare their
calculations. Although we lose the early termination of the loop since each
core doesn’t know if a solution has been found, we can reduce the number of
checks each core has to do (if we had <code class="calibre26">M</code> cores, each core would have to do
<code class="calibre26">sqrtN / M</code> checks). However, because of the GIL, only one core can be used at
a time. This means that we would effectively be running the same code as the
unparalleled version, but we no longer have early termination. We can avoid
this problem by using multiple processes (with the <code class="calibre26">multiprocessing</code> module)
instead of multiple threads, or by using Cython or foreign
functions.<a data-type="indexterm" data-primary="" data-startref="a_con" id="idm46122435391160" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pvm_ab" id="idm46122435390184" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vm_ab" id="idm46122435389240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="So Why Use Python?" class="calibre3"><div class="preface" id="idm46122435388168">
<h1 class="calibre25">So Why Use Python?</h1>

<p class="author1">Python is highly expressive and easy to learn—new programmers quickly discover
that they can do quite a lot in a short space of time. Many Python libraries
wrap tools written in other languages to make it easy to call other systems; for
example, the scikit-learn machine learning system wraps LIBLINEAR and LIBSVM
(both of which are written in C), and the <code class="calibre26">numpy</code> library includes BLAS and other
C and Fortran libraries. As a result, Python code that properly utilizes these
modules can indeed be as fast as comparable C code.</p>

<p class="author1"><a data-type="indexterm" data-primary="Python" data-secondary="attributes" id="py_att" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Python is described as “batteries included,” as many important tools and stable
libraries are built in. These include the following:<a data-type="indexterm" data-primary="libraries" id="li_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<dl class="calibre28">
<dt class="calibre29"><code class="calibre26">unicode</code> and <code class="calibre26">bytes</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="bytes library" id="idm46122435380440" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="unicode library" id="idm46122435379736" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Baked into the core language</p>
</dd>
<dt class="calibre29"><code class="calibre26">array</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="array module" id="idm46122435377656" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Memory-efficient arrays for primitive types</p>
</dd>
<dt class="calibre29"><code class="calibre26">math</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="math module" id="idm46122435375544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Basic mathematical operations, including some simple statistics</p>
</dd>
<dt class="calibre29"><code class="calibre26">sqlite3</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="sqlite3 library" id="idm46122435373432" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A wrapper around the prevalent SQL file-based storage engine SQLite3</p>
</dd>
<dt class="calibre29"><code class="calibre26">collections</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="collections library" id="idm46122435371320" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A wide variety of objects, including a deque, counter, and dictionary variants</p>
</dd>
<dt class="calibre29"><code class="calibre26">asyncio</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="AsyncIO (module)" id="idm46122435369208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Concurrent support for I/O-bound tasks using async and await syntax</p>
</dd>
</dl>

<p class="author1">A huge variety of libraries can be found outside the core language, including these:</p>
<dl class="calibre28">
<dt class="calibre29"><code class="calibre26">numpy</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="numpy" data-secondary="library in" id="idm46122435365912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A numerical Python library (a bedrock library for anything to do with <span class="publishername">matrices)</span></p>
</dd>
<dt class="calibre29"><code class="calibre26">scipy</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="SciPy" id="idm46122435362968" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A very large collection of trusted scientific libraries, often wrapping highly respected C and Fortran libraries</p>
</dd>
<dt class="calibre29"><code class="calibre26">pandas</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="pandas library" id="idm46122435360728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A library for data analysis, similar to R’s data frames or an Excel spreadsheet, built on <code class="calibre26">scipy</code> and <code class="calibre26">numpy</code></p>
</dd>
<dt class="calibre29">scikit-learn</dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="scikit-learn" data-secondary="library" id="idm46122435357896" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Rapidly turning into the default machine learning library, built on <code class="calibre26">scipy</code></p>
</dd>
<dt class="calibre29"><code class="calibre26">tornado</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="tornado" id="idm46122435355224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="asynchronous programming" data-secondary="tornado" id="idm46122435354520" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A library that provides easy bindings for concurrency</p>
</dd>
<dt class="calibre29">PyTorch and TensorFlow</dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="PyTorch" id="idm46122435352264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="TensorFlow" id="idm46122435351560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Deep learning frameworks from Facebook and Google with strong Python and GPU support</p>
</dd>
<dt class="calibre29"><code class="calibre26">NLTK</code>, <code class="calibre26">SpaCy</code>, and <code class="calibre26">Gensim</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="NLTK library" id="idm46122435348584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="SpaCy library" id="idm46122435347880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Gensim library" id="idm46122435347208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Natural language-processing libraries with deep Python support</p>
</dd>
<dt class="calibre29">Database bindings</dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="database bindings" id="idm46122435345256" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>For communicating with virtually all databases, including Redis, MongoDB, HDF5, and SQL</p>
</dd>
<dt class="calibre29">Web development frameworks</dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="Web development frameworks" id="idm46122435343304" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Performant systems for creating websites, such as <code class="calibre26">aiohttp</code>, <code class="calibre26">django</code>, <code class="calibre26">pyramid</code>, <code class="calibre26">flask</code>, and <code class="calibre26">tornado</code></p>
</dd>
<dt class="calibre29"><code class="calibre26">OpenCV</code></dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="OpenCV library" id="idm46122435338984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Bindings for computer vision</p>
</dd>
<dt class="calibre29">API bindings</dt>
<dd class="calibre30">
<p class="calibre31"><a data-type="indexterm" data-primary="API bindings" id="idm46122435337000" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>For easy access to popular web APIs such as Google, Twitter, and LinkedIn<a data-type="indexterm" data-primary="" data-startref="li_ab" id="idm46122435336168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</dd>
</dl>

<p class="author1">A large selection of managed environments and shells is available to fit
various deployment scenarios, including the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">The standard distribution, available at <a href="http://python.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">http://python.org</em></a></p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="pipenv" id="idm46122435332056" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="pyenv" id="idm46122435331352" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="virtualenv" id="idm46122435330680" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">pipenv</code>, <code class="calibre26">pyenv</code>, and <code class="calibre26">virtualenv</code> for simple, lightweight, and portable
Python environments</p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="Docker" data-secondary="about" id="idm46122435327912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Docker for simple-to-start-and-reproduce environments for development or
production</p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="Anaconda Inc." id="idm46122435266872" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Anaconda Inc.’s Anaconda, a scientifically focused environment</p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="Sage" id="idm46122435265256" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Sage, a Matlab-like environment that includes an integrated development environment (IDE)</p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="IPython" id="idm46122435263608" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>IPython, an interactive Python shell heavily used by scientists and developers</p>
</li>
<li class="calibre21">
<p class="calibre27"><a data-type="indexterm" data-primary="Jupyter Notebooks" id="idm46122435262072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Jupyter Notebook, a browser-based extension to IPython, heavily used for teaching and demonstrations</p>
</li>
</ul>

<p class="author1">One of Python’s main strengths is that it enables fast prototyping of an idea.
Because of the wide variety of supporting libraries, it is easy to test whether an idea is
feasible, even if the first implementation might be rather flaky.</p>

<p class="author1">If you want to make your mathematical routines faster, look to <code class="calibre26">numpy</code>. If
you want to experiment with machine learning, try scikit-learn. If you are
cleaning and manipulating data, then <code class="calibre26">pandas</code> is a good choice.</p>

<p class="author1">In general, it is sensible to raise the question, “If our system runs faster,
will we as a team run slower in the long run?” It is always possible to squeeze
more performance out of a system if enough work-hours are invested, but this
might lead to brittle and poorly understood optimizations that ultimately trip up
the team.</p>

<p class="author1">One example might be the introduction of <a data-type="indexterm" data-primary="Cython" data-secondary="about" id="idm46122435257624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="compiling" id="idm46122435256648" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Cython (see <a data-type="xref" href="ch07.xhtml#compiling-cython" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Cython”</a>), a
compiler-based approach to annotating Python code with C-like types so the
transformed code can be compiled using a C compiler. While the speed gains can
be impressive (often achieving C-like speeds with relatively little effort), the
cost of supporting this code will increase. In particular, it might be harder to
support this new module, as team members will need a certain maturity in their
programming ability to understand some of the trade-offs that have occurred when
leaving the Python virtual machine that introduced the performance increase.<a data-type="indexterm" data-primary="" data-startref="py_att" id="idm46122435254440" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="How to Be a Highly Performant Programmer" class="calibre3"><div class="preface" id="idm46122435387576">
<h1 class="calibre25">How to Be a Highly Performant Programmer</h1>

<p class="author1">Writing high performance code is only one part of being highly performant with
successful projects over the longer term. Overall team velocity is far more
important than speedups and complicated solutions. Several factors are key to
this—good structure, documentation, debuggability, and shared standards.</p>

<p class="author1">Let’s say you create a prototype. You didn’t test it thoroughly, and it didn’t get reviewed by your team. It does seem to be “good enough,” and it gets pushed to production. Since it was never written in a structured way, it lacks tests and is undocumented. All of a sudden there’s
an inertia-causing piece of code for someone else to support, and often
management can’t quantify the cost to the team.</p>

<p class="author1">As this solution is hard to maintain, it tends to stay unloved—it never gets
restructured, it doesn’t get the tests that’d help the team refactor it, and nobody
else likes to touch it, so it falls to one developer to keep it running. This can
cause an awful bottleneck at times of stress and raises a significant risk: what would happen if that developer left the project?</p>

<p class="author1">Typically, this development style occurs when the management team doesn’t understand the ongoing inertia that’s caused by hard-to-maintain code. Demonstrating that in the longer-term tests and documentation can help a team stay highly productive and can help convince managers to allocate time to “cleaning up” this prototype code.</p>

<p class="author1">In a research environment, it is common to create many Jupyter Notebooks using
poor coding practices while iterating through ideas and different datasets.
The 
<span class="publishername">intention</span> is always to “write it up properly” at a later stage, but that
later stage never occurs. In the end, a working result is obtained, but the
infrastructure to reproduce it, test it, and trust the result is missing. Once
again the risk factors are high, and the trust in the result will be low.</p>

<p class="author1">There’s a general approach that will serve you well:</p>
<dl class="calibre28">
<dt class="calibre29">Make it work</dt>
<dd class="calibre30">
<p class="calibre31">First you build a good-enough solution. It is very sensible to “build one to throw away” that acts as a prototype solution, enabling a better structure to be used for the second version. It is always sensible to do some up-front planning before coding; otherwise, you’ll come to reflect that “We saved an hour’s thinking by coding all afternoon.” In some fields this is better known as “Measure twice, cut once.”</p>
</dd>
<dt class="calibre29">Make it right</dt>
<dd class="calibre30">
<p class="calibre31">Next, you add a strong test suite backed by documentation and clear reproducibility instructions so that another team member can take it on.</p>
</dd>
<dt class="calibre29">Make it fast</dt>
<dd class="calibre30">
<p class="calibre31">Finally, we can focus on profiling and compiling or parallelization and using the existing test suite to confirm that the new, faster solution still works as expected.</p>
</dd>
</dl>








<section data-type="sect2" data-pdf-bookmark="Good Working Practices" class="calibre3"><div class="preface" id="idm46122435241608">
<h2 class="calibre43">Good Working Practices</h2>

<p class="author1">There are a few “must haves”—documentation, good structure, and testing are key.</p>

<p class="author1">Some project-level documentation will help you stick to a clean structure. It’ll
also help you and your colleagues in the future. Nobody will thank you (yourself
included) if you skip this part. Writing this up in a <em class="hyperlink">README</em> file at the
top level is a sensible starting point; it can always be expanded into a <em class="hyperlink">docs/</em>
folder later if required.</p>

<p class="author1">Explain the purpose of the project, what’s in the folders, where the data comes
from, which files are critical, and how to run it all, including how to run the
tests.</p>

<p class="author1">Micha recommends also using <a data-type="indexterm" data-primary="Docker" data-secondary="about" id="idm46122435237368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Docker. A top-level Dockerfile will explain to
your future-self exactly which libraries you need from the operating system
to make this project run successfully. It also removes the difficulty of running
this code on other machines or deploying it to a cloud environment.</p>

<p class="author1">Add a <em class="hyperlink">tests/</em> folder and add some unit tests. We prefer<a data-type="indexterm" data-primary="pytest" id="idm46122435234920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">pytest</code> as a modern
test runner, as it builds on Python’s built-in <a data-type="indexterm" data-primary="unittest module" id="idm46122435233672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">unittest</code> module. Start with just a
couple of tests and then build them up. Progress to using the<a data-type="indexterm" data-primary="coverage tool" id="idm46122435232472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">coverage</code> tool,
which will report how many lines of your code are actually covered by the tests—it’ll help avoid nasty surprises.</p>

<p class="author1">If you’re inheriting legacy code and it lacks tests, a high-value activity is
to add some tests up front. Some “integration tests” that check the overall flow
of the project and confirm that with certain input data you get specific output
results will help your sanity as you subsequently make modifications.</p>

<p class="author1">Every time something in the code bites you, add a test. There’s no value to
being bitten twice by the same problem.</p>

<p class="author1"><a data-type="indexterm" data-primary="Docstrings" id="idm46122435229624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Docstrings in your code for each function, class, and module will always help
you. Aim to provide a useful description of what’s <em class="hyperlink">achieved</em> by the function,
and where possible include a short example to demonstrate the expected output.
Look at the docstrings inside <code class="calibre26">numpy</code> and scikit-learn if you’d like
inspiration.</p>

<p class="author1">Whenever your code becomes too long—such as functions longer than one screen—be comfortable with refactoring the code to make it shorter. Shorter code is easier
to test and easier to support.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1"><a data-type="indexterm" data-primary="test-driven development" id="idm46122435226136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>When you’re developing your tests, think about following a test-driven
development methodology. When you know exactly what you need to
develop and you have testable examples at hand—this method becomes very
efficient.</p>

<p class="author1">You write your tests, run them, watch them fail, and <em class="hyperlink">then</em> add
the functions and the necessary minimum logic to support the tests that you’ve
written. When your tests all work, you’re done. By figuring out the expected input and output of a function ahead of time, you’ll find implementing the logic of the function relatively straightforward.</p>

<p class="author1">If you can’t define your tests ahead of time, it naturally raises the question, do you really
understand what your function needs to do? If not, can you write it correctly in an
efficient manner? This method doesn’t work so well if you’re in a creative process and researching data that you don’t
yet understand well.</p>
</div>

<p class="author1">Always use <a data-type="indexterm" data-primary="source control" id="idm46122435222600" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>source control—you’ll only thank yourself when you overwrite
something critical at an inconvenient moment. Get used to committing frequently
(daily, or even every 10 minutes) and pushing to your repository every day.</p>

<p class="author1">Keep to the standard <a data-type="indexterm" data-primary="PEP8 coding standard" id="idm46122435221112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">PEP8</code> coding standard. Even better, adopt <code class="calibre26">black</code> (the
opinionated code formatter) on a pre-commit source control hook so it just
rewrites your code to the standard for you. Use <code class="calibre26">flake8</code> to lint your code to
avoid other mistakes.</p>

<p class="author1">Creating environments that are isolated from the operating system will make your
life easier. Ian prefers Anaconda, while Micha prefers <a data-type="indexterm" data-primary="pipenv" id="idm46122435218328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">pipenv</code> coupled with Docker.
Both are sensible solutions and are significantly better using the operating
system’s global Python environment!</p>

<p class="author1">Remember that automation is your friend. Doing less manual work means there’s less
chance of errors creeping in. Automated build systems, continuous integration with
automated test suite runners, and automated deployment systems turn tedious and error-prone
tasks into standard processes that anyone can run and support.</p>

<p class="author1">Finally, remember that readability is far more important than being clever.
Short snippets of complex and hard-to-read code will be hard for you and your
colleagues to maintain, so people will be scared of touching this code. Instead, write a longer, easier-to-read function and back it with useful
documentation showing what it’ll return, and complement this with tests to
confirm that it <em class="hyperlink">does</em> work as you expect.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Some Thoughts on Good Notebook Practice" class="calibre3"><div class="preface" id="idm46122435240984">
<div class="calibre24" id="calibre_pb_0"/>
</div></section>













</div></section>







</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" epub:type="chapter" class="calibre3" data-pdf-bookmark="Chapter 1. Understanding Performant Python">
<div class="preface" id="understanding_performant_python">
<section data-type="sect1" data-pdf-bookmark="How to Be a Highly Performant Programmer" class="calibre3">
<div class="preface" id="idm46122435387576">
<section data-type="sect2" data-pdf-bookmark="Some Thoughts on Good Notebook Practice" class="calibre3">
<div class="preface" id="idm46122435240984">
<h2 class="calibre43">Some Thoughts on Good Notebook Practice</h2>

<p class="author1">If you’re using <a data-type="indexterm" data-primary="Jupyter Notebooks" id="idm46122435213576" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Jupyter Notebooks, they’re great for visual communication, but
they facilitate laziness. If you find yourself leaving long functions inside
your Notebooks, be comfortable extracting them out to a Python module and then
adding tests.</p>

<p class="author1">Consider prototyping your code in <a data-type="indexterm" data-primary="IPython" id="idm46122435212024" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>IPython or the <a data-type="indexterm" data-primary="QTConsole" id="idm46122435211192" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>QTConsole; turn lines of code into
functions in a Notebook and then promote them out of the Notebook and into a module complemented by
tests. Finally, consider wrapping the code in a class if encapsulation and data
hiding are useful.</p>

<p class="author1">Liberally spread <a data-type="indexterm" data-primary="assert statements" id="idm46122435209720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">assert</code> statements throughout a Notebook to check that your functions are behaving as expected.
You can’t easily test code inside a Notebook, and until you’ve refactored your functions into separate modules, <code class="calibre26">assert</code> checks
are a simple way to add some level of validation. You shouldn’t trust this code until you’ve <span class="publishername">extracted</span> it to a module
and written sensible unit tests.</p>

<p class="author1">Using <code class="calibre26">assert</code> statements to check data in your code should be frowned upon. It is an easy way to assert that certain conditions are
being met, but it isn’t idiomatic Python. To make your code easier to read by other developers, check your expected data state
and then raise an appropriate exception if the check fails. A common exception would be <code class="calibre26">ValueError</code> if a function encounters
an unexpected value. The <a data-type="indexterm" data-primary="Bulwark library" id="idm46122435205512" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/c6QbY" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Bulwark library</a> is an example
of a testing framework focused on Pandas to check that your data meets the specified constraints.</p>

<p class="author1">You may also want to add some sanity checks at the end of your Notebook—a
mixture of logic checks and<a data-type="indexterm" data-primary="raise statement" id="idm46122435203496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="print statement" id="idm46122435202792" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">raise</code> and <code class="calibre26">print</code> statements that demonstrate that you’ve just
generated exactly what you needed. When you return to this code in six months,
you’ll thank yourself for making it easy to see that it worked correctly all the
way through!</p>

<p class="author1">One difficulty with Notebooks is sharing code with source control systems.<a data-type="indexterm" data-primary="nbdime tool" id="idm46122435200472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
<a href="https://oreil.ly/PfR-H" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">nbdime</a> is one of a growing set of new tools that let you diff your Notebooks.
It is a lifesaver and enables collaboration with colleagues.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Getting the Joy Back into Your Work" class="calibre3"><div class="preface" id="idm46122435198680">
<h2 class="calibre43">Getting the Joy Back into Your Work</h2>

<p class="author1">Life can be complicated. In the five years since your authors wrote the first
edition of this book, we’ve jointly experienced through friends and family a number of life
situations, including depression, cancer, home relocations, successful business
exits and failures, and career direction shifts. Inevitably, these external events
will have an impact on anyone’s work and outlook on life.</p>

<p class="author1">Remember to keep looking for the joy in new activities. There are always interesting
details or requirements once you start poking around. You might ask, “why did they make that decision?”
and “how would I do it differently?” and all of a sudden you’re ready to start a conversation
about how things might be changed or improved.</p>

<p class="author1">Keep a log of things that are worth celebrating. It is so easy to forget about
accomplishments and to get caught up in the day-to-day. People get burned out
because they’re always running to keep up, and they forget how much progress
they’ve made.</p>

<p class="author1">We suggest that you build a list of items worth celebrating and note how you
celebrate them. Ian keeps such a list—he’s happily surprised when he
goes to update the list and sees just how many cool things have happened (and
might otherwise have been forgotten!) in the last year. These shouldn’t just be
work milestones; include hobbies and sports, and celebrate the milestones you’ve
achieved. Micha makes sure to prioritize his personal life and spend days
away from the computer to work on nontechnical projects. It is critical to keep
developing your skill set, but it is not necessary to burn out!</p>

<p class="author1">Programming, particularly when performance focused, thrives on a sense of
curiosity and a willingness to always delve deeper into the technical details.
Unfortunately, this curiosity is the first thing to go when you burn out; so take
your time and make sure you enjoy the journey, and keep the joy and the
curiosity.<a data-type="indexterm" data-primary="" data-startref="pp_ch" id="idm46122435193480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mvc_ch" id="idm46122435192504" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="vmc_ch" id="idm46122435191560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>







<div data-type="footnotes" class="calibre52"><p data-type="footnote" id="idm46122429262840" class="calibre53"><sup class="calibre54"><a href="ch01_split_000.xhtml#idm46122429262840-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> Not to be confused with interprocess communication, which shares the same acronym—we’ll look at that topic in <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 9</a>.</p><p data-type="footnote" id="idm46122428772888" class="calibre53"><sup class="calibre54"><a href="ch01_split_000.xhtml#idm46122428772888-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> Speeds in this section are from <a href="https://oreil.ly/pToi7" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">https://oreil.ly/pToi7</em></a>.</p><p data-type="footnote" id="idm46122429019976" class="calibre53"><sup class="calibre54"><a href="ch01_split_000.xhtml#idm46122429019976-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup> Data is from <a href="https://oreil.ly/7SC8d" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">https://oreil.ly/7SC8d</em></a>.</p><p data-type="footnote" id="idm46122435398952" class="calibre53"><sup class="calibre54"><a href="ch01_split_000.xhtml#idm46122435398952-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup> In <a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>, we’ll see how we can regain this control and tune our code all the way down to the memory utilization patterns.</p></div></div></section></div>



  </body></html>