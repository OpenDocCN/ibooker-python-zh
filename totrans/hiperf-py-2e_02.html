<html><head></head><body><div id="sbo-rt-content" class="calibre2"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Profiling to Find Bottlenecks" class="calibre3"><div class="preface" id="chapter-profiling">
<h1 class="calibre23"><span class="publishername">Chapter 2. </span>Profiling to Find Bottlenecks</h1>

<aside data-type="sidebar" epub:type="sidebar" class="calibre40"><div class="sidebar" id="idm46122435188728">
<h5 class="calibre41">Questions You’ll Be Able to Answer After This Chapter</h5>
<ul class="printings">
<li class="calibre21">
<p class="calibre42">How can I identify speed and RAM bottlenecks in my code?</p>
</li>
<li class="calibre21">
<p class="calibre42">How do I profile CPU and memory usage?</p>
</li>
<li class="calibre21">
<p class="calibre42">What depth of profiling should I use?</p>
</li>
<li class="calibre21">
<p class="calibre42">How can I profile a long-running application?</p>
</li>
<li class="calibre21">
<p class="calibre42">What’s happening under the hood with CPython?</p>
</li>
<li class="calibre21">
<p class="calibre42">How do I keep my code correct while tuning performance?</p>
</li>
</ul>
</div></aside>

<p class="author1"><a data-type="indexterm" data-primary="profiling" data-secondary="about" id="pro_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">Profiling</em> lets us find bottlenecks so we can do the least amount of work to get the biggest practical performance gain. While we’d like to get huge gains in speed and reductions in resource usage with little work, practically you’ll aim for your code to run “fast enough” and “lean enough” to fit your needs. Profiling will let you make the most pragmatic decisions for the least overall effort.</p>

<p class="author1">Any measurable resource can be profiled (not just the CPU!). In this chapter we look at both CPU time and memory usage. You could apply similar techniques to measure network bandwidth and disk I/O too.</p>

<p class="author1">If a program is running too slowly or using too much RAM, you’ll want to fix whichever parts of your code are responsible. You could, of course, skip profiling and fix what you <em class="hyperlink">believe</em> might be the problem—but be wary, as you’ll often end up “fixing” the wrong thing. Rather than using your intuition, it is far more sensible to first profile, having defined a
hypothesis, before making changes to the structure of your code.</p>

<p class="author1">Sometimes it’s good to be lazy. By profiling first, you can quickly identify the bottlenecks that need to be solved, and then you can solve just enough of these to achieve the performance you need. If you avoid profiling and jump to optimization, you’ll quite likely do more work in the long run. Always be driven by the results of 
<span class="publishername">profiling</span>.</p>






<section data-type="sect1" data-pdf-bookmark="Profiling Efficiently" class="calibre3"><div class="preface" id="idm46122435175832">
<h1 class="calibre25">Profiling Efficiently</h1>

<p class="author1">The first aim of profiling is to test a representative system to identify what’s slow (or using too much RAM, or causing too much disk I/O or network I/O). Profiling typically adds an overhead (10× to 100× slowdowns can be typical), and you still want your code to be used in as similar to a real-world situation as possible. Extract a test case and isolate the piece of the system that you need to test. Preferably, it’ll have been written to be in its own set of modules already.</p>

<p class="author1">The basic techniques that are introduced first in this chapter include the <a data-type="indexterm" data-primary="%timeit function" data-primary-sortas="timeit" id="idm46122435173160" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="%timeit function" id="idm46122435172184" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">%timeit</code> magic in IPython, <a data-type="indexterm" data-primary="time.time() function" id="idm46122435171128" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">time.time()</code>, and a timing decorator. You can use these techniques to understand the behavior of statements and functions.</p>

<p class="author1">Then we will cover<a data-type="indexterm" data-primary="cProfile" id="idm46122435169464" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">cProfile</code> (<a data-type="xref" href="#profiling-cprofile" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using the cProfile Module”</a>), showing you how to use this built-in tool to understand which functions in your code take the longest to run. This will give you a high-level view of the problem so you can direct your attention to the critical functions.</p>

<p class="author1">Next, we’ll look at <a data-type="indexterm" data-primary="line_profiler" id="idm46122435166696" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">line_profiler</code> (<a data-type="xref" href="#profiling-line-profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using line_profiler for Line-by-Line Measurements”</a>), which will profile your chosen functions on a line-by-line basis. The result will include a count of the number of times each line is called and the <span class="publishername">percentage</span> of time spent on each line. This is exactly the information you need to understand what’s running slowly and why.</p>

<p class="author1">Armed with the results of <code class="calibre26">line_profiler</code>, you’ll have the information you need to move on to using a compiler (<a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>).</p>

<p class="author1">In <a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>, you’ll learn how to use<a data-type="indexterm" data-primary="perf stat" id="idm46122435160744" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">perf stat</code> to understand the number of instructions that are ultimately executed on a CPU and how efficiently the CPU’s caches are utilized. This allows for advanced-level tuning of matrix operations. You should take a look at <a data-type="xref" href="ch06_split_000.xhtml#matrix_perf_python_memory" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-8</a> when you’re done with this chapter.</p>

<p class="author1">After <code class="calibre26">line_profiler</code>, if you’re working with long-running systems, then you’ll be interested in <code class="calibre26">py-spy</code> to peek into already-running Python processes.</p>

<p class="author1">To help you understand why your RAM usage is high, we’ll show you<a data-type="indexterm" data-primary="memory_profiler" id="idm46122435156632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">memory_profiler</code> (<a data-type="xref" href="#memory_profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using memory_profiler to Diagnose Memory Usage”</a>). It is particularly useful for tracking RAM usage over time on a labeled chart, so you can explain to colleagues why certain functions use more RAM than expected.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">Whatever approach you take to profiling your code, you must remember to have adequate unit test coverage in your code. Unit tests help you to avoid silly mistakes and to keep your results reproducible. Avoid them at your peril.</p>

<p class="author1"><em class="hyperlink">Always</em> profile your code before compiling or rewriting your algorithms. You need evidence to determine the most efficient ways to make your code run faster.</p>
</div>

<p class="author1">Next, we’ll give you an introduction to the Python bytecode inside <a data-type="indexterm" data-primary="CPython" data-secondary="bytecode" id="idm46122435151544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>CPython (<a data-type="xref" href="#profiling-dis" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using the dis Module to Examine CPython Bytecode”</a>), so you can understand what’s happening “under the hood.” In particular, having an understanding of how Python’s stack-based virtual machine operates will help you understand why certain coding styles run more slowly than others.</p>

<p class="author1">Before the end of the chapter, we’ll review how to integrate unit tests while profiling (<a data-type="xref" href="#profiling-unit-testing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Unit Testing During Optimization to Maintain Correctness”</a>) to preserve the correctness of your code while you make it run more efficiently.</p>

<p class="author1">We’ll finish with a discussion of profiling strategies (<a data-type="xref" href="#profiling-strategies" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Strategies to Profile Your Code Successfully”</a>) so you can reliably profile your code and gather the correct data to test your hypotheses. Here you’ll learn how dynamic CPU <a data-type="indexterm" data-primary="CPUs (central processing units)" data-secondary="frequency scaling" id="idm46122435146504" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="frequency scaling" id="idm46122435145496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>frequency scaling and features like Turbo Boost can skew your profiling results, and you’ll learn how they can be disabled.</p>

<p class="author1">To walk through all of these steps, we need an easy-to-analyze function. The next section introduces the Julia set. It is a CPU-bound function that’s a little hungry for RAM; it also exhibits nonlinear behavior (so we can’t easily predict the outcomes), which means we need to profile it at runtime rather than analyzing it offline.<a data-type="indexterm" data-primary="" data-startref="pro_ab" id="idm46122435143816" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Introducing the Julia Set" class="calibre3"><div class="preface" id="idm46122435175176">
<h1 class="calibre25">Introducing the Julia Set</h1>

<p class="author1"><a data-type="indexterm" data-primary="Julia set" id="js_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="Julia set" id="pro_js" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <a href="https://oreil.ly/zJ1oB" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Julia set</a> is an interesting CPU-bound problem for us to begin with. It is a fractal sequence that generates a complex output image, named after Gaston Julia.</p>

<p class="author1">The code that follows is a little longer than a version you might write yourself. It has a CPU-bound component and a very explicit set of inputs. This configuration allows us to profile both the CPU usage and the RAM usage so we can understand which parts of our code are consuming two of our scarce computing resources. This implementation is <em class="hyperlink">deliberately</em> suboptimal, so we can identify memory-consuming operations and slow statements. Later in this chapter we’ll fix a slow logic statement and a memory-consuming statement, and in <a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a> we’ll significantly speed up the overall execution time of this function.</p>

<p class="author1">We will analyze a block of code that produces both a false grayscale plot (<a data-type="xref" href="#FIG-julia-example" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-1</a>) and a pure grayscale variant of the Julia set (<a data-type="xref" href="#FIG-julia-example-greyscale" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-3</a>), at the complex point <code class="calibre26">c=-0.62772-0.42193j</code>. A Julia set is produced by calculating each pixel in isolation; this is an “embarrassingly parallel problem,” as no data is shared between points.</p>

<figure class="calibre46"><div id="FIG-julia-example" class="figure">
<img src="Images/hpp2_0201.png" alt="Julia set at -0.62772-0.42193i" class="calibre55"/>
<h6 class="calibre47"><span class="publishername">Figure 2-1. </span>Julia set plot with a false gray scale to highlight detail</h6>
</div></figure>

<p class="author1">If we chose a different <code class="calibre26">c</code>, we’d get a different image. The location we have chosen has regions that are quick to calculate and others that are slow to calculate; this is useful for our analysis.</p>

<p class="author1">The problem is interesting because we calculate each pixel by applying a loop that could be applied an indeterminate number of times. On each iteration we test to see if this coordinate’s value escapes toward infinity, or if it seems to be held by an attractor. <span class="publishername">Coordinates</span> that cause few iterations are colored darkly in <a data-type="xref" href="#FIG-julia-example" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-1</a>, and those that cause a high number of iterations are colored white. White regions are more complex to calculate and so take longer to generate.</p>

<p class="author1">We define a set of <em class="hyperlink">z</em> coordinates that we’ll test. The function that we calculate squares the complex number <code class="calibre26">z</code> and adds <code class="calibre26">c</code>:</p>
<div data-type="equation" class="calibre56">
<math display="block" alttext="f left-parenthesis z right-parenthesis equals z squared plus c">
  <mrow>
    <mi>f</mi>
    <mrow>
      <mo>(</mo>
      <mi>z</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <msup><mi>z</mi> <mn>2</mn> </msup>
    <mo>+</mo>
    <mi>c</mi>
  </mrow>
</math>
</div>

<p class="author1">We iterate on this function while testing to see if the escape condition holds using <code class="calibre26">abs</code>. If the escape function is <code class="calibre26">False</code>, we break out of the loop and record the number of iterations we performed at this coordinate. If the escape function is never <code class="calibre26">False</code>, we stop after <code class="calibre26">maxiter</code> iterations. We will later turn this <code class="calibre26">z</code>’s result into a colored pixel representing this complex location.</p>

<p class="author1">In pseudocode, it might look like this:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">for</code> <code class="n">z</code> <code class="ow">in</code> <code class="n">coordinates</code><code class="p">:</code>
    <code class="kn">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">maxiter</code><code class="p">):</code>  <code class="c"># limited iterations per point</code>
        <code class="kn">if</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2.0</code><code class="p">:</code>  <code class="c"># has the escape condition been broken?</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code><code class="o">*</code><code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
        <code class="kn">else</code><code class="p">:</code>
            <code class="kn">break</code>
    <code class="c"># store the iteration count for each z and draw later</code></pre>

<p class="author1">To explain this function, let’s try two coordinates.</p>

<p class="author1">We’ll use the coordinate that we draw in the top-left corner of the plot at <code class="calibre26">-1.8-1.8j</code>. We must test <code class="calibre26">abs(z) &lt; 2</code> before we can try the update rule:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">z</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1.8</code><code class="o">-</code><code class="mi">1.8j</code>
<code class="kn">print</code><code class="p">(</code><code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">))</code></pre>

<pre data-type="programlisting" class="calibre50">2.54558441227</pre>

<p class="author1">We can see that for the top-left coordinate, the <code class="calibre26">abs(z)</code> test will be <code class="calibre26">False</code> on the zeroth iteration as <code class="calibre26">2.54 &gt;= 2.0</code>, so we do not perform the update rule. The <code class="calibre26">output</code> value for this coordinate <span class="publishername">is <code class="calibre26">0</code>.</span></p>

<p class="author1">Now let’s jump to the center of the plot at <code class="calibre26">z = 0 + 0j</code> and try a few iterations:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">c</code> <code class="o">=</code> <code class="o">-</code><code class="mi">0.62772</code><code class="o">-</code><code class="mi">0.42193j</code>
<code class="n">z</code> <code class="o">=</code> <code class="mi">0</code><code class="o">+</code><code class="mi">0j</code>
<code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">9</code><code class="p">):</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">z</code><code class="o">*</code><code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"{n}: z={z: .5f}, abs(z)={abs(z):0.3f}, c={c: .5f}"</code><code class="p">)</code></pre>

<pre data-type="programlisting" class="calibre50">0: z=-0.62772-0.42193j, abs(z)=0.756, c=-0.62772-0.42193j
1: z=-0.41171+0.10778j, abs(z)=0.426, c=-0.62772-0.42193j
2: z=-0.46983-0.51068j, abs(z)=0.694, c=-0.62772-0.42193j
3: z=-0.66777+0.05793j, abs(z)=0.670, c=-0.62772-0.42193j
4: z=-0.18516-0.49930j, abs(z)=0.533, c=-0.62772-0.42193j
5: z=-0.84274-0.23703j, abs(z)=0.875, c=-0.62772-0.42193j
6: z= 0.02630-0.02242j, abs(z)=0.035, c=-0.62772-0.42193j
7: z=-0.62753-0.42311j, abs(z)=0.757, c=-0.62772-0.42193j
8: z=-0.41295+0.10910j, abs(z)=0.427, c=-0.62772-0.42193j</pre>

<p class="author1">We can see that each update to <code class="calibre26">z</code> for these first iterations leaves it with a value where <code class="calibre26">abs(z) &lt; 2</code> is <code class="calibre26">True</code>. For this coordinate we can iterate 300 times, and still the test will be <code class="calibre26">True</code>. We cannot tell how many iterations we must perform before the condition becomes <code class="calibre26">False</code>, and this may be an infinite sequence. The maximum iteration (<code class="calibre26">maxiter</code>) break clause will stop us from iterating potentially forever.</p>

<p class="author1">In <a data-type="xref" href="#FIG-julia-non-convergence" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-2</a>, we see the first 50 iterations of the preceding sequence. For <code class="calibre26">0+0j</code> (the solid line with circle markers), the sequence appears to repeat every eighth iteration, but each sequence of seven calculations has a minor deviation from the previous sequence—we can’t tell if this point will iterate forever within the <a data-type="indexterm" data-primary="boundary conditions" id="idm46122434962856" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>boundary condition, or for a long time, or maybe for just a few more iterations. The dashed <code class="calibre26">cutoff</code> line shows the boundary at <code class="calibre26">+2</code>.</p>

<figure class="calibre46"><div id="FIG-julia-non-convergence" class="figure">
<img src="Images/hpp2_0202.png" alt="julia non convergence" class="calibre57"/>
<h6 class="calibre47"><span class="publishername">Figure 2-2. </span>Two coordinate examples evolving for the Julia set</h6>
</div></figure>

<p class="author1">For <code class="calibre26">-0.82+0j</code> (the dashed line with diamond markers), we can see that after the ninth update, the absolute result has exceeded the <code class="calibre26">+2</code> cutoff, so we stop updating this value.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Calculating the Full Julia Set" class="calibre3"><div class="preface" id="idm46122435141928">
<h1 class="calibre25">Calculating the Full Julia Set</h1>

<p class="author1">In this section we break down the code that generates the Julia set. We’ll analyze it in various ways throughout this chapter. As shown in <a data-type="xref" href="#profiling-juliaset-intro1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-1</a>, at the start of our module we import the <code class="calibre26">time</code> module for our first profiling approach and define some coordinate constants.</p>
<div id="profiling-juliaset-intro1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-1. </span>Defining global constants for the coordinate space</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="sd">"""Julia set generator without optional PIL-based image drawing"""</code>
<code class="kn">import</code> <code class="nn">time</code>

<code class="c"># area of complex space to investigate</code>
<code class="n">x1</code><code class="p">,</code> <code class="n">x2</code><code class="p">,</code> <code class="n">y1</code><code class="p">,</code> <code class="n">y2</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1.8</code><code class="p">,</code> <code class="mi">1.8</code><code class="p">,</code> <code class="o">-</code><code class="mi">1.8</code><code class="p">,</code> <code class="mi">1.8</code>
<code class="n">c_real</code><code class="p">,</code> <code class="n">c_imag</code> <code class="o">=</code> <code class="o">-</code><code class="mi">0.62772</code><code class="p">,</code> <code class="o">-.</code><code class="mi">42193</code></pre></div>

<p class="author1">To generate the plot, we create two lists of input data. The first is <code class="calibre26">zs</code> (complex <em class="hyperlink">z</em> coordinates), and the second is <code class="calibre26">cs</code> (a complex initial condition). Neither list varies, and we could optimize <code class="calibre26">cs</code> to a single <code class="calibre26">c</code> value as a constant. The rationale for building two input lists is so that we have some reasonable-looking data to profile when we profile RAM usage later in this chapter.</p>

<p class="author1">To build the <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists, we need to know the coordinates for each <code class="calibre26">z</code>. In <a data-type="xref" href="#profiling-juliaset-intro2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-2</a>, we build up these coordinates using <code class="calibre26">xcoord</code> and <code class="calibre26">ycoord</code> and a specified <code class="calibre26">x_step</code> and <code class="calibre26">y_step</code>. The somewhat verbose nature of this setup is useful when porting the code to other tools (such as <code class="calibre26">numpy</code>) and to other Python environments, as it helps to have everything <em class="hyperlink">very</em> clearly defined for debugging.</p>
<div id="profiling-juliaset-intro2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-2. </span>Establishing the coordinate lists as inputs to our calculation <span class="publishername">function</span></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">calc_pure_python</code><code class="p">(</code><code class="n">desired_width</code><code class="p">,</code> <code class="n">max_iterations</code><code class="p">):</code>
    <code class="sd">"""Create a list of complex coordinates (zs) and complex parameters (cs),</code>
<code class="sd">    build Julia set"""</code>
    <code class="n">x_step</code> <code class="o">=</code> <code class="p">(</code><code class="n">x2</code> <code class="o">-</code> <code class="n">x1</code><code class="p">)</code> <code class="o">/</code> <code class="n">desired_width</code>
    <code class="n">y_step</code> <code class="o">=</code> <code class="p">(</code><code class="n">y1</code> <code class="o">-</code> <code class="n">y2</code><code class="p">)</code> <code class="o">/</code> <code class="n">desired_width</code>
    <code class="n">x</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">y</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">ycoord</code> <code class="o">=</code> <code class="n">y2</code>
    <code class="kn">while</code> <code class="n">ycoord</code> <code class="o">&gt;</code> <code class="n">y1</code><code class="p">:</code>
        <code class="n">y</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">ycoord</code><code class="p">)</code>
        <code class="n">ycoord</code> <code class="o">+=</code> <code class="n">y_step</code>
    <code class="n">xcoord</code> <code class="o">=</code> <code class="n">x1</code>
    <code class="kn">while</code> <code class="n">xcoord</code> <code class="o">&lt;</code> <code class="n">x2</code><code class="p">:</code>
        <code class="n">x</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">xcoord</code><code class="p">)</code>
        <code class="n">xcoord</code> <code class="o">+=</code> <code class="n">x_step</code>
    <code class="c"># build a list of coordinates and the initial condition for each cell.</code>
    <code class="c"># Note that our initial condition is a constant and could easily be removed,</code>
    <code class="c"># we use it to simulate a real-world scenario with several inputs to our</code>
    <code class="c"># function</code>
    <code class="n">zs</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">cs</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="kn">for</code> <code class="n">ycoord</code> <code class="ow">in</code> <code class="n">y</code><code class="p">:</code>
        <code class="kn">for</code> <code class="n">xcoord</code> <code class="ow">in</code> <code class="n">x</code><code class="p">:</code>
            <code class="n">zs</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">complex</code><code class="p">(</code><code class="n">xcoord</code><code class="p">,</code> <code class="n">ycoord</code><code class="p">))</code>
            <code class="n">cs</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">complex</code><code class="p">(</code><code class="n">c_real</code><code class="p">,</code> <code class="n">c_imag</code><code class="p">))</code>

    <code class="kn">print</code><code class="p">(</code><code class="s">"Length of x:"</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">x</code><code class="p">))</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Total elements:"</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">))</code>
    <code class="n">start_time</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">output</code> <code class="o">=</code> <code class="n">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">max_iterations</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">)</code>
    <code class="n">end_time</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">secs</code> <code class="o">=</code> <code class="n">end_time</code> <code class="o">-</code> <code class="n">start_time</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="o">.</code><code class="calibre26">__name__</code> <code class="o">+</code> <code class="s">" took"</code><code class="p">,</code> <code class="n">secs</code><code class="p">,</code> <code class="s">"seconds"</code><code class="p">)</code>

    <code class="c"># This sum is expected for a 1000^2 grid with 300 iterations</code>
    <code class="c"># It ensures that our code evolves exactly as we'd intended</code>
    <code class="kn">assert</code> <code class="nb">sum</code><code class="p">(</code><code class="n">output</code><code class="p">)</code> <code class="o">==</code> <code class="mi">33219980</code></pre></div>

<p class="author1">Having built the <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists, we output some information about the size of the lists and calculate the <code class="calibre26">output</code> list  via <a data-type="indexterm" data-primary="calculate_z_serial_purepython function" id="idm46122434891480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">calculate_z_serial_purepython</code>. Finally, we <code class="calibre26">sum</code> the contents of <code class="calibre26">output</code> and <code class="calibre26">assert</code> that it matches the expected output value. Ian uses it here to confirm that no errors creep into the book.</p>

<p class="author1">As the code is deterministic, we can verify that the function works as we expect by summing all the calculated values. This is useful as a sanity check—when we make changes to numerical code, it is <em class="hyperlink">very</em> sensible to check that we haven’t broken the algorithm. Ideally, we would use unit tests and test more than one configuration of the problem.</p>

<p class="author1">Next, in <a data-type="xref" href="#profiling-juliaset-intro3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-3</a>, we define the <code class="calibre26">calculate_z_serial_purepython</code> function, which expands on the algorithm we discussed earlier. Notably, we also define an <code class="calibre26">output</code> list at the start that has the same length as the input <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists.</p>
<div id="profiling-juliaset-intro3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-3. </span>Our CPU-bound calculation function</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code> <code class="ow">and</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">Now we call the calculation routine in <a data-type="xref" href="#profiling-juliaset-intro4" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-4</a>. By wrapping it in a <code class="calibre26">__main__</code> check, we can safely import the module without starting the calculations for some of the profiling methods. Here, we’re not showing the method used to plot the output.</p>
<div id="profiling-juliaset-intro4" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-4. </span><code class="calibre26">__main__</code> for our code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="c"># Calculate the Julia set using a pure Python solution with</code>
    <code class="c"># reasonable defaults for a laptop</code>
    <code class="n">calc_pure_python</code><code class="p">(</code><code class="n">desired_width</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">max_iterations</code><code class="o">=</code><code class="mi">300</code><code class="p">)</code></pre></div>

<p class="author1">Once we run the code, we see some output about the complexity of the problem:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="c"># running the above produces:</code>
<code class="n">Length</code> <code class="n">of</code> <code class="n">x</code><code class="p">:</code> <code class="mi">1000</code>
<code class="n">Total</code> <code class="n">elements</code><code class="p">:</code> <code class="mi">1000000</code>
<code class="n">calculate_z_serial_purepython</code> <code class="n">took</code> <code class="mi">8.087012767791748</code> <code class="n">seconds</code></pre>

<p class="author1">In the false-grayscale plot (<a data-type="xref" href="#FIG-julia-example" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-1</a>), the high-contrast color changes gave us an idea of where the cost of the function was slow changing or fast changing. Here, in <a data-type="xref" href="#FIG-julia-example-greyscale" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-3</a>, we have a linear color map: black is quick to calculate, and white is expensive to calculate.</p>

<p class="author1">By showing two representations of the same data, we can see that lots of detail is lost in the linear mapping. Sometimes it can be useful to have various representations in mind when investigating the cost of a function.<a data-type="indexterm" data-primary="" data-startref="js_ab" id="idm46122434563320" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_js" id="idm46122434420248" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<figure class="calibre46"><div id="FIG-julia-example-greyscale" class="figure">
<img src="Images/hpp2_0203.png" alt="Julia set at -0.62772-0.42193i" class="calibre60"/>
<h6 class="calibre47"><span class="publishername">Figure 2-3. </span>Julia plot example using a pure gray scale</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Simple Approaches to Timing—print and a Decorator" class="calibre3"><div class="preface" id="idm46122434957432">
<h1 class="calibre25">Simple Approaches to Timing—print and a Decorator</h1>

<p class="author1"><a data-type="indexterm" data-primary="profiling" data-secondary="timing" id="pro_tim" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>After <a data-type="xref" href="#profiling-juliaset-intro4" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-4</a>, we saw the output generated by several <code class="calibre26">print</code> statements in our code. On Ian’s laptop, this code takes approximately 8 seconds to run using CPython 3.7. It is useful to note that execution time always varies. You must observe the normal variation when you’re timing your code, or you might incorrectly attribute an improvement in your code to what is simply a random variation in execution time.</p>

<p class="author1">Your computer will be performing other tasks while running your code, such as <span class="publishername">accessing</span> the network, disk, or RAM, and these factors can cause variations in the execution time of your program.</p>

<p class="author1">Ian’s laptop is a Dell 9550 with an Intel Core I7 6700HQ (2.6 GHz, 6 MB cache, Quad Core with Hyperthreading) and 32 GB of RAM running Linux Mint 19.1 (Ubuntu 18.04).</p>

<p class="author1">In<a data-type="indexterm" data-primary="calc_pure_python function" id="idm46122434410040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">calc_pure_python</code> (<a data-type="xref" href="#profiling-juliaset-intro2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-2</a>), we can see several<a data-type="indexterm" data-primary="timing" data-secondary="print" id="idm46122434407912" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">print</code> statements. This is the simplest way to measure the <a data-type="indexterm" data-primary="execution time variations" id="idm46122434406328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>execution time of a piece of code <em class="hyperlink">inside</em> a function. It is a basic approach, but despite being quick and dirty, it can be very useful when you’re first looking at a piece of code.</p>

<p class="author1">Using <a data-type="indexterm" data-primary="print statement" id="idm46122434404648" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">print</code> statements is commonplace when debugging and profiling code. It quickly becomes unmanageable but is useful for short investigations. Try to tidy up the <code class="calibre26">print</code> statements when you’re done with them, or they will clutter your <code class="calibre26">stdout</code>.</p>

<p class="author1">A slightly cleaner approach is to use a<a data-type="indexterm" data-primary="timing" data-secondary="decorators" id="idm46122434402072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="decorators" id="idm46122434401096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">decorator</em>—here, we add one line of code above the function that we care about. Our decorator can be very simple and just replicate the effect of the <code class="calibre26">print</code> statements. Later, we can make it more advanced.</p>

<p class="author1">In <a data-type="xref" href="#profiling-juliaset-timefn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-5</a>, we define a new function, <a data-type="indexterm" data-primary="timefn function" id="idm46122434383400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">timefn</code>, which takes a function as an argument: the inner function, <code class="calibre26">measure_time</code>, takes <code class="calibre26">*args</code> (a variable number of positional arguments) and <code class="calibre26">**kwargs</code> (a variable number of key/value arguments) and passes them through to <code class="calibre26">fn</code> for execution. Around the execution of <code class="calibre26">fn</code>, we capture <a data-type="indexterm" data-primary="time.time() function" id="idm46122434380168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">time.time()</code> and then <code class="calibre26">print</code> the result along with <code class="calibre26">fn.__name__</code>. The overhead of using this decorator is small, but if you’re calling <code class="calibre26">fn</code> millions of times, the overhead might become noticeable. We use <code class="calibre26">@wraps(fn)</code> to expose the function name and docstring to the caller of the decorated function (otherwise, we would see the function name and docstring for the decorator, not the function it decorates).</p>
<div id="profiling-juliaset-timefn" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-5. </span>Defining a decorator to automate timing measurements</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">functools</code> <code class="kn">import</code> <code class="n">wraps</code>

<code class="kn">def</code> <code class="nf">timefn</code><code class="p">(</code><code class="n">fn</code><code class="p">):</code>
    <code class="nd">@wraps</code><code class="p">(</code><code class="n">fn</code><code class="p">)</code>
    <code class="kn">def</code> <code class="nf">measure_time</code><code class="p">(</code><code class="o">*</code><code class="n">args</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="n">t1</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
        <code class="n">result</code> <code class="o">=</code> <code class="n">fn</code><code class="p">(</code><code class="o">*</code><code class="n">args</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="n">t2</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
        <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"@timefn: {fn.__name__} took {t2 - t1} seconds"</code><code class="p">)</code>
        <code class="kn">return</code> <code class="n">result</code>
    <code class="kn">return</code> <code class="n">measure_time</code>

<code class="nd">@timefn</code>
<code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="o">...</code></pre></div>

<p class="author1">When we run this version (we keep the <code class="calibre26">print</code> statements from before), we can see that the execution time in the decorated version is ever-so-slightly quicker than the call from <code class="calibre26">calc_pure_python</code>. This is due to the overhead of calling a function (the difference is very tiny):</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">Length</code> <code class="n">of</code> <code class="n">x</code><code class="p">:</code> <code class="mi">1000</code>
<code class="n">Total</code> <code class="n">elements</code><code class="p">:</code> <code class="mi">1000000</code>
<code class="nd">@timefn</code><code class="p">:</code><code class="n">calculate_z_serial_purepython</code> <code class="n">took</code> <code class="mi">8.00485110282898</code> <code class="n">seconds</code>
<code class="n">calculate_z_serial_purepython</code> <code class="n">took</code> <code class="mi">8.004898071289062</code> <code class="n">seconds</code></pre>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">The addition of profiling information will inevitably slow down your code—some profiling options are very informative and induce a heavy speed penalty. The trade-off between profiling detail and speed will be something you have to consider.</p>
</div>

<p class="author1">We can use the <code class="calibre26">timeit</code> module as another way to get a coarse measurement of the execution speed of our CPU-bound function. More typically, you would use this when timing different types of simple expressions as you experiment with ways to solve a problem.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">The <code class="calibre26">timeit</code> module temporarily disables the garbage <span class="publishername">collector.</span> This might impact the speed you’ll see with real-world operations if the garbage collector would normally be invoked by your operations. See the <a href="https://oreil.ly/2Zvyk" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Python documentation</a> for help on this.</p>
</div>

<p class="author1">From the command line, you can run <code class="calibre26">timeit</code> as follows:</p>

<pre data-type="programlisting" class="calibre50">python -m timeit -n 5 -r 1 -s "import julia1" \
 "julia1.calc_pure_python(desired_width=1000, max_iterations=300)"</pre>

<p class="author1">Note that you have to import the module as a setup step using <code class="calibre26">-s</code>, as <code class="calibre26">calc_pure_python</code> is inside that module. <code class="calibre26">timeit</code> has some sensible defaults for short sections of code, but for longer-running functions it can be sensible to specify the number of loops (<code class="calibre26">-n 5</code>) and the number of repetitions (<code class="calibre26">-r 5</code>) to repeat the experiments. The best result of all the repetitions is given as the answer. Adding the <a data-type="indexterm" data-primary="verbose flag" id="idm46122434283992" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>verbose flag (<code class="calibre26">-v</code>) shows the cumulative time of all the loops by each repetition, which can help your variability in the results.</p>

<p class="author1">By default, if we run <code class="calibre26">timeit</code> on this function without specifying <code class="calibre26">-n</code> and <code class="calibre26">-r</code>, it runs 10 loops with 5 repetitions, and this takes six minutes to complete. Overriding the defaults can make sense if you want to get your results a little faster.</p>

<p class="author1">We’re interested only in the best-case results, as other results will probably have been impacted by other processes:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="mi">5</code> <code class="n">loops</code><code class="p">,</code> <code class="n">best</code> <code class="n">of</code> <code class="mi">1</code><code class="p">:</code> <code class="mi">8.45</code> <code class="n">sec</code> <code class="n">per</code> <code class="n">loop</code></pre>

<p class="author1">Try running the benchmark several times to check if you get varying results—you may need more repetitions to settle on a stable fastest-result time. There is no “correct” configuration, so if you see a wide variation in your timing results, do more repetitions until your final result is stable.</p>

<p class="author1">Our results show that the overall cost of calling <code class="calibre26">calc_pure_python</code> is 8.45 seconds (as the best case), while single calls to <a data-type="indexterm" data-primary="calculate_z_serial_purepython function" id="idm46122434271544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">calculate_z_serial_purepython</code> take 8.0 seconds as measured by the <code class="calibre26">@timefn</code> decorator. The difference is mainly the time taken to create the <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists.</p>

<p class="author1">Inside IPython, we can use the magic <a data-type="indexterm" data-primary="%timeit function" data-primary-sortas="timeit" id="idm46122434269016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="%timeit function" id="idm46122434191672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">%timeit</code> in the same way. If you are developing your code interactively in IPython or in a Jupyter Notebook, you can use this:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">In</code> <code class="p">[</code><code class="mi">1</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">julia1</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">julia1</code><code class="o">.</code><code class="n">calc_pure_python</code><code class="p">(</code><code class="n">desired_width</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">max_iterations</code><code class="o">=</code><code class="mi">300</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">Be aware that “best” is calculated differently by the <code class="calibre26">timeit.py</code> approach and the <code class="calibre26">%timeit</code> approach in Jupyter and IPython. <code class="calibre26">timeit.py</code> uses the minimum value seen. IPython in 2016 switched to using the mean and standard deviation. Both methods have their flaws, but generally they’re both “reasonably good”; you can’t compare between them, though. Use one method or the other; don’t mix them.</p>
</div>

<p class="author1">It is worth considering the variation in load that you get on a normal computer. Many background tasks are running (e.g., Dropbox, backups) that could impact the CPU and disk resources at random. Scripts in web pages can also cause unpredictable resource usage. <a data-type="xref" href="#FIG-julia-set-system-monitor-trimmed" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-4</a> shows the single CPU being used at 100% for some of the timing steps we just performed; the other cores on this machine are each lightly working on other tasks.</p>

<figure class="calibre46"><div id="FIG-julia-set-system-monitor-trimmed" class="figure">
<img src="Images/hpp2_0204.png" alt="System Monitor (Ubuntu) showing background CPU usage during timings" class="calibre61"/>
<h6 class="calibre47"><span class="publishername">Figure 2-4. </span>System Monitor on Ubuntu showing variation in background CPU usage while we time our function</h6>
</div></figure>

<p class="author1">Occasionally, the System Monitor shows spikes of activity on this machine. It is sensible to watch your System Monitor to check that nothing else is interfering with your critical resources (CPU, disk, network).</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Simple Timing Using the Unix time Command" class="calibre3"><div class="preface" id="idm46122434416456">
<h1 class="calibre25">Simple Timing Using the Unix time Command</h1>

<p class="author1"><a data-type="indexterm" data-primary="timing" data-secondary="Unix time command" id="tim_utc" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>We can step outside of Python for a moment to use a standard system utility on Unix-like systems. The following will record various views on the execution time of your program, and it won’t care about the internal structure of your code:</p>

<pre data-type="programlisting" class="calibre50">$ /usr/bin/time -p python julia1_nopil.py
Length of x: 1000
Total elements: 1000000
calculate_z_serial_purepython took 8.279886722564697 seconds
real 8.84
user 8.73
sys 0.10</pre>

<p class="author1">Note that we specifically use <code class="calibre26">/usr/bin/time</code> rather than <code class="calibre26">time</code> so we get the system’s <code class="calibre26">time</code> and not the simpler (and less useful) version built into our shell. If you try <code class="calibre26">time --verbose</code> quick-and-dirty get an error, you’re probably looking at the shell’s built-in <code class="calibre26">time</code> command and not the system command.</p>

<p class="author1">Using the <a data-type="indexterm" data-primary="-p portability flag" data-primary-sortas="p" id="idm46122434137624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="-p portability flag" id="idm46122434136616" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">-p</code> portability flag, we get three results:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27"><code class="calibre26">real</code> records the wall clock or elapsed time.</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">user</code> records the amount of time the CPU spent on your task outside of <a data-type="indexterm" data-primary="Kernel" id="idm46122434132936" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>kernel functions.</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">sys</code> records the time spent in kernel-level functions.</p>
</li>
</ul>

<p class="author1">By adding <code class="calibre26">user</code> and <code class="calibre26">sys</code>, you get a sense of how much time was spent in the CPU. The difference between this and <code class="calibre26">real</code> might tell you about the amount of time spent waiting for I/O; it might also suggest that your system is busy running other tasks that are distorting your measurements.</p>

<p class="author1"><code class="calibre26">time</code> is useful because it isn’t specific to Python. It includes the time taken to start the <code class="calibre26">python</code> executable, which might be significant if you start lots of fresh processes (rather than having a long-running single process). If you often have short-running scripts where the startup time is a significant part of the overall runtime, then <code class="calibre26">time</code> can be a more useful measure.</p>

<p class="author1">We can add the <code class="calibre26">--verbose</code> flag to get even more output:</p>

<pre data-type="programlisting" class="calibre50">$ /usr/bin/time --verbose python julia1_nopil.py
Length of x: 1000
Total elements: 1000000
calculate_z_serial_purepython took 8.477287530899048 seconds
 Command being timed: "python julia1_nopil.py"
 User time (seconds): 8.97
 System time (seconds): 0.05
 Percent of CPU this job got: 99%
 Elapsed (wall clock) time (h:mm:ss or m:ss): 0:09.03
 Average shared text size (kbytes): 0
 Average unshared data size (kbytes): 0
 Average stack size (kbytes): 0
 Average total size (kbytes): 0
 Maximum resident set size (kbytes): 98620
 Average resident set size (kbytes): 0
 Major (requiring I/O) page faults: 0
 Minor (reclaiming a frame) page faults: 26645
 Voluntary context switches: 1
 Involuntary context switches: 27
 Swaps: 0
 File system inputs: 0
 File system outputs: 0
 Socket messages sent: 0
 Socket messages received: 0
 Signals delivered: 0
 Page size (bytes): 4096
 Exit status: 0</pre>

<p class="author1">Probably the most useful indicator here is <code class="calibre26">Major (requiring I/O) page faults</code>, as this indicates whether the operating system is having to load pages of data from the disk because the data no longer resides in RAM. This will cause a speed penalty.</p>

<p class="author1">In our example, the code and data requirements are small, so no page faults occur. If you have a memory-bound process, or several programs that use variable and large amounts of RAM, you might find that this gives you a clue as to which program is being slowed down by disk accesses at the operating system level because parts of it have been swapped out of RAM to disk.<a data-type="indexterm" data-primary="" data-startref="pro_tim" id="idm46122434095032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="tim_utc" id="idm46122434094056" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Using the cProfile Module" class="calibre3"><div class="preface" id="profiling-cprofile">
<h1 class="calibre25">Using the cProfile Module</h1>

<p class="author1"><a data-type="indexterm" data-primary="cProfile" id="cpro_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="cProfile" id="pro_cpro" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">cProfile</code> is a built-in profiling tool in the standard library. It hooks into the virtual machine in CPython to measure the time taken to run every function that it sees. This introduces a greater overhead, but you get correspondingly more information. Sometimes the additional information can lead to surprising insights into your code.</p>

<p class="author1"><code class="calibre26">cProfile</code> is one of two profilers in the standard library, alongside <code class="calibre26">profile</code>. <code class="calibre26">profile</code> is the original and slower pure Python profiler; <code class="calibre26">cProfile</code> has the same interface as <code class="calibre26">profile</code> and is written in <code class="calibre26">C</code> for a lower overhead. If you’re curious about the history of these libraries, see <a href="http://bit.ly/cProfile_request" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Armin Rigo’s 2005 request</a> to include <code class="calibre26">cProfile</code> in the standard library.</p>

<p class="author1">A good practice when profiling is to generate a<a data-type="indexterm" data-primary="profiling" data-secondary="forming a hypothesis" id="idm46122434083368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">hypothesis</em> about the speed of parts of your code before you profile it. Ian likes to print out the code snippet in question and annotate it. Forming a hypothesis ahead of time means you can measure how wrong you are (and you will be!) and improve your intuition about certain coding styles.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">You should never avoid profiling in favor of a gut instinct (we warn you—you <em class="hyperlink">will</em> get it wrong!). It is definitely worth forming a hypothesis ahead of profiling to help you learn to spot possible slow choices in your code, and you should always back up your choices with evidence.</p>
</div>

<p class="author1">Always be driven by results that you have measured, and always start with some quick-and-dirty profiling to make sure you’re addressing the right area. There’s nothing more humbling than cleverly optimizing a section of code only to realize (hours or days later) that you missed the slowest part of the process and haven’t really addressed the underlying problem at all.</p>

<p class="author1">Let’s hypothesize that <code class="calibre26">calculate_z_serial_purepython</code> is the slowest part of the code. In that function, we do a lot of dereferencing and make many calls to basic arithmetic operators and the <code class="calibre26">abs</code> function. These will probably show up as consumers of CPU resources.</p>

<p class="author1">Here, we’ll use the <code class="calibre26">cProfile</code> module to run a variant of the code. The output is spartan but helps us figure out where to analyze further.</p>

<p class="author1">The <code class="calibre26">-s cumulative</code> flag tells <code class="calibre26">cProfile</code> to sort by cumulative time spent inside each function; this gives us a view into the slowest parts of a section of code. The <code class="calibre26">cProfile</code> output is written to screen directly after our usual <code class="calibre26">print</code> results:</p>

<pre data-type="programlisting" data-code-language="python3" class="calibre50"><code class="err">$</code> <code class="n">python</code> <code class="o">-</code><code class="n">m</code> <code class="n">cProfile</code> <code class="o">-</code><code class="n">s</code> <code class="n">cumulative</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code>
<code class="o">...</code>
<code class="n">Length</code> <code class="n">of</code> <code class="n">x</code><code class="p">:</code> <code class="mi">1000</code>
<code class="n">Total</code> <code class="n">elements</code><code class="p">:</code> <code class="mi">1000000</code>
<code class="n">calculate_z_serial_purepython</code> <code class="n">took</code> <code class="mi">11.498265266418457</code> <code class="n">seconds</code>
         <code class="mi">36221995</code> <code class="n">function</code> <code class="n">calls</code> <code class="ow">in</code> <code class="mi">12.234</code> <code class="n">seconds</code>

  <code class="n">Ordered</code> <code class="n">by</code><code class="p">:</code> <code class="n">cumulative</code> <code class="n">time</code>

  <code class="n">ncalls</code>  <code class="n">tottime</code>  <code class="n">percall</code>  <code class="n">cumtime</code>  <code class="n">percall</code> <code class="n">filename</code><code class="p">:</code><code class="n">lineno</code><code class="p">(</code><code class="n">function</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>   <code class="mi">12.234</code>   <code class="mi">12.234</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">exec</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.038</code>    <code class="mi">0.038</code>   <code class="mi">12.234</code>   <code class="mi">12.234</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">0.571</code>    <code class="mi">0.571</code>   <code class="mi">12.197</code>   <code class="mi">12.197</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">23</code>
                                              <code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">8.369</code>    <code class="mi">8.369</code>   <code class="mi">11.498</code>   <code class="mi">11.498</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">9</code>
                                              <code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
<code class="mi">34219980</code>    <code class="mi">3.129</code>    <code class="mi">0.000</code>    <code class="mi">3.129</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">abs</code><code class="p">}</code>
 <code class="mi">2002000</code>    <code class="mi">0.121</code>    <code class="mi">0.000</code>    <code class="mi">0.121</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">method</code> <code class="s">'append'</code> <code class="n">of</code> <code class="s">'list'</code> <code class="n">objects</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">sum</code><code class="p">}</code>
       <code class="mi">3</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">print</code><code class="p">}</code>
       <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">}</code>
       <code class="mi">4</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">len</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">method</code> <code class="s">'disable'</code> <code class="n">of</code>
                                              <code class="s">'_lsprof.Profiler'</code> <code class="n">objects</code><code class="p">}</code></pre>

<p class="author1">Sorting by cumulative time gives us an idea about where the majority of execution time is spent. This result shows us that 36,221,995 function calls occurred in just over 12 seconds (this time includes the overhead of using <code class="calibre26">cProfile</code>). Previously, our code took around 8 seconds to execute—we’ve just added a 4-second penalty by measuring how long each function takes to execute.</p>

<p class="author1">We can see that the entry point to the code <code class="calibre26">julia1_nopil.py</code> on line 1 takes a total of 12 seconds. This is just the <code class="calibre26">__main__</code> call to <code class="calibre26">calc_pure_python</code>. <code class="calibre26">ncalls</code> is 1, indicating that this line is executed only once.</p>

<p class="author1">Inside <code class="calibre26">calc_pure_python</code>, the call to <code class="calibre26">calculate_z_serial_purepython</code> consumes 11 seconds. Both functions are called only once. We can derive that approximately 1 second is spent on lines of code inside <code class="calibre26">calc_pure_python</code>, separate to calling the CPU-intensive <code class="calibre26">calculate_z_serial_purepython</code> function. However, we can’t derive <em class="hyperlink">which</em> lines take the time inside the function using <code class="calibre26">cProfile</code>.</p>

<p class="author1">Inside <code class="calibre26">calculate_z_serial_purepython</code>, the time spent on lines of code (without calling other functions) is 8 seconds. This function makes 34,219,980 calls to <code class="calibre26">abs</code>, which take a total of 3 seconds, along with other calls that do not cost much time.</p>

<p class="author1">What about the <code class="calibre26">{abs}</code> call? This line is measuring the individual calls to the <code class="calibre26">abs</code> function inside <code class="calibre26">calculate_z_serial_purepython</code>. While the per-call cost is negligible (it is recorded as 0.000 seconds), the total time for 34,219,980 calls is 3 seconds. We couldn’t predict in advance exactly how many calls would be made to <code class="calibre26">abs</code>, as the Julia function has unpredictable dynamics (that’s why it is so interesting to look at).</p>

<p class="author1">At best we could have said that it will be called a minimum of 1 million times, as we’re calculating <code class="calibre26">1000*1000</code> pixels. At most it will be called 300 million times, as we calculate 1,000,000 pixels with a maximum of 300 iterations. So 34 million calls is roughly 10% of the worst case.</p>

<p class="author1">If we look at the original grayscale image (<a data-type="xref" href="#FIG-julia-example-greyscale" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-3</a>) and, in our mind’s eye, squash the white parts together and into a corner, we can estimate that the expensive white region accounts for roughly 10% of the rest of the image.</p>

<p class="author1">The next line in the profiled output, <code class="calibre26">{method 'append' of 'list' objects}</code>, details the creation of 2,002,000 list items.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Why 2,002,000 items? Before you read on, think about how many list items are being constructed.</p>
</div>

<p class="author1">This creation of 2,002,000 items is occurring in <code class="calibre26">calc_pure_python</code> during the setup phase.</p>

<p class="author1">The <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists will be <code class="calibre26">1000*1000</code> items each (generating 1,000,000 * 2 calls), and these are built from a list of 1,000 <em class="hyperlink">x</em> and 1,000 <em class="hyperlink">y</em> coordinates. In total, this is 2,002,000 calls to append.</p>

<p class="author1">It is important to note that this <code class="calibre26">cProfile</code> output is not ordered by parent functions; it is summarizing the expense of all functions in the executed block of code. Figuring out what is happening on a line-by-line basis is very hard with <code class="calibre26">cProfile</code>, as we get profile information only for the function calls themselves, not for each line within the functions.</p>

<p class="author1">Inside <code class="calibre26">calculate_z_serial_purepython</code>, we can account for <code class="calibre26">{abs}</code>, and in total this function costs approximately 3.1 seconds. We know that <code class="calibre26">calculate_z_serial_purepython</code> costs 11.4 seconds in total.</p>

<p class="author1">The final line of the profiling output refers to <code class="calibre26">lsprof</code>; this is the original name of the tool that evolved into <code class="calibre26">cProfile</code> and can be ignored.</p>

<p class="author1">To get more control over the results of <code class="calibre26">cProfile</code>, we can write a statistics file and then analyze it in Python:</p>

<pre data-type="programlisting" class="calibre50">$ python -m cProfile -o profile.stats julia1.py</pre>

<p class="author1">We can load this into Python as follows, and it will give us the same cumulative time report as before:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">In</code> <code class="p">[</code><code class="mi">1</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">pstats</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="n">p</code> <code class="o">=</code> <code class="n">pstats</code><code class="o">.</code><code class="n">Stats</code><code class="p">(</code><code class="s">"profile.stats"</code><code class="p">)</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="n">p</code><code class="o">.</code><code class="n">sort_stats</code><code class="p">(</code><code class="s">"cumulative"</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="o">&lt;</code><code class="n">pstats</code><code class="o">.</code><code class="n">Stats</code> <code class="n">at</code> <code class="mi">0x7f77088edf28</code><code class="o">&gt;</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">4</code><code class="p">]:</code> <code class="n">p</code><code class="o">.</code><code class="n">print_stats</code><code class="p">()</code>
<code class="n">Fri</code> <code class="n">Jun</code> <code class="mi">14</code> <code class="mi">17</code><code class="p">:</code><code class="mi">59</code><code class="p">:</code><code class="mi">28</code> <code class="mi">2019</code>    <code class="n">profile</code><code class="o">.</code><code class="n">stats</code>

         <code class="mi">36221995</code> <code class="n">function</code> <code class="n">calls</code> <code class="ow">in</code> <code class="mi">12.169</code> <code class="n">seconds</code>

  <code class="n">Ordered</code> <code class="n">by</code><code class="p">:</code> <code class="n">cumulative</code> <code class="n">time</code>

  <code class="n">ncalls</code>  <code class="n">tottime</code>  <code class="n">percall</code>  <code class="n">cumtime</code>  <code class="n">percall</code> <code class="n">filename</code><code class="p">:</code><code class="n">lineno</code><code class="p">(</code><code class="n">function</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>   <code class="mi">12.169</code>   <code class="mi">12.169</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">exec</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.033</code>    <code class="mi">0.033</code>   <code class="mi">12.169</code>   <code class="mi">12.169</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">0.576</code>    <code class="mi">0.576</code>   <code class="mi">12.135</code>   <code class="mi">12.135</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">23</code>
                                              <code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
       <code class="mi">1</code>    <code class="mi">8.266</code>    <code class="mi">8.266</code>   <code class="mi">11.429</code>   <code class="mi">11.429</code> <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">9</code>
                                              <code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
<code class="mi">34219980</code>    <code class="mi">3.163</code>    <code class="mi">0.000</code>    <code class="mi">3.163</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">abs</code><code class="p">}</code>
 <code class="mi">2002000</code>    <code class="mi">0.123</code>    <code class="mi">0.000</code>    <code class="mi">0.123</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">method</code> <code class="s">'append'</code> <code class="n">of</code> <code class="s">'list'</code> <code class="n">objects</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">sum</code><code class="p">}</code>
       <code class="mi">3</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">print</code><code class="p">}</code>
       <code class="mi">4</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">len</code><code class="p">}</code>
       <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">}</code>
       <code class="mi">1</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code> <code class="p">{</code><code class="n">method</code> <code class="s">'disable'</code> <code class="n">of</code>
                                              <code class="s">'_lsprof.Profiler'</code> <code class="n">objects</code><code class="p">}</code></pre>

<p class="author1">To trace which functions we’re profiling, we can print the caller information. In the following two listings we can see that <code class="calibre26">calculate_z_serial_purepython</code> is the most expensive function, and it is called from one place. If it were called from many places, these listings might help us narrow down the locations of the most expensive parents:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">In</code> <code class="p">[</code><code class="mi">5</code><code class="p">]:</code> <code class="n">p</code><code class="o">.</code><code class="n">print_callers</code><code class="p">()</code>
   <code class="n">Ordered</code> <code class="n">by</code><code class="p">:</code> <code class="n">cumulative</code> <code class="n">time</code>

<code class="n">Function</code>                                          <code class="n">was</code> <code class="n">called</code> <code class="n">by</code><code class="o">...</code>
                                                <code class="n">ncalls</code>  <code class="n">tottime</code> <code class="n">cumtime</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">exec</code><code class="p">}</code>       <code class="o">&lt;-</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>           <code class="o">&lt;-</code>       <code class="mi">1</code>    <code class="mi">0.033</code>   <code class="mi">12.169</code>
                                               <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">exec</code><code class="p">}</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>  <code class="o">&lt;-</code>       <code class="mi">1</code>    <code class="mi">0.576</code>   <code class="mi">12.135</code>
                                               <code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">9</code><code class="p">(</code><code class="o">...</code><code class="p">)</code>                <code class="o">&lt;-</code>       <code class="mi">1</code>    <code class="mi">8.266</code>   <code class="mi">11.429</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">abs</code><code class="p">}</code>        <code class="o">&lt;-</code> <code class="mi">34219980</code>   <code class="mi">3.163</code>    <code class="mi">3.163</code>
                                               <code class="p">:</code><code class="mi">9</code><code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
<code class="p">{</code><code class="n">method</code> <code class="s">'append'</code> <code class="n">of</code> <code class="s">'list'</code> <code class="n">objects</code><code class="p">}</code>   <code class="o">&lt;-</code> <code class="mi">2002000</code>    <code class="mi">0.123</code>    <code class="mi">0.123</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">sum</code><code class="p">}</code>        <code class="o">&lt;-</code>       <code class="mi">1</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">print</code><code class="p">}</code>      <code class="o">&lt;-</code>       <code class="mi">3</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">len</code><code class="p">}</code>        <code class="o">&lt;-</code>       <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                               <code class="p">:</code><code class="mi">9</code><code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
                                               <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">}</code>           <code class="o">&lt;-</code>       <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                               <code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code></pre>

<p class="author1">We can flip this around the other way to show which functions call other functions:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">In</code> <code class="p">[</code><code class="mi">6</code><code class="p">]:</code> <code class="n">p</code><code class="o">.</code><code class="n">print_callees</code><code class="p">()</code>
   <code class="n">Ordered</code> <code class="n">by</code><code class="p">:</code> <code class="n">cumulative</code> <code class="n">time</code>

<code class="n">Function</code>                                          <code class="n">called</code><code class="o">...</code>
                                              <code class="n">ncalls</code>  <code class="n">tottime</code>  <code class="n">cumtime</code>
<code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">exec</code><code class="p">}</code>      <code class="o">-&gt;</code>       <code class="mi">1</code>    <code class="mi">0.033</code>   <code class="mi">12.169</code>
                                              <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">1</code><code class="p">(</code><code class="o">&lt;</code><code class="n">module</code><code class="o">&gt;</code><code class="p">)</code>          <code class="o">-&gt;</code>       <code class="mi">1</code>    <code class="mi">0.576</code>   <code class="mi">12.135</code>
                                              <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">23</code>
                                                <code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">23</code><code class="p">(</code><code class="n">calc_pure_python</code><code class="p">)</code> <code class="o">-&gt;</code>       <code class="mi">1</code>    <code class="mi">8.266</code>   <code class="mi">11.429</code>
                                              <code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">9</code>
                                                <code class="p">(</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
                                              <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">len</code><code class="p">}</code>
                                              <code class="mi">3</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="kn">print</code><code class="p">}</code>
                                              <code class="mi">1</code>    <code class="mi">0.006</code>    <code class="mi">0.006</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">sum</code><code class="p">}</code>
                                              <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">}</code>
                                        <code class="mi">2002000</code>    <code class="mi">0.123</code>    <code class="mi">0.123</code>
                                              <code class="p">{</code><code class="n">method</code> <code class="s">'append'</code> <code class="n">of</code> <code class="s">'list'</code> <code class="n">objects</code><code class="p">}</code>
<code class="n">julia1_nopil</code><code class="o">.</code><code class="n">py</code><code class="p">:</code><code class="mi">9</code><code class="p">(</code><code class="o">...</code><code class="p">)</code>              <code class="o">-&gt;</code> <code class="mi">34219980</code>    <code class="mi">3.163</code>    <code class="mi">3.163</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">abs</code><code class="p">}</code>
					                          <code class="mi">2</code>    <code class="mi">0.000</code>    <code class="mi">0.000</code>
                                              <code class="p">{</code><code class="n">built</code><code class="o">-</code><code class="ow">in</code> <code class="n">method</code> <code class="n">builtins</code><code class="o">.</code><code class="n">len</code><code class="p">}</code></pre>

<p class="author1"><code class="calibre26">cProfile</code> is rather verbose, and you need a side screen to see it without lots of word wrapping. Since it is built in, though, it is a convenient tool for quickly identifying <span class="publishername">bottlenecks</span>. Tools like <code class="calibre26">line_profiler</code> and <a data-type="indexterm" data-primary="memory_profiler" id="idm46122431955480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">memory_profiler</code>, which we discuss later in this chapter, will then help you to drill down to the specific lines that you should pay attention to.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Visualizing cProfile Output with SnakeViz" class="calibre3"><div class="preface" id="idm46122434092200">
<h1 class="calibre25">Visualizing cProfile Output with SnakeViz</h1>

<p class="author1"><a data-type="indexterm" data-primary="snakeviz" id="sna_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">snakeviz</code> is a visualizer that draws the output of <code class="calibre26">cProfile</code> as a diagram in which larger boxes are areas of code that take longer to run. It replaces the older <code class="calibre26">runsnake</code> tool.</p>

<p class="author1">Use <code class="calibre26">snakeviz</code> to get a high-level understanding of a <code class="calibre26">cProfile</code> statistics file, particularly if you’re investigating a new project for which you have little intuition. The diagram will help you visualize the CPU-usage behavior of the system, and it may highlight areas that you hadn’t expected to be expensive.</p>

<p class="author1">To install SnakeViz, use <code class="calibre26">$ pip install snakeviz</code>.</p>

<p class="author1">In <a data-type="xref" href="#FIG-snakeviz" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-5</a> we have the visual output of the <em class="hyperlink">profile.stats</em> file we’ve just generated. The entry point for the program is shown at the top of the diagram. Each layer down is a function called from the function above.</p>

<p class="author1">The width of the diagram represents the entire time taken by the program’s execution. The fourth layer shows that the majority of the time is spent in <a data-type="indexterm" data-primary="calculate_z_serial_purepython function" id="idm46122431667080" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">calculate_z_serial_purepython</code>. The fifth layer breaks this down some more—the unannotated block to the right occupying approximately 25% of that layer represents the time spent in the <code class="calibre26">abs</code> function. Seeing these larger blocks quickly brings home how the time is spent inside your program.</p>

<figure class="calibre46"><div id="FIG-snakeviz" class="figure">
<img src="Images/hpp2_0205.png" alt="snakeviz visualizing profile.stats" class="calibre62"/>
<h6 class="calibre47"><span class="publishername">Figure 2-5. </span><code class="calibre26">snakeviz</code> visualizing profile.stats</h6>
</div></figure>

<p class="author1">The next section down shows a table that is a pretty-printed version of the statistics we’ve just been looking at, which you can sort by <code class="calibre26">cumtime</code> (cumulative time), <code class="calibre26">percall</code> (cost per call), or <code class="calibre26">ncalls</code> (number of calls altogether), among other categories. Starting with <code class="calibre26">cumtime</code> will tell you which functions cost the most overall. They’re a pretty good place to start your investigations.</p>

<p class="author1">If you’re comfortable looking at tables, the console output for <code class="calibre26">cProfile</code> may be adequate for you. To communicate to others, we strongly suggest you use diagrams—such as this output from <code class="calibre26">snakeviz</code>—to help others quickly understand the point you’re making.<a data-type="indexterm" data-primary="" data-startref="cpro_ab" id="idm46122431659128" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_cpro" id="idm46122431658152" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="sna_ab" id="idm46122431657208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Using line_profiler for Line-by-Line Measurements" class="calibre3"><div class="preface" id="profiling-line-profiler">
<h1 class="calibre25">Using line_profiler for Line-by-Line Measurements</h1>

<p class="author1"><a data-type="indexterm" data-primary="line_profiler" id="lpro_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="line_profiler" id="pro_lpro" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In Ian’s opinion, Robert Kern’s <code class="calibre26">line_profiler</code> is the strongest tool for identifying the cause of CPU-bound problems in Python code. It works by profiling individual functions on a line-by-line basis, so you should start with <code class="calibre26">cProfile</code> and use the high-level view to guide which functions to profile with <code class="calibre26">line_profiler</code>.</p>

<p class="author1">It is worthwhile printing and annotating versions of the output from this tool as you modify your code, so you have a record of changes (successful or not) that you can quickly refer to. Don’t rely on your memory when you’re working on line-by-line changes.</p>

<p class="author1">To install <code class="calibre26">line_profiler</code>, issue the command <code class="calibre26">pip install line_profiler</code>.</p>

<p class="author1">A decorator (<code class="calibre26">@profile</code>) is used to mark the chosen function. The <code class="calibre26">kernprof</code> script is used to execute your code, and the CPU time and other statistics for each line of the chosen function are recorded.</p>

<p class="author1">The arguments are <code class="calibre26">-l</code> for line-by-line (rather than function-level) profiling and <code class="calibre26">-v</code> for verbose output. Without <code class="calibre26">-v</code>, you receive an <em class="hyperlink">.lprof</em> output that you can later analyze with the <code class="calibre26">line_profiler</code> module. In <a data-type="xref" href="#profiling-kernprof-run1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-6</a>, we’ll do a full run on our CPU-bound function.</p>
<div id="profiling-kernprof-run1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-6. </span>Running <code class="calibre26">kernprof</code> with line-by-line output on a decorated function to record the CPU cost of each line’s execution</h5>

<pre data-type="programlisting" class="calibre59">$ kernprof -l -v julia1_lineprofiler.py
...
Wrote profile results to julia1_lineprofiler.py.lprof
Timer unit: 1e-06 s

Total time: 49.2011 s
File: julia1_lineprofiler.py
Function: calculate_z_serial_purepython at line 9

Line #      Hits  Per Hit   % Time  Line Contents
==============================================================
     9                              @profile
    10                              def calculate_z_serial_purepython(maxiter,
                                                                      zs, cs):
    11                            """Calculate output list using Julia update rule"""
    12         1   3298.0      0.0      output = [0] * len(zs)
    13   1000001      0.4      0.8      for i in range(len(zs)):
    14   1000000      0.4      0.7          n = 0
    15   1000000      0.4      0.9          z = zs[i]
    16   1000000      0.4      0.8          c = cs[i]
    17  34219980      0.5     38.0          while abs(z) &lt; 2 and n &lt; maxiter:
    18  33219980      0.5     30.8              z = z * z + c
    19  33219980      0.4     27.1              n += 1
    20   1000000      0.4      0.8          output[i] = n
    21         1      1.0      0.0      return output</pre></div>

<p class="author1">Introducing <code class="calibre26">kernprof.py</code> adds a substantial amount to the runtime. In this example, <code class="calibre26">calculate_z_serial_purepython</code> takes 49 seconds; this is up from 8 seconds using simple <code class="calibre26">print</code> statements and 12 seconds using <code class="calibre26">cProfile</code>. The gain is that we get a line-by-line breakdown of where the time is spent inside the function.</p>

<p class="author1">The <code class="calibre26">% Time</code> column is the most helpful—we can see that 38% of the time is spent on the <a data-type="indexterm" data-primary="while statement" id="idm46122431636040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">while</code> testing. We don’t know whether the first statement (<code class="calibre26">abs(z) &lt; 2</code>) is more expensive than the second (<code class="calibre26">n &lt; maxiter</code>), though. Inside the loop, we see that the update to <code class="calibre26">z</code> is also fairly expensive. Even <code class="calibre26">n += 1</code> is expensive! Python’s dynamic lookup machinery is at work for every loop, even though we’re using the same types for each variable in each loop—this is where compiling and type specialization (<a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>) give us a massive win. The creation of the <code class="calibre26">output</code> list and the updates on line 20 are relatively cheap compared to the cost of the <code class="calibre26">while</code> loop.</p>

<p class="author1">If you haven’t thought about the complexity of Python’s dynamic machinery before, do think about what happens in that <code class="calibre26">n += 1</code> operation. Python has to check that the <code class="calibre26">n</code> object has an <code class="calibre26">__add__</code> function (and if it didn’t, it’d walk up any inherited classes to see if they provided this functionality), and then the other object (<code class="calibre26">1</code> in this case) is passed in so that the <code class="calibre26">__add__</code> function can decide how to handle the operation. Remember that the second argument might be a <code class="calibre26">float</code> or other object that may or may not be compatible. This all happens dynamically.</p>

<p class="author1">The obvious way to further analyze the <code class="calibre26">while</code> statement is to break it up. While there has been some discussion in the Python community around the idea of rewriting the <em class="hyperlink">.pyc</em> files with more detailed information for multipart, single-line statements, we are unaware of any production tools that offer a more fine-grained analysis than <code class="calibre26">line_profiler</code>.</p>

<p class="author1">In <a data-type="xref" href="#profiling-kernprof-run2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-7</a>, we break the <code class="calibre26">while</code> logic into several statements. This additional complexity will increase the runtime of the function, as we have more lines of code to execute, but it <em class="hyperlink">might</em> also help us understand the costs incurred in this part of the code.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1"><em class="hyperlink">Before you look at the code</em>, do you think we’ll learn about the costs of the fundamental operations this way? Might other factors complicate the analysis?</p>
</div>
<div id="profiling-kernprof-run2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-7. </span>Breaking the compound <code class="calibre26">while</code> statement into individual statements to record the cost of each part of the original statement</h5>

<pre data-type="programlisting" class="calibre59">$ kernprof -l -v julia1_lineprofiler2.py
...
Wrote profile results to julia1_lineprofiler2.py.lprof
Timer unit: 1e-06 s

Total time: 82.88 s
File: julia1_lineprofiler2.py
Function: calculate_z_serial_purepython at line 9

Line #      Hits  Per Hit   % Time  Line Contents
==============================================================
     9                              @profile
    10                              def calculate_z_serial_purepython(maxiter,
                                                                      zs, cs):
    11                            """Calculate output list using Julia update rule"""
    12         1   3309.0      0.0      output = [0] * len(zs)
    13   1000001      0.4      0.5      for i in range(len(zs)):
    14   1000000      0.4      0.5          n = 0
    15   1000000      0.5      0.5          z = zs[i]
    16   1000000      0.4      0.5          c = cs[i]
    17   1000000      0.4      0.5          while True:
    18  34219980      0.6     23.1            not_yet_escaped = abs(z) &lt; 2
    19  34219980      0.4     18.3            iterations_left = n &lt; maxiter
    20  34219980      0.4     17.3            if not_yet_escaped and iterations_left:
    21  33219980      0.5     20.5                z = z * z + c
    22  33219980      0.4     17.3                n += 1
    23                                        else:
    24   1000000      0.4      0.5                break
    25   1000000      0.4      0.5          output[i] = n
    26         1      0.0      0.0      return output</pre></div>

<p class="author1">This version takes 82 seconds to execute, while the previous version took 49 seconds. Other factors <em class="hyperlink">did</em> complicate the analysis. In this case, having extra statements that have to be executed 34,219,980 times each slows down the code. If we hadn’t used <code class="calibre26">kernprof.py</code> to investigate the line-by-line effect of this change, we might have drawn other conclusions about the reason for the slowdown, as we’d have lacked the necessary <span class="publishername">evidence.</span></p>

<p class="author1">At this point it makes sense to step back to the earlier <code class="calibre26">timeit</code> technique to test the cost of individual expressions:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">Python</code> <code class="mi">3.7</code><code class="o">.</code><code class="mi">3</code> <code class="p">(</code><code class="n">default</code><code class="p">,</code> <code class="n">Mar</code> <code class="mi">27</code> <code class="mi">2019</code><code class="p">,</code> <code class="mi">22</code><code class="p">:</code><code class="mi">11</code><code class="p">:</code><code class="mi">17</code><code class="p">)</code>
<code class="n">Type</code> <code class="s">'copyright'</code><code class="p">,</code> <code class="s">'credits'</code><code class="p">,</code> <code class="ow">or</code> <code class="s">'license'</code> <code class="kn">for</code> <code class="n">more</code> <code class="n">information</code>
<code class="n">IPython</code> <code class="mi">7.5</code><code class="o">.</code><code class="mi">0</code> <code class="o">--</code> <code class="n">An</code> <code class="n">enhanced</code> <code class="n">Interactive</code> <code class="n">Python</code><code class="o">.</code> <code class="n">Type</code> <code class="s">'?'</code> <code class="kn">for</code> <code class="n">help</code><code class="o">.</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">1</code><code class="p">]:</code> <code class="n">z</code> <code class="o">=</code> <code class="mi">0</code><code class="o">+</code><code class="mi">0j</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code>
<code class="mi">97.6</code> <code class="n">ns</code> <code class="err">±</code> <code class="mi">0.138</code> <code class="n">ns</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">10000000</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="n">n</code> <code class="o">=</code> <code class="mi">1</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">4</code><code class="p">]:</code> <code class="n">maxiter</code> <code class="o">=</code> <code class="mi">300</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">5</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code>
<code class="mi">42.1</code> <code class="n">ns</code> <code class="err">±</code> <code class="mi">0.0355</code> <code class="n">ns</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">10000000</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code></pre>

<p class="author1">From this simple analysis, it looks as though the logic test on <code class="calibre26">n</code> is more than two times faster than the call to <code class="calibre26">abs</code>. Since the order of evaluation for Python statements is both left to right and opportunistic, it makes sense to put the cheapest test on the left side of the equation. On 1 in every 301 tests for each coordinate, the <code class="calibre26">n &lt; maxiter</code> test will be <code class="calibre26">False</code>, so Python wouldn’t need to evaluate the other side of the <code class="calibre26">and</code> 
<span class="publishername">operator</span>.</p>

<p class="author1">We never know whether <code class="calibre26">abs(z) &lt; 2</code> will be <code class="calibre26">False</code> until we evaluate it, and our earlier observations for this region of the complex plane suggest it is <code class="calibre26">True</code> around 10% of the time for all 300 iterations. If we wanted to have a strong understanding of the time complexity of this part of the code, it would make sense to continue the numerical analysis. In this situation, however, we want an easy check to see if we can get a quick win.</p>

<p class="author1">We can form a new<a data-type="indexterm" data-primary="profiling" data-secondary="forming a hypothesis" id="idm46122431442616" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> hypothesis stating, “By swapping the order of the operators in the <code class="calibre26">while</code> statement, we will achieve a reliable speedup.” We <em class="hyperlink">can</em> test this hypothesis using <code class="calibre26">kernprof</code>, but the additional overheads of profiling this way might add too much noise. Instead, we can use an earlier version of the code, running a test comparing <code class="calibre26">while abs(z) &lt; 2 and n &lt; maxiter:</code> against <code class="calibre26">while n &lt; maxiter and abs(z) &lt; 2:</code>, which we see in <a data-type="xref" href="#profiling-kernprof-run3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-8</a>.</p>

<p class="author1">Running the two variants <em class="hyperlink">outside</em> of <code class="calibre26">line_profiler</code> means they run at similar speeds. The overheads of <code class="calibre26">line_profiler</code> also confuse the result, and the results on line 17 for both versions are similar. We should reject the hypothesis that in Python 3.7 changing the order of the logic results in a consistent speedup—there’s no clear evidence for this. Ian notes that with Python 2.7 we <em class="hyperlink">could</em> accept this hypothesis, but with Python 3.7 that’s no longer the case.</p>

<p class="author1">Using a more suitable approach to solve this problem (e.g., swapping to using Cython or PyPy, as described in <a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>) would yield greater gains.</p>

<p class="author1">We can be confident in our result because of the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">We stated a hypothesis that was easy to test.</p>
</li>
<li class="calibre21">
<p class="calibre27">We changed our code so that only the hypothesis would be tested (never test two things at once!).</p>
</li>
<li class="calibre21">
<p class="calibre27">We gathered enough evidence to support our conclusion.</p>
</li>
</ul>

<p class="author1">For completeness, we can run a final <code class="calibre26">kernprof</code> on the two main functions including our optimization to confirm that we have a full picture of the overall complexity of our code.</p>
<div id="profiling-kernprof-run3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-8. </span>Swapping the order of the compound <code class="calibre26">while</code> statement makes the function fractionally faster</h5>

<pre data-type="programlisting" class="calibre59">$ kernprof -l -v julia1_lineprofiler3.py
...
Wrote profile results to julia1_lineprofiler3.py.lprof
Timer unit: 1e-06 s

Total time: 48.9154 s
File: julia1_lineprofiler3.py
Function: calculate_z_serial_purepython at line 9

Line #    Hits  Per Hit % Time  Line Contents
=======================================================
   9                            @profile
  10                            def calculate_z_serial_purepython(maxiter,
                                                                  zs, cs):
  11                             """Calculate output list using Julia update rule"""
  12         1   3312.0    0.0      output = [0] * len(zs)
  13   1000001      0.4   0.8      for i in range(len(zs)):
  14   1000000      0.4   0.7          n = 0
  15   1000000      0.4   0.8          z = zs[i]
  16   1000000      0.4   0.8          c = cs[i]
  17  34219980      0.5  38.2          while n &lt; maxiter and abs(z) &lt; 2:
  18  33219980      0.5  30.7              z = z * z + c
  19  33219980      0.4  27.1              n += 1
  20   1000000      0.4   0.8          output[i] = n
  21         1      1.0   0.0      return output</pre></div>

<p class="author1">As expected, we can see from the output in <a data-type="xref" href="#profiling-kernprof-run4" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-9</a> that <code class="calibre26">calculate_z_serial_purepython</code> takes most (97%) of the time of its parent function. The list-creation steps are minor in comparison.</p>
<div id="profiling-kernprof-run4" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-9. </span>Testing the line-by-line costs of the setup routine</h5>

<pre data-type="programlisting" class="calibre59">Total time: 88.334 s
File: julia1_lineprofiler3.py
Function: calc_pure_python at line 24

Line #      Hits  Per Hit   % Time  Line Contents
==============================================================
    24                              @profile
    25                              def calc_pure_python(draw_output,
                                                         desired_width,
                                                         max_iterations):
    26                               """Create a list of complex...
...
    44         1          1.0      0.0      zs = []
    45         1          0.0      0.0      cs = []
    46      1001          0.7      0.0      for ycoord in y:
    47   1001000          0.6      0.7          for xcoord in x:
    48   1000000          0.9      1.0            zs.append(complex(xcoord, ycoord))
    49   1000000          0.9      1.0            cs.append(complex(c_real, c_imag))
    50
    51         1         40.0      0.0      print("Length of x:", len(x))
    52         1          7.0      0.0      print("Total elements:", len(zs))
    53         1          4.0      0.0      start_time = time.time()
    54         1   85969310.0    97.3     output = calculate_z_serial_purepython \
                                           (max_iterations, zs, cs)
    55         1          4.0      0.0      end_time = time.time()
    56         1          1.0      0.0      secs = end_time - start_time
    57         1         36.0      0.0      print(calculate_z_serial...
    58
    59         1       6345.0      0.0      assert sum(output) == 33219980</pre></div>

<p class="author1"><code class="calibre26">line_profiler</code> gives us a great insight into the cost of lines inside loops and expensive functions; even though profiling adds a speed penalty, it is a great boon to scientific developers. Remember to use representative data to make sure you’re focusing on the lines of code that’ll give you the biggest win.<a data-type="indexterm" data-primary="" data-startref="lpro_ab" id="idm46122431419704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_lpro" id="idm46122431418728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Using memory_profiler to Diagnose Memory Usage" class="calibre3"><div class="preface" id="memory_profiler">
<h1 class="calibre25">Using memory_profiler to Diagnose Memory Usage</h1>

<p class="author1"><a data-type="indexterm" data-primary="memory_profiler" id="mp_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="memory_profiler" id="pro_mp" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Just as Robert Kern’s <code class="calibre26">line_profiler</code> package measures CPU usage, the <code class="calibre26">memory_profiler</code> module by <a data-type="indexterm" data-primary="Pedregosa, Fabian" id="idm46122431412712" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Gervais, Philippe" id="idm46122431411976" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Fabian Pedregosa and Philippe Gervais measures memory usage on a line-by-line basis. Understanding the memory usage characteristics of your code allows you to ask yourself two questions:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Could we use <em class="hyperlink">less</em> RAM by rewriting this function to work more efficiently?</p>
</li>
<li class="calibre21">
<p class="calibre27">Could we use <em class="hyperlink">more</em> RAM and save CPU cycles by caching?</p>
</li>
</ul>

<p class="author1"><code class="calibre26">memory_profiler</code> operates in a very similar way to <code class="calibre26">line_profiler</code> but runs far more slowly. If you install the <code class="calibre26">psutil</code> package (optional but recommended), <code class="calibre26">memory_profiler</code> will run faster. Memory profiling may easily make your code run 10 to 100 times slower. In practice, you will probably use <code class="calibre26">memory_profiler</code> occasionally and <code class="calibre26">line_profiler</code> (for CPU profiling) more frequently.</p>

<p class="author1">Install <code class="calibre26">memory_profiler</code> with the command <code class="calibre26">pip install memory_profiler</code> (and optionally with <code class="calibre26">pip install psutil</code>).</p>

<p class="author1">As mentioned, the implementation of <code class="calibre26">memory_profiler</code> is not as performant as the implementation of <code class="calibre26">line_profiler</code>. It may therefore make sense to run your tests on a smaller problem that completes in a useful amount of time. Overnight runs might be sensible for validation, but you need quick and reasonable iterations to diagnose problems and hypothesize solutions. The code in <a data-type="xref" href="#profiling-memoryprofiler1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-10</a> uses the full 1,000 × 1,000 grid, and the statistics took about two hours to collect on Ian’s laptop.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">The requirement to modify the source code is a minor annoyance. As with <code class="calibre26">line_profiler</code>, a decorator (<code class="calibre26">@profile</code>) is used to mark the chosen function. This will break your unit tests unless you make a dummy decorator—see <a data-type="xref" href="#no_op_profile_decorator" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“No-op @profile Decorator”</a>.</p>
</div>

<p class="author1">When dealing with memory allocation, you must be aware that the situation is not as clear-cut as it is with CPU usage. Generally, it is more efficient to overallocate memory in a process that can be used at leisure, as memory allocation operations are relatively expensive. Furthermore, garbage collection is not instantaneous, so objects may be unavailable but still in the garbage collection pool for some time.</p>

<p class="author1">The outcome of this is that it is hard to really understand what is happening with memory usage and release inside a Python program, as a line of code may not allocate a deterministic amount of memory <em class="hyperlink">as observed from outside the process</em>. Observing the gross trend over a set of lines is likely to lead to better insight than would be gained by observing the behavior of just one line.</p>

<p class="author1">Let’s take a look at the output from <code class="calibre26">memory_profiler</code> in <a data-type="xref" href="#profiling-memoryprofiler1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-10</a>. Inside <a data-type="indexterm" data-primary="calculate_z_serial_purepython function" id="idm46122431393400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">calculate_z_serial_purepython</code> on line 12, we see that the allocation of 1,000,000 items causes approximately 7 MB of RAM to be added to this process.<sup class="calibre44"><a data-type="noteref" id="idm46122431392152-marker" href="ch02.xhtml#idm46122431392152" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> This does not mean that the <code class="calibre26">output</code> list is definitely 7 MB in size, just that the process grew by approximately 7 MB during the internal allocation of the list.</p>

<p class="author1">In the parent function on line 46, we see that the allocation of the <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists changes the <code class="calibre26">Mem usage</code> column from 48 MB to 125 MB (a change of +77 MB). Again, it is worth noting that this is not necessarily the true size of the arrays, just the size that the process grew by after these lists had been created.</p>

<p class="author1">At the time of writing, the <code class="calibre26">memory_usage</code> module exhibits a bug—the <code class="calibre26">Increment</code> column does not always match the change in the <code class="calibre26">Mem usage</code> column. During the first edition of this book, these columns were correctly tracked; you might want to check the status of this bug on <a href="https://oreil.ly/vuQPN" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">GitHub</a>. We recommend you use the <code class="calibre26">Mem usage</code> column, as this correctly tracks the change in process size per line of code.</p>
<div id="profiling-memoryprofiler1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-10. </span><code class="calibre26">memory_profiler</code>’s result on both of our main functions, showing an unexpected memory use in <code class="calibre26">calculate_z_serial_purepython</code></h5>

<pre data-type="programlisting" class="calibre59">$ python -m memory_profiler julia1_memoryprofiler.py
...

Line #    Mem usage    Increment   Line Contents
================================================
     9  126.363 MiB  126.363 MiB   @profile
    10                             def calculate_z_serial_purepython(maxiter,
                                                                     zs, cs):
    11                                 """Calculate output list using...
    12  133.973 MiB    7.609 MiB       output = [0] * len(zs)
    13  136.988 MiB    0.000 MiB       for i in range(len(zs)):
    14  136.988 MiB    0.000 MiB           n = 0
    15  136.988 MiB    0.000 MiB           z = zs[i]
    16  136.988 MiB    0.000 MiB           c = cs[i]
    17  136.988 MiB    0.258 MiB           while n &lt; maxiter and abs(z) &lt; 2:
    18  136.988 MiB    0.000 MiB               z = z * z + c
    19  136.988 MiB    0.000 MiB               n += 1
    20  136.988 MiB    0.000 MiB           output[i] = n
    21  136.988 MiB    0.000 MiB       return output

...

Line #    Mem usage    Increment   Line Contents
================================================
    24   48.113 MiB   48.113 MiB   @profile
    25                             def calc_pure_python(draw_output,
                                                        desired_width,
                                                        max_iterations):
    26                                 """Create a list of complex...
    27   48.113 MiB    0.000 MiB       x_step = (x2 - x1) / desired_width
    28   48.113 MiB    0.000 MiB       y_step = (y1 - y2) / desired_width
    29   48.113 MiB    0.000 MiB       x = []
    30   48.113 MiB    0.000 MiB       y = []
    31   48.113 MiB    0.000 MiB       ycoord = y2
    32   48.113 MiB    0.000 MiB       while ycoord &gt; y1:
    33   48.113 MiB    0.000 MiB           y.append(ycoord)
    34   48.113 MiB    0.000 MiB           ycoord += y_step
    35   48.113 MiB    0.000 MiB       xcoord = x1
    36   48.113 MiB    0.000 MiB       while xcoord &lt; x2:
    37   48.113 MiB    0.000 MiB           x.append(xcoord)
    38   48.113 MiB    0.000 MiB           xcoord += x_step
    44   48.113 MiB    0.000 MiB       zs = []
    45   48.113 MiB    0.000 MiB       cs = []
    46  125.961 MiB    0.000 MiB       for ycoord in y:
    47  125.961 MiB    0.258 MiB           for xcoord in x:
    48  125.961 MiB    0.512 MiB               zs.append(complex(xcoord, ycoord))
    49  125.961 MiB    0.512 MiB               cs.append(complex(c_real, c_imag))
    50
    51  125.961 MiB    0.000 MiB       print("Length of x:", len(x))
    52  125.961 MiB    0.000 MiB       print("Total elements:", len(zs))
    53  125.961 MiB    0.000 MiB       start_time = time.time()
    54  136.609 MiB   10.648 MiB       output = calculate_z_serial...
    55  136.609 MiB    0.000 MiB       end_time = time.time()
    56  136.609 MiB    0.000 MiB       secs = end_time - start_time
    57  136.609 MiB    0.000 MiB       print(calculate_z_serial_purepython...
    58
    59  136.609 MiB    0.000 MiB       assert sum(output) == 33219980</pre></div>

<p class="author1">Another way to visualize the change in memory use is to sample over time and plot the result. <code class="calibre26">memory_profiler</code> has a utility called <code class="calibre26">mprof</code>, used once to sample the memory usage and a second time to visualize the samples. It samples by time and not by line, so it barely impacts the runtime of the code.</p>

<p class="author1"><a data-type="xref" href="#FIG-julia-memoryprofiler-mprof" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-6</a> is created using <code class="calibre26">mprof run julia1_memoryprofiler.py</code>. This writes a statistics file that is then visualized using <code class="calibre26">mprof plot</code>. Our two functions are bracketed: this shows where in time they are entered, and we can see the growth in RAM as they run. Inside <code class="calibre26">calculate_z_serial_purepython</code>, we can see the steady increase in RAM usage throughout the execution of the function; this is caused by all the small objects (<code class="calibre26">int</code> and <code class="calibre26">float</code> types) that are created.</p>
<div class="preface">
<figure class="calibre46"><div id="FIG-julia-memoryprofiler-mprof" class="figure"><img src="Images/hpp2_0206.png" class="calibre63"/>
<h6 class="calibre47"><span class="publishername">Figure 2-6. </span><code class="calibre26">memory_profiler</code> report using <code class="calibre26">mprof</code></h6>
</div></figure>
</div>

<p class="author1">In addition to observing the behavior at the function level, we can add labels using a context manager. The snippet in <a data-type="xref" href="#profiling-memoryprofiler1-labels" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-11</a> is used to generate the graph in <a data-type="xref" href="#FIG-julia-memoryprofiler-mprof-labels" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-7</a>. We can see the <code class="calibre26">create_output_list</code> label: it appears momentarily at around 1.5 seconds after <code class="calibre26">calculate_z_serial_purepython</code> and results in the process being allocated more RAM. We then pause for a second; <code class="calibre26">time.sleep(1)</code> is an artificial addition to make the graph easier to understand.</p>
<div id="profiling-memoryprofiler1-labels" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-11. </span>Using a context manager to add labels to the <code class="calibre26">mprof</code> graph</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="nd">@profile</code>
<code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="kn">with</code> <code class="n">profile</code><code class="o">.</code><code class="n">timestamp</code><code class="p">(</code><code class="s">"create_output_list"</code><code class="p">):</code>
        <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
    <code class="kn">with</code> <code class="n">profile</code><code class="o">.</code><code class="n">timestamp</code><code class="p">(</code><code class="s">"calculate_output"</code><code class="p">):</code>
        <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
            <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
            <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
            <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code><code class="p">:</code>
                <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
                <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
            <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">In the <code class="calibre26">calculate_output</code> block that runs for most of the graph, we see a very slow, linear increase in RAM usage. This will be from all of the temporary numbers used in the inner loops. Using the labels really helps us to understand at a fine-grained level where memory is being consumed. Interestingly, we see the “peak RAM usage” line—a dashed vertical line just before the 10-second mark—occurring before the termination of the program. Potentially this is due to the garbage collector recovering some RAM from the temporary objects used during <code class="calibre26">calculate_output</code>.</p>

<p class="author1">What happens if we simplify our code and remove the creation of the <code class="calibre26">zs</code> and <code class="calibre26">cs</code> lists? We then have to calculate these coordinates inside <code class="calibre26">calculate_z_serial_purepython</code> (so the same work is performed), but we’ll save RAM by not storing them in lists. You can see the code in <a data-type="xref" href="#profiling-memoryprofiler2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-12</a>.</p>

<p class="author1">In <a data-type="xref" href="#FIG-julia-memoryprofiler2-removed-large-lists" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-8</a>, we see a major change in behavior—the overall envelope of RAM usage drops from 140 MB to 60 MB, reducing our RAM usage by half!</p>
<div class="preface">
<figure class="calibre46"><div id="FIG-julia-memoryprofiler-mprof-labels" class="figure"><img src="Images/hpp2_0207.png" class="calibre64"/>
<h6 class="calibre47"><span class="publishername">Figure 2-7. </span><code class="calibre26">memory_profiler</code> report using <code class="calibre26">mprof</code> with labels</h6>
</div></figure>
</div>
<div class="preface">
<figure class="calibre46"><div id="FIG-julia-memoryprofiler2-removed-large-lists" class="figure"><img src="Images/hpp2_0208.png" class="calibre65"/>
<h6 class="calibre47"><span class="publishername">Figure 2-8. </span><code class="calibre26">memory_profiler</code> after removing two large lists</h6>
</div></figure>
</div>
<div id="profiling-memoryprofiler2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-12. </span>Creating complex coordinates on the fly to save RAM</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="nd">@profile</code>
<code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">x</code><code class="p">,</code> <code class="n">y</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="kn">for</code> <code class="n">ycoord</code> <code class="ow">in</code> <code class="n">y</code><code class="p">:</code>
        <code class="kn">for</code> <code class="n">xcoord</code> <code class="ow">in</code> <code class="n">x</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="nb">complex</code><code class="p">(</code><code class="n">xcoord</code><code class="p">,</code> <code class="n">ycoord</code><code class="p">)</code>
            <code class="n">c</code> <code class="o">=</code> <code class="nb">complex</code><code class="p">(</code><code class="n">c_real</code><code class="p">,</code> <code class="n">c_imag</code><code class="p">)</code>
            <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
            <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code><code class="p">:</code>
                <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
                <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
            <code class="n">output</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">n</code><code class="p">)</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">If we want to measure the RAM used by several statements, we can use the IPython magic <code class="calibre26">%memit</code>, which works just like <code class="calibre26">%timeit</code>. In <a data-type="xref" href="ch11_split_000.xhtml#chapter-lessram" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 11</a>, we will look at using <code class="calibre26">%memit</code> to measure the memory cost of lists and discuss various ways of using RAM more <span class="publishername">efficiently</span>.</p>

<p class="author1"><code class="calibre26">memory_profiler</code> offers an interesting aid to debugging a large process via the 
<span class="publishername"><code class="calibre26">--pdb-mmem=<em class="calibre66">XXX</em></code></span> flag.  The <code class="calibre26">pdb</code> debugger will be activated after the process exceeds <code class="calibre26"><em class="calibre66">XXX</em></code> MB. This will drop you in directly at the point in your code where too many allocations are occurring, if you’re in a space-constrained environment.<a data-type="indexterm" data-primary="" data-startref="mp_ab" id="idm46122431055944" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_mp" id="idm46122431055000" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Introspecting an Existing Process with PySpy" class="calibre3"><div class="preface" id="profiling-pyspy">
<h1 class="calibre25">Introspecting an Existing Process with PySpy</h1>

<p class="author1"><a data-type="indexterm" data-primary="PySpy" id="pyspy_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">py-spy</code> is an intriguing new sampling profiler—rather than requiring any code changes, it introspects an already-running Python process and reports in the console with a <code class="calibre26">top</code>-like display. Being a sampling profiler, it has almost no runtime impact on your code. It is written in Rust and requires elevated privileges to introspect another process.</p>

<p class="author1">This tool could be very useful in a production environment with <a data-type="indexterm" data-primary="profiling" data-secondary="long-running applications" id="idm46122431049976" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>long-running processes or complicated installation requirements. It supports Windows, Mac, and Linux. Install it using <code class="calibre26">pip install py-spy</code> (note the dash in the name—there’s a separate <code class="calibre26">pyspy</code> project that isn’t related). If your process is already running, you’ll want to use <code class="calibre26">ps</code> to get its process identifier (the PID); then this can be passed into <code class="calibre26">py-spy</code> as shown in <a data-type="xref" href="#profiling-pyspy1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-13</a>.</p>
<div id="profiling-pyspy1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-13. </span>Running PySpy at the command line</h5>

<pre data-type="programlisting" class="calibre59">$ ps -A -o pid,rss,cmd | ack python
...
15953 96156 python julia1_nopil.py
...
$ sudo env "PATH=$PATH" py-spy --pid 15953</pre></div>

<p class="author1">In <a data-type="xref" href="#FIG-julia-pyspy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-9</a>, you’ll see a static picture of a <code class="calibre26">top</code>-like display in the console; this updates every second to show which functions are currently taking most of the time.</p>

<figure class="calibre46"><div id="FIG-julia-pyspy" class="figure">
<img src="Images/hpp2_0209.png" alt="Introspecting a Python process using PySpy" class="calibre67"/>
<h6 class="calibre47"><span class="publishername">Figure 2-9. </span>Introspecting a Python process using PySpy</h6>
</div></figure>

<p class="author1">PySpy can also export a flame chart. Here, we’ll run that option while asking PySpy to run our code directly without requiring a PID using <code class="calibre26">$ py-spy --flame profile.svg -- python julia1_nopil.py</code>. You’ll see in <a data-type="xref" href="#FIG-julia-pyspy-flame" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 2-10</a> that the width of the display represents the entire program’s runtime, and each layer moving down the image represents functions called from above.<a data-type="indexterm" data-primary="" data-startref="pyspy_ab" id="idm46122431038248" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<figure class="calibre46"><div id="FIG-julia-pyspy-flame" class="figure">
<img src="Images/hpp2_0210.png" alt="Part of a flame chart for PySpy" class="calibre68"/>
<h6 class="calibre47"><span class="publishername">Figure 2-10. </span>Part of a flame chart for PySpy</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Bytecode: Under the Hood" class="calibre3"><div class="preface" id="idm46122431035224">
<h1 class="calibre25">Bytecode: Under the Hood</h1>

<p class="author1">So far we’ve reviewed various ways to measure the cost of Python code (for both CPU and RAM usage). We haven’t yet looked at the underlying bytecode used by the virtual machine, though. Understanding what’s going on “under the hood” helps to build a mental model of what’s happening in slow functions, and it’ll help when you come to compile your code. So let’s introduce some bytecode.</p>








<section data-type="sect2" data-pdf-bookmark="Using the dis Module to Examine CPython Bytecode" class="calibre3"><div class="preface" id="profiling-dis">
<h2 class="calibre43">Using the dis Module to Examine CPython Bytecode</h2>

<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="bytecode" id="cp_by" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="dis module" id="dis_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="dis module" id="pro_dis" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <code class="calibre26">dis</code> module lets us inspect the underlying bytecode that we run inside the stack-based CPython virtual machine. Having an understanding of what’s happening in the virtual machine that runs your higher-level Python code will help you to understand why some styles of coding are faster than others. It will also help when you come to use a tool like Cython, which steps outside of Python and generates C code.</p>

<p class="author1">The <code class="calibre26">dis</code> module is built in. You can pass it code or a module, and it will print out a disassembly. In <a data-type="xref" href="#profiling-dis1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-14</a>, we disassemble the outer loop of our CPU-bound <span class="publishername">function.</span></p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">You should try to disassemble one of your own functions and to follow <em class="hyperlink">exactly</em> how the disassembled code matches to the <span class="publishername">disassembled</span> output. Can you match the following <code class="calibre26">dis</code> output to the original function?</p>
</div>
<div id="profiling-dis1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-14. </span>Using the built-in <code class="calibre26">dis</code> to understand the underlying stack-based virtual machine that runs our Python code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">In</code> <code class="p">[</code><code class="mi">1</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">dis</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">julia1_nopil</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="n">dis</code><code class="o">.</code><code class="n">dis</code><code class="p">(</code><code class="n">julia1_nopil</code><code class="o">.</code><code class="n">calculate_z_serial_purepython</code><code class="p">)</code>
 <code class="mi">11</code>           <code class="mi">0</code> <code class="n">LOAD_CONST</code>               <code class="mi">1</code> <code class="p">(</code><code class="mi">0</code><code class="p">)</code>
              <code class="mi">2</code> <code class="n">BUILD_LIST</code>               <code class="mi">1</code>
              <code class="mi">4</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">0</code> <code class="p">(</code><code class="nb">len</code><code class="p">)</code>
              <code class="mi">6</code> <code class="n">LOAD_FAST</code>                <code class="mi">1</code> <code class="p">(</code><code class="n">zs</code><code class="p">)</code>
              <code class="mi">8</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
             <code class="mi">10</code> <code class="n">BINARY_MULTIPLY</code>
             <code class="mi">12</code> <code class="n">STORE_FAST</code>               <code class="mi">3</code> <code class="p">(</code><code class="n">output</code><code class="p">)</code>

 <code class="mi">12</code>          <code class="mi">14</code> <code class="n">SETUP_LOOP</code>              <code class="mi">94</code> <code class="p">(</code><code class="n">to</code> <code class="mi">110</code><code class="p">)</code>
             <code class="mi">16</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">1</code> <code class="p">(</code><code class="nb">range</code><code class="p">)</code>
             <code class="mi">18</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">0</code> <code class="p">(</code><code class="nb">len</code><code class="p">)</code>
             <code class="mi">20</code> <code class="n">LOAD_FAST</code>                <code class="mi">1</code> <code class="p">(</code><code class="n">zs</code><code class="p">)</code>
             <code class="mi">22</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
             <code class="mi">24</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
             <code class="mi">26</code> <code class="n">GET_ITER</code>
        <code class="o">&gt;&gt;</code>   <code class="mi">28</code> <code class="n">FOR_ITER</code>                <code class="mi">78</code> <code class="p">(</code><code class="n">to</code> <code class="mi">108</code><code class="p">)</code>
             <code class="mi">30</code> <code class="n">STORE_FAST</code>               <code class="mi">4</code> <code class="p">(</code><code class="n">i</code><code class="p">)</code>

 <code class="mi">13</code>          <code class="mi">32</code> <code class="n">LOAD_CONST</code>               <code class="mi">1</code> <code class="p">(</code><code class="mi">0</code><code class="p">)</code>
             <code class="mi">34</code> <code class="n">STORE_FAST</code>               <code class="mi">5</code> <code class="p">(</code><code class="n">n</code><code class="p">)</code>
<code class="o">...</code>
 <code class="mi">19</code>     <code class="o">&gt;&gt;</code>   <code class="mi">98</code> <code class="n">LOAD_FAST</code>                <code class="mi">5</code> <code class="p">(</code><code class="n">n</code><code class="p">)</code>
            <code class="mi">100</code> <code class="n">LOAD_FAST</code>                <code class="mi">3</code> <code class="p">(</code><code class="n">output</code><code class="p">)</code>
            <code class="mi">102</code> <code class="n">LOAD_FAST</code>                <code class="mi">4</code> <code class="p">(</code><code class="n">i</code><code class="p">)</code>
            <code class="mi">104</code> <code class="n">STORE_SUBSCR</code>
            <code class="mi">106</code> <code class="n">JUMP_ABSOLUTE</code>           <code class="mi">28</code>
        <code class="o">&gt;&gt;</code>  <code class="mi">108</code> <code class="n">POP_BLOCK</code>

 <code class="mi">20</code>     <code class="o">&gt;&gt;</code>  <code class="mi">110</code> <code class="n">LOAD_FAST</code>                <code class="mi">3</code> <code class="p">(</code><code class="n">output</code><code class="p">)</code>
            <code class="mi">112</code> <code class="n">RETURN_VALUE</code></pre></div>

<p class="author1">The output is fairly straightforward, if terse. The first column contains line numbers that relate to our original file. The second column contains several <code class="calibre26">&gt;&gt;</code> symbols; these are the destinations for jump points elsewhere in the code. The third column is the operation address; the fourth has the operation name. The fifth column contains the parameters for the operation. The sixth column contains annotations to help line up the bytecode with the original Python parameters.</p>

<p class="author1">Refer back to <a data-type="xref" href="#profiling-juliaset-intro3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-3</a> to match the bytecode to the corresponding Python code. The bytecode starts on Python line 11 by putting the constant value 0 onto the stack, and then it builds a single-element list. Next, it searches the namespaces to find the <code class="calibre26">len</code> function, puts it on the stack, searches the namespaces again to find <code class="calibre26">zs</code>, and then puts that onto the stack. Inside Python line 12, it calls the <code class="calibre26">len</code> function from the stack, which consumes the <code class="calibre26">zs</code> reference in the stack; then it applies a binary multiply to the last two arguments (the length of <code class="calibre26">zs</code> and the single-element list) and stores the result in <code class="calibre26">output</code>. That’s the first line of our Python function now dealt with. Follow the next block of bytecode to understand the behavior of the second line of Python code (the outer <code class="calibre26">for</code> loop).</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">The <a data-type="indexterm" data-primary="&gt;&gt; (jump points)" id="idm46122430778536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="jump points (&gt;&gt;)" id="idm46122430777800" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>jump points (<code class="calibre26">&gt;&gt;</code>) match to instructions like <code class="calibre26">JUMP_ABSOLUTE</code> and <code class="calibre26">POP_JUMP_IF_FALSE</code>. Go through your own disassembled function and match the jump points to the jump instructions.</p>
</div>

<p class="author1">Having introduced bytecode, we can now ask: what’s the bytecode and time cost of writing a function out explicitly versus using built-ins to perform the same task?</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Different Approaches, Different Complexity" class="calibre3"><div class="preface" id="idm46122431032920">
<h2 class="calibre43">Different Approaches, Different Complexity</h2>
<blockquote class="calibre69 pcalibre5 pcalibre6">
<p class="calibre70">There should be one—and preferably only one—obvious way to do it.
Although that way may not be obvious at first unless you’re Dutch.<sup class="calibre44"><a data-type="noteref" id="idm46122430772872-marker" href="ch02.xhtml#idm46122430772872" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup></p>
<p data-type="attribution" class="calibre71 pcalibre7">Tim Peters, <cite class="publishername">The Zen of Python</cite></p>
</blockquote>

<p class="author1">There will be various ways to express your ideas using Python. Generally, the most sensible option should be clear, but if your experience is primarily with an older version of Python or another programming language, you may have other methods in mind. Some of these ways of expressing an idea may be slower than others.</p>

<p class="author1">You probably care more about readability than speed for most of your code, so your team can code efficiently without being puzzled by performant but opaque code. Sometimes you will want performance, though (without sacrificing readability). Some speed testing might be what you need.</p>

<p class="author1">Take a look at the two code snippets in <a data-type="xref" href="#profiling-dis2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-15</a>. Both do the same job, but the first generates a lot of additional Python bytecode, which will cause more <span class="publishername">overhead.</span></p>
<div id="profiling-dis2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-15. </span>A naive and a more efficient way to solve the same summation problem</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">fn_expressive</code><code class="p">(</code><code class="n">upper</code><code class="o">=</code><code class="mi">1</code><code class="n">_000_000</code><code class="p">):</code>
    <code class="n">total</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">upper</code><code class="p">):</code>
        <code class="n">total</code> <code class="o">+=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">total</code>

<code class="kn">def</code> <code class="nf">fn_terse</code><code class="p">(</code><code class="n">upper</code><code class="o">=</code><code class="mi">1</code><code class="n">_000_000</code><code class="p">):</code>
    <code class="kn">return</code> <code class="nb">sum</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="n">upper</code><code class="p">))</code>

<code class="kn">assert</code> <code class="n">fn_expressive</code><code class="p">()</code> <code class="o">==</code> <code class="n">fn_terse</code><code class="p">(),</code> <code class="s">"Expect identical results from both functions"</code></pre></div>

<p class="author1">Both functions calculate the sum of a range of integers. A simple rule of thumb (but one you <em class="hyperlink">must</em> back up using profiling!) is that more lines of bytecode will execute more slowly than fewer equivalent lines of bytecode that use built-in functions. In <a data-type="xref" href="#profiling-dis3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-16</a>, we use IPython’s <a data-type="indexterm" data-primary="%timeit function" data-primary-sortas="timeit" id="idm46122430715784" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="%timeit function" id="idm46122430714872" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">%timeit</code> magic function to measure the best execution time from a set of runs. <code class="calibre26">fn_terse</code> runs over twice as fast as <code class="calibre26">fn_expressive</code>!</p>
<div id="profiling-dis3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-16. </span>Using <code class="calibre26">%timeit</code> to test our hypothesis that using built-in functions should be faster than writing our own functions</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">fn_expressive</code><code class="p">()</code>
<code class="mi">52.4</code> <code class="n">ms</code> <code class="err">±</code> <code class="mi">86.4</code> <code class="err">µ</code><code class="n">s</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">10</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="o">%</code><code class="n">timeit</code> <code class="n">fn_terse</code><code class="p">()</code>
<code class="mi">18.1</code> <code class="n">ms</code> <code class="err">±</code> <code class="mi">1.38</code> <code class="n">ms</code> <code class="n">per</code> <code class="n">loop</code> <code class="p">(</code><code class="n">mean</code> <code class="err">±</code> <code class="n">std</code><code class="o">.</code> <code class="n">dev</code><code class="o">.</code> <code class="n">of</code> <code class="mi">7</code> <code class="n">runs</code><code class="p">,</code> <code class="mi">100</code> <code class="n">loops</code> <code class="n">each</code><code class="p">)</code></pre></div>

<p class="author1">If we use the <code class="calibre26">dis</code> module to investigate the code for each function, as shown in <a data-type="xref" href="#profiling-dis4" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-17</a>, we can see that the virtual machine has 17 lines to execute with the more expressive function and only 6 to execute with the very readable but terser second function.</p>
<div id="profiling-dis4" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-17. </span>Using <code class="calibre26">dis</code> to view the number of bytecode instructions involved in our two functions</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">In</code> <code class="p">[</code><code class="mi">4</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">dis</code>
<code class="n">In</code> <code class="p">[</code><code class="mi">5</code><code class="p">]:</code> <code class="n">dis</code><code class="o">.</code><code class="n">dis</code><code class="p">(</code><code class="n">fn_expressive</code><code class="p">)</code>
  <code class="mi">2</code>           <code class="mi">0</code> <code class="n">LOAD_CONST</code>               <code class="mi">1</code> <code class="p">(</code><code class="mi">0</code><code class="p">)</code>
              <code class="mi">2</code> <code class="n">STORE_FAST</code>               <code class="mi">1</code> <code class="p">(</code><code class="n">total</code><code class="p">)</code>

  <code class="mi">3</code>           <code class="mi">4</code> <code class="n">SETUP_LOOP</code>              <code class="mi">24</code> <code class="p">(</code><code class="n">to</code> <code class="mi">30</code><code class="p">)</code>
              <code class="mi">6</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">0</code> <code class="p">(</code><code class="nb">range</code><code class="p">)</code>
              <code class="mi">8</code> <code class="n">LOAD_FAST</code>                <code class="mi">0</code> <code class="p">(</code><code class="n">upper</code><code class="p">)</code>
             <code class="mi">10</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
             <code class="mi">12</code> <code class="n">GET_ITER</code>
        <code class="o">&gt;&gt;</code>   <code class="mi">14</code> <code class="n">FOR_ITER</code>                <code class="mi">12</code> <code class="p">(</code><code class="n">to</code> <code class="mi">28</code><code class="p">)</code>
             <code class="mi">16</code> <code class="n">STORE_FAST</code>               <code class="mi">2</code> <code class="p">(</code><code class="n">n</code><code class="p">)</code>

  <code class="mi">4</code>          <code class="mi">18</code> <code class="n">LOAD_FAST</code>                <code class="mi">1</code> <code class="p">(</code><code class="n">total</code><code class="p">)</code>
             <code class="mi">20</code> <code class="n">LOAD_FAST</code>                <code class="mi">2</code> <code class="p">(</code><code class="n">n</code><code class="p">)</code>
             <code class="mi">22</code> <code class="n">INPLACE_ADD</code>
             <code class="mi">24</code> <code class="n">STORE_FAST</code>               <code class="mi">1</code> <code class="p">(</code><code class="n">total</code><code class="p">)</code>
             <code class="mi">26</code> <code class="n">JUMP_ABSOLUTE</code>           <code class="mi">14</code>
        <code class="o">&gt;&gt;</code>   <code class="mi">28</code> <code class="n">POP_BLOCK</code>

  <code class="mi">5</code>     <code class="o">&gt;&gt;</code>   <code class="mi">30</code> <code class="n">LOAD_FAST</code>                <code class="mi">1</code> <code class="p">(</code><code class="n">total</code><code class="p">)</code>
             <code class="mi">32</code> <code class="n">RETURN_VALUE</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">6</code><code class="p">]:</code> <code class="n">dis</code><code class="o">.</code><code class="n">dis</code><code class="p">(</code><code class="n">fn_terse</code><code class="p">)</code>
  <code class="mi">8</code>           <code class="mi">0</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">0</code> <code class="p">(</code><code class="nb">sum</code><code class="p">)</code>
              <code class="mi">2</code> <code class="n">LOAD_GLOBAL</code>              <code class="mi">1</code> <code class="p">(</code><code class="nb">range</code><code class="p">)</code>
              <code class="mi">4</code> <code class="n">LOAD_FAST</code>                <code class="mi">0</code> <code class="p">(</code><code class="n">upper</code><code class="p">)</code>
              <code class="mi">6</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
              <code class="mi">8</code> <code class="n">CALL_FUNCTION</code>            <code class="mi">1</code>
             <code class="mi">10</code> <code class="n">RETURN_VALUE</code></pre></div>

<p class="author1">The difference between the two code blocks is striking. Inside <code class="calibre26">fn_expressive()</code>, we maintain two local variables and iterate over a list using a <code class="calibre26">for</code> statement. The <code class="calibre26">for</code> loop will be checking to see if a <code class="calibre26">StopIteration</code> exception has been raised on each loop. Each iteration applies the <code class="calibre26">total.__add__</code> function, which will check the type of the second variable (<code class="calibre26">n</code>) on each iteration. These checks all add a little expense.</p>

<p class="author1">Inside <code class="calibre26">fn_terse()</code>, we call out to an optimized C list comprehension function that knows how to generate the final result without creating intermediate Python objects. This is much faster, although each iteration must still check for the types of the objects that are being added together (in <a data-type="xref" href="ch04.xhtml#section-dictionary-sets" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 4</a>, we look at ways of fixing the type so we don’t need to check it on each iteration).</p>

<p class="author1">As noted previously, you <em class="hyperlink">must</em> profile your code—if you just rely on this heuristic, you will inevitably write slower code at some point. It is definitely worth learning whether a shorter and still readable way to solve your problem is built into Python. If so, it is more likely to be easily readable by another programmer, and it will <em class="hyperlink">probably</em> run faster.<a data-type="indexterm" data-primary="" data-startref="cp_by" id="idm46122430358152" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="dis_ab" id="idm46122430357144" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pro_dis" id="idm46122430356200" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Unit Testing During Optimization to Maintain Correctness" class="calibre3"><div class="preface" id="profiling-unit-testing">
<h1 class="calibre25">Unit Testing During Optimization to Maintain Correctness</h1>

<p class="author1"><a data-type="indexterm" data-primary="unit testing" id="idm46122430353480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="unit testing" id="idm46122430352776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>If you aren’t already unit testing your code, you are probably hurting your longer-term productivity. Ian (blushing) is embarrassed to note that he once spent a day <span class="publishername">optimizing</span> his code, having disabled unit tests because they were inconvenient, only to discover that his significant speedup result was due to breaking a part of the algorithm he was improving. You do not need to make this mistake even once.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Add unit tests to your code for a saner life. You’ll be giving your current self and your colleagues faith that your code works, and you’ll be giving a present to your future-self who has to maintain this code later. You really will save a lot of time in the long term by adding tests to your code.</p>
</div>

<p class="author1">In addition to unit testing, you should also strongly consider using <code class="calibre26">coverage.py</code>. It checks to see which lines of code are exercised by your tests and identifies the sections that have no coverage. This quickly lets you figure out whether you’re testing the code that you’re about to optimize, such that any mistakes that might creep in during the optimization process are quickly caught.</p>








<section data-type="sect2" data-pdf-bookmark="No-op @profile Decorator" class="calibre3"><div class="preface" id="no_op_profile_decorator">
<h2 class="calibre43">No-op @profile Decorator</h2>

<p class="author1"><a data-type="indexterm" data-primary="decorators" id="dec_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="no-op decorator" id="idm46122430344840" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="@profile decorator" data-primary-sortas="profile" id="idm46122430344168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="@profile decorator" id="idm46122430343224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Your unit tests will fail with a <code class="calibre26">NameError</code> exception if your code uses <code class="calibre26">@profile</code> from <code class="calibre26">line_profiler</code> or <code class="calibre26">memory_profiler</code>. The reason is that the unit test framework will not be injecting the <code class="calibre26">@profile</code> decorator into the local namespace. The no-op decorator shown here solves this problem. It is easiest to add it to the block of code that you’re testing and remove it when you’re done.</p>

<p class="author1">With the no-op decorator, you can run your tests without modifying the code that you’re testing. This means you can run your tests after every profile-led optimization you make so you’ll never be caught out by a bad optimization step.</p>

<p class="author1">Let’s say we have the trivial <code class="calibre26">ex.py</code> module shown in <a data-type="xref" href="#profiling-noop1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-18</a>. It has a test (for <code class="calibre26">pytest</code>) and a function that we’ve been profiling with either <code class="calibre26">line_profiler</code> or <code class="calibre26">memory_profiler</code>.</p>
<div id="profiling-noop1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-18. </span>Simple function and test case where we wish to use <code class="calibre26">@profile</code></h5>

<pre data-type="programlisting" class="calibre59">import time

def test_some_fn():
    """Check basic behaviors for our function"""
    assert some_fn(2) == 4
    assert some_fn(1) == 1
    assert some_fn(-1) == 1


@profile
def some_fn(useful_input):
    """An expensive function that we wish to both test and profile"""
    # artificial "we're doing something clever and expensive" delay
    time.sleep(1)
    return useful_input ** 2


if __name__ == "__main__":
    print(f"Example call `some_fn(2)` == {some_fn(2)}")</pre></div>

<p class="author1">If we run <code class="calibre26">pytest</code> on our code, we’ll get a <code class="calibre26">NameError</code>, as shown in <a data-type="xref" href="#profiling-no-decorator" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-19</a>.</p>
<div id="profiling-no-decorator" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-19. </span>A missing decorator during testing breaks out tests in an unhelpful way!</h5>

<pre data-type="programlisting" class="calibre59">$ pytest utility.py
=============== test session starts ===============
platform linux -- Python 3.7.3, pytest-4.6.2, py-1.8.0, pluggy-0.12.0
rootdir: noop_profile_decorator
plugins: cov-2.7.1
collected 0 items / 1 errors

====================== ERRORS =====================
___________ ERROR collecting utility.py ___________
utility.py:20: in &lt;module&gt;
    @profile
E   NameError: name 'profile' is not defined</pre></div>

<p class="author1">The solution is to add a no-op decorator at the start of our module (you can remove it after you’re done with profiling). If the <code class="calibre26">@profile</code> decorator is not found in one of the <span class="publishername">namespaces</span> (because <code class="calibre26">line_profiler</code> or <code class="calibre26">memory_profiler</code> is not being used), the no-op version we’ve written is added. If <code class="calibre26">line_profiler</code> or <code class="calibre26">memory_profiler</code> has injected the new function into the namespace, our no-op version is ignored.</p>

<p class="author1">For both <code class="calibre26">line_profiler</code> and <code class="calibre26">memory_profiler</code>, we can add the code in <a data-type="xref" href="#profiling-noop2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-20</a>.</p>
<div id="profiling-noop2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-20. </span>Add a no-op <code class="calibre26">@profile</code> decorator to the namespace while unit testing</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c"># check for line_profiler or memory_profiler in the local scope, both</code>
<code class="c"># are injected by their respective tools or they're absent</code>
<code class="c"># if these tools aren't being used (in which case we need to substitute</code>
<code class="c"># a dummy @profile decorator)</code>
<code class="kn">if</code> <code class="s">'line_profiler'</code> <code class="ow">not</code> <code class="ow">in</code> <code class="nb">dir</code><code class="p">()</code> <code class="ow">and</code> <code class="s">'profile'</code> <code class="ow">not</code> <code class="ow">in</code> <code class="nb">dir</code><code class="p">():</code>
    <code class="kn">def</code> <code class="nf">profile</code><code class="p">(</code><code class="n">func</code><code class="p">):</code>
        <code class="kn">return</code> <code class="n">func</code></pre></div>

<p class="author1">Having added the no-op decorator, we can now run our <code class="calibre26">pytest</code> successfully, as shown in <a data-type="xref" href="#profiling-noop3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 2-21</a>, along with our profilers—with no additional code changes.</p>
<div id="profiling-noop3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 2-21. </span>With the no-op decorator, we have working tests, and both of our profilers work correctly</h5>

<pre data-type="programlisting" class="calibre59">$ pytest utility.py
=============== test session starts ===============
platform linux -- Python 3.7.3, pytest-4.6.2, py-1.8.0, pluggy-0.12.0
rootdir: /home/ian/workspace/personal_projects/high_performance_python_book_2e/
         high-performance-python-2e/examples_ian/ian/ch02/noop_profile_decorator
plugins: cov-2.7.1
collected 1 item

utility.py .

============= 1 passed in 3.04 seconds ============

$ kernprof -l -v utility.py
Example call `some_fn(2)` == 4
...
Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    20                                           @profile
    21                                           def some_fn(useful_input):
    22                                               """An expensive function that...
    23                                               # artificial 'we're doing...
    24         1    1001345.0 1001345.0    100.0      time.sleep(1)
    25         1          7.0      7.0      0.0      return useful_input ** 2

$ python -m memory_profiler utility.py
Example call `some_fn(2)` == 4
Filename: utility.py

Line #    Mem usage    Increment   Line Contents
================================================
    20   48.277 MiB   48.277 MiB   @profile
    21                             def some_fn(useful_input):
    22                                 """An expensive function that we wish to...
    23                                 # artificial 'we're doing something clever...
    24   48.277 MiB    0.000 MiB       time.sleep(1)
    25   48.277 MiB    0.000 MiB       return useful_input ** 2</pre></div>

<p class="author1">You can save yourself a few minutes by avoiding the use of these decorators, but once you’ve lost hours making a false optimization that breaks your code, you’ll want to integrate this into your workflow.<a data-type="indexterm" data-primary="" data-startref="dec_ab" id="idm46122430309160" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Strategies to Profile Your Code Successfully" class="calibre3"><div class="preface" id="profiling-strategies">
<h1 class="calibre25">Strategies to Profile Your Code Successfully</h1>

<p class="author1"><a data-type="indexterm" data-primary="profiling" data-secondary="success strategies" id="pro_ss" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Profiling requires some time and concentration. You will stand a better chance of understanding your code if you separate the section you want to test from the main body of your code. You can then unit test the code to preserve correctness, and you can pass in realistic fabricated data to exercise the inefficiencies you want to address.</p>

<p class="author1">Do remember to disable any BIOS-based accelerators, as they will only confuse your results. On Ian’s laptop, the Intel Turbo Boost feature can temporarily accelerate a CPU above its normal maximum speed if it is cool enough. This means that a cool CPU may run the same block of code faster than a hot CPU. Your operating system may also control the clock speed—a laptop on battery power is likely to more aggressively control CPU speed than a laptop on AC power. To create a more stable benchmarking configuration, we do the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Disable Turbo Boost in the BIOS.</p>
</li>
<li class="calibre21">
<p class="calibre27">Disable the operating system’s ability to override the SpeedStep (you will find this in your BIOS if you’re allowed to control it).</p>
</li>
<li class="calibre21">
<p class="calibre27">Use only AC power (never battery power).</p>
</li>
<li class="calibre21">
<p class="calibre27">Disable background tools like backups and Dropbox while running experiments.</p>
</li>
<li class="calibre21">
<p class="calibre27">Run the experiments many times to obtain a stable measurement.</p>
</li>
<li class="calibre21">
<p class="calibre27">Possibly drop to run level 1 (Unix) so that no other tasks are running.</p>
</li>
<li class="calibre21">
<p class="calibre27">Reboot and rerun the experiments to double-confirm the results.</p>
</li>
</ul>

<p class="author1">Try to hypothesize the expected behavior of your code and then validate (or disprove!) the hypothesis with the result of a profiling step. Your choices will not change (you should only drive your decisions by using the profiled results), but your intuitive understanding of the code will improve, and this will pay off in future projects as you will be more likely to make performant decisions. Of course, you will verify these performant decisions by profiling as you go.</p>

<p class="author1">Do not skimp on the preparation. If you try to performance test code deep inside a larger project without separating it from the larger project, you are likely to witness side effects that will sidetrack your efforts. It is likely to be harder to unit test a larger project when you’re making fine-grained changes, and this may further hamper your efforts. Side effects could include other threads and processes impacting CPU and memory usage and network and disk activity, which will skew your results.</p>

<p class="author1">Naturally, you’re already using source code control (e.g., Git or Mercurial), so you’ll be able to run multiple experiments in different branches without ever losing “the versions that work well.” If you’re <em class="hyperlink">not</em> using source code control, do yourself a huge favor and start to do so!</p>

<p class="author1">For web servers, investigate <a data-type="indexterm" data-primary="dowser" id="idm46122430291352" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="profiling" data-secondary="dowser" id="idm46122430290648" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">dowser</code> and <code class="calibre26">dozer</code>; you can use these to visualize in real time the behavior of objects in the namespace. Definitely consider separating the code you want to test out of the main web application if possible, as this will make profiling significantly easier.</p>

<p class="author1">Make sure your unit tests exercise all the code paths in the code that you’re analyzing. Anything you don’t test that is used in your benchmarking may cause subtle errors that will slow down your progress. Use <code class="calibre26">coverage.py</code> to confirm that your tests are covering all the code paths.</p>

<p class="author1">Unit testing a complicated section of code that generates a large numerical output may be difficult. Do not be afraid to output a text file of results to run through <code class="calibre26">diff</code> or to use a <code class="calibre26">pickled</code> object. For numeric optimization problems, Ian likes to create long text files of floating-point numbers and use <code class="calibre26">diff</code>—minor rounding errors show up immediately, even if they’re rare in the output.</p>

<p class="author1">If your code might be subject to numerical rounding issues due to subtle changes, you are better off with a large output that can be used for a before-and-after comparison. One cause of rounding errors is the difference in floating-point precision between CPU registers and main memory. Running your code through a different code path can cause subtle rounding errors that might later confound you—it is better to be aware of this as soon as they occur.</p>

<p class="author1">Obviously, it makes sense to use a source code control tool while you are profiling and optimizing. Branching is cheap, and it will preserve your sanity.<a data-type="indexterm" data-primary="" data-startref="pro_ss" id="idm46122430284008" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Wrap-Up" class="calibre3"><div class="preface" id="idm46122430307592">
<h1 class="calibre25">Wrap-Up</h1>

<p class="author1">Having looked at profiling techniques, you should have all the tools you need to identify bottlenecks around CPU and RAM usage in your code. Next, we’ll look at how Python implements the most common containers, so you can make sensible decisions about representing larger collections of data.</p>
</div></section>







<div data-type="footnotes" class="calibre52"><p data-type="footnote" id="idm46122431392152" class="calibre53"><sup class="calibre54"><a href="ch02.xhtml#idm46122431392152-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> <code class="calibre26">memory_profiler</code> measures memory usage according to the  International Electrotechnical Commission’s MiB (mebibyte) of 2<sup class="calibre54">20</sup> bytes. This is slightly different from the more common but also more ambiguous MB (megabyte has two commonly accepted definitions!). 1 MiB is equal to 1.048576 (or approximately 1.05) MB. For our discussion, unless we’re dealing with very specific amounts, we’ll consider the two equivalent.</p><p data-type="footnote" id="idm46122430772872" class="calibre53"><sup class="calibre54"><a href="ch02.xhtml#idm46122430772872-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> The language creator Guido van Rossum is Dutch, and not everyone has agreed with his “obvious” choices, but on the whole we like the choices that Guido makes!</p></div></div></section></div>



  </body></html>