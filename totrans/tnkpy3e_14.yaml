- en: 12\. Text Analysis and Generation#
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://allendowney.github.io/ThinkPython/chap12.html](https://allendowney.github.io/ThinkPython/chap12.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'At this point we have covered Python’s core data structures – lists, dictionaries,
    and tuples – and some algorithms that use them. In this chapter, we’ll use them
    to explore text analysis and Markov generation:'
  prefs: []
  type: TYPE_NORMAL
- en: Text analysis is a way to describe the statistical relationships between the
    words in a document, like the probability that one word is followed by another,
    and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov generation is a way to generate new text with words and phrases similar
    to the original text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These algorithms are similar to parts of a Large Language Model (LLM), which
    is the key component of a chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by counting the number of times each word appears in a book. Then
    we’ll look at pairs of words, and make a list of the words that can follow each
    word. We’ll make a simple version of a Markov generator, and as an exercise, you’ll
    have a chance to make a more general version.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1\. Unique words[#](#unique-words "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a first step toward text analysis, let’s read a book – *The Strange Case
    Of Dr. Jekyll And Mr. Hyde* by Robert Louis Stevenson – and count the number of
    unique words. Instructions for downloading the book are in the notebook for this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We’ll use a `for` loop to read lines from the file and `split` to divide the
    lines into words. Then, to keep track of unique words, we’ll store each word as
    a key in a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The length of the dictionary is the number of unique words – about `6000` by
    this way of counting. But if we inspect them, we’ll see that some are not valid
    words.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s look at the longest words in `unique_words`. We can use `sorted`
    to sort the words, passing the `len` function as a keyword argument so the words
    are sorted by length.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The slice index, `[-5:]`, selects the last `5` elements of the sorted list,
    which are the longest words.
  prefs: []
  type: TYPE_NORMAL
- en: The list includes some legitimately long words, like “circumscription”, and
    some hyphenated words, like “chocolate-coloured”. But some of the longest “words”
    are actually two words separated by a dash. And other words include punctuation
    like periods, exclamation points, and quotation marks.
  prefs: []
  type: TYPE_NORMAL
- en: So, before we move on, let’s deal with dashes and other punctuation.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2\. Punctuation[#](#punctuation "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To identify the words in the text, we need to deal with two issues:'
  prefs: []
  type: TYPE_NORMAL
- en: When a dash appears in a line, we should replace it with a space – then when
    we use `split`, the words will be separated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After splitting the words, we can use `strip` to remove punctuation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To handle the first issue, we can use the following function, which takes a
    string, replaces dashes with spaces, splits the string, and returns the resulting
    list.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Notice that `split_line` only replaces dashes, not hyphens. Here’s an example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now, to remove punctuation from the beginning and end of each word, we can use
    `strip`, but we need a list of characters that are considered punctuation.
  prefs: []
  type: TYPE_NORMAL
- en: Characters in Python strings are in Unicode, which is an international standard
    used to represent letters in nearly every alphabet, numbers, symbols, punctuation
    marks, and more. The `unicodedata` module provides a `category` function we can
    use to tell which characters are punctuation. Given a letter, it returns a string
    with information about what category the letter is in.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The category string of `'A'` is `'Lu'` – the `'L'` means it is a letter and
    the `'u'` means it is uppercase.
  prefs: []
  type: TYPE_NORMAL
- en: The category string of `'.'` is `'Po'` – the `'P'` means it is punctuation and
    the `'o'` means its subcategory is “other”.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can find the punctuation marks in the book by checking for characters with
    categories that begin with `'P'`. The following loop stores the unique punctuation
    marks in a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To make a list of punctuation marks, we can join the keys of the dictionary
    into a string.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now that we know which characters in the book are punctuation, we can write
    a function that takes a word, strips punctuation from the beginning and end, and
    converts it to lower case.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here’s an example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Because `strip` removes characters from the beginning and end, it leaves hyphenated
    words alone.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now here’s a loop that uses `split_line` and `clean_word` to identify the unique
    words in the book.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: With this stricter definition of what a word is, there are about 4000 unique
    words. And we can confirm that the list of longest words has been cleaned up.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s see how many times each word is used.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3\. Word frequencies[#](#word-frequencies "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following loop computes the frequency of each unique word.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The first time we see a word, we initialize its frequency to `1`. If we see
    the same word again later, we increment its frequency.
  prefs: []
  type: TYPE_NORMAL
- en: To see which words appear most often, we can use `items` to get the key-value
    pairs from `word_counter`, and sort them by the second element of the pair, which
    is the frequency. First we’ll define a function that selects the second element.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can use `sorted` with two keyword arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`key=second_element` means the items will be sorted according to the frequencies
    of the words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reverse=True` means they items will be sorted in reverse order, with the most
    frequent words first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here are the five most frequent words.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we’ll encapsulate this loop in a function. And we’ll use
    it to demonstrate a new feature – optional parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 12.4\. Optional parameters[#](#optional-parameters "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve used built-in functions that take optional parameters. For example, `round`
    takes an optional parameters called `ndigits` that indicates how many decimal
    places to keep.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: But it’s not just built-in functions – we can write functions with optional
    parameters, too. For example, the following function takes two parameters, `word_counter`
    and `num`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The second parameter looks like an assignment statement, but it’s not – it’s
    an optional parameter.
  prefs: []
  type: TYPE_NORMAL
- en: If you call this function with one argument, `num` gets the **default value**,
    which is `5`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: If you call this function with two arguments, the second argument gets assigned
    to `num` instead of the default value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In that case, we would say the optional argument **overrides** the default value.
  prefs: []
  type: TYPE_NORMAL
- en: If a function has both required and optional parameters, all of the required
    parameters have to come first, followed by the optional ones.
  prefs: []
  type: TYPE_NORMAL
- en: '## 12.5\. Dictionary subtraction[#](#dictionary-subtraction "Link to this heading")'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we want to spell-check a book – that is, find a list of words that might
    be misspelled. One way to do that is to find words in the book that don’t appear
    in a list of valid words. In previous chapters, we’ve used a list of words that
    are considered valid in word games like Scrabble. Now we’ll use this list to spell-check
    Robert Louis Stevenson.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of this problem as set subtraction – that is, we want to find all
    the words from one set (the words in the book) that are not in the other (the
    words in the list).
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve done before, we can read the contents of `words.txt` and split it into
    a list of strings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The we’ll store the words as keys in a dictionary so we can use the `in` operator
    to check quickly whether a word is valid.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Now, to identify words that appear in the book but not in the word list, we’ll
    use `subtract`, which takes two dictionaries as parameters and returns a new dictionary
    that contains all the keys from one that are not in the other.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Here’s how we use it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: To get a sample of words that might be misspelled, we can print the most common
    words in `diff`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The most common “misspelled” words are mostly names and a few single-letter
    words (Mr. Utterson is Dr. Jekyll’s friend and lawyer).
  prefs: []
  type: TYPE_NORMAL
- en: If we select words that only appear once, they are more likely to be actual
    misspellings. We can do that by looping through the items and making a list of
    words with frequency `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Here are the last few elements of the list.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Most of them are valid words that are not in the word list. But `'reindue'`
    appears to be a misspelling of `'reinduce'`, so at least we found one legitimate
    error.
  prefs: []
  type: TYPE_NORMAL
- en: 12.6\. Random numbers[#](#random-numbers "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a step toward Markov text generation, next we’ll choose a random sequence
    of words from `word_counter`. But first let’s talk about randomness.
  prefs: []
  type: TYPE_NORMAL
- en: Given the same inputs, most computer programs are **deterministic**, which means
    they generate the same outputs every time. Determinism is usually a good thing,
    since we expect the same calculation to yield the same result. For some applications,
    though, we want the computer to be unpredictable. Games are one example, but there
    are more.
  prefs: []
  type: TYPE_NORMAL
- en: Making a program truly nondeterministic turns out to be difficult, but there
    are ways to fake it. One is to use algorithms that generate **pseudorandom** numbers.
    Pseudorandom numbers are not truly random because they are generated by a deterministic
    computation, but just by looking at the numbers it is all but impossible to distinguish
    them from random.
  prefs: []
  type: TYPE_NORMAL
- en: The `random` module provides functions that generate pseudorandom numbers –
    which I will simply call “random” from here on. We can import it like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `random` module provides a function called `choice` that chooses an element
    from a list at random, with every element having the same probability of being
    chosen.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: If you call the function again, you might get the same element again, or a different
    one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the long run, we expect to get every element about the same number of times.
  prefs: []
  type: TYPE_NORMAL
- en: If you use `choice` with a dictionary, you get a `KeyError`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: To choose a random key, you have to put the keys in a list and then call `choice`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: If we generate a random sequence of words, it doesn’t make much sense.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Part of the problem is that we are not taking into account that some words are
    more common than others. The results will be better if we choose words with different
    “weights”, so that some are chosen more often than others.
  prefs: []
  type: TYPE_NORMAL
- en: If we use the values from `word_counter` as weights, each word is chosen with
    a probability that depends on its frequency.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `random` module provides another function called `choices` that takes weights
    as an optional argument.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: And it takes another optional argument, `k`, that specifies the number of words
    to select.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The result is a list of strings that we can join into something that’s looks
    more like a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: If you choose words from the book at random, you get a sense of the vocabulary,
    but a series of random words seldom makes sense because there is no relationship
    between successive words. For example, in a real sentence you expect an article
    like “the” to be followed by an adjective or a noun, and probably not a verb or
    adverb. So the next step is to look at these relationships between words.
  prefs: []
  type: TYPE_NORMAL
- en: 12.7\. Bigrams[#](#bigrams "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of looking at one word at a time, now we’ll look at sequences of two
    words, which are called **bigrams**. A sequence of three words is called a **trigram**,
    and a sequence with some unspecified number of words is called an **n-gram**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write a program that finds all of the bigrams in the book and the number
    of times each one appears. To store the results, we’ll use a dictionary where
  prefs: []
  type: TYPE_NORMAL
- en: The keys are tuples of strings that represent bigrams, and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The values are integers that represent frequencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s call it `bigram_counter`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The following function takes a list of two strings as a parameter. First it
    makes a tuple of the two strings, which can be used as a key in a dictionary.
    Then it adds the key to `bigram_counter`, if it doesn’t exist, or increments the
    frequency if it does.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: As we go through the book, we have to keep track of each pair of consecutive
    words. So if we see the sequence “man is not truly one”, we would add the bigrams
    “man is”, “is not”, “not truly”, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: To keep track of these bigrams, we’ll use a list called `window`, because it
    is like a window that slides over the pages of the book, showing only two words
    at a time. Initially, `window` is empty.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: We’ll use the following function to process the words one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The first time this function is called, it appends the given word to `window`.
    Since there is only one word in the window, we don’t have a bigram yet, so the
    function ends.
  prefs: []
  type: TYPE_NORMAL
- en: The second time it’s called – and every time thereafter – it appends a second
    word to `window`. Since there are two words in the window, it calls `count_bigram`
    to keep track of how many times each bigram appears. Then it uses `pop` to remove
    the first word from the window.
  prefs: []
  type: TYPE_NORMAL
- en: The following program loops through the words in the book and processes them
    one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The result is a dictionary that maps from each bigram to the number of times
    it appears. We can use `print_most_common` to see the most common bigrams.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Looking at these results, we can get a sense of which pairs of words are most
    likely to appear together. We can also use the results to generate random text,
    like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '`bigrams` is a list of the bigrams that appear in the books. `weights` is a
    list of their frequencies, so `random_bigrams` is a sample where the probability
    a bigram is selected is proportional to its frequency.'
  prefs: []
  type: TYPE_NORMAL
- en: Here are the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: This way of generating text is better than choosing random words, but still
    doesn’t make a lot of sense.
  prefs: []
  type: TYPE_NORMAL
- en: 12.8\. Markov analysis[#](#markov-analysis "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can do better with Markov chain text analysis, which computes, for each
    word in a text, the list of words that come next. As an example, we’ll analyze
    these lyrics from the Monty Python song *Eric, the Half a Bee*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: To store the results, we’ll use a dictionary that maps from each word to the
    list of words that follow it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: As an example, let’s start with the first two words of the song.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: If the first word is not in `successor_map`, we have to add a new item that
    maps from the first word to a list containing the second word.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: If the first word is already in the dictionary, we can look it up to get the
    list of successors we’ve seen so far, and append the new one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: The following function encapsulates these steps.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: If the same bigram appears more that once, the second word is added to the list
    more than once. In this way, `successor_map` keeps track of how many times each
    successor appears.
  prefs: []
  type: TYPE_NORMAL
- en: As we did in the previous section, we’ll use a list called `window` to store
    pairs of consecutive words. And we’ll use the following function to process the
    words one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Here’s how we use it to process the words in the song.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: And here are the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: The word `'half'` can be followed by `'a'`, `'not'`, or `'the'`. The word `'a'`
    can be followed by `'bee'` or `'vis'`. Most of the other words appear only once,
    so they are followed by only a single word.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s analyze the book.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: We can look up any word and find the words that can follow it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: In this list of successors, notice that the word `'to'` appears three times
    – the other successors only appear once.
  prefs: []
  type: TYPE_NORMAL
- en: 12.9\. Generating text[#](#generating-text "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can use the results from the previous section to generate new text with
    the same relationships between consecutive words as in the original. Here’s how
    it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Starting with any word that appears in the text, we look up its possible successors
    and choose one at random.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, using the chosen word, we look up its possible successors, and choose
    one at random.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can repeat this process to generate as many words as we want. As an example,
    let’s start with the word `'although'`. Here are the words that can follow it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: We can use `choice` to choose from the list with equal probability.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: If the same word appears more than once in the list, it is more likely to be
    selected.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating these steps, we can use the following loop to generate a longer series.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: The result sounds more like a real sentence, but it still doesn’t make much
    sense.
  prefs: []
  type: TYPE_NORMAL
- en: We can do better using more than one word as a key in `successor_map`. For example,
    we can make a dictionary that maps from each bigram – or trigram – to the list
    of words that come next. As an exercise, you’ll have a chance to implement this
    analysis and see what the results look like.
  prefs: []
  type: TYPE_NORMAL
- en: '## 12.10\. Debugging[#](#debugging "Link to this heading")'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point we are writing more substantial programs, and you might find
    that you are spending more time debugging. If you are stuck on a difficult bug,
    here are a few things to try:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading: Examine your code, read it back to yourself, and check that it says
    what you meant to say.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running: Experiment by making changes and running different versions. Often
    if you display the right thing at the right place in the program, the problem
    becomes obvious, but sometimes you have to build scaffolding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ruminating: Take some time to think! What kind of error is it: syntax, runtime,
    or semantic? What information can you get from the error messages, or from the
    output of the program? What kind of error could cause the problem you’re seeing?
    What did you change last, before the problem appeared?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rubberducking: If you explain the problem to someone else, you sometimes find
    the answer before you finish asking the question. Often you don’t need the other
    person; you could just talk to a rubber duck. And that’s the origin of the well-known
    strategy called **rubber duck debugging**. I am not making this up – see [https://en.wikipedia.org/wiki/Rubber_duck_debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Retreating: At some point, the best thing to do is back up – undoing recent
    changes – until you get to a program that works. Then you can start rebuilding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Resting: If you give your brain a break, sometime it will find the problem
    for you.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beginning programmers sometimes get stuck on one of these activities and forget
    the others. Each activity comes with its own failure mode.
  prefs: []
  type: TYPE_NORMAL
- en: For example, reading your code works if the problem is a typographical error,
    but not if the problem is a conceptual misunderstanding. If you don’t understand
    what your program does, you can read it 100 times and never see the error, because
    the error is in your head.
  prefs: []
  type: TYPE_NORMAL
- en: Running experiments can work, especially if you run small, simple tests. But
    if you run experiments without thinking or reading your code, it can take a long
    time to figure out what’s happening.
  prefs: []
  type: TYPE_NORMAL
- en: You have to take time to think. Debugging is like an experimental science. You
    should have at least one hypothesis about what the problem is. If there are two
    or more possibilities, try to think of a test that would eliminate one of them.
  prefs: []
  type: TYPE_NORMAL
- en: But even the best debugging techniques will fail if there are too many errors,
    or if the code you are trying to fix is too big and complicated. Sometimes the
    best option is to retreat, simplifying the program until you get back to something
    that works.
  prefs: []
  type: TYPE_NORMAL
- en: Beginning programmers are often reluctant to retreat because they can’t stand
    to delete a line of code (even if it’s wrong). If it makes you feel better, copy
    your program into another file before you start stripping it down. Then you can
    copy the pieces back one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a hard bug requires reading, running, ruminating, retreating, and sometimes
    resting. If you get stuck on one of these activities, try the others.
  prefs: []
  type: TYPE_NORMAL
- en: 12.11\. Glossary[#](#glossary "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**default value:** The value assigned to a parameter if no argument is provided.'
  prefs: []
  type: TYPE_NORMAL
- en: '**override:** To replace a default value with an argument.'
  prefs: []
  type: TYPE_NORMAL
- en: '**deterministic:** A deterministic program does the same thing each time it
    runs, given the same inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '**pseudorandom:** A pseudorandom sequence of numbers appears to be random,
    but is generated by a deterministic program.'
  prefs: []
  type: TYPE_NORMAL
- en: '**bigram:** A sequence of two elements, often words.'
  prefs: []
  type: TYPE_NORMAL
- en: '**trigram:** A sequence of three elements.'
  prefs: []
  type: TYPE_NORMAL
- en: '**n-gram:** A sequence of an unspecified number of elements.'
  prefs: []
  type: TYPE_NORMAL
- en: '**rubber duck debugging:** A way of debugging by explaining a problem aloud
    to an inanimate object.'
  prefs: []
  type: TYPE_NORMAL
- en: 12.12\. Exercises[#](#exercises "Link to this heading")
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 12.12.1\. Ask a virtual assistant[#](#ask-a-virtual-assistant "Link to this
    heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In `add_bigram`, the `if` statement creates a new list or appends an element
    to an existing list, depending on whether the key is already in the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Dictionaries provide a method called `setdefault` that we can use to do the
    same thing more concisely. Ask a virtual assistant how it works, or copy `add_word`
    into a virtual assistant and ask “Can you rewrite this using `setdefault`?”
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we implemented Markov chain text analysis and generation. If
    you are curious, you can ask a virtual assistant for more information on the topic.
    One of the things you might learn is that virtual assistants use algorithms that
    are similar in many ways – but also different in important ways. Ask a VA, “What
    are the differences between large language models like GPT and Markov chain text
    analysis?”
  prefs: []
  type: TYPE_NORMAL
- en: 12.12.2\. Exercise[#](#exercise "Link to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Write a function that counts the number of times each trigram (sequence of three
    words) appears. If you test your function with the text of *Dr. Jekyll and Mr.
    Hyde*, you should find that the most common trigram is “said the lawyer”.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hint: Write a function called `count_trigram` that is similar to `count_bigram`.
    Then write a function called `process_word_trigram` that is similar to `process_word_bigram`.'
  prefs: []
  type: TYPE_NORMAL
- en: 12.12.3\. Exercise[#](#id1 "Link to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let’s implement Markov chain text analysis with a mapping from each bigram
    to a list of possible successors.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with `add_bigram`, write a function called `add_trigram` that takes
    a list of three words and either adds or updates an item in `successor_map`, using
    the first two words as the key and the third word as a possible successor.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a version of `process_word_trigram` that calls `add_trigram`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: You can use the following loop to test your function with the words from the
    book.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: In the next exercise, you’ll use the results to generate new random text.
  prefs: []
  type: TYPE_NORMAL
- en: 12.12.4\. Exercise[#](#id2 "Link to this heading")
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this exercise, we’ll assume that `successor_map` is a dictionary that maps
    from each bigram to the list of words that follow it.
  prefs: []
  type: TYPE_NORMAL
- en: To generate random text, we’ll start by choosing a random key from `successor_map`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Now write a loop that generates 50 more words following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In `successor_map`, look up the list of words that can follow `bigram`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose one of them at random and print it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the next iteration, make a new bigram that contains the second word from
    `bigram` and the chosen successor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For example, if we start with the bigram `('doubted', 'if')` and choose `'from'`
    as its successor, the next bigram is `('if', 'from')`.
  prefs: []
  type: TYPE_NORMAL
- en: If everything is working, you should find that the generated text is recognizably
    similar in style to the original, and some phrases make sense, but the text might
    wander from one topic to another.
  prefs: []
  type: TYPE_NORMAL
- en: As a bonus exercise, modify your solution to the last two exercises to use trigrams
    as keys in `successor_map`, and see what effect it has on the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[Think Python: 3rd Edition](https://allendowney.github.io/ThinkPython/index.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Copyright 2024 [Allen B. Downey](https://allendowney.com)
  prefs: []
  type: TYPE_NORMAL
- en: 'Code license: [MIT License](https://mit-license.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)'
  prefs: []
  type: TYPE_NORMAL
