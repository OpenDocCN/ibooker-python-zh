<html><head></head><body><div id="sbo-rt-content"><section data-type="appendix" epub:type="appendix" data-pdf-bookmark="Appendix A. Key System Concepts for Dask Users"><div class="appendix" id="appA">
<h1><span class="label">Appendix A. </span>Key System Concepts for Dask Users</h1>


<p>We’ve covered a few distributed system concepts briefly as needed in this book, but as you get ready to head out on your own, it’s a good idea to review some of the core concepts that Dask is built on. In this appendix, you will learn more about the key principles used in Dask and how they impact the code you write on top of Dask.</p>






<section data-type="sect1" data-pdf-bookmark="Testing"><div class="sect1" id="id110">
<h1>Testing</h1>

<p>Testing is an often overlooked part <a data-type="indexterm" data-primary="testing" id="id971"/>of data science and data engineering. Some of our tools, like SQL and Jupyter notebooks, do not encourage testing or make it easy to test—but this does not absolve us of the responsibility to test our code. Data privacy concerns can add another layer of challenge, where we don’t want to store user data for testing, requiring us to put in the effort to create “fake” data for testing or break our code down into testable components where we don’t need user data.</p>








<section data-type="sect2" data-pdf-bookmark="Manual Testing"><div class="sect2" id="id111">
<h2>Manual Testing</h2>

<p>We often perform some kind of manual <a data-type="indexterm" data-primary="testing" data-secondary="manual" id="id972"/><a data-type="indexterm" data-primary="manual testing" id="id973"/>testing while writing software or data tools. This can include simply running the tool and eyeballing the results to see if they look reasonable. Manual testing is time-consuming and not automatically repeatable, so while it is great during development, it is insufficient for long-lived projects.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Unit Testing"><div class="sect2" id="id112">
<h2>Unit Testing</h2>

<p>Unit testing refers to testing individual <a data-type="indexterm" data-primary="testing" data-secondary="unit testing" id="id974"/><a data-type="indexterm" data-primary="unit testing" id="id975"/>units of code rather than the whole system together. This requires having your code be composed in different units, like modules or functions. While this is less common with notebooks, we believe that structuring your code for testability is a good practice to follow.</p>

<p>Writing unit tests for notebooks can be challenging; doctests are slightly easier to inline within a notebook. If you want to use traditional unit test libraries, the <a href="https://oreil.ly/yUxXy">ipython-unittest magics</a> let you inline your unit tests within your notebook.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Integration Testing"><div class="sect2" id="id113">
<h2>Integration Testing</h2>

<p>Integration testing refers to <a data-type="indexterm" data-primary="testing" data-secondary="integration testing" id="id976"/><a data-type="indexterm" data-primary="integration testing" id="id977"/>testing how different parts of a system work together. It is often much closer to the real usage of your code, but it can be more complicated, as it involves setting up other systems to test against. You can (to an extent) use some of the same libraries for integration testing, but these tests tend to involve more setup and teardown work.<sup><a data-type="noteref" id="id978-marker" href="app01.xhtml#id978">1</a></sup> Integration testing is also more likely to be “flaky,” since making sure that all of the different components your software needs are present in your test environment before starting the tests can be challenging.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Test-Driven Development"><div class="sect2" id="id114">
<h2>Test-Driven Development</h2>

<p>Test-driven development involves <a data-type="indexterm" data-primary="testing" data-secondary="test-driven development" id="id979"/><a data-type="indexterm" data-primary="test-driven development" id="id980"/><a data-type="indexterm" data-primary="development, test-driven" id="id981"/>taking the requirements or expectations of your code and writing tests and then writing the code after. For data science pipelines this can often be done by creating a sample input (sometimes called a golden set) and writing out what you expect the output to be. Test-driven development can be complicated, especially when integrating multiple data sources.</p>

<p>While you don’t need to use test-driven development, we believe it’s important to make tests alongside the development of your data pipelines. Tests added after development are better than no tests, but in our experience the context you have during the development helps you create better tests (and validate your assumptions 
<span class="keep-together">early on).</span></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Property Testing"><div class="sect2" id="id115">
<h2>Property Testing</h2>

<p>Property testing is a potentially great <a data-type="indexterm" data-primary="property testing" id="id982"/><a data-type="indexterm" data-primary="testing" data-secondary="property testing" id="id983"/>solution to the challenge of coming up with test data that covers all of the edge cases in terms of data that your code could trip up on. Instead of writing the traditional “for input A, result B is expected,” you specify properties, like “if we have 0 customers, we should have 0 sales” or “all (valid) customers should have a fraud score after this pipeline.”</p>

<p><a href="https://oreil.ly/zQhnh">Hypothesis</a> is the most popular library for property testing in 
<span class="keep-together">Python.</span></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Working with Notebooks"><div class="sect2" id="id116">
<h2>Working with Notebooks</h2>

<p>Testing notebooks is painful, which is <a data-type="indexterm" data-primary="notebooks, testing" id="id984"/><a data-type="indexterm" data-primary="testing" data-secondary="notebooks" id="id985"/>unfortunate given their immense popularity. Generally, you can either have your testing outside of the notebook, which allows you the use of existing Python testing libraries, or try to put it inside the notebook.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Out-of-Notebook Testing"><div class="sect2" id="id117">
<h2>Out-of-Notebook Testing</h2>

<p>The traditional option (besides ignoring testing) is <a data-type="indexterm" data-primary="notebooks, testing" data-secondary="out-of-notebook testing" id="id986"/><a data-type="indexterm" data-primary="testing" data-secondary="notebooks" data-tertiary="out-of-notebook testing" id="id987"/><a data-type="indexterm" data-primary="out-of-notebook testing" id="id988"/>to refactor the parts of your code you want to test into separate regular Python files and test those using normal testing libraries. While the partial refactoring can be painful, rewriting to more testable components can bring benefits to debugging as well.</p>

<p>The <a href="https://oreil.ly/3_YsK">testbook project</a> is an alternative to refactoring that takes an interesting approach, allowing you to write your tests outside of your notebook, and not requiring you to give up on notebooks. Instead, you use the libraries decorator to annotate tests—for example, <code>@testbook('untitled_7.ipynb', execute=True)</code> will import and execute the notebook before executing the test. You can also control which parts of the notebook are executed, but this partial execution can be brittle and prone to breakage on updates.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="In-Notebook Testing: In-Line Assertions"><div class="sect2" id="id118">
<h2>In-Notebook Testing: In-Line Assertions</h2>

<p>Some people like to use in-line <a data-type="indexterm" data-primary="testing" data-secondary="notebooks" data-tertiary="in-notebook testing" id="id989"/><a data-type="indexterm" data-primary="notebooks, testing" data-secondary="in-notebook testing" id="id990"/><a data-type="indexterm" data-primary="in-notebook testing" id="id991"/>
assertions in their notebooks as a form of testing. In this case, if something fails (e.g., the assertion that there should be some customers), the rest of the notebook will not run. While we think that having in-line assertions is great, we don’t believe it is a replacement for traditional testing.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Data and Output Validation"><div class="sect1" id="id119">
<h1>Data and Output Validation</h1>

<p>While good testing can catch many <a data-type="indexterm" data-primary="validation, output" id="vldoupu"/><a data-type="indexterm" data-primary="output, validation" id="oupuvdt"/>problems, sometimes the real world is more creative than we can ever be, and our code will still fail. In many situations, the worst case is that our program fails and produces an incorrect output that we don’t know is incorrect, and then we (or others) take action based on its results. Validation attempts to notify us when our job has failed so that we can take action on it before someone else does. In many ways, it is like running spell-check on a term paper before submission—if there are a few errors, OK, but if everything is red, it’s probably good to double-check. Depending on what your job does, validating it will be different.</p>

<p>There are a number of different tools you can use to validate the output of your Dask job, including of course Dask itself. Some tools, like <a href="https://oreil.ly/Vfb1Z">TFX’s data validation</a>, attempt to compare previous versions for statistical similarity and schema changes.<sup><a data-type="noteref" id="id992-marker" href="app01.xhtml#id992">2</a></sup> <a href="https://oreil.ly/RN8aI">Pydantic</a> is relatively new, but it has Dask integration and does excellent type and schema validation. You can also do more complex statistical assertions using its Hypothesis component (which is different from Python’s Hypothesis).</p>

<p>ML models can be more difficult to validate without impacting users, but statistical techniques can still help (as can incremental deployments). Since ML models are produced from data, a good (partial) step can be validating the data.</p>

<p>It is useful to think of what the implications could be of your pipeline failing. For example, you might want to spend more time validating a pipeline that determines dosages of medicine in a clinical trial, compared to a job that predicts which version of your ad will <a data-type="indexterm" data-primary="validation, output" data-startref="vldoupu" id="id993"/><a data-type="indexterm" data-primary="output, validation" data-startref="oupuvdt" id="id994"/>be the most successful.<sup><a data-type="noteref" id="id995-marker" href="app01.xhtml#id995">3</a></sup></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Peer-to-Peer Versus Centralized Distributed"><div class="sect1" id="id120">
<h1>Peer-to-Peer Versus Centralized Distributed</h1>

<p>Even inside of a distributed system, there <a data-type="indexterm" data-primary="centralized distributed systems" id="id996"/><a data-type="indexterm" data-primary="distributed systems" data-secondary="centralized" id="id997"/>are various levels of “distributed.” Dask is a centralized distributed system, where there is a static leader node responsible for various tasks and coordination among the workers. In more distributed systems, there is no static leader node, and if the head node goes away, the remaining peers can elect a new head node, like with ZooKeeper. In even more distributed systems, there is no head node distinction, and all of the nodes in the cluster are effectively equally capable (from a software point of view; the hardware may be different).</p>

<p>Centralized distributed systems tend to be faster, while encountering limitations earlier in terms of scaling and challenges around the failure of the centralized 
<span class="keep-together">component.</span></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Methods of Parallelism"><div class="sect1" id="id280">
<h1>Methods of Parallelism</h1>

<p>There are many different ways to split up our work, and in this book we’ve mostly looked at task and data parallelism.</p>








<section data-type="sect2" data-pdf-bookmark="Task Parallelism"><div class="sect2" id="id121">
<h2>Task Parallelism</h2>

<p><code>dask.delayed</code> and Python’s <a data-type="indexterm" data-primary="parallelism" data-secondary="task" id="id998"/><a data-type="indexterm" data-primary="task parallelism" id="id999"/>multi-processing both represent task parallelism. With task parallelism, you are not limited to executing the same code. Task parallelism offers the most flexibility but requires more changes to your code to take advan­tage of it.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Data Parallelism"><div class="sect2" id="id122">
<h2>Data Parallelism</h2>

<p>Data parallelism <a data-type="indexterm" data-primary="data parallelism" id="id1000"/><a data-type="indexterm" data-primary="parallelism" data-secondary="data parallelism" id="id1001"/>refers to taking the same operation and running it in parallel on different chunks (or partitions) of data. This is a wonderful technique for operations on DataFrames and arrays. Data parallelism depends on partitioning to split up the work. We cover partitioning in detail in <a data-type="xref" href="ch04.xhtml#ch04">Chapter 4</a>.</p>










<section data-type="sect3" data-pdf-bookmark="Shuffles and narrow versus wide transformations"><div class="sect3" id="id123">
<h3>Shuffles and narrow versus wide transformations</h3>

<p><em>Narrow</em> transformations (or data parallelism without any <a data-type="indexterm" data-primary="data parallelism" data-secondary="narrow transformations" id="id1002"/><a data-type="indexterm" data-primary="parallelism" data-secondary="data parallelism" data-tertiary="narrow transformations" id="id1003"/><a data-type="indexterm" data-primary="data parallelism" data-secondary="wide transformations" id="id1004"/><a data-type="indexterm" data-primary="parallelism" data-secondary="data parallelism" data-tertiary="wide transformations" id="id1005"/><a data-type="indexterm" data-primary="wide transformations" id="id1006"/><a data-type="indexterm" data-primary="narrow transformations" id="id1007"/><a data-type="indexterm" data-primary="transformations" data-secondary="narrow" id="id1008"/><a data-type="indexterm" data-primary="transformations" data-secondary="wide" id="id1009"/><a data-type="indexterm" data-primary="shuffles" id="id1010"/>aggregation or shuffle) are often much faster than <em>wide</em> transformations, which involve shuffles or aggregations. While this terminology is borrowed from the Spark community, the distinction (and implications for fault tolerance) applies to Dask’s data-parallel operations as well.</p>
</div></section>










<section data-type="sect3" data-pdf-bookmark="Limitations"><div class="sect3" id="id199">
<h3>Limitations</h3>

<p>Data parallelism is not well suited <a data-type="indexterm" data-primary="data parallelism" data-secondary="limitations" id="id1011"/><a data-type="indexterm" data-primary="parallelism" data-secondary="data parallelism" data-tertiary="limitations" id="id1012"/>to many different kinds of work. Even when working on data problems, it is not as well suited to doing many different things (non-uniform computation). Data parallelism is often poorly suited to computation on small amounts of data—for example, model serving where you may need to evaluate a single request at a time.</p>
</div></section>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Load Balancing"><div class="sect2" id="id124">
<h2>Load Balancing</h2>

<p>Load balancing is another <a data-type="indexterm" data-primary="parallelism" data-secondary="load balancing" id="id1013"/><a data-type="indexterm" data-primary="load balancing" id="id1014"/>way of looking at parallelism where a system (or systems) routes the requests (or tasks) to different servers. Load balancing can range from basic, like round-robin, to “smart,” taking advantage of information about the relative load, resources, and data on the workers/servers to schedule the task. The more complex the load balancing is, the more work the load balancer has to do. In Dask all of this load balancing is handled centrally, which requires that the head node has a relatively complete view of most workers’ state to intelligently assign tasks.</p>

<p>The other extreme is “simple” load balancing, where some systems, like DNS round-robin-based load balancing (not used in Dask), do not have any information about the system loads and just pick the “next” node. When tasks (or requests) are roughly equal in complexity, round-robin-based load balancing can work well. This technique is most often used for handling web requests or external API requests where you don’t have a lot of control over the client making the requests. You are most likely to see this in model serving, like translating text or predicting fraudulent transactions.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Network Fault Tolerance and CAP Theorem"><div class="sect1" id="id125">
<h1>Network Fault Tolerance and CAP Theorem</h1>

<p>If you search for “distributed computing concepts,” you will likely come across the CAP theorem. The CAP theorem <a data-type="indexterm" data-primary="CAP theorem" id="id1015"/><a data-type="indexterm" data-primary="fault tolerance" id="id1016"/>is most relevant for distributed data stores, but it’s useful to understand regardless. The theorem states that we cannot build a distributed system that is consistent, available, and partition-tolerant. Partitions can occur from hardware failure or, more commonly, from overloaded network links.</p>

<p>Dask itself has already made the trade-off of not being partition-tolerant; whichever side of a network partition has the “leader” is the side that continues on, and the other side is unable to progress.</p>

<p>It’s important to understand how this applies to the resources that you are accessing from Dask. For example, you may find yourself in a case in which a network partition means that Dask is unable to write its output. Or—even worse, in our opinion—it can result in situations in which the data you store from Dask is discarded.<sup><a data-type="noteref" id="id1017-marker" href="app01.xhtml#id1017">4</a></sup></p>

<p>The <a href="https://jepsen.io">Jepsen project</a>, by Kyle Kingsbury, is one of the best projects that we know of for testing distributed storage and query systems.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Recursion (Tail and Otherwise)"><div class="sect1" id="id126">
<h1>Recursion (Tail and Otherwise)</h1>

<p>Recursion refers to functions that <a data-type="indexterm" data-primary="recursion" id="id1018"/>call themselves (either directly or indirectly). When it’s indirect, it’s called <em>co-recursion</em>, and recursive functions that return the final value are called <em>tail-recursive</em>.<sup><a data-type="noteref" id="id1019-marker" href="app01.xhtml#id1019">5</a></sup> Tail-recursive functions are similar to loops, and sometimes the language can translate tail-recursive calls into loops or maps.</p>

<p>Recursive functions are sometimes avoided in languages that cannot optimize them, since there is overhead to calling a function. Instead, users will try to express the recursive logic using loops.</p>

<p>Excessive non-optimized recursion can result in a stack overflow error. In C, Java, 
<span class="keep-together">C++</span>, and more, stack memory is allocated separately from the main memory (also called heap memory). In Python, the amount of recursion is controlled by <code>set​recur⁠sionlimit</code>. Python provides a <a href="https://oreil.ly/QTHYz">tail-recursive annotation</a> that you can use to help optimize these recursive calls.</p>

<p>In Dask, while recursive calls don’t have the exact same stack problem, excessive recursion can be one of the causes of load on the head node. This is because scheduling the recursive call must pass through the head node, and the excessive number of recursive functions will cause Dask’s scheduler to slow down long before any stack size issues are countered.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Versioning and Branching: Code and Data"><div class="sect1" id="id127">
<h1>Versioning and Branching: Code and Data</h1>

<p>Versioning is an important computer <a data-type="indexterm" data-primary="versioning" id="id1020"/><a data-type="indexterm" data-primary="branching" id="id1021"/>science concept, and it can be applied to both code and data. Ideally, versioning makes it easy to undo errors and go back to earlier versions or explore multiple directions simultaneously. Many of the items we produce are a combination of both our code and our data; to truly meet the goal of being able to quickly roll back and support experimentation, you will want to have versioning for both your code and your data.</p>

<p>Version control tools for source code have existed for a long time. For code, <a href="https://git-scm.com">Git</a> has become the most popular open source version control system in usage, overtaking tools such as Subversion, Concurrent Version Systems, and many others.</p>

<p>While understanding Git thoroughly can be very complicated,<sup><a data-type="noteref" id="id1022-marker" href="app01.xhtml#id1022">6</a></sup> for common usage there are a few <a href="https://oreil.ly/ZYBJM">core commands</a> that often see you through. Teaching Git is beyond the scope of this appendix, but there are a great many resources, including <a href="https://learning.oreilly.com/library/view/head-first-git/9781492092506/" class="orm:hideurl"><em>Head First Git</em></a> by Raju Gandhi (O’Reilly) and <em>Oh Shit, Git!</em> by Julia Evans, as well as free online resources.</p>

<p>Unfortunately, software version control tools don’t currently have the best notebook integration experience and often require additional tools like <a href="https://www.reviewnb.com">ReviewNB</a> to make the changes understandable.</p>

<p>Now, a natural question is, can you use the same tools for versioning your data as your software? Sometimes you can—provided that your data is small enough and does not contain any personal information, using source control on data can be OK. However, software tends to be stored in text and is normally relatively smaller than your data, and many of the source control tools do not work well when files start to exceed even a few dozen MBs.</p>

<p>Instead, tools like <a href="https://lakefs.io">LakeFS</a> add Git-like versioning semantics on top of existing external data stores (e.g., S3, HDFS, Iceberg, Delta).<sup><a data-type="noteref" id="id1023-marker" href="app01.xhtml#id1023">7</a></sup> Another option is to make copies of your tables manually, but we find this leads to the familiar “-final2-really-final” problem with naming notebooks and Word docs.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Isolation and Noisy Neighbors"><div class="sect1" id="id128">
<h1>Isolation and Noisy Neighbors</h1>

<p class="widows5">So far, we’ve talked about isolation in the <a data-type="indexterm" data-primary="isolation" id="id1024"/>context of being able to have your Python packages, but there are more kinds of isolation. Some other levels of isolation include CPU, GPU, memory, and network.<sup><a data-type="noteref" id="id1025-marker" href="app01.xhtml#id1025">8</a></sup> Many cluster managers do not provide full isolation—this means that if your tasks get scheduled on the wrong nodes, they might have bad performance. A common solution to this is to request the amounts of resources in-line with the full node to avoid having other jobs scheduled alongside your own.</p>

<p>Strict isolation can also have downsides, especially if the isolation framework doesn’t support bursting. Strict isolation without bursting can result in resource waste, but for mission-critical workflows this is often the trade-off.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Machine Fault Tolerance"><div class="sect1" id="id129">
<h1>Machine Fault Tolerance</h1>

<p>Fault tolerance is a key concept in <a data-type="indexterm" data-primary="fault tolerance" data-secondary="machine fault tolerance" id="id1026"/><a data-type="indexterm" data-primary="machine tolerance" id="id1027"/>distributed computing because the more computers you add, the higher the probability of a fault on any given computer. In some smaller deployments of Dask, machine fault tolerance is not as important, so if you’re running Dask exclusively in local mode or on two or three computers you keep under your desk, you might be OK to skip this section.<sup><a data-type="noteref" id="id1028-marker" href="app01.xhtml#id1028">9</a></sup></p>

<p>Dask’s core fault tolerance approach is to re-compute lost data. This is the approach chosen by many modern data-parallel systems since failures are not super common, so making the situation with no failures fast is the priority.<sup><a data-type="noteref" id="id1029-marker" href="app01.xhtml#id1029">10</a></sup></p>

<p>It is important to consider, with fault tolerance of Dask, what the fault condition possibilities are in the components Dask is connected to. While re-compute is a fine approach for distributed computing, distributed storage has different trade-offs.</p>

<p>Dask’s approach to re-compute on failure means that the data that Dask used for the computation remains present to re-load when needed. In most systems, this will be the case, but in some streaming systems you may need to configure longer TTLs or otherwise have a buffer on top to provide the reliability that Dask requires. Also, if you are deploying your own storage layer (e.g., MinIO), it’s important that you deploy it in a way to minimize data loss.</p>

<p>Dask’s fault tolerance does not extend to the leader node. A partial solution to this is often called high availability, where a system outside of Dask monitors and restarts your Dask leader node.</p>

<p>Fault tolerance techniques are often also used when scaling down, since fault tolerance and scale down both involve the loss of a node.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Scalability (Up and Down)"><div class="sect1" id="id130">
<h1>Scalability (Up and Down)</h1>

<p>Scalability refers to the ability of a distributed system to grow to handle larger problems and the sometimes overlooked ability to shrink when the needs are reduced (say, after the grad students go to sleep). In computer science, we generally categorize scalability <a data-type="indexterm" data-primary="scalability" data-secondary="horizontal" id="id1030"/><a data-type="indexterm" data-primary="scalability" data-secondary="vertical" id="id1031"/><a data-type="indexterm" data-primary="horizontal scalability" id="id1032"/><a data-type="indexterm" data-primary="vertical scalability" id="id1033"/>as either <em>horizontal</em> or <em>vertical</em>. Horizontal scaling refers to adding more computers, whereas vertical scaling refers to using bigger computers.</p>

<p>Another important <a data-type="indexterm" data-primary="auto-scaling" id="id1034"/><a data-type="indexterm" data-primary="manual scaling" id="id1035"/><a data-type="indexterm" data-primary="scalability" data-secondary="automatic" id="id1036"/><a data-type="indexterm" data-primary="scalability" data-secondary="manual" id="id1037"/>consideration is <em>auto</em>-scaling versus <em>manual</em> scaling. In auto-scaling, the execution engine (in our case, Dask) will scale the resources for us. Dask’s auto-scaler will horizontally scale by adding your workers when needed (provided the deployment supports it). To scale up vertically, you can add larger instance types to Dask’s auto-scaler and request those resources with your jobs.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In a way, Dask’s task “stealing” can be viewed as a form of automatic vertical scaling. If a node is incapable of (or especially slow at) handling a task, then another Dask worker can “steal” the task. In practice, the auto-scaler does not allocate higher resource nodes unless you schedule a task that asks for those resources.</p>
</div>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Cache, Memory, Disk, and Networking: &#10;How the Performance Changes"><div class="sect1" id="id131">
<h1>Cache, Memory, Disk, and Networking: 
<span class="keep-together">How the Performance Changes</span></h1>

<p>Dask jobs are frequently data-heavy, <a data-type="indexterm" data-primary="CPU cache" id="id1038"/><a data-type="indexterm" data-primary="memory" id="id1039"/>and the cost of transferring data to the CPU (or GPU) can have a large impact on performance. CPU cache is normally more than an order of magnitude faster than reading from memory. Reading data from an SSD is roughly 4x slower than memory, and sending data within a data center can be ~10 times slower.<sup><a data-type="noteref" id="id1040-marker" href="app01.xhtml#id1040">11</a></sup> CPU caches can normally contain only a few elements.</p>

<p>Transferring data from RAM (or even worse, from disk/network) can result in the CPU stalling or not being able to do any useful work. This makes chaining operations especially important.</p>

<p>The <a href="https://oreil.ly/Iyzds">Computers Are Fast website</a> does an excellent job of illustrating these performance impacts with real code.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Hashing"><div class="sect1" id="id132">
<h1>Hashing</h1>

<p>Hashing is an important part <a data-type="indexterm" data-primary="hashing" id="id1041"/>not only of Dask but also of computer science in general. Dask uses hashing to convert complex data types into integers to assign the data to the correct partition. Hashing is generally a “one-way” operation that embeds the larger key space into a smaller key space. For many operations, like assigning data to the correct partitions, you want hashing to be fast. However, for tasks like pseudonymization and passwords, you intentionally choose slower hashing algorithms and frequently add more iterations to make it more difficult to reverse. It’s important to pick the right hashing algorithm to match your purposes, since the different behaviors could be a feature in one use case but a bug in the other.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Data Locality"><div class="sect1" id="id133">
<h1>Data Locality</h1>

<p>Data transfer costs can quickly <a data-type="indexterm" data-primary="locality" id="id1042"/>overwhelm data compute costs for simple computation. When possible, scheduling tasks on nodes that already have the data is often much faster since the task has to be scheduled somewhere (e.g., you pay the network cost of copying the task regardless), but you can avoid moving the data if you put the task in the right place. Network copies are also generally slower than disk.</p>

<p>Dask allows you to specify a desired worker in your <code>client.submit</code> with <code>workers=</code>. Also, if you have data that is going to be accessed everywhere, rather than doing a regular scatter, you can broadcast it by adding <code>broadcast=True</code> so that all workers have a full copy of the collection.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Exactly Once Versus At Least Once"><div class="sect1" id="id134">
<h1>Exactly Once Versus At Least Once</h1>

<p>In most software development <a data-type="indexterm" data-primary="exactly-once execution" id="id1043"/>the concept of <em>exactly once</em> is so much of a given that we don’t even think of it as a requirement. For example, doubly applied debits or credits to a bank account could be catastrophic. Exactly-once execution in Dask requires the use of external systems because of Dask’s approach to fault tolerance. A common approach is to use a database (distributed or non-distributed) along with transactions to ensure exactly-once execution.</p>

<p>Not all distributed systems have this challenge. Systems in which the inputs and outputs are controlled and fault tolerance is achieved by redundant writes have an easier time with exactly-once execution. Some systems that use re-compute on failure are still able to offer exactly-once execution by integrating distributed locks.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="id281">
<h1>Conclusion</h1>

<p>Distributed systems are fun, but as you can see from the distributed systems concepts, they add a substantial amount of overhead. If you don’t need distributed systems, then using Dask in local mode and using local data stores can greatly simplify your life. Regardless of whether you decide on local mode or distributed, having an understanding of general systems concepts will help you build better Dask pipelines.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id978"><sup><a href="app01.xhtml#id978-marker">1</a></sup> This can include creating a database, filling it with data, starting up cluster services, etc.</p><p data-type="footnote" id="id992"><sup><a href="app01.xhtml#id992-marker">2</a></sup> We do not recommend TFX for new environments, as it can be challenging to get running.</p><p data-type="footnote" id="id995"><sup><a href="app01.xhtml#id995-marker">3</a></sup> We acknowledge that society is often not structured this way.</p><p data-type="footnote" id="id1017"><sup><a href="app01.xhtml#id1017-marker">4</a></sup> This is not the most common fault tolerance of databases, but some default configurations of common databases can result in this.</p><p data-type="footnote" id="id1019"><sup><a href="app01.xhtml#id1019-marker">5</a></sup> <em>Indirect</em> here means with another function in between; for example, “A calls B, which calls A” is an example of co-recursion.</p><p data-type="footnote" id="id1022"><sup><a href="app01.xhtml#id1022-marker">6</a></sup> One classic <a href="https://oreil.ly/9zAmg">XKCD comic</a> comes surprisingly close to capturing our early experiences with Git.</p><p data-type="footnote" id="id1023"><sup><a href="app01.xhtml#id1023-marker">7</a></sup> Conflict-of-interest disclosure: Holden has received a T-shirt and stickers from the LakeFS project. Some alternatives include Project Nessie (focused on Iceberg tables).</p><p data-type="footnote" id="id1025"><sup><a href="app01.xhtml#id1025-marker">8</a></sup> For example, two ML tasks on the same node may both try to use all of the CPU resources.</p><p data-type="footnote" id="id1028"><sup><a href="app01.xhtml#id1028-marker">9</a></sup> We choose three here since the probability of the failure of a worker node that does not have the driver is only 2x that of the driver (which we can’t recover from), and this scales linearly as you add more machines.</p><p data-type="footnote" id="id1029"><sup><a href="app01.xhtml#id1029-marker">10</a></sup> You can cache intermediate steps to reduce the cost of re-computing, but this only works if the cached location has not failed and requires you to clean up any caching.</p><p data-type="footnote" id="id1040"><sup><a href="app01.xhtml#id1040-marker">11</a></sup> Exact performance numbers depend on your hardware.</p></div></div></section></div></body></html>