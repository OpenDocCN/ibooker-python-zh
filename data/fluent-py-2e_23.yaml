- en: Chapter 19\. Concurrency Models in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第19章 并发模型在Python中
- en: Concurrency is about dealing with lots of things at once.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并发是关于同时处理许多事情。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Parallelism is about doing lots of things at once.
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并行是同时做许多事情的概念。
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Not the same, but related.
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不同，但相关。
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One is about structure, one is about execution.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个是关于结构，一个是关于执行。
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Concurrency provides a way to structure a solution to solve a problem that may
    (but not necessarily) be parallelizable.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并发提供了一种结构解决问题的方法，该问题可能（但不一定）是可并行化的。
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Rob Pike, co-inventor of the Go language^([1](ch19.html#idm46582393037920))
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Rob Pike，Go语言的共同发明人^([1](ch19.html#idm46582393037920))
- en: This chapter is about how to make Python deal with “lots of things at once.”
    This may involve concurrent or parallel programming—even academics who are keen
    on jargon disagree on how to use those terms. I will adopt Rob Pike’s informal
    definitions in this chapter’s epigraph, but note that I’ve found papers and books
    that claim to be about parallel computing but are mostly about concurrency.^([2](ch19.html#idm46582393034960))
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是关于如何让Python处理“许多事情同时发生”。这可能涉及并发或并行编程，即使对术语敏感的学者们对如何使用这些术语存在分歧。在本章的引言中，我将采用Rob
    Pike的非正式定义，但请注意，我发现有些论文和书籍声称是关于并行计算，但实际上主要是关于并发。^([2](ch19.html#idm46582393034960))
- en: Parallelism is a special case of concurrency, in Pike’s view. All parallel systems
    are concurrent, but not all concurrent systems are parallel. In the early 2000s
    we used single-core machines that handled 100 processes concurrently on GNU Linux.
    A modern laptop with 4 CPU cores is routinely running more than 200 processes
    at any given time under normal, casual use. To execute 200 tasks in parallel,
    you’d need 200 cores. So, in practice, most computing is concurrent and not parallel.
    The OS manages hundreds of processes, making sure each has an opportunity to make
    progress, even if the CPU itself can’t do more than four things at once.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pike��来，并行是并发的特例。所有并行系统都是并发的，但并非所有并发系统都是并行的。在2000年代初，我们使用单核机器在GNU Linux上同时处理100个进程。现代笔记本电脑具有4个CPU核心，在正常的日常使用中通常会同时运行200多个进程。要并行执行200个任务，您需要200个核心。因此，在实践中，大多数计算是并发的而不是并行的。操作系统管理数百个进程，确保每个进程都有机会取得进展，即使CPU本身一次只能做四件事。
- en: 'This chapter assumes no prior knowledge of concurrent or parallel programming.
    After a brief conceptual introduction, we will study simple examples to introduce
    and compare Python’s core packages for concurrent programming: `threading`, `multiprocessing`,
    and `asyncio`.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设您没有并发或并行编程的先前知识。在简要的概念介绍之后，我们将研究简单示例，介绍并比较Python的核心包用于并发编程：`threading`，`multiprocessing`和`asyncio`。
- en: The last 30% of the chapter is a high-level overview of third-party tools, libraries,
    application servers, and distributed task queues—all of which can enhance the
    performance and scalability of Python applications. These are all important topics,
    but beyond the scope of a book focused on core Python language features. Nevertheless,
    I felt it was important to address these themes in this second edition of *Fluent
    Python*, because Python’s fitness for concurrent and parallel computing is not
    limited to what the standard library provides. That’s why YouTube, DropBox, Instagram,
    Reddit, and others were able to achieve web scale when they started, using Python
    as their primary language—despite persistent claims that “Python doesn’t scale.”
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后30%是对第三方工具，库，应用服务器和分布式任务队列的高级概述，所有这些都可以增强Python应用程序的性能和可伸缩性。这些都是重要的主题，但超出了专注于核心Python语言特性的书籍的范围。尽管如此，我认为在《流畅的Python》第二版中解决这些主题很重要，因为Python在并发和并行计算方面的适用性不仅限于标准库提供的内容。这就是为什么YouTube，DropBox，Instagram，Reddit等在开始时能够实现Web规模，使用Python作为他们的主要语言，尽管一直有人声称“Python不具备扩展性”。
- en: What’s New in This Chapter
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章新内容
- en: 'This chapter is new in the second edition of *Fluent Python*. The spinner examples
    in [“A Concurrent Hello World”](#concurrent_hello_world) previously were in the
    chapter about *asyncio*. Here they are improved, and provide the first illustration
    of Python’s three approaches to concurrency: threads, processes, and native coroutines.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是《流畅的Python》第二版中的新内容。[“一个并发的Hello World”](#concurrent_hello_world)中的旋转示例以前在关于*asyncio*的章节中。在这里它们得到改进，并提供Python处理并发的三种方法的第一个示例：线程，进程和本机协程。
- en: The remaining content is new, except for a few paragraphs that originally appeared
    in the chapters on `concurrent.futures` and *asyncio*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的内容是新的，除了一些最初出现在`concurrent.futures`和*asyncio*章节中的段落。
- en: '[“Python in the Multicore World”](#py_in_multicore_world_sec) is different
    from the rest of the book: there are no code examples. The goal is to mention
    important tools that you may want to study to achieve high-performance concurrency
    and parallelism beyond what’s possible with Python’s standard library.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[“Python在多核世界中”](#py_in_multicore_world_sec)与本书其他部分不同：没有代码示例。目标是提及重要工具，您可能希望学习以实现高性能并发和并行，超越Python标准库所能实现的范围。'
- en: The Big Picture
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大局观
- en: 'There are many factors that make concurrent programming hard, but I want to
    touch on the most basic factor: starting threads or processes is easy enough,
    but how do you keep track of them?^([3](ch19.html#idm46582393018064))'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多因素使并发编程变得困难，但我想谈谈最基本的因素：启动线程或进程很容易，但如何跟踪它们呢？^([3](ch19.html#idm46582393018064))
- en: When you call a function, the calling code is blocked until the function returns.
    So you know when the function is done, and you can easily get the value it returned.
    If the function raises an exception, the calling code can surround the call site
    with `try/except` to catch the error.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当您调用一个函数时，调用代码会被阻塞，直到函数返回。因此，您知道函数何时完成，并且可以轻松获取其返回的值。如果函数引发异常，调用代码可以在调用点周围使用`try/except`来捕获错误。
- en: 'Those familiar options are not available when you start a thread or process:
    you don’t automatically know when it’s done, and getting back results or errors
    requires setting up some communication channel, such as a message queue.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当你启动一个线程或进程时，这些熟悉的选项不可用：你不会自动知道它何时完成，获取结果或错误需要设置一些通信渠道，比如消息队列。
- en: Additionally, starting a thread or a process is not cheap, so you don’t want
    to start one of them just to perform a single computation and quit. Often you
    want to amortize the startup cost by making each thread or process into a “worker”
    that enters a loop and stands by for inputs to work on. This further complicates
    communications and introduces more questions. How do you make a worker quit when
    you don’t need it anymore? And how do you make it quit without interrupting a
    job partway, leaving half-baked data and unreleased resources—like open files?
    Again the usual answers involve messages and queues.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，启动线程或进程并不廉价，因此你不希望启动其中一个只是为了执行一个计算然后退出。通常情况下，你希望通过将每个线程或进程变成一个“工作者”，进入一个循环并等待输入来分摊启动成本。这进一步复杂了通信，并引入了更多问题。当你不再需要一个工作者时，如何让它退出？如何让它退出而不中断正在进行的工作，留下半成品数据和未释放的资源—比如打开的文件？再次，通常的答案涉及消息和队列。
- en: A coroutine is cheap to start. If you start a coroutine using the `await` keyword,
    it’s easy to get a value returned by it, it can be safely cancelled, and you have
    a clear site to catch exceptions. But coroutines are often started by the asynchronous
    framework, and that can make them as hard to monitor as threads or processes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 协程很容易启动。如果你使用`await`关键字启动一个协程，很容易获得它返回的值，它可以被安全地取消，并且你有一个明确的地方来捕获异常。但协程通常由异步框架启动，这使得它们像线程或进程一样难以监控。
- en: Finally, Python coroutines and threads are not suitable for CPU-intensive tasks,
    as we’ll see.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Python 协程和线程不适合 CPU 密集型任务，我们将会看到。
- en: That’s why concurrent programming requires learning new concepts and coding
    patterns. Let’s first make sure we are on the same page regarding some core concepts.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么并发编程需要学习新的概念和编码模式。让我们首先确保我们对一些核心概念有共识。
- en: A Bit of Jargon
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一点行话
- en: 'Here are some terms I will use for the rest of this chapter and the next two:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我将在本章和接下来的两章中使用的一些术语：
- en: Concurrency
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 并发性
- en: The ability to handle multiple pending tasks, making progress one at a time
    or in parallel (if possible) so that each of them eventually succeeds or fails.
    A single-core CPU is capable of concurrency if it runs an OS scheduler that interleaves
    the execution of the pending tasks. Also known as multitasking.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 能够处理多个待处理任务，逐个或并行（如果可能）地取得进展，以便每个任务最终成功或失败。如果单核 CPU 运行一个交错执行待处理任务的 OS 调度程序，那么它就具备并发能力。也被称为多任务处理。
- en: Parallelism
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 并行性
- en: The ability to execute multiple computations at the same time. This requires
    a multicore CPU, multiple CPUs, a [GPU](https://fpy.li/19-2), or multiple computers
    in a cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 能够同时执行多个计算的能力。这需要一个多核 CPU、多个 CPU、一个[GPU](https://fpy.li/19-2)，或者一个集群中的多台计算机。
- en: Execution unit
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 执行单元
- en: 'General term for objects that execute code concurrently, each with independent
    state and call stack. Python natively supports three kinds of execution units:
    *processes*, *threads*, and *coroutines*.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码并发的通用术语，每个都有独立的状态和调用堆栈。Python 本地支持三种执行单元：*进程*、*线程* 和 *协程*。
- en: Process
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 进程
- en: 'An instance of a computer program while it is running, using memory and a slice
    of the CPU time. Modern desktop operating systems routinely manage hundreds of
    processes concurrently, with each process isolated in its own private memory space.
    Processes communicate via pipes, sockets, or memory mapped files—all of which
    can only carry raw bytes. Python objects must be serialized (converted) into raw
    bytes to pass from one process to another. This is costly, and not all Python
    objects are serializable. A process can spawn subprocesses, each called a child
    process. These are also isolated from each other and from the parent. Processes
    allow *preemptive multitasking*: the OS scheduler *preempts*—i.e., suspends—each
    running process periodically to allow other processes to run. This means that
    a frozen process can’t freeze the whole system—in theory.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机程序在运行时的一个实例，使用内存和 CPU 时间片。现代桌面操作系统通常同时管理数百个进程，每个进程都在自己的私有内存空间中隔离。进程通过管道、套接字或内存映射文件进行通信，所有这些通信方式只能传递原始字节。Python
    对象必须被序列化（转换）为原始字节才能从一个进程传递到另一个进程。这是昂贵的，而且并非所有的 Python 对象都是可序列化的。一个进程可以生成子进程，每个子进程称为一个子进程。它们也彼此隔离，也与父进程隔离。进程允许*抢占式多任务处理*：操作系统调度程序*抢占*—即暂停—每个运行的进程，以允许其他进程运行。这意味着一个冻结的进程不能冻结整个系统—理论上。
- en: Thread
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 线程
- en: 'An execution unit within a single process. When a process starts, it uses a
    single thread: the main thread. A process can create more threads to operate concurrently
    by calling operating system APIs. Threads within a process share the same memory
    space, which holds live Python objects. This allows easy data sharing between
    threads, but can also lead to corrupted data when more than one thread updates
    the same object concurrently. Like processes, threads also enable *preemptive
    multitasking* under the supervision of the OS scheduler. A thread consumes less
    resources than a process doing the same job.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 单个进程内的执行单元。当一个进程启动时，它使用一个线程：主线程。一个进程可以通过调用操作系统 API 创建更多线程以并发操作。进程内的线程共享相同的内存空间，其中保存着活跃的
    Python 对象。这允许线程之间轻松共享数据，但也可能导致数据损坏，当多个线程同时更新同一对象时。与进程一样，线程也在操作系统调度程序的监督下实现*抢占式多任务处理*。一个线程消耗的资源比执行相同工作的进程少。
- en: Coroutine
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 协程
- en: 'A function that can suspend itself and resume later. In Python, *classic coroutines*
    are built from generator functions, and *native coroutines* are defined with `async
    def`. [“Classic Coroutines”](ch17.html#classic_coroutines_sec) introduced the
    concept, and [Chapter 21](ch21.html#async_ch) covers the use of native coroutines.
    Python coroutines usually run within a single thread under the supervision of
    an *event loop*, also in the same thread. Asynchronous programming frameworks
    such as *asyncio*, *Curio*, or *Trio* provide an event loop and supporting libraries
    for nonblocking, coroutine-based I/O. Coroutines support *cooperative multitasking*:
    each coroutine must explicitly cede control with the `yield` or `await` keyword,
    so that another may proceed concurrently (but not in parallel). This means that
    any blocking code in a coroutine blocks the execution of the event loop and all
    other coroutines—in contrast with the *preemptive multitasking* supported by processes
    and threads. On the other hand, each coroutine consumes less resources than a
    thread or process doing the same job.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可以暂停自身并稍后恢复的函数。在Python中，*经典协程*是由生成器函数构建的，而*原生协程*则是用`async def`定义的。[“经典协程”](ch17.html#classic_coroutines_sec)介绍了这个概念，而[第21章](ch21.html#async_ch)涵盖了原生协程的使用。Python协程通常在同一个线程中在*事件循环*的监督下运行，也在同一个线程中。异步编程框架如*asyncio*、*Curio*或*Trio*提供了事件循环和支持非阻塞、基于协程的I/O的支持库。协程支持*协作式多任务*：每个协程必须使用`yield`或`await`关键字明确放弃控制，以便另一个可以同时进行（但不是并行）。这意味着协程中的任何阻塞代码都会阻止事件循环和所有其他协程的执行，与进程和线程支持的*抢占式多任务*相反。另一方面，每个协程消耗的资源比执行相同工作的线程或进程少。
- en: Queue
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 队列
- en: 'A data structure that lets us put and get items, usually in FIFO order: first
    in, first out. Queues allow separate execution units to exchange application data
    and control messages, such as error codes and signals to terminate. The implementation
    of a queue varies according to the underlying concurrency model: the `queue` package
    in Python’s standard library provides queue classes to support threads, while
    the `multiprocessing` and `asyncio` packages implement their own queue classes.
    The `queue` and `asyncio` packages also include queues that are not FIFO: `LifoQueue`
    and `PriorityQueue`.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个数据结构，让我们以FIFO顺序（先进先出）放置和获取项目。队列允许独立的执行单元交换应用程序数据和控制消息，如错误代码和终止信号。队列的实现根据底层并发模型而变化：Python标准库中的`queue`包提供了支持线程的队列类，而`multiprocessing`和`asyncio`包实现了自己的队列类。`queue`和`asyncio`包还包括不是FIFO的队列：`LifoQueue`和`PriorityQueue`。
- en: Lock
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 锁
- en: An object that execution units can use to synchronize their actions and avoid
    corrupting data. While updating a shared data structure, the running code should
    hold an associated lock. This signals other parts of the program to wait until
    the lock is released before accessing the same data structure. The simplest type
    of lock is also known as a mutex (for mutual exclusion). The implementation of
    a lock depends on the underlying concurrency model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个执行单元可以使用的对象，用于同步它们的操作并避免破坏数据。在更新共享数据结构时，运行的代码应持有相关锁。这会通知程序的其他部分等待，直到锁被释放才能访问相同的数据结构。最简单类型的锁也被称为互斥锁（用于互斥排除）。锁的实现取决于底层并发模型。
- en: Contention
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 争用
- en: Dispute over a limited asset. Resource contention happens when multiple execution
    units try to access a shared resource—such as a lock or storage. There’s also
    CPU contention, when compute-intensive processes or threads must wait for the
    OS scheduler to give them a share of the CPU time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 争用有限资源。当多个执行单元尝试访问共享资源（如锁或存储）时，资源争用就会发生。还有CPU争用，当计算密集型进程或线程必须等待操作系统调度程序为它们分配CPU时间时。
- en: Now let’s use some of that jargon to understand concurrency support in Python.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用一些行话来理解Python中的并发支持。
- en: Processes, Threads, and Python’s Infamous GIL
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进程、线程和Python臭名昭著的GIL
- en: 'Here is how the concepts we just saw apply to Python programming, in 10 points:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们刚刚看到的概念如何应用于Python编程的10个要点：
- en: Each instance of the Python interpreter is a process. You can start additional
    Python processes using the *multiprocessing* or *concurrent.futures* libraries.
    Python’s *subprocess* library is designed to launch processes to run external
    programs, regardless of the languages used to write them.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python解释器的每个实例都是一个进程。您可以使用*multiprocessing*或*concurrent.futures*库启动额外的Python进程。Python的*subprocess*库旨在启动进程来运行外部程序，无论使用何种语言编写。
- en: The Python interpreter uses a single thread to run the user’s program and the
    memory garbage collector. You can start additional Python threads using the *threading*
    or *concurrent.futures* libraries.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python解释器使用单个线程来运行用户程序和内存垃圾收集器。您可以使用*threading*或*concurrent.futures*库启动额外的Python线程。
- en: Access to object reference counts and other internal interpreter state is controlled
    by a lock, the Global Interpreter Lock (GIL). Only one Python thread can hold
    the GIL at any time. This means that only one thread can execute Python code at
    any time, regardless of the number of CPU cores.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对象引用计数和其他内部解释器状态的访问受到一个锁的控制，全局解释器锁（GIL）。在任何时候只有一个Python线程可以持有GIL。这意味着无论CPU核心数量如何，只有一个线程可以同时执行Python代码。
- en: To prevent a Python thread from holding the GIL indefinitely, Python’s bytecode
    interpreter pauses the current Python thread every 5ms by default,^([4](ch19.html#idm46582392964240))
    releasing the GIL. The thread can then try to reacquire the GIL, but if there
    are other threads waiting for it, the OS scheduler may pick one of them to proceed.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了防止Python线程无限期地持有GIL，Python的字节码解释器默认每5毫秒暂停当前Python线程，释放GIL。然后线程可以尝试重新获取GIL，但如果有其他线程在等待，操作系统调度程序可能会选择其中一个继续进行。
- en: When we write Python code, we have no control over the GIL. But a built-in function
    or an extension written in C—or any language that interfaces at the Python/C API
    level—can release the GIL while running time-consuming tasks.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们编写Python代码时，我们无法控制GIL。但是一个内置函数或用C编写的扩展——或者任何与Python/C API级别进行接口的语言——可以在运行��时任务时释放GIL。
- en: Every Python standard library function that makes a syscall^([5](ch19.html#idm46582392959952))
    releases the GIL. This includes all functions that perform disk I/O, network I/O,
    and `time.sleep()`. Many CPU-intensive functions in the NumPy/SciPy libraries,
    as well as the compressing/decompressing functions from the `zlib` and `bz2` modules,
    also release the GIL.^([6](ch19.html#idm46582392957152))
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个调用系统调用的Python标准库函数都会释放GIL。这包括所有执行磁盘I/O、网络I/O和`time.sleep()`的函数。NumPy/SciPy库中的许多CPU密集型函数，以及`zlib`和`bz2`模块中的压缩/解压缩函数也会释放GIL。
- en: Extensions that integrate at the Python/C API level can also launch other non-Python
    threads that are not affected by the GIL. Such GIL-free threads generally cannot
    change Python objects, but they can read from and write to the memory underlying
    objects that support the [buffer protocol](https://fpy.li/pep3118), such as `bytearray`,
    `array.array`, and *NumPy* arrays.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python/C API级别集成的扩展还可以启动其他不受GIL影响的非Python线程。这些无GIL的线程通常不能更改Python对象，但它们可以读取和写入支持[缓冲区协议](https://fpy.li/pep3118)的对象的底层内存，如`bytearray`、`array.array`和*NumPy*数组。
- en: 'The effect of the GIL on network programming with Python threads is relatively
    small, because the I/O functions release the GIL, and reading or writing to the
    network always implies high latency—compared to reading and writing to memory.
    Consequently, each individual thread spends a lot of time waiting anyway, so their
    execution can be interleaved without major impact on the overall throughput. That’s
    why David Beazley says: “Python threads are great at doing nothing.”^([7](ch19.html#idm46582392951088))'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GIL对使用Python线程进行网络编程的影响相对较小，因为I/O函数会释放GIL，并且与读写内存相比，读写网络总是意味着高延迟。因此，每个单独的线程都会花费大量时间在等待上，因此它们的执行可以交错进行，而对整体吞吐量的影响不大。这就是为什么David
    Beazley说：“Python线程非常擅长无所事事。”
- en: Contention over the GIL slows down compute-intensive Python threads. Sequential,
    single-threaded code is simpler and faster for such tasks.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GIL争用会减慢计算密集型Python线程的速度。对于这种任务，顺序、单线程的代码更简单、更快。
- en: To run CPU-intensive Python code on multiple cores, you must use multiple Python
    processes.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在多个核心上运行CPU密集型的Python代码，必须使用多个Python进程。
- en: Here is a good summary from the `threading` module documentation:^([8](ch19.html#idm46582392946960))
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有来自`threading`模块文档的一个很好的总结：
- en: '**CPython implementation detail**: In CPython, due to the Global Interpreter
    Lock, only one thread can execute Python code at once (even though certain performance-oriented
    libraries might overcome this limitation). If you want your application to make
    better use of the computational resources of multicore machines, you are advised
    to use `multiprocessing` or `concurrent.futures.ProcessPoolExecutor`. However,
    threading is still an appropriate model if you want to run multiple I/O-bound
    tasks simultaneously.'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**CPython实现细节**：在CPython中，由于全局解释器锁，只有一个线程可以同时执行Python代码（尽管某些性能导向的库可能克服这一限制）。如果你希望应用程序更好地利用多核机器的计算资源，建议使用`multiprocessing`或`concurrent.futures.ProcessPoolExecutor`。然而，对于同时运行多个I/O密集型任务，线程仍然是一个合适的模型。'
- en: The previous paragraph starts with “CPython implementation detail” because the
    GIL is not part of the Python language definition. The Jython and IronPython implementations
    don’t have a GIL. Unfortunately, both are lagging behind—still tracking Python
    2.7. The highly performant [PyPy interpreter](https://fpy.li/19-9) also has a
    GIL in its 2.7 and 3.7 versions—the latest as of June 2021.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 前一段以“CPython实现细节”开头，因为GIL不是Python语言定义的一部分。Jython和IronPython实现没有GIL。不幸的是，它们都落后了——仍在追踪Python
    2.7。高性能的[PyPy解释器](https://fpy.li/19-9)在其2.7和3.7版本中也有GIL——截至2021年6月的最新版本。
- en: Note
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This section did not mention coroutines, because by default they share the same
    Python thread among themselves and with the supervising event loop provided by
    an asynchronous framework, therefore the GIL does not affect them. It is possible
    to use multiple threads in an asynchronous program, but the best practice is that
    one thread runs the event loop and all coroutines, while additional threads carry
    out specific tasks. This will be explained in [“Delegating Tasks to Executors”](ch21.html#delegating_to_executors_sec).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这一节没有提到协程，因为默认情况下它们在彼此之间共享同一个Python线程，并与异步框架提供的监督事件循环共享，因此GIL不会影响它们。在异步程序中可以使用多个线程，但最佳实践是一个线程运行事件循环和所有协程，而其他线程执行特定任务。这将在“委托任务给执行器”中解释。
- en: Enough concepts for now. Let’s see some code.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经足够的概念了。让我们看一些代码。
- en: A Concurrent Hello World
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个并发的Hello World
- en: 'During a discussion about threads and how to avoid the GIL, Python contributor
    Michele Simionato [posted an example](https://fpy.li/19-10) that is like a concurrent
    “Hello World”: the simplest program to show how Python can “walk and chew gum.”'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于线程和如何避免GIL的讨论中，Python贡献者Michele Simionato[发布了一个示例](https://fpy.li/19-10)，类似于并发的“Hello
    World”：展示Python如何“边走边嚼”的最简单程序。
- en: Simionato’s program uses `multiprocessing`, but I adapted it to introduce `threading`
    and `asyncio` as well. Let’s start with the `threading` version, which may look
    familiar if you’ve studied threads in Java or C.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Simionato的程序使用了`multiprocessing`，但我对其进行了调整，引入了`threading`和`asyncio`。让我们从`threading`版本开始，如果你学过Java或C中的线程，这可能看起来很熟悉。
- en: Spinner with Threads
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用线程的旋转器
- en: 'The idea of the next few examples is simple: start a function that blocks for
    3 seconds while animating characters in the terminal to let the user know that
    the program is “thinking” and not stalled.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来几个示例的想法很简单：启动一个函数，在终端中以动画方式显示字符，同时阻塞3秒钟，让用户知道程序在“思考”，而不是停滞不前。
- en: 'The script makes an animated spinner displaying each character in the string
    `"\|/-"` in the same screen position.^([9](ch19.html#idm46582392926960)) When
    the slow computation finishes, the line with the spinner is cleared and the result
    is shown: `Answer: 42`.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '该脚本制作了一个动画旋转器，以相同的屏幕位置显示字符串`"\|/-"`中的每个字符。当慢速计算完成时，旋转器所在行将被清除，并显示结果：`Answer:
    42`。'
- en: '[Figure 19-1](#spinner_fig) shows the output of two versions of the spinning
    example: first with threads, then with coroutines. If you’re away from the computer,
    imagine the `\` in the last line is spinning.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 19-1](#spinner_fig)显示了旋转示例的两个版本的输出：首先是使用线程，然后是使用协程。如果你离开电脑，想象最后一行的`\`在旋转。'
- en: '![Shell console showing output of two spinner examples.](assets/flpy_1901.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Shell控制台显示两个旋转器示例的输出。](assets/flpy_1901.png)'
- en: 'Figure 19-1\. The scripts spinner_thread.py and spinner_async.py produce similar
    output: the repr of a spinner object and the text “Answer: 42”. In the screenshot,
    spinner_async.py is still running, and the animated message “/ thinking!” is shown;
    that line will be replaced by “Answer: 42” after 3 seconds.'
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 19-1\. 脚本spinner_thread.py和spinner_async.py产生类似的输出：一个旋转器对象的repr和文本“Answer:
    42”。在截图中，spinner_async.py仍在运行，并显示动画消息“/ thinking!”；3秒后，该行将被替换为“Answer: 42”。'
- en: Let’s review the *spinner_thread.py* script first. [Example 19-1](#spinner_thread_top_ex)
    lists the first two functions in the script, and [Example 19-2](#spinner_thread_rest_ex)
    shows the rest.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先回顾*spinner_thread.py*脚本。[示例 19-1](#spinner_thread_top_ex)列出了脚本中的前两个函数，[示例 19-2](#spinner_thread_rest_ex)显示了其余部分。
- en: 'Example 19-1\. spinner_thread.py: the `spin` and `slow` functions'
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-1\. spinner_thread.py：`spin`和`slow`函数
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO1-1)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO1-1)'
- en: This function will run in a separate thread. The `done` argument is an instance
    of `threading.Event`, a simple object to synchronize threads.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将在一个单独的线程中运行。`done`参数是`threading.Event`的一个实例，用于同步线程。
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO1-2)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO1-2)'
- en: This is an infinite loop because `itertools.cycle` yields one character at a
    time, cycling through the string forever.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个无限循环，因为`itertools.cycle`每次产生一个字符，永远循环遍历字符串。
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO1-3)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO1-3)'
- en: 'The trick for text-mode animation: move the cursor back to the start of the
    line with the carriage return ASCII control character (`''\r''`).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 文本模式动画的技巧：使用回车ASCII控制字符(`'\r'`)将光标移回行的开头。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO1-4)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO1-4)'
- en: The `Event.wait(timeout=None)` method returns `True` when the event is set by
    another thread; if the `timeout` elapses, it returns `False`. The .1s timeout
    sets the “frame rate” of the animation to 10 FPS. If you want the spinner to go
    faster, use a smaller timeout.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`Event.wait(timeout=None)`方法在另一个线程设置事件时返回`True`；如果超时时间到期，则返回`False`。0.1秒的超时设置了动画的“帧率”为10
    FPS。如果希望旋转器旋转得更快，可以使用较小的超时时间。'
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO1-5)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO1-5)'
- en: Exit the infinite loop.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 退出无限循环。
- en: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO1-6)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO1-6)'
- en: Clear the status line by overwriting with spaces and moving the cursor back
    to the beginning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过用空格覆盖并将光标移回开头来清除状态行。
- en: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO1-7)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO1-7)'
- en: '`slow()` will be called by the main thread. Imagine this is a slow API call
    over the network. Calling `sleep` blocks the main thread, but the GIL is released
    so the spinner thread can proceed.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`slow()`将被主线程调用。想象这是一个在网络上慢速调用API。调用`sleep`会阻塞主线程，但GIL会被释放，因此旋转器线程可以继续执行。'
- en: Tip
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The first important insight of this example is that `time.sleep()` blocks the
    calling thread but releases the GIL, allowing other Python threads to run.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的第一个重要见解是`time.sleep()`会阻塞调用线程，但会释放GIL，允许其他Python线程运行。
- en: The `spin` and `slow` functions will execute concurrently. The main thread—the
    only thread when the program starts—will start a new thread to run `spin` and
    then call `slow`. By design, there is no API for terminating a thread in Python.
    You must send it a message to shut down.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`spin`和`slow`函数将并发执行。主线程——程序启动时唯一的线程——将启动一个新线程来运行`spin`，然后调用`slow`。按设计，Python中没有终止线程的API。你必须发送消息来关闭它。'
- en: The `threading.Event` class is Python’s simplest signalling mechanism to coordinate
    threads. An `Event` instance has an internal boolean flag that starts as `False`.
    Calling `Event.set()` sets the flag to `True`. While the flag is false, if a thread
    calls `Event.wait()`, it is blocked until another thread calls `Event.set()`,
    at which time `Event.wait()` returns `True`. If a timeout in seconds is given
    to `Event.wait(s)`, this call returns `False` when the timeout elapses, or returns
    `True` as soon as `Event.set()` is called by another thread.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading.Event`类是Python中最简单的线程协调机制。`Event`实例有一个内部布尔标志，起始值为`False`。调用`Event.set()`将标志设置为`True`。当标志为false时，如果一个线程调用`Event.wait()`，它将被阻塞，直到另一个线程调用`Event.set()`，此时`Event.wait()`返回`True`。如果给`Event.wait(s)`传递了秒数的超时时间，当超时时间到期时，此调用将返回`False`，或者在另一个线程调用`Event.set()`时立即返回`True`。'
- en: The `supervisor` function, listed in [Example 19-2](#spinner_thread_rest_ex),
    uses an `Event` to signal the `spin` function to exit.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 19-2](#spinner_thread_rest_ex)中列出的`supervisor`函数使用`Event`来向`spin`函数发出退出信号。
- en: 'Example 19-2\. spinner_thread.py: the `supervisor` and `main` functions'
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-2\. spinner_thread.py：`supervisor`和`main`函数
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO2-1)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO2-1)'
- en: '`supervisor` will return the result of `slow`.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`supervisor` 将返回 `slow` 的结果。'
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO2-2)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO2-2)'
- en: The `threading.Event` instance is the key to coordinate the activities of the
    `main` thread and the `spinner` thread, as explained further down.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading.Event` 实例是协调 `main` 线程和 `spinner` 线程活动的关键，如下所述。'
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO2-3)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO2-3)'
- en: To create a new `Thread`, provide a function as the `target` keyword argument,
    and positional arguments to the `target` as a tuple passed via `args`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新的 `Thread`，请将函数作为 `target` 关键字参数，并通过 `args` 传递的元组提供给 `target` 作为位置参数。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO2-4)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO2-4)'
- en: Display the `spinner` object. The output is `<Thread(Thread-1, initial)>`, where
    `initial` is the state of the thread—meaning it has not started.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 显示 `spinner` 对象。输出为 `<Thread(Thread-1, initial)>`，其中 `initial` 是线程的状态，表示它尚未启动。
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO2-5)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO2-5)'
- en: Start the `spinner` thread.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 `spinner` 线程。
- en: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO2-6)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO2-6)'
- en: Call `slow`, which blocks the `main` thread. Meanwhile, the secondary thread
    is running the spinner animation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `slow`，会阻塞 `main` 线程。与此同时，辅助线程正在运行旋转动画。
- en: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO2-7)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO2-7)'
- en: Set the `Event` flag to `True`; this will terminate the `for` loop inside the
    `spin` function.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `Event` 标志设置为 `True`；这将终止 `spin` 函数内的 `for` 循环。
- en: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO2-8)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO2-8)'
- en: Wait until the `spinner` thread finishes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 等待 `spinner` 线程完成。
- en: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO2-9)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO2-9)'
- en: Run the `supervisor` function. I wrote separate `main` and `supervisor` functions
    to make this example look more like the `asyncio` version in [Example 19-4](#spinner_async_start_ex).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `supervisor` 函数。我编写了单独的 `main` 和 `supervisor` 函数，使得这个示例看起来更像[示例 19-4](#spinner_async_start_ex)中的
    `asyncio` 版本。
- en: When the `main` thread sets the `done` event, the `spinner` thread will eventually
    notice and exit cleanly.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `main` 线程设置 `done` 事件时，`spinner` 线程最终会注意到并干净地退出。
- en: Now let’s take a look at a similar example using the `multiprocessing` package.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个类似的例子，使用 `multiprocessing` 包。
- en: Spinner with Processes
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用进程的旋转器
- en: The `multiprocessing` package supports running concurrent tasks in separate
    Python processes instead of threads. When you create a `multiprocessing.Process`
    instance, a whole new Python interpreter is started as a child process in the
    background. Since each Python process has its own GIL, this allows your program
    to use all available CPU cores—but that ultimately depends on the operating system
    scheduler. We’ll see practical effects in [“A Homegrown Process Pool”](#naive_multiprocessing_sec),
    but for this simple program it makes no real difference.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing` 包支持在单独的 Python 进程中运行并发任务，而不是线程。当你创建一个 `multiprocessing.Process`
    实例时，一个全新的 Python 解释器会作为后台的子进程启动。由于每个 Python 进程都有自己的 GIL，这使得你的程序可以使用所有可用的 CPU 核心，但最终取决于操作系统调度程序。我们将在[“自制进程池”](#naive_multiprocessing_sec)中看到实际效果，但对于这个简单的程序来说，这并没有真正的区别。'
- en: The point of this section is to introduce `multiprocessing` and show that its
    API emulates the `threading` API, making it easy to convert simple programs from
    threads to processes, as shown in *spinner_proc.py* ([Example 19-3](#spinner_proc_ex)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的重点是介绍 `multiprocessing` 并展示其 API 模仿了 `threading` API，使得将简单程序从线程转换为进程变得容易，如
    *spinner_proc.py* 中所示（[示例 19-3](#spinner_proc_ex)）。
- en: 'Example 19-3\. spinner_proc.py: only the changed parts are shown; everything
    else is the same as spinner_thread.py'
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-3\. spinner_proc.py：只显示更改的部分；其他所有内容与 spinner_thread.py 相同
- en: '[PRE2]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO3-1)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO3-1)'
- en: 'The basic `multiprocessing` API imitates the `threading` API, but type hints
    and Mypy expose this difference: `multiprocessing.Event` is a function (not a
    class like `threading.Event`) which returns a `synchronize.Event` instance…'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的 `multiprocessing` API 模仿了 `threading` API，但类型提示和 Mypy 暴露了这种差异：`multiprocessing.Event`
    是一个函数（不像 `threading.Event` 那样是一个类），它返回一个 `synchronize.Event` 实例…
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO3-2)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO3-2)'
- en: …forcing us to import `multiprocessing.synchronize`…
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: …迫使我们导入 `multiprocessing.synchronize`…
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO3-3)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO3-3)'
- en: …to write this type hint.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: …来写这个类型提示。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO3-4)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO3-4)'
- en: Basic usage of the `Process` class is similar to `Thread`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`Process` 类的基本用法类似于 `Thread`。'
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO3-5)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO3-5)'
- en: The `spinner` object is displayed as `<Process name='Process-1' parent=14868
    initial>`, where `14868` is the process ID of the Python instance running *spinner_proc.py*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`spinner` 对象显示为 `<Process name=''Process-1'' parent=14868 initial>`，其中 `14868`
    是运行 *spinner_proc.py* 的 Python 实例的进程 ID。'
- en: The basic API of `threading` and `multiprocessing` are similar, but their implementation
    is very different, and `multiprocessing` has a much larger API to handle the added
    complexity of multiprocess programming. For example, one challenge when converting
    from threads to processes is how to communicate between processes that are isolated
    by the operating system and can’t share Python objects. This means that objects
    crossing process boundaries have to be serialized and deserialized, which creates
    overhead. In [Example 19-3](#spinner_proc_ex), the only data that crosses the
    process boundary is the `Event` state, which is implemented with a low-level OS
    semaphore in the C code underlying the `multiprocessing` module.^([10](ch19.html#idm46582392270416))
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`threading` 和 `multiprocessing` 的基本 API 相似，但它们的实现非常不同，而 `multiprocessing` 有一个更大的
    API 来处理多进程编程的复杂性。例如，从线程转换为进程时的一个挑战是如何在被操作系统隔离且无法共享 Python 对象的进程之间进行通信。这意味着跨进程边界的对象必须进行序列化和反序列化，这会产生额外的开销。在
    [Example 19-3](#spinner_proc_ex) 中，跨进程边界的唯一数据是 `Event` 状态，它是在支持 `multiprocessing`
    模块的 C 代码中实现的低级操作系统信号量。^([10](ch19.html#idm46582392270416))'
- en: Tip
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Since Python 3.8, there’s a [`multiprocessing.shared_memory`](https://fpy.li/19-12)
    package in the standard library, but it does not support instances of user-defined
    classes. Besides raw bytes, the package allows processes to share a `ShareableList`,
    a mutable sequence type that can hold a fixed number of items of types `int`,
    `float`, `bool`, and `None`, as well as `str` and `bytes` up to 10 MB per item.
    See the [`ShareableList`](https://fpy.li/19-13) documentation for more.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 自 Python 3.8 起，标准库中有一个 [`multiprocessing.shared_memory`](https://fpy.li/19-12)
    包，但它不支持用户定义类的实例。除了原始字节外，该包允许进程共享 `ShareableList`，这是一个可变序列类型，可以容纳固定数量的 `int`、`float`、`bool`
    和 `None` 类型的项目，以及每个项目最多 10 MB 的 `str` 和 `bytes`。请查看 [`ShareableList`](https://fpy.li/19-13)
    文档以获取更多信息。
- en: Now let’s see how the same behavior can be achieved with coroutines instead
    of threads or processes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用协程而不是线程或进程来实现相同的行为。
- en: Spinner with Coroutines
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用协程的旋转器
- en: Note
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '[Chapter 21](ch21.html#async_ch) is entirely devoted to asynchronous programming
    with coroutines. This is just a high-level introduction to contrast this approach
    with the threads and processes concurrency models. As such, we will overlook many
    details.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chapter 21](ch21.html#async_ch) 完全致力于使用协程进行异步编程。这只是一个高层介绍，用来对比线程和进程并发模型的方法。因此，我们将忽略许多细节。'
- en: It is the job of OS schedulers to allocate CPU time to drive threads and processes.
    In contrast, coroutines are driven by an application-level event loop that manages
    a queue of pending coroutines, drives them one by one, monitors events triggered
    by I/O operations initiated by coroutines, and passes control back to the corresponding
    coroutine when each event happens. The event loop and the library coroutines and
    the user coroutines all execute in a single thread. Therefore, any time spent
    in a coroutine slows down the event loop—and all other coroutines.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统调度程序的工作是分配 CPU 时间来驱动线程和进程。相比之下，协程由应用级事件循环驱动，该事件循环管理一个挂起协程的队列，逐个驱动它们，监视由协程发起的
    I/O 操作触发的事件，并在每次事件发生时将控制权传递回相应的协程。事件循环和库协程以及用户协程都在单个线程中执行。因此，在协程中花费的任何时间都会减慢事件循环和所有其他协程。
- en: The coroutine version of the spinner program is easier to understand if we start
    from the `main` function, then study the `supervisor`. That’s what [Example 19-4](#spinner_async_start_ex)
    shows.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从 `main` 函数开始，然后研究 `supervisor`，那么协程版本的旋转器程序会更容易理解。这就是 [Example 19-4](#spinner_async_start_ex)
    所展示的内容。
- en: 'Example 19-4\. spinner_async.py: the `main` function and `supervisor` coroutine'
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 19-4\. spinner_async.py：`main` 函数和 `supervisor` 协程
- en: '[PRE3]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO4-1)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO4-1)'
- en: '`main` is the only regular function defined in this program—the others are
    coroutines.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`main` 是此程序中唯一定义的常规函数，其他都是协程。'
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO4-2)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO4-2)'
- en: The `asyncio.run` function starts the event loop to drive the coroutine that
    will eventually set the other coroutines in motion. The `main` function will stay
    blocked until `supervisor` returns. The return value of `supervisor` will be the
    return value of `asyncio.run`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.run` 函数启动事件循环，驱动最终会启动其他协程的协程。`main` 函数将保持阻塞，直到 `supervisor` 返回。`supervisor`
    的返回值将是 `asyncio.run` 的返回值。'
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO4-3)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO4-3)'
- en: Native coroutines are defined with `async def`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本机协程使用 `async def` 定义。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO4-4)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO4-4)'
- en: '`asyncio.create_task` schedules the eventual execution of `spin`, immediately
    returning an instance of `asyncio.Task`.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.create_task` 调度了 `spin` 的最终执行，立即返回一个 `asyncio.Task` 实例。'
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO4-5)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO4-5)'
- en: The `repr` of the `spinner` object looks like `<Task pending name='Task-2' coro=<spin()
    running at /path/to/spinner_async.py:11>>`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`spinner` 对象的 `repr` 看起来像 `<Task pending name=''Task-2'' coro=<spin() running
    at /path/to/spinner_async.py:11>>`。'
- en: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO4-6)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO4-6)'
- en: The `await` keyword calls `slow`, blocking `supervisor` until `slow` returns.
    The return value of `slow` will be assigned to `result`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`await` 关键字调用 `slow`，阻塞 `supervisor` 直到 `slow` 返回。`slow` 的返回值将被赋给 `result`。'
- en: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO4-7)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO4-7)'
- en: The `Task.cancel` method raises a `CancelledError` exception inside the `spin`
    coroutine, as we’ll see in [Example 19-5](#spinner_async_top_ex).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`Task.cancel` 方法在 `spin` 协程内部引发 `CancelledError` 异常，我们将在 [Example 19-5](#spinner_async_top_ex)
    中看到。'
- en: '[Example 19-4](#spinner_async_start_ex) demonstrates the three main ways of
    running a coroutine:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[Example 19-4](#spinner_async_start_ex) 展示了运行协程的三种主要方式：'
- en: '`asyncio.run(coro())`'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.run(coro())`'
- en: Called from a regular function to drive a coroutine object that usually is the
    entry point for all the asynchronous code in the program, like the `supervisor`
    in this example. This call blocks until the body of `coro` returns. The return
    value of the `run()` call is whatever the body of `coro` returns.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从常规函数中调用以驱动通常是程序中所有异步代码的入口点的协程对象，就像本示例中的`supervisor`一样。此调用会阻塞，直到`coro`的主体返回。`run()`调用的返回值是`coro`的主体返回的任何内容。
- en: '`asyncio.create_task(coro())`'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio.create_task(coro())`'
- en: Called from a coroutine to schedule another coroutine to execute eventually.
    This call does not suspend the current coroutine. It returns a `Task` instance,
    an object that wraps the coroutine object and provides methods to control and
    query its state.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 从协程中调用以安排另一个协程最终执行。此调用不会挂起当前协程。它返回一个`Task`实例，一个包装协程对象并提供控制和查询其状态的方法的对象。
- en: '`await coro()`'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`await coro()`'
- en: Called from a coroutine to transfer control to the coroutine object returned
    by `coro()`. This suspends the current coroutine until the body of `coro` returns.
    The value of the await expression is whatever the body of `coro` returns.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 从协程中调用以将控制传递给`coro()`返回的协程对象。这将挂起当前协程，直到`coro`的主体返回。`await`表达式的值是`coro`的主体返回的任何内容。
- en: Note
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Remember: invoking a coroutine as `coro()` immediately returns a coroutine
    object, but does not run the body of the `coro` function. Driving the body of
    coroutines is the job of the event loop.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 记住：将协程作为`coro()`调用会立即返回一个协程对象，但不会运行`coro`函数的主体。驱动协程主体的工作是事件循环的工作。
- en: Now let’s study the `spin` and `slow` coroutines in [Example 19-5](#spinner_async_top_ex).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们研究[示例19-5](#spinner_async_top_ex)中的`spin`和`slow`协程。
- en: 'Example 19-5\. spinner_async.py: the `spin` and `slow` coroutines'
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例19-5\. spinner_async.py：`spin`和`slow`协程
- en: '[PRE4]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO5-1)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO5-1)'
- en: We don’t need the `Event` argument that was used to signal that `slow` had completed
    its job in *spinner_thread.py* ([Example 19-1](#spinner_thread_top_ex)).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要在*spinner_thread.py*中使用的`Event`参数，该参数用于表示`slow`已完成其工作（[示例19-1](#spinner_thread_top_ex)）。
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO5-2)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO5-2)'
- en: Use `await asyncio.sleep(.1)` instead of `time.sleep(.1)`, to pause without
    blocking other coroutines. See the experiment after this example.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`await asyncio.sleep(.1)`代替`time.sleep(.1)`，以暂停而不阻塞其他协程。查看此示例之后的实验。
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO5-3)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO5-3)'
- en: '`asyncio.CancelledError` is raised when the `cancel` method is called on the
    `Task` controlling this coroutine. Time to exit the loop.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当在控制此协程的`Task`上调用`cancel`方法时，会引发`asyncio.CancelledError`。是时候退出循环了。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO5-4)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO5-4)'
- en: The `slow` coroutine also uses `await asyncio.sleep` instead of `time.sleep`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`slow`协程也使用`await asyncio.sleep`而不是`time.sleep`。'
- en: 'Experiment: Break the spinner for an insight'
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验：打破旋转器以获得洞察
- en: Here is an experiment I recommend to understand how *spinner_async.py* works.
    Import the `time` module, then go to the `slow` coroutine and replace the line
    `await asyncio.sleep(3)` with a call to `time.sleep(3)`, like in [Example 19-6](#spinner_async_time_sleep_ex).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我推荐的一个实验，以了解*spinner_async.py*的工作原理。导入`time`模块，然后转到`slow`协程，并将`await asyncio.sleep(3)`替换为调用`time.sleep(3)`，就像在[示例19-6](#spinner_async_time_sleep_ex)中一样。
- en: 'Example 19-6\. spinner_async.py: replacing `await asyncio.sleep(3)` with `time.sleep(3)`'
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例19-6\. spinner_async.py：将`await asyncio.sleep(3)`替换为`time.sleep(3)`
- en: '[PRE5]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Watching the behavior is more memorable than reading about it. Go ahead, I’ll
    wait.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 观察行为比阅读有关它的内容更容易记忆。继续，我会等待。
- en: 'When you run the experiment, this is what you see:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行实验时，您会看到以下内容：
- en: 'The spinner object is shown, similar to this: `<Task pending name=''Task-2''
    coro=<spin() running at /path/to/spinner_async.py:12>>`.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示了类似于这样的旋转器对象：`<Task pending name='Task-2' coro=<spin() running at /path/to/spinner_async.py:12>>`。
- en: The spinner never appears. The program hangs for 3 seconds.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 旋转器永远不会出现。程序会在3秒钟内挂起。
- en: '`Answer: 42` is displayed and the program ends.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '显示`Answer: 42`，然后程序结束。'
- en: To understand what is happening, recall that Python code using `asyncio` has
    only one flow of execution, unless you’ve explicitly started additional threads
    or processes. That means only one coroutine executes at any point in time. Concurrency
    is achieved by control passing from one coroutine to another. In [Example 19-7](#spinner_async_experiment_ex),
    let’s focus on what happens in the `supervisor` and `slow` coroutines during the
    proposed experiment.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解发生了什么，请记住，使用`asyncio`的Python代码只有一个执行流程，除非您明确启动了额外的线程或进程。这意味着在任何时候只有一个协程在执行。并发是通过控制从一个协程传递到另一个协程来实现的。在[示例19-7](#spinner_async_experiment_ex)中，让我们关注在拟议实验期间`supervisor`和`slow`协程中发生了什么。
- en: 'Example 19-7\. spinner_async_experiment.py: the `supervisor` and `slow` coroutines'
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例19-7\. spinner_async_experiment.py：`supervisor`和`slow`协程
- en: '[PRE6]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO6-2)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO6-2)'
- en: The `spinner` task is created, to eventually drive the execution of `spin`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了`spinner`任务，最终驱动`spin`的执行。
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO6-3)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO6-3)'
- en: The display shows the `Task` is “pending.”
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 显示`Task`为“挂起”状态。
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO6-4)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO6-4)'
- en: The `await` expression transfers control to the `slow` coroutine.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`await`表达式将控制传递给`slow`协程。'
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO6-1)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO6-1)'
- en: '`time.sleep(3)` blocks for 3 seconds; nothing else can happen in the program,
    because the main thread is blocked—and it is the only thread. The operating system
    will continue with other activities. After 3 seconds, `sleep` unblocks, and `slow`
    returns.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`time.sleep(3)`会阻塞3秒钟；程序中不会发生任何其他事情，因为主线程被阻塞了，而且它是唯一的线程。操作系统将继续进行其他活动。3秒后，`sleep`解除阻塞，`slow`返回。'
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO6-5)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO6-5)'
- en: Right after `slow` returns, the `spinner` task is cancelled. The flow of control
    never reached the body of the `spin` coroutine.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在`slow`返回后，`spinner`任务被取消。控制流从未到达`spin`协程的主体。
- en: The *spinner_async_experiment.py* teaches an important lesson, as explained
    in the following warning.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*spinner_async_experiment.py*教导了一个重要的教训，如下警告所述。'
- en: Warning
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Never use `time.sleep(…)` in `asyncio` coroutines unless you want to pause your
    whole program. If a coroutine needs to spend some time doing nothing, it should
    `await asyncio.sleep(DELAY)`. This yields control back to the `asyncio` event
    loop, which can drive other pending coroutines.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你想暂停整个程序，否则不要在`asyncio`协程中使用`time.sleep(…)`。如果一个协程需要花一些时间什么都不做，它应该`await asyncio.sleep(DELAY)`。这会将控制权交还给`asyncio`事件循环，它可以驱动其他待处理的协程。
- en: Supervisors Side-by-Side
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并排的监督者
- en: The line count of *spinner_thread.py* and *spinner_async.py* is nearly the same.
    The `supervisor` functions are the heart of these examples. Let’s compare them
    in detail. [Example 19-8](#thread_supervisor_ex) lists only the `supervisor` from
    [Example 19-2](#spinner_thread_rest_ex).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*spinner_thread.py*和*spinner_async.py*的行数几乎相同。`supervisor`函数是这些示例的核心。让我们详细比较一下。[示例
    19-8](#thread_supervisor_ex)仅列出了[示例 19-2](#spinner_thread_rest_ex)中的`supervisor`。'
- en: 'Example 19-8\. spinner_thread.py: the threaded `supervisor` function'
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-8\. spinner_thread.py：线程化的`supervisor`函数
- en: '[PRE7]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For comparison, [Example 19-9](#asyncio_supervisor_ex) shows the `supervisor`
    coroutine from [Example 19-4](#spinner_async_start_ex).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较，[示例 19-9](#asyncio_supervisor_ex)展示了[示例 19-4](#spinner_async_start_ex)中的`supervisor`协程。
- en: 'Example 19-9\. spinner_async.py: the asynchronous `supervisor` coroutine'
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-9\. spinner_async.py：异步的`supervisor`协程
- en: '[PRE8]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here is a summary of the differences and similarities to note between the two
    `supervisor` implementations:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是需要注意的两个`supervisor`实现之间的差异和相似之处的摘要：
- en: An `asyncio.Task` is roughly the equivalent of a `threading.Thread`.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`asyncio.Task`大致相当于一个`threading.Thread`。
- en: A `Task` drives a coroutine object, and a `Thread` invokes a callable.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`Task`驱动一个协程对象，而一个`Thread`调用一个可调用对象。
- en: A coroutine yields control explicitly with the `await` keyword.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个协程使用`await`关键字显式地让出控制。
- en: You don’t instantiate `Task` objects yourself, you get them by passing a coroutine
    to `asyncio.create_task(…)`.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不需要自己实例化`Task`对象，你通过将协程传递给`asyncio.create_task(…)`来获取它们。
- en: When `asyncio.create_task(…)` returns a `Task` object, it is already scheduled
    to run, but a `Thread` instance must be explicitly told to run by calling its
    `start` method.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`asyncio.create_task(…)`返回一个`Task`对象时，它已经被安排运行，但必须显式调用`start`方法来告诉`Thread`实例运行。
- en: In the threaded `supervisor`, `slow` is a plain function and is directly invoked
    by the main thread. In the asynchronous `supervisor`, `slow` is a coroutine driven
    by `await`.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程化的`supervisor`中，`slow`是一个普通函数，由主线程直接调用。在异步的`supervisor`中，`slow`是一个由`await`驱动的协程。
- en: There’s no API to terminate a thread from the outside; instead, you must send
    a signal—like setting the `done` `Event` object. For tasks, there is the `Task.cancel()`
    instance method, which raises `CancelledError` at the `await` expression where
    the coroutine body is currently suspended.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有API可以从外部终止一个线程；相反，你必须发送一个信号，比如设置`done` `Event`对象。对于任务，有`Task.cancel()`实例方法，它会在当前挂起协程体中的`await`表达式处引发`CancelledError`。
- en: The `supervisor` coroutine must be started with `asyncio.run` in the `main`
    function.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`supervisor`协程必须在`main`函数中使用`asyncio.run`启动。'
- en: This comparison should help you understand how concurrent jobs are orchestrated
    with *asyncio*, in contrast to how it’s done with the `Threading` module, which
    may be more familiar to you.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个比较应该帮助你理解*asyncio*如何编排并发作业，与使用`Threading`模块的方式相比，后者可能更为熟悉。
- en: 'One final point related to threads versus coroutines: if you’ve done any nontrivial
    programming with threads, you know how challenging it is to reason about the program
    because the scheduler can interrupt a thread at any time. You must remember to
    hold locks to protect the critical sections of your program, to avoid getting
    interrupted in the middle of a multistep operation—which could leave data in an
    invalid state.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线程与协程的最后一点：如果你使用线程进行了一些非平凡的编程，你会知道由于调度程序可以随时中断线程，因此理解程序是多么具有挑战性。你必须记住持有锁以保护程序的关键部分，以避免在多步操作的中途被中断，这可能会导致数据处于无效状态。
- en: 'With coroutines, your code is protected against interruption by default. You
    must explicitly `await` to let the rest of the program run. Instead of holding
    locks to synchronize the operations of multiple threads, coroutines are “synchronized”
    by definition: only one of them is running at any time. When you want to give
    up control, you use `await` to yield control back to the scheduler. That’s why
    it is possible to safely cancel a coroutine: by definition, a coroutine can only
    be cancelled when it’s suspended at an `await` expression, so you can perform
    cleanup by handling the `CancelledError` exception.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 使用协程，你的代码默认受到保护，不会被中断。你必须显式`await`来让程序的其余部分运行。与持有锁以同步多个线程的操作相反，协程是“同步”的定义：任何时候只有一个协程在运行。当你想放弃控制时，你使用`await`将控制权交还给调度程序。这就是为什么可以安全地取消一个协程：根据定义，只有在协程被挂起在`await`表达式时才能取消协程，因此你可以通过处理`CancelledError`异常来执行清理。
- en: The `time.sleep()` call blocks but does nothing. Now we’ll experiment with a
    CPU-intensive call to get a better understanding of the GIL, as well as the effect
    of CPU-intensive functions in asynchronous code.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`time.sleep()`调用会阻塞但不执行任何操作。现在我们将尝试使用一个CPU密集型调用来更好地理解GIL，以及CPU密集型函数在异步代码中的影响。'
- en: The Real Impact of the GIL
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GIL的真正影响
- en: In the threading code ([Example 19-1](#spinner_thread_top_ex)), you can replace
    the `time.sleep(3)` call in the `slow` function with an HTTP client request from
    your favorite library, and the spinner will keep spinning. That’s because a well-designed
    network library will release the GIL while waiting for the network.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在线程代码（[示例 19-1](#spinner_thread_top_ex)）中，你可以用你喜欢的库中的HTTP客户端请求替换`slow`函数中的`time.sleep(3)`调用，旋转动画将继续旋转。这是因为设计良好的网络库在等待网络时会释放GIL。
- en: You can also replace the `asyncio.sleep(3)` expression in the `slow` coroutine
    to `await` for a response from a well-designed asynchronous network library, because
    such libraries provide coroutines that yield control back to the event loop while
    waiting for the network. Meanwhile, the spinner will keep spinning.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将`slow`协程中的`asyncio.sleep(3)`表达式替换为等待来自设计良好的异步网络库的响应的`await`，因为这些库提供的协程在等待网络时会将控制权交还给事件循环。与此同时，旋转动画将继续旋转。
- en: With CPU-intensive code, the story is different. Consider the function `is_prime`
    in [Example 19-10](#def_is_prime_ex), which returns `True` if the argument is
    a prime number, `False` if it’s not.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 对于CPU密集型代码，情况就不同了。考虑[示例 19-10](#def_is_prime_ex)中的`is_prime`函数，如果参数是质数则返回`True`，否则返回`False`。
- en: 'Example 19-10\. primes.py: an easy to read primality check, from Python’s [`ProcessPool​Executor`
    example](https://fpy.li/19-19)'
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-10\. primes.py：一个易于阅读的素数检查，来自Python的[`ProcessPool​Executor`示例](https://fpy.li/19-19)
- en: '[PRE9]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The call `is_prime(5_000_111_000_222_021)` takes about 3.3s on the company laptop
    I am using now.^([12](ch19.html#idm46582391425184))
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在我现在使用的公司笔记本电脑上，调用`is_prime(5_000_111_000_222_021)`大约需要3.3秒。^([12](ch19.html#idm46582391425184))
- en: Quick Quiz
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速测验
- en: Given what we’ve seen so far, please take the time to consider the following
    three-part question. One part of the answer is tricky (at least it was for me).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们迄今所见，请花时间考虑以下三部分问题。答案的一部分有点棘手（至少对我来说是这样）。
- en: 'What would happen to the spinner animation if you made the following changes,
    assuming that `n = 5_000_111_000_222_021`—that prime which my machine takes 3.3s
    to verify:'
  id: totrans-234
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你对旋转动画进行以下更改，假设`n = 5_000_111_000_222_021`——这个让我的机器花费3.3秒来验证的质数，那么旋转动画会发生什么变化呢？
- en: ''
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In *spinner_proc.py*, replace `time.sleep(3)` with a call to `is_prime(n)`?
  id: totrans-236
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*spinner_proc.py*中，用调用`is_prime(n)`替换`time.sleep(3)`？
- en: ''
  id: totrans-237
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-238
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: In *spinner_thread.py*, replace `time.sleep(3)` with a call to `is_prime(n)`?
  id: totrans-239
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*spinner_thread.py*中，用调用`is_prime(n)`替换`time.sleep(3)`？
- en: ''
  id: totrans-240
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-241
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: In *spinner_async.py*, replace `await asyncio.sleep(3)` with a call to `is_prime(n)`?
  id: totrans-242
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*spinner_async.py*中，用调用`is_prime(n)`替换`await asyncio.sleep(3)`？
- en: Before you run the code or read on, I recommend figuring out the answers on
    your own. Then, you may want to copy and modify the *spinner_*.py* examples as
    suggested.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行代码或继续阅读之前，我建议你自己想出答案。然后，你可能想按照建议复制和修改*spinner_*.py*示例。
- en: Now the answers, from easier to hardest.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是答案，从简单到困难。
- en: 1\. Answer for multiprocessing
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 多进程的答案
- en: The spinner is controlled by a child process, so it continues spinning while
    the primality test is computed by the parent process.^([13](ch19.html#idm46582391326528))
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转动画由一个子进程控制，因此在父进程计算素数测试时它会继续旋转。^([13](ch19.html#idm46582391326528))
- en: 2\. Answer for threading
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 线程的答案
- en: The spinner is controlled by a secondary thread, so it continues spinning while
    the primality test is computed by the main thread.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转动画由一个辅助线程控制，因此在主线程计算素数测试时它会继续旋转。
- en: 'I did not get this answer right at first: I was expecting the spinner to freeze
    because I overestimated the impact of the GIL.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 起初我没有得到这个答案：我预期旋转动画会冻结，因为我高估了GIL的影响。
- en: In this particular example, the spinner keeps spinning because Python suspends
    the running thread every 5ms (by default), making the GIL available to other pending
    threads. Therefore, the main thread running `is_prime` is interrupted every 5ms,
    allowing the secondary thread to wake up and iterate once through the `for` loop,
    until it calls the `wait` method of the `done` event, at which time it will release
    the GIL. The main thread will then grab the GIL, and the `is_prime` computation
    will proceed for another 5ms.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定示例中，旋转动画会继续旋转，因为Python默认每5ms挂起运行线程，使GIL可供其他挂起线程使用。因此，运行`is_prime`的主线程每5ms被中断一次，允许辅助线程唤醒并迭代一次`for`循环，直到调用`done`事件的`wait`方法，此时它将释放GIL。然后主线程将获取GIL，并且`is_prime`计算将继续进行5ms。
- en: This does not have a visible impact on the running time of this specific example,
    because the `spin` function quickly iterates once and releases the GIL as it waits
    for the `done` event, so there is not much contention for the GIL. The main thread
    running `is_prime` will have the GIL most of the time.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这对这个特定示例的运行时间没有明显影响，因为`spin`函数快速迭代一次并在等待`done`事件时释放GIL，因此对GIL的争夺不多。运行`is_prime`的主线程大部分时间都会持有GIL。
- en: 'We got away with a compute-intensive task using threading in this simple experiment
    because there are only two threads: one hogging the CPU, and the other waking
    up only 10 times per second to update the spinner.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的实验中，我们使用线程来处理计算密集型任务，因为只有两个线程：一个占用CPU，另一个每秒只唤醒10次以更新旋转动画。
- en: But if you have two or more threads vying for a lot of CPU time, your program
    will be slower than sequential code.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果有两个或更多线程争夺大量CPU时间，你的程序将比顺序代码慢。
- en: 3\. Answer for asyncio
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. asyncio的答案
- en: 'If you call `is_prime(5_000_111_000_222_021)` in the `slow` coroutine of the
    *spinner_async.py* example, the spinner will never appear. The effect would be
    the same we had in [Example 19-6](#spinner_async_time_sleep_ex), when we replaced
    `await asyncio.sleep(3)` with `time.sleep(3)`: no spinning at all. The flow of
    control will pass from `supervisor` to `slow`, and then to `is_prime`. When `is_prime`
    returns, `slow` returns as well, and `supervisor` resumes, cancelling the `spinner`
    task before it is executed even once. The program appears frozen for about 3s,
    then shows the answer.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在 *spinner_async.py* 示例的 `slow` 协程中调用 `is_prime(5_000_111_000_222_021)`，那么旋转器将永远不会出现。效果与我们在
    [示例 19-6](#spinner_async_time_sleep_ex) 中替换 `await asyncio.sleep(3)` 为 `time.sleep(3)`
    时相同：根本没有旋转。控制流将从 `supervisor` 传递到 `slow`，然后到 `is_prime`。当 `is_prime` 返回时，`slow`
    也返回，`supervisor` 恢复，甚至在执行一次旋转器任务之前取消 `spinner` 任务。程序会在约 3 秒钟内冻结，然后显示答案。
- en: So far, we’ve only experimented with a single call to a CPU-intensive function.
    The next section presents concurrent execution of multiple CPU-intensive calls.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只尝试了对一个 CPU 密集型函数的单次调用。下一部分将展示多个 CPU 密集型调用的并发执行。
- en: A Homegrown Process Pool
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自制进程池
- en: Note
  id: totrans-258
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'I wrote this section to show the use of multiple processes for CPU-intensive
    tasks, and the common pattern of using queues to distribute tasks and collect
    results. [Chapter 20](ch20.html#futures_ch) will show a simpler way of distributing
    tasks to processes: a `ProcessPoolExecutor` from the `concurrent.futures` package,
    which uses queues internally.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我编写这一部分是为了展示多进程用于 CPU 密集型任务的使用，以及使用队列分发任务和收集结果的常见模式。[第 20 章](ch20.html#futures_ch)
    将展示一种更简单的方式将任务分发给进程：`concurrent.futures` 包中的 `ProcessPoolExecutor`，它在内部使用队列。
- en: In this section we’ll write programs to compute the primality of a sample of
    20 integers, from 2 to 9,999,999,999,999,999—i.e., 10^(16) – 1, or more than 2^(53).
    The sample includes small and large primes, as well as composite numbers with
    small and large prime factors.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将编写程序来计算 20 个整数样本的素性，范围从 2 到 9,999,999,999,999,999—即 10^(16) – 1，或超过
    2^(53)。样本包括小型和大型素数，以及具有小型和大型素数因子的合数。
- en: 'The *sequential.py* program provides the performance baseline. Here is a sample
    run:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '*sequential.py* 程序提供了性能基准。以下是一个示例运行：'
- en: '[PRE10]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results are shown in three columns:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在三列中：
- en: The number to be checked.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要检查的数字。
- en: '`P` if it’s a prime number, blank if not.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是素数，则为 `P`，否则为空。
- en: Elapsed time for checking the primality for that specific number.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查该特定数字的素性所花费的经过时间。
- en: In this example, the total time is approximately the sum of the times for each
    check, but it is computed separately, as you can see in [Example 19-12](#primes_sequential_ex).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，总时间大约等于每个检查的时间之和，但是它是单独计算的，正如您在 [示例 19-12](#primes_sequential_ex) 中所看到的。
- en: 'Example 19-12\. sequential.py: sequential primality check for a small dataset'
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-12\. sequential.py：小数据集的顺序素性检查
- en: '[PRE11]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO8-1)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO8-1)'
- en: The `check` function (in the next callout) returns a `Result` tuple with the
    boolean value of the `is_prime` call and the elapsed time.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`check` 函数（在下一个 callout 中）返回一个带有 `is_prime` 调用的布尔值和经过时间的 `Result` 元组。'
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO8-2)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO8-2)'
- en: '`check(n)` calls `is_prime(n)` and computes the elapsed time to return a `Result`.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`check(n)` 调用 `is_prime(n)` 并计算经过的时间以返回一个 `Result`。'
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO8-3)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO8-3)'
- en: For each number in the sample, we call `check` and display the result.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于样本中的每个数字，我们调用 `check` 并显示结果。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO8-4)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO8-4)'
- en: Compute and display the total elapsed time.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 计算并显示总经过时间。
- en: Process-Based Solution
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于进程的解决方案
- en: 'The next example, *procs.py*, shows the use of multiple processes to distribute
    the primality checks across multiple CPU cores. These are the times I get with
    *procs.py*:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例 *procs.py* 展示了使用多个进程将素性检查分布到多个 CPU 核心上。这是我用 *procs.py* 得到的时间：
- en: '[PRE12]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The last line of the output shows that *procs.py* was 4.2 times faster than
    *sequential.py*.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的最后一行显示 *procs.py* 比 *sequential.py* 快了 4.2 倍。
- en: Understanding the Elapsed Times
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解经过时间
- en: Note that the elapsed time in the first column is for checking that specific
    number. For example, `is_prime(7777777777777753)` took almost 8.4s to return `True`.
    Meanwhile, other processes were checking other numbers in parallel.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，第一列中的经过时间是用于检查该特定数字的。例如，`is_prime(7777777777777753)` 几乎花费了 8.4 秒才返回 `True`。同时，其他进程正在并行检查其他数字。
- en: There were 20 numbers to check. I wrote *procs.py* to start a number of worker
    processes equal to the number of CPU cores, as determined by `multiprocessing.cpu_count()`.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 有 20 个数字需要检查。我编写了 *procs.py* 来启动与 CPU 核心数量相等的工作进程，这个数量由 `multiprocessing.cpu_count()`
    确定。
- en: The total time in this case is much less than the sum of the elapsed time for
    the individual checks. There is some overhead in spinning up processes and in
    inter-process communication, so the end result is that the multiprocess version
    is only about 4.2 times faster than the sequential. That’s good, but a little
    disappointing considering the code launches 12 processes to use all cores on this
    laptop.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，总时间远远小于各个检查的经过时间之和。在启动进程和进程间通信中存在一些开销，因此最��结果是多进程版本仅比顺序版本快约 4.2 倍。这很好，但考虑到代码启动了
    12 个进程以利用笔记本电脑上的所有核心，有点令人失望。
- en: Note
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `multiprocessing.cpu_count()` function returns `12` on the MacBook Pro
    I’m using to write this chapter. It’s actually a 6-CPU Core-i7, but the OS reports
    12 CPUs because of hyperthreading, an Intel technology which executes 2 threads
    per core. However, hyperthreading works better when one of the threads is not
    working as hard as the other thread in the same core—perhaps the first is stalled
    waiting for data after a cache miss, and the other is crunching numbers. Anyway,
    there’s no free lunch: this laptop performs like a 6-CPU machine for compute-intensive
    work that doesn’t use a lot of memory—like that simple primality test.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.cpu_count()`函数在我用来撰写本章的MacBook Pro上返回`12`。实际上是一个6-CPU Core-i7，但由于超线程技术，操作系统报告有12个CPU，每个核心执行2个线程。然而，当一个线程不像同一核心中的另一个线程那样努力工作时，超线程效果更好——也许第一个在缓存未命中后等待数据，而另一个在进行数字计算。无论如何，没有免费午餐：这台笔记本电脑在不使用大量内存的计算密集型工作中表现得像一台6-CPU机器，比如简单的素数测试。'
- en: Code for the Multicore Prime Checker
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多核素数检查的代码
- en: When we delegate computing to threads or processes, our code does not call the
    worker function directly, so we can’t simply get a return value. Instead, the
    worker is driven by the thread or process library, and it eventually produces
    a result that needs to be stored somewhere. Coordinating workers and collecting
    results are common uses of queues in concurrent programming—and also in distributed
    systems.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将计算委托给线程或进程时，我们的代码不会直接调用工作函数，因此我们不能简单地获得返回值。相反，工作由线程或进程库驱动，并最终产生需要存储的结果。协调工作人员和收集结果是并发编程中常见队列的用途，也是分布式系统中的用途。
- en: Much of the new code in *procs.py* has to do with setting up and using queues.
    The top of the file is in [Example 19-13](#primes_procs_top_ex).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '*procs.py*中的许多新代码涉及设置和使用队列。文件顶部在[示例19-13](#primes_procs_top_ex)中。'
- en: Warning
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: '`SimpleQueue` was added to `multiprocessing` in Python 3.9. If you’re using
    an earlier version of Python, you can replace `SimpleQueue` with `Queue` in [Example 19-13](#primes_procs_top_ex).'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '`SimpleQueue`在Python 3.9中添加到`multiprocessing`中。如果您使用的是早期版本的Python，可以在[示例19-13](#primes_procs_top_ex)中用`Queue`替换`SimpleQueue`。'
- en: 'Example 19-13\. procs.py: multiprocess primality check; imports, types, and
    functions'
  id: totrans-293
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例19-13。procs.py：多进程素数检查；导入、类型和函数
- en: '[PRE13]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO9-1)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO9-1)'
- en: Trying to emulate `threading`, `multiprocessing` provides `multiprocessing.SimpleQueue`,
    but this is a method bound to a predefined instance of a lower-level `BaseContext`
    class. We must call this `SimpleQueue` to build a queue, we can’t use it in type
    hints.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试模拟`threading`，`multiprocessing`提供`multiprocessing.SimpleQueue`，但这是绑定到预定义实例的低级`BaseContext`类的方法。我们必须调用这个`SimpleQueue`来构建一个队列，不能在类型提示中使用它。
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO9-2)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO9-2)'
- en: '`multiprocessing.queues` has the `SimpleQueue` class we need for type hints.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '`multiprocessing.queues`有我们在类型提示中需要的`SimpleQueue`类。'
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO9-3)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO9-3)'
- en: '`PrimeResult` includes the number checked for primality. Keeping `n` together
    with the other result fields simplifies displaying results later.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '`PrimeResult`包括检查素数的数字。将`n`与其他结果字段一起保持简化后续显示结果。'
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO9-4)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO9-4)'
- en: This is a type alias for a `SimpleQueue` that the `main` function ([Example 19-14](#primes_procs_main_ex))
    will use to send numbers to the processes that will do the work.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`main`函数将用于向执行工作的进程发送数字的`SimpleQueue`的类型别名。
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO9-5)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO9-5)'
- en: Type alias for a second `SimpleQueue` that will collect the results in `main`.
    The values in the queue will be tuples made of the number to be tested for primality,
    and a `Result` tuple.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个将在`main`中收集结果的`SimpleQueue`的类型别名。队列中的值将是由要测试素数的数字和一个`Result`元组组成的元组。
- en: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO9-6)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO9-6)'
- en: This is similar to *sequential.py*.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于*sequential.py*。
- en: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO9-7)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO9-7)'
- en: '`worker` gets a queue with the numbers to be checked, and another to put results.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '`worker`获取一个包含要检查的数字的队列，另一个用于放置结果。'
- en: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO9-8)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO9-8)'
- en: 'In this code, I use the number `0` as a *poison pill*: a signal for the worker
    to finish. If `n` is not `0`, proceed with the loop.^([14](ch19.html#idm46582390464160))'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我使用数字`0`作为*毒丸*：一个信号，告诉工作进程完成。如果`n`不是`0`，则继续循环。^([14](ch19.html#idm46582390464160))
- en: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO9-9)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO9-9)'
- en: Invoke the primality check and enqueue `PrimeResult`.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 调用素数检查并将`PrimeResult`入队。
- en: '[![10](assets/10.png)](#co_concurrency_models_in_python_CO9-10)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '[![10](assets/10.png)](#co_concurrency_models_in_python_CO9-10)'
- en: Send back a `PrimeResult(0, False, 0.0)` to let the main loop know that this
    worker is done.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 发回一个`PrimeResult(0, False, 0.0)`，以让主循环知道这个工作进程已完成。
- en: '[![11](assets/11.png)](#co_concurrency_models_in_python_CO9-11)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[![11](assets/11.png)](#co_concurrency_models_in_python_CO9-11)'
- en: '`procs` is the number of processes that will compute the prime checks in parallel.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`procs`是将并行计算素数检查的进程数。'
- en: '[![12](assets/12.png)](#co_concurrency_models_in_python_CO9-12)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '[![12](assets/12.png)](#co_concurrency_models_in_python_CO9-12)'
- en: Enqueue the numbers to be checked in `jobs`.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 将要检查的数字入队到`jobs`中。
- en: '[![13](assets/13.png)](#co_concurrency_models_in_python_CO9-13)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '[![13](assets/13.png)](#co_concurrency_models_in_python_CO9-13)'
- en: Fork a child process for each worker. Each child will run the loop inside its
    own instance of the `worker` function, until it fetches a `0` from the `jobs`
    queue.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个工作进程分叉一个子进程。每个子进程将在其自己的`worker`函数实例内运行循环，直到从`jobs`队列中获取`0`。
- en: '[![14](assets/14.png)](#co_concurrency_models_in_python_CO9-14)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '[![14](assets/14.png)](#co_concurrency_models_in_python_CO9-14)'
- en: Start each child process.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 启动每个子进程。
- en: '[![15](assets/15.png)](#co_concurrency_models_in_python_CO9-15)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[![15](assets/15.png)](#co_concurrency_models_in_python_CO9-15)'
- en: Enqueue one `0` for each process, to terminate them.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个进程入队一个`0`，以终止它们。
- en: Now let’s study the `main` function of *procs.py* in [Example 19-14](#primes_procs_main_ex).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来研究*procs.py*中的`main`函数在[示例 19-14](#primes_procs_main_ex)中。
- en: 'Example 19-14\. procs.py: multiprocess primality check; `main` function'
  id: totrans-326
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 19-14\. procs.py：多进程素数检查；`main`函数
- en: '[PRE14]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO10-1)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_concurrency_models_in_python_CO10-1)'
- en: If no command-line argument is given, set the number of processes to the number
    of CPU cores; otherwise, create as many processes as given in the first argument.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有给出命令行参数，则将进程数量设置为CPU核心数；否则，根据第一个参数创建相同数量的进程。
- en: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO10-2)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_concurrency_models_in_python_CO10-2)'
- en: '`jobs` and `results` are the queues described in [Example 19-13](#primes_procs_top_ex).'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '`jobs`和`results`是[示例 19-13](#primes_procs_top_ex)中描述的队列。'
- en: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO10-3)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_concurrency_models_in_python_CO10-3)'
- en: Start `proc` processes to consume `jobs` and post `results`.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 启动`proc`进程来消费`jobs`并发布`results`。
- en: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO10-4)'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_concurrency_models_in_python_CO10-4)'
- en: Retrieve the results and display them; `report` is defined in ![6](assets/6.png).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 检索结果并显示它们；`report`在![6](assets/6.png)中定义。
- en: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO10-5)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_concurrency_models_in_python_CO10-5)'
- en: Display how many numbers were checked and the total elapsed time.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 显示检查的数字数量和总经过时间。
- en: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO10-6)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_concurrency_models_in_python_CO10-6)'
- en: The arguments are the number of `procs` and the queue to post the results.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 参数是`procs`的数量和用于发布结果的队列。
- en: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO10-7)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_concurrency_models_in_python_CO10-7)'
- en: Loop until all processes are done.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 循环直到所有进程完成。
- en: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO10-8)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](assets/8.png)](#co_concurrency_models_in_python_CO10-8)'
- en: Get one `PrimeResult`. Calling `.get()` on a queue block until there is an item
    in the queue. It’s also possible to make this nonblocking, or set a timeout. See
    the [`SimpleQueue.get`](https://fpy.li/19-23) documentation for details.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 获取一个`PrimeResult`。在队列上调用`.get()`会阻塞，直到队列中有一个项目。也可以将其设置为非阻塞，或设置超时。有关详细信息，请参阅[`SimpleQueue.get`](https://fpy.li/19-23)文档。
- en: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO10-9)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](assets/9.png)](#co_concurrency_models_in_python_CO10-9)'
- en: If `n` is zero, then one process exited; increment the `procs_done` count.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`n`为零，则一个进程退出；增加`procs_done`计数。
- en: '[![10](assets/10.png)](#co_concurrency_models_in_python_CO10-10)'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '[![10](assets/10.png)](#co_concurrency_models_in_python_CO10-10)'
- en: Otherwise, increment the `checked` count (to keep track of the numbers checked)
    and display the results.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，增加`checked`计数（以跟踪检查的数字）并显示结果。
- en: The results will not come back in the same order the jobs were submitted. That’s
    why I had to put `n` in each `PrimeResult` tuple. Otherwise, I’d have no way to
    know which result belonged to each number.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将不会按照提交作业的顺序返回。这就是为什么我必须在每个`PrimeResult`元组中放入`n`。否则，我将无法知道哪个结果属于每个数字。
- en: If the main process exits before all subprocesses are done, you may see confusing
    tracebacks on `FileNotFoundError` exceptions caused by an internal lock in `multiprocessing`.
    Debugging concurrent code is always hard, and debugging `multiprocessing` is even
    harder because of all the complexity behind the thread-like façade. Fortunately,
    the `ProcessPoolExecutor` we’ll meet in [Chapter 20](ch20.html#futures_ch) is
    easier to use and more robust.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主进程在所有子进程完成之前退出，则可能会看到由`multiprocessing`中的内部锁引起的`FileNotFoundError`异常的令人困惑的回溯。调试并发代码总是困难的，而调试`multiprocessing`更加困难，因为在类似线程的外观背后有着复杂性。幸运的是，我们将在[第20章](ch20.html#futures_ch)中遇到的`ProcessPoolExecutor`更易于使用且更健壮。
- en: Note
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Thanks to reader Michael Albert who noticed the code I published during the
    early release had a [*race condition*](https://fpy.li/19-24) in [Example 19-14](#primes_procs_main_ex).
    A race condition is a bug that may or may not occur depending on the order of
    actions performed by concurrent execution units. If “A” happens before “B,” all
    is fine; but it “B” happens first, something goes wrong. That’s the race.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢读者Michael Albert注意到我在早期发布时发布的代码在[示例 19-14](#primes_procs_main_ex)中有一个[*竞争条件*](https://fpy.li/19-24)。竞争条件是一个可能发生也可能不发生的错误，取决于并发执行单元执行操作的顺序。如果“A”发生在“B”之前，一切都很好；但如果“B”先发生，就会出现问题。这就是竞争条件。
- en: 'If you are curious, this diff shows the bug and how I fixed it: [*example-code-2e/commit/2c123057*](https://fpy.li/19-25)—but
    note that I later refactored the example to delegate parts of `main` to the `start_jobs`
    and `report` functions. There’s a [*README.md*](https://fpy.li/19-26) file in
    the same directory explaining the problem and the solution.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，这个差异显示了错误以及我如何修复它：[*example-code-2e/commit/2c123057*](https://fpy.li/19-25)—但请注意，我后来重构了示例，将`main`的部分委托给`start_jobs`和`report`函数。在同一目录中有一个[*README.md*](https://fpy.li/19-26)文件解释了问题和解决方案。
- en: Experimenting with More or Fewer Processes
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试使用更多或更少的进程
- en: You may want try running *procs.py*, passing arguments to set the number of
    worker processes. For example, this command…
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想尝试运行*procs.py*，传递参数来设置工作进程的数量。例如，这个命令…
- en: '[PRE15]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: …will launch two worker processes, producing results almost twice as fast as
    *sequential.py*—if your machine has at least two cores and is not too busy running
    other programs.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: …将启动两个工作进程，几乎比*sequential.py*快两倍—如果您的计算机至少有两个核心并且没有太忙于运行其他程序。
- en: I ran *procs.py* 12 times with 1 to 20 processes, totaling 240 runs. Then I
    computed the median time for all runs with the same number of processes, and plotted
    [Figure 19-2](#procs_x_time_fig).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我用1到20个进程运行了*procs.py* 12次，总共240次运行。然后我计算了相同进程数量的所有运行的中位时间，并绘制了[图 19-2](#procs_x_time_fig)。
- en: '![Median run times for each number of processes from 1 to 20.](assets/flpy_1902.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![每个进程数量从1到20的中位运行时间。](assets/flpy_1902.png)'
- en: Figure 19-2\. Median run times for each number of processes from 1 to 20\. Highest
    median time was 40.81s, with 1 process. Lowest median time was 10.39s, with 6
    processes, indicated by the dotted line.
  id: totrans-359
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图19-2。每个进程数的中位运行时间从1到20。1个进程的最长中位时间为40.81秒。6个进程的最短中位时间为10.39秒，由虚线表示。
- en: 'In this 6-core laptop, the lowest median time was with 6 processes: 10.39s—marked
    by the dotted line in [Figure 19-2](#procs_x_time_fig). I expected the run time
    to increase after 6 processes due to CPU contention, and it reached a local maximum
    of 12.51s at 10 processes. I did not expect and I can’t explain why the performance
    improved at 11 processes and remained almost flat from 13 to 20 processes, with
    median times only slightly higher than the lowest median time at 6 processes.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在这台6核笔记本电脑中，6个进程的最短中位时间为10.39秒，由[图19-2](#procs_x_time_fig)中的虚线标记。我预计在6个进程后运行时间会增加，因为CPU争用，而在10个进程时达到12.51秒的局部最大值。我没有预料到，也无法解释为什么在11个进程时性能有所提高，并且从13到20个进程时几乎保持不变，中位时间仅略高于6个进程的最低中位时间。
- en: Thread-Based Nonsolution
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于线程的非解决方案
- en: I also wrote *threads.py*, a version of *procs.py* using `threading` instead
    of `multiprocessing`. The code is very similar—as is usually the case when converting
    simple examples between these two APIs.^([16](ch19.html#idm46582390056752)) Due
    to the GIL and the compute-intensive nature of `is_prime`, the threaded version
    is slower than the sequential code in [Example 19-12](#primes_sequential_ex),
    and it gets slower as the number of threads increase, because of CPU contention
    and the cost of context switching. To switch to a new thread, the OS needs to
    save CPU registers and update the program counter and stack pointer, triggering
    expensive side effects like invalidating CPU caches and possibly even swapping
    memory pages.^([17](ch19.html#idm46582390033840))
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我还编写了*threads.py*，这是使用`threading`而不是`multiprocessing`的*procs.py*版本。代码非常相似——在将这两个API之间的简单示例转换时通常是这种情况。^([16](ch19.html#idm46582390056752))
    由于GIL和`is_prime`的计算密集型特性，线程版本比[示例19-12](#primes_sequential_ex)中的顺序代码慢，并且随着线程数量的增加而变慢，因为CPU争用和上下文切换的成本。要切换到新线程，操作系统需要保存CPU寄存器并更新程序计数器和堆栈指针，触发昂贵的副作用，如使CPU缓存失效，甚至可能交换内存页面。^([17](ch19.html#idm46582390033840))
- en: The next two chapters will cover more about concurrent programming in Python,
    using the high-level *concurrent.futures* library to manage threads and processes
    ([Chapter 20](ch20.html#futures_ch)) and the *asyncio* library for asynchronous
    programming ([Chapter 21](ch21.html#async_ch)).
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两章将更多地介绍Python中的并发编程，使用高级*concurrent.futures*库来管理线程和进程（[第20章](ch20.html#futures_ch)）以及*asyncio*库用于异步编程（[第21章](ch21.html#async_ch)）。
- en: 'The remaining sections in this chapter aim to answer the question:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的其余部分旨在回答以下问题：
- en: Given the limitations discussed so far, how is Python thriving in a multicore
    world?
  id: totrans-365
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鉴于迄今为止讨论的限制，Python如何在多核世界中蓬勃发展？
- en: Python in the Multicore World
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python在多核世界中
- en: 'Consider this citation from the widely quoted article [“The Free Lunch Is Over:
    A Fundamental Turn Toward Concurrency in Software” by Herb Sutter](https://fpy.li/19-29):'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑这段引用自广为引用的文章[“软件中的并发：免费午餐已经结束”（作者：Herb Sutter）](https://fpy.li/19-29)：
- en: The major processor manufacturers and architectures, from Intel and AMD to Sparc
    and PowerPC, have run out of room with most of their traditional approaches to
    boosting CPU performance. Instead of driving clock speeds and straight-line instruction
    throughput ever higher, they are instead turning en masse to hyper-threading and
    multicore architectures. March 2005\. [Available online].
  id: totrans-368
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从英特尔和AMD到Sparc和PowerPC等主要处理器制造商和架构，他们几乎用尽了传统方法来提升CPU性能的空间。他们不再试图提高时钟速度和直线指令吞吐量，而是大规模转向超线程和多核架构。2005年3月。[在线提供]。
- en: 'What Sutter calls the “free lunch” was the trend of software getting faster
    with no additional developer effort because CPUs were executing sequential code
    faster, year after year. Since 2004, that is no longer true: clock speeds and
    execution optimizations reached a plateau, and now any significant increase in
    performance must come from leveraging multiple cores or hyperthreading, advances
    that only benefit code that is written for concurrent execution.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: Sutter所说的“免费午餐”是软件随着时间推移变得更快，而无需额外的开发人员努力的趋势，因为CPU一直在以更快的速度执行指令代码。自2004年以来，这种情况不再成立：时钟速度和执行优化已经达到瓶颈，现在任何显著的性能提升都必须来自于利用多核或超线程，这些进步只有为并发执行编写的代码才能受益。
- en: Python’s story started in the early 1990s, when CPUs were still getting exponentially
    faster at sequential code execution. There was no talk about multicore CPUs except
    in supercomputers back then. At the time, the decision to have a GIL was a no-brainer.
    The GIL makes the interpreter faster when running on a single core, and its implementation
    simpler.^([18](ch19.html#idm46582390019472)) The GIL also makes it easier to write
    simple extensions through the Python/C API.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: Python的故事始于20世纪90年代初，当时CPU仍在以指令代码执行的方式呈指数级增长。当时除了超级计算机外，几乎没有人谈论多核CPU。当时，决定使用GIL是理所当然的。GIL使解释器在单核运行时更快，其实现更简单。^([18](ch19.html#idm46582390019472))
    GIL还使得通过Python/C API编写简单扩展变得更容易。
- en: Note
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: I just wrote “simple extensions” because an extension does not need to deal
    with the GIL at all. A function written in C or Fortran may be hundreds of times
    faster than the equivalent in Python.^([19](ch19.html#idm46582390017680)) Therefore
    the added complexity of releasing the GIL to leverage multicore CPUs may not be
    needed in many cases. So we can thank the GIL for many extensions available for
    Python—and that is certainly one of the key reasons why the language is so popular
    today.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我之所以写“简单扩展”，是因为扩展根本不需要处理GIL。用C或Fortran编写的函数可能比Python中的等效函数快几百倍。^([19](ch19.html#idm46582390017680))
    因此，在许多情况下，可能不需要释放GIL以利用多核CPU的增加复杂性。因此，我们可以感谢GIL为Python提供了许多扩展，这无疑是该语言如今如此受欢迎的关键原因之一。
- en: Despite the GIL, Python is thriving in applications that require concurrent
    or parallel execution, thanks to libraries and software architectures that work
    around the limitations of CPython.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有全局解释器锁（GIL），Python在需要并发或并行执行的应用程序中蓬勃发展，这要归功于绕过CPython限制的库和软件架构。
- en: Now let’s discuss how Python is used in system administration, data science,
    and server-side application development in the multicore, distributed computing
    world of 2021.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论Python在2021年多核、分布式计算世界中的系统管理、数据科学和服务器端应用开发中的应用。
- en: System Administration
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统管理
- en: Python is widely used to manage large fleets of servers, routers, load balancers,
    and network-attached storage (NAS). It’s also a leading option in software-defined
    networking (SDN) and ethical hacking. Major cloud service providers support Python
    through libraries and tutorials authored by the providers themselves or by their
    large communities of Python users.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: Python被广泛用于管理大量服务器、路由器、负载均衡器和网络附加存储（NAS）。它也是软件定义网络（SDN）和道德黑客的主要选择。主要的云服务提供商通过由提供者自己或由他们庞大的Python用户社区编写的库和教程来支持Python。
- en: In this domain, Python scripts automate configuration tasks by issuing commands
    to be carried out by the remote machines, so rarely there are CPU-bound operations
    to be done. Threads or coroutines are well suited for such jobs. In particular,
    the `concurrent.futures` package we’ll see in [Chapter 20](ch20.html#futures_ch)
    can be used to perform the same operations on many remote machines at the same
    time without a lot of complexity.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，Python脚本通过向远程机器发出命令来自动化配置任务，因此很少有需要进行CPU绑定操作。线程或协程非常适合这样的工作。特别是，我们将在[第20章](ch20.html#futures_ch)中看到的`concurrent.futures`包可以用于同时在许多远程机器上执行相同的操作，而不需要太多复杂性。
- en: 'Beyond the standard library, there are popular Python-based projects to manage
    server clusters: tools like [*Ansible*](https://fpy.li/19-30) and [*Salt*](https://fpy.li/19-31),
    as well as libraries like [*Fabric*](https://fpy.li/19-32).'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准库之外，还有一些流行的基于Python的项目用于管理服务器集群：像[*Ansible*](https://fpy.li/19-30)和[*Salt*](https://fpy.li/19-31)这样的工具，以及像[*Fabric*](https://fpy.li/19-32)这样的库。
- en: 'There is also a growing number of libraries for system administration supporting
    coroutines and `asyncio`. In 2016, Facebook’s [Production Engineering team reported](https://fpy.li/19-33):
    “We are increasingly relying on AsyncIO, which was introduced in Python 3.4, and
    seeing huge performance gains as we move codebases away from Python 2.”'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 还有越来越多支持协程和`asyncio`的系统管理库。2016年，Facebook的[生产工程团队报告](https://fpy.li/19-33)：“我们越来越依赖于AsyncIO，这是在Python
    3.4中引入的，并且在将代码库从Python 2迁移时看到了巨大的性能提升。”
- en: Data Science
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学
- en: Data science—including artificial intelligence—and scientific computing are
    very well served by Python. Applications in these fields are compute-intensive,
    but Python users benefit from a vast ecosystem of numeric computing libraries
    written in C, C++, Fortran, Cython, etc.—many of which are able to leverage multicore
    machines, GPUs, and/or distributed parallel computing in heterogeneous clusters.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学—包括人工智能—和科学计算非常适合Python。这些领域的应用程序需要大量计算，但Python用户受益于一个庞大的用C、C++、Fortran、Cython等编写的数值计算库生态系统—其中许多能够利用多核机器、GPU和/或异构集群中的分布式并行计算。
- en: 'As of 2021, Python’s data science ecosystem includes impressive tools such
    as:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2021年，Python的数据科学生态系统包括令人印象深刻的工具，例如：
- en: '[Project Jupyter](https://fpy.li/19-34)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '[Project Jupyter](https://fpy.li/19-34)'
- en: Two browser-based interfaces—Jupyter Notebook and JupyterLab—that allow users
    to run and document analytics code potentially running across the network on remote
    machines. Both are hybrid Python/JavaScript applications, supporting computing
    kernels written in different languages, all integrated via ZeroMQ—an asynchronous
    messaging library for distributed applications. The name *Jupyter* actually comes
    from Julia, Python, and R, the first three languages supported by the Notebook.
    The rich ecosystem built on top of the Jupyter tools include [Bokeh](https://fpy.li/19-35),
    a powerful interactive visualization library that lets users navigate and interact
    with large datasets or continuously updated streaming data, thanks to the performance
    of modern JavaScript engines and browsers.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 两个基于浏览器的界面—Jupyter Notebook和JupyterLab—允许用户在远程机器上运行和记录潜在跨网络运行的分析代码。两者都是混合Python/JavaScript应用程序，支持用不同语言编写的计算内核，通过ZeroMQ集成—一种用于分布式应用的异步消息传递库。*Jupyter*这个名字实际上来自于Julia、Python和R，这三种是Notebook支持的第一批语言。建立在Jupyter工具之上的丰富生态系统包括[Bokeh](https://fpy.li/19-35)，一个强大的交互式可视化库，让用户能够浏览和与大型数据集或持续更新的流数据进行交互，得益于现代JavaScript引擎和浏览器的性能。
- en: '[TensorFlow](https://fpy.li/19-36) and [PyTorch](https://fpy.li/19-37)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '[TensorFlow](https://fpy.li/19-36)和[PyTorch](https://fpy.li/19-37)'
- en: These are the top two deep learning frameworks, according to [O’Reilly’s January
    2021 report](https://fpy.li/19-38) on usage of their learning resources during
    2020. Both projects are written in C++, and are able to leverage multiple cores,
    GPUs, and clusters. They support other languages as well, but Python is their
    main focus and is used by the majority of their users. TensorFlow was created
    and is used internally by Google; PyTorch by Facebook.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[O’Reilly 2021年1月报告](https://fpy.li/19-38)，这是两个顶尖的深度学习框架，根据他们在2020年学习资源使用情况。这两个项目都是用C++编写的，并且能够利用多核、GPU和集群。它们也支持其他语言，但Python是它们的主要关注点，也是大多数用户使用的语言。TensorFlow由Google内部创建和使用；PyTorch由Facebook创建。
- en: '[Dask](https://fpy.li/dask)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dask](https://fpy.li/dask)'
- en: A parallel computing library that can farm out work to local processes or clusters
    of machines, “tested on some of the largest supercomputers in the world”—as their
    [home page](https://fpy.li/dask) states. Dask offers APIs that closely emulate
    NumPy, pandas, and scikit-learn—the most popular libraries in data science and
    machine learning today. Dask can be used from JupyterLab or Jupyter Notebook,
    and leverages Bokeh not only for data visualization but also for an interactive
    dashboard showing the flow of data and computations across the processes/machines
    in near real time. Dask is so impressive that I recommend watching a video such
    as this [15-minute demo](https://fpy.li/19-39) in which Matthew Rocklin—a maintainer
    of the project—shows Dask crunching data on 64 cores distributed in 8 EC2 machines
    on AWS.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 一个并行计算库，可以将工作分配给本地进程或机器集群，“在世界上一些最大的超级计算机上进行了测试”——正如他们的[主页](https://fpy.li/dask)所述。Dask
    提供了紧密模拟 NumPy、pandas 和 scikit-learn 的 API——这些是当今数据科学和机器学习中最流行的库。Dask 可以从 JupyterLab
    或 Jupyter Notebook 中使用，并利用 Bokeh 不仅用于数据可视化，还用于显示数据和计算在进程/机器之间的流动的交互式仪表板，几乎实时地展示。Dask
    如此令人印象深刻，我建议观看像这样的[15分钟演示视频](https://fpy.li/19-39)，其中项目的维护者之一 Matthew Rocklin
    展示了 Dask 在 AWS 上的 8 台 EC2 机器上的 64 个核心上处理数据的情况。
- en: These are only some examples to illustrate how the data science community is
    creating solutions that leverage the best of Python and overcome the limitations
    of the CPython runtime.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是一些例子，说明数据科学界正在创造利用 Python 最佳优势并克服 CPython 运行时限制的解决方案。
- en: Server-Side Web/Mobile Development
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务器端 Web/Mobile 开发
- en: Python is widely used in web applications and for the backend APIs supporting
    mobile applications. How is it that Google, YouTube, Dropbox, Instagram, Quora,
    and Reddit—among others—managed to build Python server-side applications serving
    hundreds of millions of users 24x7? Again, the answer goes way beyond what Python
    provides “out of the box.”
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: Python 在 Web 应用程序和支持移动应用程序的后端 API 中被广泛使用。谷歌、YouTube、Dropbox、Instagram、Quora
    和 Reddit 等公司是如何构建 Python 服务器端应用程序，为数亿用户提供 24x7 服务的？答案远远超出了 Python “开箱即用”提供的范围。
- en: 'Before we discuss tools to support Python at scale, I must quote an admonition
    from the Thoughtworks *Technology Radar*:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论支持 Python 大规模应用的工具之前，我必须引用 Thoughtworks *Technology Radar* 中的一句警告：
- en: '**High performance envy/web scale envy**'
  id: totrans-393
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**高性能嫉妒/Web 规模嫉妒**'
- en: ''
  id: totrans-394
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see many teams run into trouble because they have chosen complex tools, frameworks
    or architectures because they “might need to scale.” Companies such as Twitter
    and Netflix need to support extreme loads and so need these architectures, but
    they also have extremely skilled development teams able to handle the complexity.
    Most situations do not require these kinds of engineering feats; teams should
    keep their *web scale envy* in check in favor of simpler solutions that still
    get the job done.^([20](ch19.html#idm46582389981424))
  id: totrans-395
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到许多团队陷入困境，因为他们选择了复杂的工具、框架或架构，因为他们���可能需要扩展”。像 Twitter 和 Netflix 这样的公司需要支持极端负载，因此需要这些架构，但他们也有极其熟练的开发团队能够处理复杂性。大多数情况并不需要这种工程壮举；团队应该控制他们对*Web
    规模*的嫉妒，而选择简单的解决方案来完成工作[^20]。
- en: At *web scale*, the key is an architecture that allows horizontal scaling. At
    that point, all systems are distributed systems, and no single programming language
    is likely to be the right choice for every part of the solution.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Web 规模*上，关键是允许横向扩展的架构。在那一点上，所有系统都是分布式系统，没有单一的编程语言可能适合解决方案的每个部分。
- en: Distributed systems is a field of academic research, but fortunately some practitioners
    have written accessible books anchored on solid research and practical experience.
    One of them is Martin Kleppmann, the author of *Designing Data-Intensive Applications*
    (O’Reilly).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统是一个学术研究领域，但幸运的是一些从业者已经写了一些基于扎实研究和实践经验的易懂的书籍。其中之一是 Martin Kleppmann，他是《设计数据密集型应用》（O’Reilly）的作者。
- en: 'Consider [Figure 19-3](#one_possible_architecture_fig), the first of many architecture
    diagrams in Kleppmann’s book. Here are some components I’ve seen in Python engagements
    that I worked on or have firsthand knowledge of:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑[Kleppmann 的书中的第 19-3 图](#one_possible_architecture_fig)，这是许多架构图中的第一个。以下是我在参与的
    Python 项目中看到或拥有第一手知识的一些组件：
- en: Application caches:^([21](ch19.html#idm46582389974960)) *memcached*, *Redis*,
    *Varnish*
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序缓存：[^21] *memcached*，*Redis*，*Varnish*
- en: 'Relational databases: *PostgreSQL*, *MySQL*'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关系型数据库：*PostgreSQL*，*MySQL*
- en: 'Document databases: *Apache CouchDB*, *MongoDB*'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档数据库：*Apache CouchDB*，*MongoDB*
- en: 'Full-text indexes: *Elasticsearch*, *Apache Solr*'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全文索引：*Elasticsearch*，*Apache Solr*
- en: 'Message queues: *RabbitMQ*, *Redis*'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息队列：*RabbitMQ*，*Redis*
- en: '![Architecture for data system that combining several components](assets/flpy_1903.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![结合多个组件的数据系统架构](assets/flpy_1903.png)'
- en: Figure 19-3\. One possible architecture for a system combining several components.^([22](ch19.html#idm46582389963696))
  id: totrans-405
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 19-3\. 一个可能的结合多个组件的系统架构[^22]
- en: There are other industrial-strength open source products in each of those categories.
    Major cloud providers also offer their own proprietary alternatives.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个类别中还有其他工业级开源产品。主要云服务提供商也提供了他们自己的专有替代方案。
- en: 'Kleppmann’s diagram is general and language independent—as is his book. For
    Python server-side applications, two specific components are often deployed:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: Kleppmann 的图是通用的，与语言无关——就像他的书一样。对于 Python 服务器端应用程序，通常部署了两个特定组件：
- en: An application server to distribute the load among several instances of the
    Python application. The application server would appear near the top in [Figure 19-3](#one_possible_architecture_fig),
    handling client requests before they reached the application code.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个应用服务器，用于在几个 Python 应用程序实例之间分发负载。应用服务器将出现在[图 19-3](#one_possible_architecture_fig)中的顶部，处理客户端请求，然后再到达应用程序代码。
- en: A task queue built around the message queue on the righthand side of [Figure 19-3](#one_possible_architecture_fig),
    providing a higher-level, easier-to-use API to distribute tasks to processes running
    on other machines.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立在[图 19-3](#one_possible_architecture_fig)右侧的消息队列周围的任务队列，提供了一个更高级、更易于使用的 API，将任务分发给在其他机器上运行的进程。
- en: The next two sections explore these components that are recommended best practices
    in Python server-side deployments.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两节探讨了这些组件，在 Python 服务器端部署中被推荐为最佳实践。
- en: WSGI Application Servers
  id: totrans-411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WSGI 应用程序服务器
- en: WSGI—the [Web Server Gateway Interface](https://fpy.li/pep3333)—is a standard
    API for a Python framework or application to receive requests from an HTTP server
    and send responses to it.^([23](ch19.html#idm46582389951472)) WSGI application
    servers manage one or more processes running your application, maximizing the
    use of the available CPUs.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI——[Web 服务器网关接口](https://fpy.li/pep3333)——是 Python 框架或应用程序接收来自 HTTP 服务器的请求并向其发送响应的标准
    API。^([23](ch19.html#idm46582389951472)) WSGI 应用程序服务器管理一个或多个运行应用程序的进程，最大限度地利用可用的
    CPU。
- en: '[Figure 19-4](#app_server_fig) illustrates a typical WSGI deployment.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 19-4](#app_server_fig) 说明了一个典型的 WSGI 部署。'
- en: Tip
  id: totrans-414
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: If we wanted to merge the previous pair of diagrams, the content of the dashed
    rectangle in [Figure 19-4](#app_server_fig) would replace the solid “Application
    code” rectangle at the top of [Figure 19-3](#one_possible_architecture_fig).
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要合并前面一对图表，[图 19-4](#app_server_fig) 中虚线矩形的内容将取代 [图 19-3](#one_possible_architecture_fig)
    顶部的实线“应用程序代码”矩形。
- en: 'The best-known application servers in Python web projects are:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: Python web 项目中最知名的应用程序服务器有：
- en: '[*mod_wsgi*](https://fpy.li/19-41)'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*mod_wsgi*](https://fpy.li/19-41)'
- en: '[*uWSGI*](https://fpy.li/19-42)^([24](ch19.html#idm46582389942976))'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*uWSGI*](https://fpy.li/19-42)^([24](ch19.html#idm46582389942976))'
- en: '[*Gunicorn*](https://fpy.li/gunicorn)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*Gunicorn*](https://fpy.li/gunicorn)'
- en: '[*NGINX Unit*](https://fpy.li/19-43)'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*NGINX Unit*](https://fpy.li/19-43)'
- en: For users of the Apache HTTP server, *mod_wsgi* is the best option. It’s as
    old as WSGI itself, but is actively maintained, and now provides a command-line
    launcher called `mod_wsgi-express` that makes it easier to configure and more
    suitable for use in Docker containers.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Apache HTTP 服务器的用户，*mod_wsgi* 是最佳选择。它与 WSGI 一样古老，但仍在积极维护��并且现在提供了一个名为 `mod_wsgi-express`
    的命令行启动器，使其更易于配置，并更适合在 Docker 容器中使用。
- en: '![Block diagram showing client connected to HTTP server, connected to application
    server, connected to four Python processes.](assets/flpy_1904.png)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![块图显示客户端连接到 HTTP 服务器，连接到应用程序服务器，连接到四个 Python 进程。](assets/flpy_1904.png)'
- en: Figure 19-4\. Clients connect to an HTTP server that delivers static files and
    routes other requests to the application server, which forks child processes to
    run the application code, leveraging multiple CPU cores. The WSGI API is the glue
    between the application server and the Python application code.
  id: totrans-423
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 19-4\. 客户端连接到一个 HTTP 服务器，该服务器提供静态文件并将其他请求路由到应用程序服务器，后者分叉子进程来运行应用程序代码，利用多个
    CPU 核心。WSGI API 是应用程序服务器和 Python 应用程序代码之间的粘合剂。
- en: '*uWSGI* and *Gunicorn* are the top choices in recent projects I know about.
    Both are often used with the *NGINX* HTTP server. *uWSGI* offers a lot of extra
    functionality, including an application cache, a task queue, cron-like periodic
    tasks, and many other features. On the flip side, *uWSGI* is much harder to configure
    properly than *Gunicorn*.^([25](ch19.html#idm46582389932352))'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '*uWSGI* 和 *Gunicorn* 是我所知道的最近项目中的首选。两者通常与 *NGINX* HTTP 服务器一起使用。*uWSGI* 提供了许多额外功能，包括应用程序缓存、任务队列、类似
    cron 的定期任务以及许多其他功能。然而，与 *Gunicorn* 相比，*uWSGI* 要难以正确配置得多。^([25](ch19.html#idm46582389932352))'
- en: Released in 2018, *NGINX Unit* is a new product from the makers of the well-known
    *NGINX* HTTP server and reverse proxy.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 2018 年发布的 *NGINX Unit* 是著名 *NGINX* HTTP 服务器和反向代理的制造商推出的新产品。
- en: '*mod_wsgi* and *Gunicorn* support Python web apps only, while *uWSGI* and *NGINX
    Unit* work with other languages as well. Please browse their docs to learn more.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '*mod_wsgi* 和 *Gunicorn* 仅支持 Python web 应用程序，而 *uWSGI* 和 *NGINX Unit* 也可以与其他语言一起使用。请浏览它们的文档以了解更多信息。'
- en: 'The main point: all of these application servers can potentially use all CPU
    cores on the server by forking multiple Python processes to run traditional web
    apps written in good old sequential code in *Django*, *Flask*, *Pyramid*, etc.
    This explains why it’s been possible to earn a living as a Python web developer
    without ever studying the `threading`, `multiprocessing`, or `asyncio` modules:
    the application server handles concurrency transparently.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 主要观点：所有这些应用程序服务器都可以通过分叉多个 Python 进程来使用服务器上的所有 CPU 核心，以运行传统的使用旧的顺序代码编写的 Web 应用程序，如
    *Django*、*Flask*、*Pyramid* 等。这就解释了为什么可以作为 Python web 开发人员谋生，而无需学习 `threading`、`multiprocessing`
    或 `asyncio` 模块：应用程序服务器会透明地处理并发。
- en: ASGI—Asynchronous Server Gateway Interface
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ASGI——异步服务器网关接口
- en: WSGI is a synchronous API. It doesn’t support coroutines with `async/await`—the
    most efficient way to implement WebSockets or HTTP long polling in Python. The
    [ASGI specification](https://fpy.li/19-46) is a successor to WSGI, designed for
    asynchronous Python web frameworks such as *aiohttp*, *Sanic*, *FastAPI*, etc.,
    as well as *Django* and *Flask*, which are gradually adding asynchronous functionality.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: WSGI 是一个同步 API。它不支持使用 `async/await` 实现 WebSockets 或 HTTP 长轮询的协程——这是在 Python
    中实现最有效的方法。[ASGI 规范](https://fpy.li/19-46) 是 WSGI 的继任者，专为异步 Python web 框架设计，如 *aiohttp*、*Sanic*、*FastAPI*
    等，以及逐渐添加异步功能的 *Django* 和 *Flask*。
- en: Now let’s turn to another way of bypassing the GIL to achieve higher performance
    with server-side Python applications.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向另一种绕过 GIL 以实现更高性能的服务器端 Python 应用程序的方法。
- en: Distributed Task Queues
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式任务队列
- en: 'When the application server delivers a request to one of the Python processes
    running your code, your app needs to respond quickly: you want the process to
    be available to handle the next request as soon as possible. However, some requests
    demand actions that may take longer—for example, sending email or generating a
    PDF. That’s the problem that distributed task queues are designed to solve.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用服务器将请求传递给运行您代码的 Python 进程之一时，您的应用需要快速响应：您希望进程尽快可用以处理下一个请求。但是，某些请求需要执行可能需要较长时间的操作，例如发送电子邮件或生成
    PDF。这就是分布式任务队列旨在解决的问题。
- en: '[*Celery*](https://fpy.li/19-47) and [*RQ*](https://fpy.li/19-48) are the best
    known open source task queues with Python APIs. Cloud providers also offer their
    own proprietary task queues.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Celery*](https://fpy.li/19-47) 和 [*RQ*](https://fpy.li/19-48) 是最知名的具有 Python
    API 的开源任务队列。云服务提供商也提供他们自己的专有任务队列。'
- en: These products wrap a message queue and offer a high-level API for delegating
    tasks to workers, possibly running on different machines.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这些产品包装了一个消息队列，并提供了一个高级 API，用于将任务委托给工作者，可能在不同的机器上运行。
- en: Note
  id: totrans-435
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In the context of task queues, the words *producer* and *consumer* are used
    instead of traditional client/server terminology. For example, a *Django* view
    handler *produces* job requests, which are put in the queue to be *consumed* by
    one or more PDF rendering processes.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务队列的背景下，使用 *生产者* 和 *消费者* 这两个词，而不是传统的客户端/服务器术语。例如，*Django* 视图处理程序*生成*作业请求，这些请求被放入队列中，以便由一个或多个
    PDF 渲染进程*消耗*。
- en: 'Quoting directly from *Celery*’s [FAQ](https://fpy.li/19-49), here are some
    typical use cases:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 直接引用自 *Celery* 的 [FAQ](https://fpy.li/19-49)，以下是一些典型的用例：
- en: Running something in the background. For example, to finish the web request
    as soon as possible, then update the users page incrementally. This gives the
    user the impression of good performance and “snappiness,” even though the real
    work might actually take some time.
  id: totrans-438
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在后台运行某些东西。例如，尽快完成网页请求，然后逐步更新用户页面。这给用户留下了良好性能和“灵敏度”的印象，即使实际工作可能需要一些时间。
- en: ''
  id: totrans-439
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-440
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Running something after the web request has finished.
  id: totrans-441
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在网页请求完成后运行某些内容。
- en: ''
  id: totrans-442
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-443
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Making sure something is done, by executing it asynchronously and using retries.
  id: totrans-444
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保某事已完成，通过异步执行并使用重试。
- en: ''
  id: totrans-445
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-446
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Scheduling periodic work.
  id: totrans-447
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期调度工作。
- en: 'Besides solving these immediate problems, task queues support horizontal scalability.
    Producers and consumers are decoupled: a producer doesn’t call a consumer, it
    puts a request in a queue. Consumers don’t need to know anything about the producers
    (but the request may include information about the producer, if an acknowledgment
    is required). Crucially, you can easily add more workers to consume tasks as demand
    grows. That’s why *Celery* and *RQ* are called distributed task queues.'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 除了解决这些直接问题外，任务队列还支持水平扩展。生产者和消费者是解耦的：生产者不调用消费者，而是将请求放入队列中。消费者不需要了解生产者的任何信息（但如果需要确认，则请求可能包含有关生产者的信息）。至关重要的是，随着需求增长，您可以轻松地添加更多的工作者来消耗任务。这就是为什么
    *Celery* 和 *RQ* 被称为分布式任务队列。
- en: 'Recall that our simple *procs.py* ([Example 19-13](#primes_procs_top_ex)) used
    two queues: one for job requests, the other for collecting results. The distributed
    architecture of *Celery* and *RQ* uses a similar pattern. Both support using the
    [*Redis*](https://fpy.li/19-50) NoSQL database as a message queue and result storage.
    *Celery* also supports other message queues like *RabbitMQ* or *Amazon SQS*, as
    well other databases for result storage.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们简单的*procs.py*（[示例 19-13](#primes_procs_top_ex)）使用了两个队列：一个用于作业请求，另一个用于收集结果。*Celery*
    和 *RQ* 的分布式架构使用了类似的模式。两者都支持使用 [*Redis*](https://fpy.li/19-50) NoSQL 数据库作为消息队列和结果存储。*Celery*
    还支持其他消息队列，如 *RabbitMQ* 或 *Amazon SQS*，以及其他数据库用于结果存储。
- en: This wraps up our introduction to concurrency in Python. The next two chapters
    will continue this theme, focusing on the `concurrent.futures` and `asyncio` packages
    of the standard library.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对 Python 中并发性的介绍。接下来的两章将继续这个主题，重点关注标准库中的 `concurrent.futures` 和 `asyncio`
    包。
- en: Chapter Summary
  id: totrans-451
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节总结
- en: 'After a bit of theory, this chapter presented the spinner scripts implemented
    in each of Python’s three native concurrency programming models:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一点理论，本章介绍了在 Python 的三种本机并发编程模型中实现的旋转器脚本：
- en: Threads, with the `threading` package
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程，使用 `threading` 包
- en: Processes, with `multiprocessing`
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程，使用 `multiprocessing`
- en: Asynchronous coroutines with `asyncio`
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `asyncio` 进行异步协程
- en: 'We then explored the real impact of the GIL with an experiment: changing the
    spinner examples to compute the primality of a large integer and observe the resulting
    behavior. This demonstrated graphically that CPU-intensive functions must be avoided
    in `asyncio`, as they block the event loop. The threaded version of the experiment
    worked—despite the GIL—because Python periodically interrupts threads, and the
    example used only two threads: one doing compute-intensive work, and the other
    driving the animation only 10 times per second. The `multiprocessing` variant
    worked around the GIL, starting a new process just for the animation, while the
    main process did the primality check.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过一个实验探讨了 GIL 的真正影响：将旋转器示例更改为计算大整数的素性，并观察结果行为。这直观地证明了 CPU 密集型函数必须在 `asyncio`
    中避免，因为它们会阻塞事件循环。尽管 GIL 的存在，线程版本的实验仍然有效，因为 Python 周期性地中断线程，而且示例仅使用了两个线程：一个执行计算密集型工作，另一个每秒仅驱动动画
    10 次。`multiprocessing` 变体绕过了 GIL，为动画启动了一个新进程，而主进程则执行素性检查。
- en: The next example, computing several primes, highlighted the difference between
    `multiprocessing` and `threading`, proving that only processes allow Python to
    benefit from multicore CPUs. Python’s GIL makes threads worse than sequential
    code for heavy computations.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例，计算多个素数，突出了 `multiprocessing` 和 `threading` 之间的区别，证明只有进程才能让 Python 受益于多核
    CPU。Python 的 GIL 使线程比顺序代码更糟糕，用于重型计算。
- en: 'The GIL dominates discussions about concurrent and parallel computing in Python,
    but we should not overestimate its impact. That was the point of [“Python in the
    Multicore World”](#py_in_multicore_world_sec). For example, the GIL doesn’t affect
    many use cases of Python in system administration. On the other hand, the data
    science and server-side development communities have worked around the GIL with
    industrial-strength solutions tailored to their specific needs. The last two sections
    mentioned two common elements to support Python server-side applications at scale:
    WSGI application servers and distributed task queues.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: GIL主导了关于Python并发和并行计算的讨论，但我们不应该过高估计其影响。这就是[“Python在多核世界中的应用”](#py_in_multicore_world_sec)的观点。例如，GIL并不影响Python在系统管理中的许多用例。另一方面，数据科学和服务器端开发社区已经通过针对其特定需求定制的工业级解决方案绕过了GIL。最后两节提到了支持Python服务器端应用程序规模化的两个常见元素：WSGI应用程序服务器和分布式任务队列。
- en: Further Reading
  id: totrans-459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This chapter has an extensive reading list, so I split it into subsections.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有一个广泛的阅读列表，因此我将其分成了子章节。
- en: Concurrency with Threads and Processes
  id: totrans-461
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程和进程并发
- en: The *concurrent.futures* library covered in [Chapter 20](ch20.html#futures_ch)
    uses threads, processes, locks, and queues under the hood, but you won’t see individual
    instances of them; they’re bundled and managed by the higher-level abstractions
    of a `ThreadPoolExecutor` and a `ProcessPoolExecutor`. If you want to learn more
    about the practice of concurrent programming with those low-level objects, [“An
    Intro to Threading in Python”](https://fpy.li/19-51) by Jim Anderson is a good
    first read. Doug Hellmann has a chapter titled “Concurrency with Processes, Threads,
    and Coroutines” on his [website](https://fpy.li/19-52) and book, [*The Python
    3 Standard Library by Example*](https://fpy.li/19-53) (Addison-Wesley).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第20章](ch20.html#futures_ch)中涵盖的*concurrent.futures*库在底层使用线程、进程、锁和队列，但您不会看到它们的单独实例；它们被捆绑并由`ThreadPoolExecutor`和`ProcessPoolExecutor`的更高级抽象管理。如果您想了解更多关于使用这些低级对象进行并发编程的实践，Jim
    Anderson的[“Python中的线程简介”](https://fpy.li/19-51)是一个很好的首次阅读。Doug Hellmann在他的[网站](https://fpy.li/19-52)和书籍[*The
    Python 3 Standard Library by Example*](https://fpy.li/19-53)（Addison-Wesley）中有一章标题为“进程、线程和协程并发”的章节。
- en: Brett Slatkin’s [*Effective Python*](https://fpy.li/effectpy), 2nd ed. (Addison-Wesley),
    David Beazley’s *Python Essential Reference*, 4th ed. (Addison-Wesley), and Martelli
    et al., *Python in a Nutshell*, 3rd ed. (O’Reilly) are other general Python references
    with significant coverage of `threading` and `multiprocessing`. The vast `multiprocessing`
    official documentation includes useful advice in its [“Programming guidelines”
    section](https://fpy.li/19-54).
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: Brett Slatkin的[*Effective Python*](https://fpy.li/effectpy)，第2版（Addison-Wesley），David
    Beazley的*Python Essential Reference*，第4版（Addison-Wesley），以及Martelli等人的*Python
    in a Nutshell*，第3版（O’Reilly）是其他涵盖`threading`和`multiprocessing`的一般Python参考资料。广泛的`multiprocessing`官方文档在其[“编程指南”部分](https://fpy.li/19-54)中包含有用的建议。
- en: Jesse Noller and Richard Oudkerk contributed the `multiprocessing` package,
    introduced in [PEP 371—Addition of the multiprocessing package to the standard
    library](https://fpy.li/pep371). The official documentation for the package is
    a [93 KB *.rst* file](https://fpy.li/19-55)—that’s about 63 pages—making it one
    of the longest chapters in the Python standard library.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: Jesse Noller和Richard Oudkerk贡献了`multiprocessing`包，该包在[PEP 371—将multiprocessing包添加到标准库](https://fpy.li/pep371)中介绍。该包的官方文档是一个93
    KB的*.rst*文件，大约63页，使其成为Python标准库中最长的章节之一。
- en: In [*High Performance Python*, 2nd ed.,](https://fpy.li/19-56) (O’Reilly), authors
    Micha Gorelick and Ian Ozsvald include a chapter about `multiprocessing` with
    an example about checking for primes with a different strategy than our *procs.py*
    example. For each number, they split the range of possible factors—from 2 to `sqrt(n)`—into
    subranges, and make each worker iterate over one of the subranges. Their divide-and-conquer
    approach is typical of scientific computing applications where the datasets are
    huge, and workstations (or clusters) have more CPU cores than users. On a server-side
    system handling requests from many users, it is simpler and more efficient to
    let each process work on one computation from start to finish—reducing the overhead
    of communication and coordination among processes. Besides `multiprocessing`,
    Gorelick and Ozsvald present many other ways of developing and deploying high-performance
    data science applications leveraging multiple cores, GPUs, clusters, profilers,
    and compilers like Cython and Numba. Their last chapter, “Lessons from the Field,”
    is a valuable collection of short case studies contributed by other practitioners
    of high-performance computing in Python.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*High Performance Python*，第2版，](https://fpy.li/19-56)（O’Reilly）中，作者Micha Gorelick和Ian
    Ozsvald包括了一个关于`multiprocessing`的章节，其中包含一个关于使用不同策略检查质数的示例，与我们的*procs.py*示例不同。对于每个数字，他们将可能因子的范围—从2到`sqrt(n)`—分成子范围，并让每个工作进程迭代其中一个子范围。他们的分而治之方法是科学计算应用程序的典型特征，其中数据集庞大，工作站（或集群）拥有比用户更多的CPU核心。在处理来自许多用户的请求的服务器端系统上，让每个进程从头到尾处理一个计算更简单、更有效—减少了进程之间的通信和协调开销。除了`multiprocessing`，Gorelick和Ozsvald还提出了许多其他开发和部署高性能数据科学应用程序的方法，利用多个核心、GPU、集群、性能分析工具和像Cython和Numba这样的编译器。他们的最后一章，“实战经验”，是其他高性能Python计算从业者贡献的短案例的宝贵收集。
- en: '[*Advanced Python Development*](https://fpy.li/19-57) by Matthew Wilkes (Apress),
    is a rare book that includes short examples to explain concepts, while also showing
    how to build a realistic application ready for production: a data aggregator,
    similar to DevOps monitoring systems or IoT data collectors for distributed sensors.
    Two chapters in *Advanced Python Development* cover concurrent programming with
    `threading` and `asyncio`.'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Advanced Python Development*](https://fpy.li/19-57)由Matthew Wilkes（Apress）编写，是一本罕见的书，其中包含简短的示例来解释概念，同时展示如何构建一个准备投入生产的现实应用程序：一个类似于DevOps监控系统或用于分布式传感器的IoT数据收集器的数据聚合器。*Advanced
    Python Development*中的两章涵盖了使用`threading`和`asyncio`进行并发编程。'
- en: Jan Palach’s [*Parallel Programming with Python*](https://fpy.li/19-58) (Packt,
    2014) explains the core concepts behind concurrency and parallelism, covering
    Python’s standard library as well as *Celery*.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: Jan Palach的[*Parallel Programming with Python*](https://fpy.li/19-58)（Packt，2014）解释了并发和并行背后的核心概念，涵盖了Python的标准库以及*Celery*。
- en: '“The Truth About Threads” is the title of Chapter 2 in [*Using Asyncio in Python*](https://fpy.li/hattingh)
    by Caleb Hattingh (O’Reilly).^([26](ch19.html#idm46582389847776)) The chapter
    covers the benefits and drawbacks of threading—with compelling quotes from several
    authoritative sources—making it clear that the fundamental challenges of threads
    have nothing to do with Python or the GIL. Quoting verbatim from page 14 of *Using
    Asyncio in Python*:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: “关于线程的真相”是Caleb Hattingh（O’Reilly）在[*Using Asyncio in Python*](https://fpy.li/hattingh)第2章的标题。该章节涵盖了线程的利弊，其中包括了几位权威来源的引人注目的引用，明确指出线程的基本挑战与Python或GIL无关。引用自*Using
    Asyncio in Python*第14页的原文：
- en: 'These themes repeat throughout:'
  id: totrans-469
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些主题反复出现：
- en: ''
  id: totrans-470
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Threading makes code hard to reason about.
  id: totrans-471
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程使代码难以理解。
- en: ''
  id: totrans-472
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-473
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Threading is an inefficient model for large-scale concurrency (thousands of
    concurrent tasks).
  id: totrans-474
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程是大规模并发（成千上万个并发任务）的一种低效模型。
- en: If you want to learn the hard way how difficult it is to reason about threads
    and locks—without risking your job—try the exercises in Allen Downey’s workbook,
    [*The Little Book of Semaphores*](https://fpy.li/19-59) (Green Tea Press). The
    exercises in Downey’s book range from easy to very hard to unsolvable, but even
    the easy ones are eye-opening.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想通过艰难的方式了解关于线程和锁的推理有多困难——而又不用担心工作——可以尝试Allen Downey的练习册[*The Little Book
    of Semaphores*](https://fpy.li/19-59)（Green Tea Press）。Downey书中的练习从简单到非常困难到无法解决，但即使是简单的练习也会让人大开眼界。
- en: The GIL
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GIL
- en: 'If you are intrigued about the GIL, remember we have no control over it from
    Python code, so the canonical reference is in the C-API documentation: [*Thread
    State and the Global Interpreter Lock*](https://fpy.li/19-60). The *Python Library
    and Extension FAQ* answers: [*“Can’t we get rid of the Global Interpreter Lock?”*](https://fpy.li/19-61).
    Also worth reading are posts by Guido van Rossum and Jesse Noller (contributor
    of the `multiprocessing` package), respectively: [“It isn’t Easy to Remove the
    GIL”](https://fpy.li/19-62) and [“Python Threads and the Global Interpreter Lock”](https://fpy.li/19-63).'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对GIL感兴趣，请记住我们无法从Python代码中控制它，因此权威参考在C-API文档中：[*Thread State and the Global
    Interpreter Lock*](https://fpy.li/19-60)。*Python Library and Extension FAQ*回答了：[*“我们不能摆脱全局解释器锁吗？”*](https://fpy.li/19-61)。值得阅读的还有Guido
    van Rossum和Jesse Noller（`multiprocessing`包的贡献者）的帖子，分别是[“摆脱GIL并不容易”](https://fpy.li/19-62)和[“Python线程和全局解释器锁”](https://fpy.li/19-63)。
- en: '[*CPython Internals*](https://fpy.li/19-64) by Anthony Shaw (Real Python) explains
    the implementation of the CPython 3 interpreter at the C programming level. Shaw’s
    longest chapter is “Parallelism and Concurrency”: a deep dive into Python’s native
    support for threads and processes, including managing the GIL from extensions
    using the C/Python API.'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '[*CPython Internals*](https://fpy.li/19-64)由Anthony Shaw（Real Python）解释了CPython
    3解释器在C编程层面的实现。 Shaw最长的章节是“并行性和并发性”：深入探讨了Python对线程和进程的本机支持，包括使用C/Python API从扩展中管理GIL。'
- en: 'Finally, David Beazley presented a detailed exploration in [“Understanding
    the Python GIL”](https://fpy.li/19-65).^([27](ch19.html#idm46582389832320)) In
    slide #54 of the [presentation](https://fpy.li/19-66), Beazley reports an increase
    in processing time for a particular benchmark with the new GIL algorithm introduced
    in Python 3.2. The issue is not significant with real workloads, according to
    [a comment](https://fpy.li/19-67) by Antoine Pitrou—who implemented the new GIL
    algorithm—in the bug report submitted by Beazley: [Python issue #7946](https://fpy.li/19-68).'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，David Beazley在[“理解Python GIL”](https://fpy.li/19-65)中进行了详细探讨。在[演示文稿](https://fpy.li/19-66)的第54页中，Beazley报告了在Python
    3.2中引入的新GIL算法对特定基准测试处理时间的增加。根据Antoine Pitrou在Beazley提交的错误报告中的[评论](https://fpy.li/19-67)，在真实工作负载中，这个问题并不显著：[Python问题＃7946](https://fpy.li/19-68)。
- en: Concurrency Beyond the Standard Library
  id: totrans-480
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越标准库的并发
- en: '*Fluent Python* focuses on core language features and core parts of the standard
    library. [*Full Stack Python*](https://fpy.li/19-69) is a great complement to
    this book: it’s about Python’s ecosystem, with sections titled “Development Environments,”
    “Data,” “Web Development,” and “DevOps,” among others.'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '*Fluent Python*专注于核心语言特性和标准库的核心部分。[*Full Stack Python*](https://fpy.li/19-69)是这本书的绝佳补充：它涵盖了Python的生态系统，包括“开发环境”，“数据”，“Web开发”和“DevOps”等部分。'
- en: 'I’ve already mentioned two books that cover concurrency using the Python standard
    library that also include significant content on third-party libraries and tools:
    [*High Performance Python*, 2nd ed.](https://fpy.li/19-56) and [*Parallel Programming
    with Python*](https://fpy.li/19-58). Francesco Pierfederici’s [*Distributed Computing
    with Python*](https://fpy.li/19-72) (Packt) covers the standard library and also
    the use of cloud providers and HPC (High-Performance Computing) clusters.'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经提到了两本涵盖使用Python标准库进行并发的书籍，它们还包括了大量关于第三方库和工具的内容：[*High Performance Python*，第2版](https://fpy.li/19-56)和[*Parallel
    Programming with Python*](https://fpy.li/19-58)。Francesco Pierfederici的[*Distributed
    Computing with Python*](https://fpy.li/19-72)（Packt）涵盖了标准库以及云提供商和HPC（高性能计算）集群的使用。
- en: '[“Python, Performance, and GPUs”](https://fpy.li/19-73) by Matthew Rocklin
    is “a status update for using GPU accelerators from Python,” posted in June 2019.'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '[“Python，性能和GPU”](https://fpy.li/19-73)是Matthew Rocklin在2019年6月发布的“关于从Python使用GPU加速器的最新情况”。'
- en: “Instagram currently features the world’s largest deployment of the *Django*
    web framework, which is written entirely in Python.” That’s the opening sentence
    of the blog post, [“Web Service Efficiency at Instagram with Python”](https://fpy.li/19-74),
    written by Min Ni—a software engineer at Instagram. The post describes metrics
    and tools Instagram uses to optimize the efficiency of its Python codebase, as
    well as detect and diagnose performance regressions as it deploys its back end
    “30-50 times a day.”
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: “Instagram目前拥有世界上最大规模的*Django* Web框架部署，完全使用Python编写。”这是Instagram软件工程师Min Ni撰写的博文[“在Instagram中使用Python的Web服务效率”](https://fpy.li/19-74)的开头句。该文章描述了Instagram用于优化其Python代码库效率的指标和工具，以及在每天部署其后端“30-50次”时检测和诊断性能回归。
- en: '[*Architecture Patterns with Python: Enabling Test-Driven Development, Domain-Driven
    Design, and Event-Driven Microservices*](https://fpy.li/19-75) by Harry Percival
    and Bob Gregory (O’Reilly) presents architectural patterns for Python server-side
    applications. The authors also made the book freely available online at [*cosmicpython.com*](https://fpy.li/19-76).'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '由Harry Percival和Bob Gregory（O’Reilly）撰写的[*Architecture Patterns with Python:
    Enabling Test-Driven Development, Domain-Driven Design, and Event-Driven Microservices*](https://fpy.li/19-75)介绍了Python服务器端应用程序的架构模式。作者还在[*cosmicpython.com*](https://fpy.li/19-76)免费提供了这本书的在线版本。'
- en: 'Two elegant and easy-to-use libraries for parallelizing tasks over processes
    are [*lelo*](https://fpy.li/19-77) by João S. O. Bueno and [*python-parallelize*](https://fpy.li/19-78)
    by Nat Pryce. The *lelo* package defines a `@parallel` decorator that you can
    apply to any function to magically make it unblocking: when you call the decorated
    function, its execution is started in another process. Nat Pryce’s *python-parallelize*
    package provides a `parallelize` generator that distributes the execution of a
    `for` loop over multiple CPUs. Both packages are built on the *multiprocessing*
    library.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在进程之间并行执行任务的两个优雅且易于使用的库是由João S. O. Bueno开发的[*lelo*](https://fpy.li/19-77)和由Nat
    Pryce开发的[*python-parallelize*](https://fpy.li/19-78)。*lelo*包定义了一个`@parallel`装饰器，您可以将其应用于任何函数，使其神奇地变为非阻塞：当您调用装饰的函数时，它的执行将在另一个进程中开始。Nat
    Pryce的*python-parallelize*包提供了一个`parallelize`生成器，将`for`循环的执行分布到多个CPU上。这两个包都构建在*multiprocessing*库上。
- en: Python core developer Eric Snow maintains a [Multicore Python](https://fpy.li/19-79)
    wiki, with notes about his and other people’s efforts to improve Python’s support
    for parallel execution. Snow is the author of [PEP 554—Multiple Interpreters in
    the Stdlib](https://fpy.li/pep554). If approved and implemented, PEP 554 lays
    the groundwork for future enhancements that may eventually allow Python to use
    multiple cores without the overheads of *multiprocessing*. One of the biggest
    blockers is the complex interaction between multiple active subinterpreters and
    extensions that assume a single interpreter.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: Python核心开发者Eric Snow维护着一个[Multicore Python](https://fpy.li/19-79)维基，其中记录了他和其他人努力改进Python对并行执行的支持的笔记。Snow是[PEP
    554—Stdlib中的多个解释器](https://fpy.li/pep554)的作者。如果得到批准并实施，PEP 554将为未来的增强奠定基础，最终可能使Python能够在没有*multiprocessing*开销的情况下使用多个核心。其中最大的障碍之一是多个活动子解释器和假定单个解释器的扩展之间的复杂交互。
- en: 'Mark Shannon—also a Python maintainer—created a [useful table](https://fpy.li/19-80)
    comparing concurrent models in Python, referenced in a discussion about subinterpreters
    between him, Eric Snow, and other developers on the [python-dev](https://fpy.li/19-81)
    mailing list. In Shannon’s table, the “Ideal CSP” column refers to the theoretical
    [Communicating sequential processes](https://fpy.li/19-82) model proposed by Tony
    Hoare in 1978. Go also allows shared objects, violating an essential constraint
    of CSP: execution units should communicate through message passing through channels.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: Python维护者Mark Shannon还创建了一个[有用的表格](https://fpy.li/19-80)，比较了Python中的并发模型，在他、Eric
    Snow和其他开发者在[python-dev](https://fpy.li/19-81)邮件列表上讨论子解释器时被引用。在Shannon的表格中，“理想的CSP”列指的是Tony
    Hoare在1978年提出的理论[通信顺序进程](https://fpy.li/19-82)模型。Go也允许共享对象，违反了CSP的一个基本约束：执行单元应通过通道进行消息传递。
- en: '[*Stackless Python*](https://fpy.li/19-83) (a.k.a. *Stackless*) is a fork of
    CPython implementing microthreads, which are application-level lightweight threads—as
    opposed to OS threads. The massively multiplayer online game [*EVE Online*](https://fpy.li/19-84)
    was built on *Stackless*, and engineers employed by the game company [CCP](https://fpy.li/19-85)
    were [maintainers of *Stackless*](https://fpy.li/19-86) for a while. Some features
    of *Stackless* were reimplemented in the [*Pypy*](https://fpy.li/19-87) interpreter
    and the [*greenlet*](https://fpy.li/19-14) package, the core technology of the
    [*gevent*](https://fpy.li/19-17) networking library, which in turn is the foundation
    of the [*Gunicorn*](https://fpy.li/gunicorn) application server.'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Stackless Python*](https://fpy.li/19-83)（又名*Stackless*）是CPython的一个分支，实现了微线程，这些线程是应用级轻量级线程，而不是操作系统线程。大型多人在线游戏[*EVE
    Online*](https://fpy.li/19-84)是基于*Stackless*构建的，游戏公司[CCP](https://fpy.li/19-85)雇用的工程师一度是*Stackless*的[维护者](https://fpy.li/19-86)。*Stackless*的一些特性在[*Pypy*](https://fpy.li/19-87)解释器和[*greenlet*](https://fpy.li/19-14)包中重新实现，后者是[*gevent*](https://fpy.li/19-17)网络库的核心技术，而后者又是[*Gunicorn*](https://fpy.li/gunicorn)应用服务器的基础。'
- en: The actor model of concurrent programming is at the core of the highly scalable
    Erlang and Elixir languages, and is also the model of the Akka framework for Scala
    and Java. If you want to try out the actor model in Python, check out the [*Thespian*](https://fpy.li/19-90)
    and [*Pykka*](https://fpy.li/19-91) libraries.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程的演员模型是高度可扩展的Erlang和Elixir语言的核心，并且也是Scala和Java的Akka框架的模型。如果你想在Python中尝试演员模型，请查看[*Thespian*](https://fpy.li/19-90)和[*Pykka*](https://fpy.li/19-91)库。
- en: My remaining recommendations have few or zero mentions of Python, but are nevertheless
    relevant to readers interested in the theme of this chapter.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 我剩下的推荐几乎没有提到Python，但对于对本章主题感兴趣的读者仍然相关。
- en: Concurrency and Scalability Beyond Python
  id: totrans-492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越Python的并发性和可扩展性
- en: '[*RabbitMQ in Action*](https://fpy.li/19-92) by Alvaro Videla and Jason J.
    W. Williams (Manning) is a very well-written introduction to *RabbitMQ* and the
    Advanced Message Queuing Protocol (AMQP) standard, with examples in Python, PHP,
    and Ruby. Regardless of the rest of your tech stack, and even if you plan to use
    *Celery* with *RabbitMQ* under the hood, I recommend this book for its coverage
    of concepts, motivation, and patterns for distributed message queues, as well
    as operating and tuning *RabbitMQ* at scale.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: Alvaro Videla 和 Jason J. W. Williams（Manning）的[*RabbitMQ 实战*](https://fpy.li/19-92)是一本非常精心编写的介绍
    *RabbitMQ* 和高级消息队列协议（AMQP）标准的书籍，其中包含 Python、PHP 和 Ruby 的示例。无论您的技术堆栈的其余部分如何，即使您计划在幕后使用
    *Celery* 与 *RabbitMQ*，我也推荐这本书，因为它涵盖了分布式消息队列的概念、动机和模式，以及在规模上操作和调整 *RabbitMQ*。
- en: I learned a lot reading [*Seven Concurrency Models in Seven Weeks*](https://fpy.li/19-93),
    by Paul Butcher (Pragmatic Bookshelf), with the eloquent subtitle *When Threads
    Unravel*. Chapter 1 of the book presents the core concepts and challenges of programming
    with threads and locks in Java.^([28](ch19.html#idm46582389786976)) The remaining
    six chapters of the book are devoted to what the author considers better alternatives
    for concurrent and parallel programming, as supported by different languages,
    tools, and libraries. The examples use Java, Clojure, Elixir, and C (for the chapter
    about parallel programming with the [OpenCL framework](https://fpy.li/19-94)).
    The CSP model is exemplified with Clojure code, although the Go language deserves
    credit for popularizing that approach. Elixir is the language of the examples
    illustrating the actor model. A freely available, alternative [bonus chapter](https://fpy.li/19-95)
    about actors uses Scala and the Akka framework. Unless you already know Scala,
    Elixir is a more accessible language to learn and experiment with the actor model
    and the Erlang/OTP distributed systems platform.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读 Paul Butcher（Pragmatic Bookshelf）的[*七周七并发模型*](https://fpy.li/19-93)让我受益匪浅，书中有着优美的副标题*当线程解开*。该书的第一章介绍了使用
    Java 中的线程和锁编程的核心概念和挑战。该书的其余六章致力于作者认为更好的并发和并行编程的替代方案，支持不同的语言、工具和库。示例使用了 Java、Clojure、Elixir
    和 C（用于关于使用[OpenCL 框架](https://fpy.li/19-94)进行并行编程的章节）。CSP 模型以 Clojure 代码为例，尽管
    Go 语言值得赞扬，因为它推广了这种方法。Elixir 是用于说明 actor 模型的示例的语言。一个免费提供的[额外章节](https://fpy.li/19-95)关于
    actor 使用 Scala 和 Akka 框架。除非您已经了解 Scala，否则 Elixir 是一个更易于学习和实验 actor 模型和 Erlang/OTP
    分布式系统平台的语言。
- en: Unmesh Joshi of Thoughtworks has contributed several pages documenting “Patterns
    of Distributed Systems” to Martin Fowler’s [blog](https://fpy.li/19-96). The [opening
    page](https://fpy.li/19-97) is a great introduction the topic, with links to individual
    patterns. Joshi is adding patterns incrementally, but what’s already there distills
    years of hard-earned experience in mission-critical systems.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: Thoughtworks 的 Unmesh Joshi 为 Martin Fowler 的[博客](https://fpy.li/19-96)贡献了几页关于“分布式系统模式”的文档。[开篇页面](https://fpy.li/19-97)是该主题的绝佳介绍，附有各个模式的链接。Joshi
    正在逐步添加模式，但已有的内容蕴含了在关键任务系统中多年辛苦积累的经验。
- en: Martin Kleppmann’s [*Designing Data-Intensive Applications*](https://fpy.li/19-98)
    (O’Reilly) is a rare book written by a practitioner with deep industry experience
    and advanced academic background. The author worked with large-scale data infrastructure
    at LinkedIn and two startups, before becoming a researcher of distributed systems
    at the University of Cambridge. Each chapter in Kleppmann’s book ends with an
    extensive list of references, including recent research results. The book also
    includes numerous illuminating diagrams and beautiful concept maps.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: Martin Kleppmann 的[*设计数据密集型应用*](https://fpy.li/19-98)（O'Reilly��是一本罕见的由具有深厚行业经验和高级学术背景的从业者撰写的书籍。作者在领英和两家初创公司的大规模数据基础设施上工作，然后成为剑桥大学分布式系统研究员。Kleppmann
    的每一章都以大量参考文献结尾，包括最新的研究结果。该书还包括许多启发性的图表和精美的概念地图。
- en: 'I was fortunate to be in the audience for Francesco Cesarini’s outstanding
    workshop on the architecture of reliable distributed systems at OSCON 2016: “Designing
    and architecting for scalability with Erlang/OTP” ([video](https://fpy.li/19-99)
    at the O’Reilly Learning Platform). Despite the title, 9:35 into the video, Cesarini
    explains:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 我很幸运能够参加 Francesco Cesarini 在 OSCON 2016 上关于可靠分布式系统架构的出色研讨会：“使用 Erlang/OTP 进行可扩展性设计和架构”（在
    O'Reilly 学习平台上的[视频](https://fpy.li/19-99)）。尽管标题如此，视频中的 9:35 处，Cesarini 解释道：
- en: Very little of what I am going to say will be Erlang-specific […]. The fact
    remains that Erlang will remove a lot of accidental difficulties to making systems
    which are resilient and which never fail, and are scalable. So it will be much
    easier if you do use Erlang, or a language running on the Erlang virtual machine.
  id: totrans-498
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我即将说的内容很少会是特定于 Erlang 的[...]. 事实仍然是，Erlang 将消除许多制约系统具有弹性、永不失败且可扩展性的偶发困难。因此，如果您使用
    Erlang 或在 Erlang 虚拟机上运行的语言，将会更容易。
- en: That workshop was based on the last four chapters of [*Designing for Scalability
    with Erlang/OTP*](https://fpy.li/19-100) by Francesco Cesarini and Steve Vinoski
    (O’Reilly).
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 那个研讨会基于 Francesco Cesarini 和 Steve Vinoski（O'Reilly）的[*使用 Erlang/OTP 进行可扩展性设计*](https://fpy.li/19-100)的最后四章。
- en: Programming distributed systems is challenging and exciting, but beware of [*web-scale
    envy*](https://fpy.li/19-40). The [KISS principle](https://fpy.li/19-102) remains
    solid engineering advice.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 编写分布式系统具有挑战性和令人兴奋，但要小心[*web-scale envy*](https://fpy.li/19-40)。[KISS 原则](https://fpy.li/19-102)仍然是可靠的工程建议。
- en: Check out the paper [“Scalability! But at what COST?”](https://fpy.li/19-103)
    by Frank McSherry, Michael Isard, and Derek G. Murray. The authors identified
    parallel graph-processing systems presented in academic symposia that require
    hundreds of cores to outperform a “competent single-threaded implementation.”
    They also found systems that “underperform one thread for all of their reported
    configurations.”
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Frank McSherry、Michael Isard和Derek G. Murray撰写的论文[“可扩展性！但以什么代价？”](https://fpy.li/19-103)。作者们在学术研讨会中发现了需要数百个核心才能胜过“胜任的单线程实现”的并行图处理系统。他们还发现了“在所有报告的配置中都不如一个线程表现”的系统。
- en: 'Those findings remind me of a classic hacker quip:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 这些发现让我想起了一个经典的黑客警句：
- en: My Perl script is faster than your Hadoop cluster.
  id: totrans-503
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的Perl脚本比你的Hadoop集群更快。
- en: ^([1](ch19.html#idm46582393037920-marker)) Slide 8 of the talk [“Concurrency
    Is Not Parallelism”](https://fpy.li/19-1).
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch19.html#idm46582393037920-marker)) 演讲[“并发不等于并行”](https://fpy.li/19-1)的第8张幻灯片。
- en: '^([2](ch19.html#idm46582393034960-marker)) I studied and worked with Prof.
    Imre Simon, who liked to say there are two major sins in science: using different
    words to mean the same thing and using one word to mean different things. Imre
    Simon (1943–2009) was a pioneer of computer science in Brazil who made seminal
    contributions to Automata Theory and started the field of Tropical Mathematics.
    He was also an advocate of free software and free culture.'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch19.html#idm46582393034960-marker)) 我曾与Imre Simon教授一起学习和工作，他喜欢说科学中有两个主要的罪过：用不同的词来表示同一件事和用一个词表示不同的事物。Imre
    Simon（1943-2009）是巴西计算机科学的先驱，对自动机理论做出了重要贡献，并开创了热带数学领域。他还是自由软件和自由文化的倡导者。
- en: ^([3](ch19.html#idm46582393018064-marker)) This section was suggested by my
    friend Bruce Eckel—author of books about Kotlin, Scala, Java, and C++.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch19.html#idm46582393018064-marker)) 这一部分是由我的朋友Bruce Eckel提出的，他是有关Kotlin、Scala、Java和C++的书籍的作者。
- en: ^([4](ch19.html#idm46582392964240-marker)) Call [`sys.getswitchinterval()`](https://fpy.li/19-3)
    to get the interval; change it with [`sys.setswitchinterval(s)`](https://fpy.li/19-4).
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch19.html#idm46582392964240-marker)) 调用[`sys.getswitchinterval()`](https://fpy.li/19-3)以获取间隔；使用[`sys.setswitchinterval(s)`](https://fpy.li/19-4)来更改它。
- en: ^([5](ch19.html#idm46582392959952-marker)) A syscall is a call from user code
    to a function of the operating system kernel. I/O, timers, and locks are some
    of the kernel services available through syscalls. To learn more, read the Wikipedia
    [“System call” article](https://fpy.li/19-5).
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch19.html#idm46582392959952-marker)) 系统调用是用户代码调用操作系统内核函数的一种方式。I/O、定时器和锁是通过系统调用提供的一些内核服务。要了解更多，请阅读维基百科的[“系统调用”文章](https://fpy.li/19-5)。
- en: ^([6](ch19.html#idm46582392957152-marker)) The `zlib` and `bz2` modules are
    specifically mentioned in a [python-dev message by Antoine Pitrou](https://fpy.li/19-6),
    who contributed the time-slicing GIL logic to Python 3.2.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch19.html#idm46582392957152-marker)) `zlib`和`bz2`模块在[Antoine Pitrou的python-dev消息](https://fpy.li/19-6)中被特别提到，他为Python
    3.2贡献了时间切片GIL逻辑。
- en: '^([7](ch19.html#idm46582392951088-marker)) Source: slide 106 of Beazley’s [“Generators:
    The Final Frontier” tutorial](https://fpy.li/19-7).'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch19.html#idm46582392951088-marker)) 来源：Beazley的[“生成器：最终领域”教程](https://fpy.li/19-7)第106页幻灯片。
- en: '^([8](ch19.html#idm46582392946960-marker)) Source: last paragraph of the [“Thread
    objects” section](https://fpy.li/19-8).'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch19.html#idm46582392946960-marker)) 来源：[“线程对象”���分](https://fpy.li/19-8)的最后一段。
- en: ^([9](ch19.html#idm46582392926960-marker)) Unicode has lots of characters useful
    for simple animations, like the [Braille patterns](https://fpy.li/19-11) for example.
    I used the ASCII characters `"\|/-"` to keep the examples simple.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch19.html#idm46582392926960-marker)) Unicode有许多对简单动画有用的字符，比如[盲文图案](https://fpy.li/19-11)。我使用ASCII字符`"\|/-"`来保持示例简单。
- en: ^([10](ch19.html#idm46582392270416-marker)) The semaphore is a fundamental building
    block that can be used to implement other synchronization mechanisms. Python provides
    different semaphore classes for use with threads, processes, and coroutines. We’ll
    see `asyncio.Semaphore` in [“Using asyncio.as_completed and a Thread”](ch21.html#using_as_completed_sec)
    ([Chapter 21](ch21.html#async_ch)).
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch19.html#idm46582392270416-marker)) 信号量是一个基本构件，可用于实现其他同步机制。Python提供了不同的信号量类，用于线程、进程和协程。我们将在[“使用asyncio.as_completed和一个线程”](ch21.html#using_as_completed_sec)中看到`asyncio.Semaphore`（[第21章](ch21.html#async_ch)）。
- en: ^([11](ch19.html#idm46582391660752-marker)) Thanks to tech reviewers Caleb Hattingh
    and Jürgen Gmach who did not let me overlook *greenlet* and *gevent*.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch19.html#idm46582391660752-marker)) 感谢技术评论家Caleb Hattingh和Jürgen Gmach，他们让我没有忽视*greenlet*和*gevent*。
- en: ^([12](ch19.html#idm46582391425184-marker)) It’s a 15” MacBook Pro 2018 with
    a 6-core, 2.2 GHz Intel Core i7 CPU.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch19.html#idm46582391425184-marker)) 这是一台配备有6核、2.2 GHz英特尔酷睿i7处理器的15英寸MacBook
    Pro 2018。
- en: '^([13](ch19.html#idm46582391326528-marker)) This is true today because you
    are probably using a modern OS with *preemptive multitasking*. Windows before
    the NT era and macOS before the OSX era were not “preemptive,” therefore any process
    could take over 100% of the CPU and freeze the whole system. We are not completely
    free of this kind of problem today but trust this graybeard: this troubled every
    user in the 1990s, and a hard reset was the only cure.'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch19.html#idm46582391326528-marker)) 今天这是真实的，因为你可能正在使用具有*抢占式多任务*的现代操作系统。NT时代之前的Windows和OSX时代之前的macOS都不是“抢占式”的，因此任何进程都可以占用100%的CPU并冻结整个系统。今天我们并没有完全摆脱这种问题，但请相信这位老者：这在20世纪90年代困扰着每个用户，硬重置是唯一的解决方法。
- en: ^([14](ch19.html#idm46582390464160-marker)) In this example, `0` is a convenient
    sentinel. `None` is also commonly used for that. Using `0` simplifies the type
    hint for `PrimeResult` and the code for `worker`.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch19.html#idm46582390464160-marker)) 在这个例子中，`0`是一个方便的标记。`None`也经常用于这个目的。使用`0`简化了`PrimeResult`的类型提示和`worker`的代码。
- en: ^([15](ch19.html#idm46582390432784-marker)) Surviving serialization without
    losing our identity is a pretty good life goal.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch19.html#idm46582390432784-marker)) 在不失去我们身份的情况下幸存下来是一个相当不错的人生目标。
- en: ^([16](ch19.html#idm46582390056752-marker)) See [*19-concurrency/primes/threads.py*](https://fpy.li/19-27)
    in the [*Fluent Python* code repository](https://fpy.li/code).
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch19.html#idm46582390056752-marker)) 请查看[*Fluent Python*代码库](https://fpy.li/code)中的[*19-concurrency/primes/threads.py*](https://fpy.li/19-27)。
- en: ^([17](ch19.html#idm46582390033840-marker)) To learn more, see [“Context switch”](https://fpy.li/19-28)
    in the English Wikipedia.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch19.html#idm46582390033840-marker)) 要了解更多，请参阅英文维基百科中的[“上下文切换”](https://fpy.li/19-28)。
- en: ^([18](ch19.html#idm46582390019472-marker)) These are probably the same reasons
    that prompted the creator of the Ruby language, Yukihiro Matsumoto, to use a GIL
    in his interpreter as well.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch19.html#idm46582390019472-marker)) 这可能是促使Ruby语言创始人松本行弘（Yukihiro Matsumoto）在他的解释器中使用GIL的相同原因。
- en: ^([19](ch19.html#idm46582390017680-marker)) As an exercise in college, I had
    to implement the LZW compression algorithm in C. But first I wrote it in Python,
    to check my understanding of the spec. The C version was about 900× faster.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch19.html#idm46582390017680-marker)) 在大学的一个练习中，我不得不用C实现LZW压缩算法。但我先用Python写了它，以检查我对规范的理解。C版本大约快了900倍。
- en: '^([20](ch19.html#idm46582389981424-marker)) Source: Thoughtworks Technology
    Advisory Board, [*Technology Radar*—November 2015](https://fpy.li/19-40).'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch19.html#idm46582389981424-marker)) 来源：Thoughtworks技术咨询委员会，《技术雷达》—2015年11月。
- en: ^([21](ch19.html#idm46582389974960-marker)) Contrast application caches—used
    directly by your application code—with HTTP caches, which would be placed on the
    top edge of [Figure 19-3](#one_possible_architecture_fig) to serve static assets
    like images, CSS, and JS files. Content Delivery Networks (CDNs) offer another
    type of HTTP cache, deployed in data centers closer to the end users of your application.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch19.html#idm46582389974960-marker)) 对比应用程序缓存—直接被应用程序代码使用—与HTTP缓存，它们将放置在[图19-3](#one_possible_architecture_fig)的顶部边缘，用于提供静态资产如图像、CSS和JS文件。内容交付网络（CDN）提供另一种类型的HTTP缓存，部署在更接近应用程序最终用户的数据中心。
- en: ^([22](ch19.html#idm46582389963696-marker)) Diagram adapted from Figure 1-1,
    *Designing Data-Intensive Applications* by Martin Kleppmann (O’Reilly).
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch19.html#idm46582389963696-marker)) 图表改编自马丁·克莱普曼（O'Reilly）的《数据密集型应用设计》第1-1图。
- en: ^([23](ch19.html#idm46582389951472-marker)) Some speakers spell out the WSGI
    acronym, while others pronounce it as one word rhyming with “whisky.”
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch19.html#idm46582389951472-marker)) 一些演讲者拼写WSGI首字母缩写，而其他人则将其发音为一个与“whisky”押韵的单词。
- en: ^([24](ch19.html#idm46582389942976-marker)) *uWSGI* is spelled with a lowercase
    “u,” but that is pronounced as the Greek letter “µ,” so the whole name sounds
    like “micro-whisky” with a “g” instead of the “k.”
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch19.html#idm46582389942976-marker)) *uWSGI*的拼写中“u”是小写的，但发音为希腊字母“µ”，因此整个名称听起来像“micro-whisky”，但“k”换成“g”。
- en: ^([25](ch19.html#idm46582389932352-marker)) Bloomberg engineers Peter Sperl
    and Ben Green wrote [“Configuring uWSGI for Production Deployment”](https://fpy.li/19-44),
    explaining how many of the default settings in *uWSGI* are not suitable for many
    common deployment scenarios. Sperl presented a summary of their recommendations
    at [EuroPython 2019](https://fpy.li/19-45). Highly recommended for users of *uWSGI*.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch19.html#idm46582389932352-marker)) 彼得·斯佩尔（Peter Sperl）和本·格林（Ben Green）撰写了[“为生产部署配置uWSGI”](https://fpy.li/19-44)，解释了*uWSGI*中许多默认设置对许多常见部署场景都不适用。斯佩尔在[2019年EuroPython](https://fpy.li/19-45)上介绍了他们建议的摘要。强烈推荐给*uWSGI*的用户。
- en: ^([26](ch19.html#idm46582389847776-marker)) Caleb is one of the tech reviewers
    for this edition of *Fluent Python*.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch19.html#idm46582389847776-marker)) 卡勒布（Caleb）是*Fluent Python*本版的技术审查员之一。
- en: ^([27](ch19.html#idm46582389832320-marker)) Thanks to Lucas Brunialti for sending
    me a link to this talk.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: ^([27](ch19.html#idm46582389832320-marker)) 感谢卢卡斯·布鲁尼亚尔蒂（Lucas Brunialti）给我发送了这个演讲链接。
- en: ^([28](ch19.html#idm46582389786976-marker)) Python’s `threading` and `concurrent.futures`
    APIs are heavily influenced by the Java standard library.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: ^([28](ch19.html#idm46582389786976-marker)) Python的`threading`和`concurrent.futures`
    API受到Java标准库的重大影响。
- en: '^([29](ch19.html#idm46582389748064-marker)) The Erlang community uses the term
    “process” for actors. In Erlang, each process is a function in its own loop, so
    they are very lightweight and it’s feasible to have millions of them active at
    once in a single machine—no relation to the heavyweight OS processes we’ve been
    talking about elsewhere in this chapter. So here we have examples of the two sins
    described by Prof. Simon: using different words to mean the same thing, and using
    one word to mean different things.'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: ^([29](ch19.html#idm46582389748064-marker)) Erlang社区将“进程”一词用于actors。在Erlang中，每个进程都是自己循环中的一个函数，因此它们非常轻量级，可以在单台机器上同时激活数百万个进程，与本章其他地方讨论的重量级操作系统进程没有关系。所以这里我们有教授西蒙描述的两种罪行的例子：使用不同的词来表示相同的事物，以及使用一个词来表示不同的事物。
