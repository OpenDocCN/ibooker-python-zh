["```py\nfrom numba import cuda, float32\n\n# CUDA kernel\n@cuda.jit\ndef mul_two(io_array):\n    pos = cuda.grid(1)\n    if pos < io_array.size:\n        io_array[pos] *= 2 # do the computation\n\n@ray.remote\ndef remote_mul(input_array):\n    # This implicitly transfers the array into the GPU and back, which is not free\n    return mul_two(input_array)\n```", "```py\n# Request a full GPU, like CPUs we can request fractional\n@ray.remote(num_gpus=1)\ndef do_serious_work():\n# Restart entire worker after each call\n@ray.remote(num_gpus=1, max_calls=1)\ndef do_serious_work():\n```", "```py\nimagePullSecrets: []\n# In practice you _might_ want an official Ray image\n# but this is for a bleeding-edge mixed arch cluster,\n# which still is not fully supported by Ray's official\n# wheels & containers.\nimage: holdenk/ray-ray:nightly\noperatorImage: holdenk/ray-ray:nightly\npodTypes:\n  rayGPUWorkerType:\n    memory: 10Gi\n    maxWorkers: 4\n    minWorkers: 1\n# Normally you'd ask for a GPU but NV auto labeler is...funky on ARM\n    CPU: 1\n    rayResources:\n      CPU: 1\n      GPU: 1\n      memory: 1000000000\n    nodeSelector:\n      node.kubernetes.io/gpu: gpu\n  rayWorkerType:\n    memory: 10Gi\n    maxWorkers: 4\n    minWorkers: 1\n    CPU: 1\n  rayHeadType:\n    memory: 3Gi\n    CPU: 1\n```", "```py\n# Function that requests a GPU\n@ray.remote(num_gpus=1)\ndef do_i_have_gpus():\n    return True\n\n# Give it at most 4 minutes to see if we can get a GPU\n# We want to give the autoscaler some time to see if it can spin up\n# a GPU node for us.\nfutures = [do_i_have_gpus.remote()]\nready_futures, rest_futures = ray.wait(futures, timeout=240)\n\nresources = {\"num_cpus\": 1}\n# If we have a ready future, we have a GPU node in our cluster\nif ready_futures:\n    resources[\"num_gpus\"] =1\n\n# \"splat\" the resources\n@ray.remote(** resources)\ndef optional_gpu_task():\n```"]