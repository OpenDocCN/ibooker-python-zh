- en: Chapter 16\. Image Processing and Text Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From Google’s self-driving cars to vending machines that recognize counterfeit
    currency, machine vision is a huge field with far-reaching goals and implications.
    This chapter focuses on one small aspect of the field: text recognition—specifically,
    how to recognize and use text-based images found online by using a variety of
    Python libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: Using an image in lieu of text is a common technique when you don’t want text
    to be found and read by bots. This is often seen on contact forms when an email
    address is partially or completely rendered as an image. Depending on how skillfully
    it is done, it might not even be noticeable to human viewers, but bots have a
    difficult time reading these images, and the technique is enough to stop most
    spammers from acquiring your email address.
  prefs: []
  type: TYPE_NORMAL
- en: CAPTCHAs, of course, take advantage of the fact that users can read security
    images but most bots can’t. Some CAPTCHAs are more difficult than others, an issue
    we’ll tackle later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: But CAPTCHAs aren’t the only place on the web where scrapers need image-to-text
    translation assistance. Even to, many documents are scanned from hard copies and
    put on the web, making these documents inaccessible as far as much of the internet
    is concerned, although they are “hiding in plain sight.” Without image-to-text
    capabilities, the only way to make these documents accessible is for a human to
    type them up by hand—and nobody has time for that.
  prefs: []
  type: TYPE_NORMAL
- en: Translating images into text is called *optical character recognition*, or *OCR*.
    A few major libraries can perform OCR, and many other libraries support them or
    are built on top of them. This system of libraries can get fairly complicated,
    so I recommend you read the next section before attempting any of the exercises
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: All example images used throughout this chapter can be found in the GitHub repository
    folder *Chapter16_ImageProcessingFiles*. For the sake of brevity, all in-text
    code samples will refer to this directory simply as *files*.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Python is a fantastic language for image processing and reading, image-based
    machine-learning, and even image creation. Although many libraries can be used
    for image processing, I’ll focus on two: Pillow and Tesseract.'
  prefs: []
  type: TYPE_NORMAL
- en: These two libraries make for a powerful complementary duo when it comes to processing
    and doing OCR on images from around the web. *Pillow* performs the first pass,
    cleaning and filtering images, and *Tesseract* attempts to match the shapes found
    in those images to its library of known text.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter covers their installation and basic usage, along with several examples
    of this library duo working together. I’ll also cover some advanced Tesseract
    training, so that you can train Tesseract to OCR additional fonts and languages
    (or even CAPTCHAs) that you might encounter on the web.
  prefs: []
  type: TYPE_NORMAL
- en: Pillow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although Pillow might not be the most fully featured image-processing library,
    it has all the features you are likely to need and then some—unless you plan to
    rewrite Photoshop in Python, in which case you’re reading the wrong book! Pillow
    also has the advantage of being one of the better-documented third-party libraries
    and is extremely easy to use out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: 'Forked off the Python Imaging Library (PIL) for Python 2.x, Pillow adds support
    for Python 3.x. Like its predecessor, Pillow allows you to easily import and manipulate
    images with a variety of filters, masks, and even pixel-specific transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the image *kitten.jpg* will open in your default image
    viewer with a blur added to it and will also be saved in its blurrier state as
    *kitten_blurred.jpg* in the same directory.
  prefs: []
  type: TYPE_NORMAL
- en: You will use Pillow to perform preprocessing on images to make them more machine
    readable, but as mentioned before, you can do many other things with the library
    aside from these simple filter applications. For more information, check out the
    [Pillow documentation](http://pillow.readthedocs.org).
  prefs: []
  type: TYPE_NORMAL
- en: Tesseract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tesseract is an OCR library. Sponsored by Google (a company obviously well-known
    for its OCR and machine-learning technologies), Tesseract is widely regarded to
    be the best, most accurate, open source OCR system available.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to being accurate, it is also extremely flexible. It can be trained
    to recognize any number of fonts (as long as those fonts are relatively consistent
    within themselves, as you will see soon). It also can be expanded to recognize
    any Unicode character.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter uses both the command-line program *Tesseract* along with its third-party
    Python wrapper *pytesseract*. Both will be explicitly named as one of these two,
    so know that when you see Tesseract, I’m referring to the command-line software,
    and when you see pytesseract, I’m specifically referring to its third-party Python
    wrapper.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Tesseract
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For Windows users, there is a convenient [executable installer](https://code.google.com/p/tesseract-ocr/downloads/list). As
    of this writing, the current version is 3.02, although newer versions should be
    fine as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linux users can install Tesseract with `apt-get`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Installing Tesseract on a Mac is slightly more complicated, although it can
    be done easily with many third-party installers, such as [Homebrew](http://brew.sh),
    which was used in [Chapter 9](ch09.html#c-9) to install MySQL. For example, you
    can install Homebrew and use it to install Tesseract in two lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Tesseract also can be installed from the source, on the [project’s download
    page](https://code.google.com/p/tesseract-ocr/downloads/list).
  prefs: []
  type: TYPE_NORMAL
- en: 'To convert images to text, Tesseract uses machine learning models that have
    been trained on large datasets in various languages (or sets of characters). To
    view the available models that come with your installation, use the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This will print the directory where the models are stored (*/usr/local/share*
    on Linux, and */opt/homebrew/share/tessdata/* on a Mac installed with HomeBrew)
    and the models that are available.
  prefs: []
  type: TYPE_NORMAL
- en: After Tesseract is installed, you’re ready to install the Python wrapper library,
    pytesseract, which uses your existing Tesseract installation to read image files
    and output strings and objects that can be used in Python scripts.
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, you can install pytesseract via pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Pytesseract can be used in conjunction with PIL to read text from images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If pytesseract does not recognize that you have Tesseract installed, you can
    get the location of your Tesseract installation using the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'and, in Python, point pytesseract to the location by including this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Pytesseract has several useful features in addition to returning the OCR results
    of an image as in the code sample above. It can estimate box files (pixel locations
    for the boundaries of each character):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'It can also return a complete output of all data, such as confidence scores,
    page and line numbers, box data, as well as other information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The default output for these last two files is as space- or tab-delimited string
    files, but you can also get output as dictionaries or (if decoding in UTF-8 isn’t
    sufficient) byte strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This chapter uses a combination of the pytesseract library, as well as command-line
    Tesseract and triggering Tesseract from Python via the `subprocess` library. Although
    the pytesseract library is useful and convenient, there are some Tesseract functions
    it cannot do, so it’s good to be familiar with all methods.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While NumPy is not required for straightforward OCR, you will need it if you
    want to train Tesseract to recognize additional character sets or fonts introduced
    later in this chapter. You will also be using it for simple math tasks (such as
    weighted averages) in some of the code samples later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy is a powerful library used for linear algebra and other large-scale math
    applications. NumPy works well with Tesseract because of its ability to mathematically
    represent and manipulate images as large arrays of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy can be installed using any third-party Python installer such as pip, or
    by [downloading the package](https://pypi.python.org/pypi/numpy) and installing
    with `$ python setup.py install`.
  prefs: []
  type: TYPE_NORMAL
- en: Even if you don’t plan on running any of the code samples that use it, I highly
    recommend installing it or adding it to your Python arsenal. It serves to round
    out Python’s built-in math library and has many useful features, particularly
    for operations with lists of numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'By convention, NumPy is imported as `np` and can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This example prints the standard deviation and mean of the set of numbers provided
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: Processing Well-Formatted Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With any luck, most of the text that you’ll need to process will be relatively
    clean and well formatted. Well-formatted text generally meets several requirements,
    although the line between what is “messy” and what is “well formatted” can be
    subjective.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, well-formatted text:'
  prefs: []
  type: TYPE_NORMAL
- en: Is written in one standard font (excluding handwriting fonts, cursive fonts,
    or excessively decorative fonts)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If copied or photographed, has extremely crisp lines, with no copying artifacts
    or dark spots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is well aligned, without slanted letters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not run off the image, nor is there cut-off text or margins on the edges
    of the image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of these things can be fixed in preprocessing. For instance, images can
    be converted to grayscale, brightness and contrast can be adjusted, and the image
    can be cropped and rotated as needed. However, some fundamental limitations might
    require more extensive training. See [“Reading CAPTCHAs and Training Tesseract”](#reading_caps_train_tesser).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 16-1](#tesseract_tiff) is an ideal example of well-formatted text.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Alt Text](assets/wsp3_1601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-1\. Sample text saved as a .tiff file, to be read by Tesseract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the *files* directory, you can run Tesseract from the command line to read
    this file and write the results to a text file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output contains the contents of the newly created *textoutput.txt* file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the results are mostly accurate, although it added an extra
    pipe character between the `!` and the `@`. On the whole, though, this lets you
    read the text fairly comfortably.
  prefs: []
  type: TYPE_NORMAL
- en: After blurring the image text, creating some JPG compression artifacts, and
    adding a slight background gradient, the Tesseract’s results get much worse (see
    [Figure 16-2](#bad_jpg)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Alt Text](assets/wsp3_1602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-2\. Unfortunately, many of the documents you will encounter on the
    internet will look more like this than the previous example
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Rather than write the results to a file, you can also pass a dash character
    (`-`) where the filename would normally be, and Tesseract will echo the results
    to the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Tesseract is not able to deal with this image nearly as well mainly because
    of the background gradient and produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the text is cut off as soon as the background gradient makes the
    text more difficult to distinguish, and that the last character from each line
    is wrong, as Tesseract tries futilely to make sense of it. In addition, the JPG
    artifacts and blurring make it difficult for Tesseract to distinguish between
    a lowercase *i* and an uppercase *I* and the number *1*.
  prefs: []
  type: TYPE_NORMAL
- en: This is where using a Python script to clean your images first comes in handy.
    Using the Pillow library, you can create a threshold filter to get rid of the
    gray in the background, bring out the text, and make the image clearer for Tesseract
    to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, instead of using Tesseract from the command line, you can use
    the pytesseract library to run the Tesseract commands and read the resulting file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The resulting image, automatically created as *text_cleaned.png*, is shown in
    [Figure 16-3](#better_image).
  prefs: []
  type: TYPE_NORMAL
- en: '![Alt Text](assets/wsp3_1603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-3\. This image was created by passing the previous “messy” version
    of the image through a threshold filter
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Apart from some barely legible or missing punctuation, the text is readable,
    at least to us. Tesseract gives it its best shot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The periods and commas, being extremely small, are the first victims of this
    image wrangling and nearly disappear, both from our view and Tesseract’s. There’s
    also the unfortunate misinterpretation of “Arial” as “Anal,” the result of Tesseract
    interpreting the *r* and the *i* as the single character *n*.
  prefs: []
  type: TYPE_NORMAL
- en: Still, it’s an improvement over the previous version, in which nearly half of
    the text was cut off.
  prefs: []
  type: TYPE_NORMAL
- en: Tesseract’s greatest weakness seems to be backgrounds with varying brightness.
    Tesseract’s algorithms attempt to adjust the contrast of the image automatically
    before reading the text, but you can probably get better results doing this yourself
    with a tool like the Pillow library.
  prefs: []
  type: TYPE_NORMAL
- en: Images you should definitely fix before submitting to Tesseract are those that
    are tilted, have large areas of nontext, or have other problems.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting Images Automatically
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous example, the value 143 was chosen experimentally as the “ideal”
    threshold to adjust all image pixels to black or white, in order for Tesseract
    to read the image. But what if you have many images, all with slightly different
    grayscale problems, and aren’t reasonably able to go and adjust all of them by
    hand?
  prefs: []
  type: TYPE_NORMAL
- en: One way to find the best solution (or at least, a pretty good one) is to run
    Tesseract against a range of images adjusted to different values and algorithmically
    choose the one with the best result, as measured by some combination of the number
    of characters and/or strings Tesseract is able to read, and the “confidence” with
    which it reads those characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Which algorithm you use, exactly, may vary slightly from application to application,
    but this is one example of iterating through image-processing thresholds to find
    the “best” setting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This script has two functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cleanFile`'
  prefs: []
  type: TYPE_NORMAL
- en: Takes in an original “bad” file and a threshold variable to run the PIL threshold
    tool with. It processes the file and returns the PIL image object.
  prefs: []
  type: TYPE_NORMAL
- en: '`getConfidence`'
  prefs: []
  type: TYPE_NORMAL
- en: Takes in the cleaned PIL image object and runs it through Tesseract. It calculates
    the average confidence of each recognized string (weighted by the number of characters
    in that string), as well as the number of recognized characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'By varying the threshold value and getting the confidence and number of recognized
    characters at each value, you get the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: There is a clear trend among both the average confidence in the result, as well
    as the number of characters recognized. Both tend to peak around a threshold of
    145, which is close to the manually found “ideal” result of 143.
  prefs: []
  type: TYPE_NORMAL
- en: Thresholds of both 140 and 145 give the maximum number of recognized characters
    (83), but a threshold of 145 gives the highest confidence for those found characters,
    so you may want to go with that result and return the text that was recognized
    at that threshold as the “best guess” for what text the image contains.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, simply finding the “most” characters does not necessarily mean that
    all of those characters are real. At some thresholds, Tesseract could split single
    characters into multiple ones, or interpret random noise in the image as a text
    character that doesn’t actually exist. In this case, you may want to rely more
    heavily on the average confidence of each score.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you find results that read (in part):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: it would probably be a no-brainer to go with the result that gives you over
    a 20% increase in confidence, with only a one-character loss, and assume that
    the result with a threshold of 145 was simply incorrect, or perhaps split a character
    or found something that wasn’t there.
  prefs: []
  type: TYPE_NORMAL
- en: This is the part where some up-front experimentation to perfect your threshold
    selection algorithm may come in handy. For instance, you may want to select the
    score for which the *product* of the confidence and the number of characters is
    maximized (in this case, 145 still wins with a product of 6272, and in our imaginary
    example, the threshold 150 would win with a product of 7964) or some other metric.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this type of selection algorithm also works with arbitrary PIL tool
    values besides just `threshold`. You also can use it to select two or more values
    by varying the values of each and similarly selecting the best resulting score.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this type of selection algorithm is computationally intensive. You’re
    running both PIL and Tesseract many times on every single image, whereas if you
    know the “ideal” threshold values ahead of time, you have to run them only once.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that, as you start to work with the images you’re processing, you
    may start to notice patterns in the “ideal” values found. Instead of trying every
    threshold from 80 to 200, you may realistically need to try only thresholds from
    130 to 180.
  prefs: []
  type: TYPE_NORMAL
- en: You may even take another approach and choose thresholds that are, say, 20 apart
    on the first pass, and then use a greedy algorithm to hone in on the best result
    by decreasing your step size for thresholds between the “best” solutions found
    in the previous iteration. This may also work best when you’re dealing with multiple
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: Scraping Text from Images on Websites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using Tesseract to read text from an image on your hard drive might not seem
    all that exciting, but it can be a powerful tool when used with a web scraper.
    Images can inadvertently obfuscate text on websites (as with the JPG copy of a
    menu on a local restaurant site), but they can also purposefully hide the text,
    as I’ll show in the next example.
  prefs: []
  type: TYPE_NORMAL
- en: Although Amazon’s *robots.txt* file allows scraping of the site’s product pages,
    book previews typically don’t get picked up by passing bots. That’s because the
    book previews are loaded via user-triggered Ajax scripts, and the images are carefully
    hidden in layers of divs and an iframe. Of course, even if you could get to the
    images, there’s the not-so-small matter of reading them as text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following script accomplishes just this feat: it navigates to the large-print
    edition of Tolstoy’s *The Death of Ivan Ilyich*, opens the reader, collects image
    URLs, and then systematically downloads, reads, and prints the text from each
    one.'
  prefs: []
  type: TYPE_NORMAL
- en: Picking a Test Subject
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to processing fonts it hasn’t been trained on, Tesseract fares
    much better with large-format editions of books, especially if the images are
    small. The next section covers how to train Tesseract on different fonts, which
    can help it read much smaller font sizes, including previews for non-large-print
    book editions!
  prefs: []
  type: TYPE_NORMAL
- en: Note that this code depends on a live Amazon listing as well as several architectural
    features of the Amazon website to run correctly. If this listing goes down or
    is replaced, please fill free to substitute the URL of another book with a Preview
    feature (I find that large print, sans serif fonts work well).
  prefs: []
  type: TYPE_NORMAL
- en: 'Because this is relatively complex code that draws on multiple concepts from
    previous chapters, I’ve added comments throughout to make it a little easier to
    understand what’s going on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Although this script can, in theory, be run with any type of Selenium webdriver,
    I’ve found that it currently works most reliably with Chrome.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you have experienced with the Tesseract reader before, this prints many
    long passages of the book mostly legibly, as seen in the preview of the first
    chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The large print and sans serif font makes for a flawless transcription of the
    images. In cases where errors in the transcription might occur, they can be fixed
    by making guesses based on a dictionary word list (perhaps with additions based
    on relevant proper nouns like “Melvinski”).
  prefs: []
  type: TYPE_NORMAL
- en: 'Occasionally, an error may span an entire word, such as on page three of the
    text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this case the word “I” is replaced by the character “1.” A Markov chain analysis
    might be useful here, in addition to a word dictionary. If any part of the text
    contains an extremely uncommon phrase (“and not 1”), it might be assumed that
    the text was actually the more common phrase (“and not I”).
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, it helps that these character substitutions follow predictable patterns:
    “vi” becomes “w,” and “I” becomes “1.” If these substitutions occur frequently
    in your text, you might create a list of them that can be used to “try” new words
    and phrases, selecting the solution that makes the most sense. An approach might
    be to substitute frequently confused characters, and use a solution that matches
    a word in a dictionary, or is a recognized (or most common) n-gram.'
  prefs: []
  type: TYPE_NORMAL
- en: If you do take this approach, be sure to read [Chapter 12](ch12.html#c-12) for
    more information about working with text and natural language processing.
  prefs: []
  type: TYPE_NORMAL
- en: Although the text in this example is a common sans serif font and Tesseract
    should be able to recognize it with relative ease, sometimes a little retraining
    helps improve the accuracy as well. The next section discusses another approach
    to solving the problem of mangled text with a little up-front time investment.
  prefs: []
  type: TYPE_NORMAL
- en: By providing Tesseract with a large collection of text images with known values,
    Tesseract can be “taught” to recognize the same font in the future with far greater
    precision and accuracy, even despite occasional background and positioning problems
    in the text.
  prefs: []
  type: TYPE_NORMAL
- en: Reading CAPTCHAs and Training Tesseract
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although the word *CAPTCHA* is familiar to most, far fewer people know what
    it stands for: *Completely Automated Public Turing Test to Tell Computers and
    Humans Apart*. Its unwieldy acronym hints at its rather unwieldy role in obstructing
    otherwise perfectly usable web interfaces, as both humans and nonhuman robots
    often struggle to solve CAPTCHA tests.'
  prefs: []
  type: TYPE_NORMAL
- en: The Turing test was first described by Alan Turing in his 1950 paper, “Computing
    Machinery and Intelligence.” In the paper, he described a theoretical scenario
    in which a human being could communicate with both humans and artificial intelligence
    programs through a computer terminal. If the human was unable to distinguish the
    humans from the AI programs during a casual conversation, the AI programs would
    be considered to have passed the Turing test. The artificial intelligence, Turing
    reasoned, would be genuinely “thinking” for all intents and purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Seventy years after the theoretical inception of Turing tests, today CAPTCHAs
    are primarily used to infuriate humans rather than machines. In 2017, Google shut
    down its iconic  reCAPTCHA due in large part to its tendency to block legitimate
    website users.^([1](ch16.html#id831))  (See [Figure 16-4](#fig-16-4) for an example.)
    Many other companies followed suit, replacing the traditional text-based CAPTCHAs
    with alternative bot blockers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-4\. Text from Google reCAPTCHA, prior to 2017
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Although CAPTCHAs have declined somewhat in popularity, they are still commonly
    used, especially on smaller sites. They are also useful as a source of sample
    “difficult” text for a computer to read. Perhaps your goal is not solving CAPTCHAs
    but reading badly scanned PDFs or handwritten notes. The principles are the same.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, I’ve created a form that robots are “blocked” from submitting
    because it requires solving a CAPTCHA: [*https://pythonscraping.com/humans-only/*](https://pythonscraping.com/humans-only/).
    In this section, you will train the Tesseract library on its specific font and
    text variations in order to solve this CAPTCHA with high reliability.
  prefs: []
  type: TYPE_NORMAL
- en: In case you are a robot and have trouble reading this image, “U8DG” is the solution
    to the CAPTCHA in [Figure 16-5](#fig-16-5). Tesseract, being a robot, certainly
    has trouble solving it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-5\. The bot-proof captcha at [*https://pythonscraping.com/humans-only/*](https://pythonscraping.com/humans-only/)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In this case, Tesseract returns five characters (including a space) and gets
    only one of the characters, the uppercase D, correctly.
  prefs: []
  type: TYPE_NORMAL
- en: The issue isn’t that Tesseract is bad at reading text, or that this CAPTCHA
    is too difficult for a computer to comprehend—it’s that this particular handwriting
    font is dissimilar to the regular English-language fonts that Tesseract has been
    trained on “out of the box.” Fortunately, it is possible to train it to recognize
    additional fonts, characters, and languages.
  prefs: []
  type: TYPE_NORMAL
- en: Training Tesseract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Whether you’re training for CAPTCHAs or any other text, there are a few factors
    to consider that greatly impact Tesseract’s performance and the approach you might
    take for training it:'
  prefs: []
  type: TYPE_NORMAL
- en: Do characters overlap in the image, or can you draw a neat rectangle around
    each character without parts of any other character infringing on this rectangle?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there multiple variations of the font or style of writing or is only a single
    font used?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any background images, lines, or other distracting garbage in the
    image?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there high contrast with clear boundaries between the characters and the
    background?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the font a fairly standard serif or sans serif font, or is it an unusual
    font with random elements and perhaps a “handwriting” style?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is some overlap of the characters in some of the text samples, you
    might consider using only text samples where no overlap occurs. If overlap occurs
    in every text sample, consider preprocessing to separate characters before training.
  prefs: []
  type: TYPE_NORMAL
- en: Scraping and preparing images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Preprocessing helps remove any background junk and improves the color, contrast,
    and separation of characters in images.
  prefs: []
  type: TYPE_NORMAL
- en: How Many Images Do You Need?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How many images should you obtain? I recommend about 10 examples per character,
    or more if there is high variation or randomness in your text. Tesseract does
    occasionally discard files as being unreadable, for having overlapping boxes,
    or for other arcane reasons, so you may want some buffer room on top of that. If
    you find that your OCR results aren’t quite as good as you’d like, or Tesseract
    is stumbling over certain characters, it’s a good debugging step to create additional
    training data and try again.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, if there are multiple variations of fonts in the same text sample
    or if there are other variations involved (randomly tilted or obfuscated text),
    you may need more training data.
  prefs: []
  type: TYPE_NORMAL
- en: If the font is fairly standard and there are no other severe complicating factors,
    make sure you’ve tried Tesseract without additional training first! The performance
    without training may be acceptable for your needs, and training can be a very
    time-consuming process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training requires giving Tesseract at least a few examples of each character
    you want it to be able to recognize. The following downloads 100 sample CAPTCHA
    images, each containing four characters, for a total of 400 character samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'After reviewing the downloaded training images, it’s time to decide what sort
    of preprocessing, if any, needs to be done. The images in this CAPTCHA have gray
    text on a black background. You can write a `cleanImage` function that transforms
    this into black text on a white background and adds a white border to make sure
    each character has separation from the edge of the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Creating box files with the Tesseract trainer project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, you need to use these cleaned images to create *box files*. A box file
    contains each character in the image on its own line, followed by the bounding
    box coordinates for that character. For example, a CAPTCHA image with the characters
    “AK6F” might have the corresponding box file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'I’ve created a project at [*https://github.com/REMitchell/tesseract-trainer*](https://github.com/REMitchell/tesseract-trainer) that
    contains, among other things, a web app that assists in creating these box files.
    To create box files using this project, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Rename each CAPTCHA image to its solution. For example, the image containing
    “AK6F” would be renamed to “AK6F.png.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Tesseract trainer project, open the file *createBoxes.html* in the web
    browser of your choice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the “Add a new file” link and select the multiple image files that you
    renamed in step 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The web app will automatically generate boxes based on the image’s name. Drag
    these boxes around their corresponding character, as shown in [Figure 16-6](#1606).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you are happy with the placement of the boxes, click “Download .box” to
    download the box file, and the next image should appear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](assets/wsp3_1606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16-6\. Creating box files using the Tesseract trainer tool
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As an optional step, I recommend putting on a good podcast or TV show, because
    it’s going to be a couple of hours of boring work. Exactly how long depends on
    how many boxes you need to draw.
  prefs: []
  type: TYPE_NORMAL
- en: The next step after creating your box files is to show off all your hard work
    to Tesseract and let it get training. The end goal of this process is to create
    a *traineddata* file that you can add to your Tesseract language directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Tesseract trainer project at [*https://github.com/REMitchell/tesseract-trainer*](https://github.com/REMitchell/tesseract-trainer),
    I’ve included a file called trainer.py. This script expects a *data* directory
    in the project root with the directories *cleaned* and *box* under it:'
  prefs: []
  type: TYPE_NORMAL
- en: '*data*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*cleaned*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CAPTCHA images with any preprocessing and cleaning done, with the filenames
    matching the box files
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*box*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Box files, as downloaded from the web app
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: After creating your folders of *.box* files and image files, copy this data
    into a backup folder before doing any further manipulation on it. Although running
    training scripts over the data is unlikely to delete anything, it’s better safe
    than sorry when hours worth of work put into *.box* file creation are involved.
  prefs: []
  type: TYPE_NORMAL
- en: Training Tesseract from box files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Performing the data analysis and creating the training files required for Tesseract
    involves many steps involves many steps. The *trainer.py* file does all of them
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'The initial settings and steps that this program takes can be seen in the `__init__`
    and `runAll` methods of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'At the bottom of *trainer.py* a new `TesseractTrainer` instance is created
    and the runAll method is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The three attributes passed into the `TesseractTrainer` object are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`languageName`'
  prefs: []
  type: TYPE_NORMAL
- en: The three-letter language code that Tesseract uses to keep track of languages.
    For specific training scenarios, I prefer to create a new language rather than
    combine it or use it to replace Tesseract’s pre-trained English data.
  prefs: []
  type: TYPE_NORMAL
- en: '`fontName`'
  prefs: []
  type: TYPE_NORMAL
- en: The name for your chosen font. This can be anything, but it must be a single
    word without spaces. In practice, this is just for internal purposes during training,
    and you’re unlikely to see it or need to reference it.
  prefs: []
  type: TYPE_NORMAL
- en: '`directory`'
  prefs: []
  type: TYPE_NORMAL
- en: The directory name containing the directories of your cleaned images and box
    files. By default, this is data. If you have multiple projects, you can pass in
    a unique data directory name for each project to keep everything organized.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some of the individual methods used.
  prefs: []
  type: TYPE_NORMAL
- en: '`createDirectories` does some initial housekeeping and creates subdirectories
    such as the *exp* directory, which will later store the trained files.'
  prefs: []
  type: TYPE_NORMAL
- en: '`createFontProperties` creates a required file, *font_properties*, that lets
    Tesseract know about the new font you are creating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This file consists of the name of the font, followed by 1s and 0s indicating
    whether italic, bold, or other versions of the font should be considered. Training
    fonts with these properties is an interesting exercise but unfortunately outside
    the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`renameFiles` renames all your *.box* files and their corresponding image files
    with the names required by Tesseract (the file numbers here are sequential digits
    to keep multiple files separate):'
  prefs: []
  type: TYPE_NORMAL
- en: '*<languageName>.<fontName>.exp<fileNumber>.box*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*<languageName>.<fontName>.exp<fileNumber>.tiff*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`extractUnicode` looks at all of the created *.box* files and determines the
    total set of characters available to be trained. The resulting Unicode file will
    tell you how many different characters you’ve found and could be a good way to
    quickly see if you’re missing anything.'
  prefs: []
  type: TYPE_NORMAL
- en: The next three functions, `runShapeClustering`, `runMfTraining`, and `runCtTraining`, create
    the files `shapetable`, `pfftable`, and `normproto`, respectively. These all provide
    information about the geometry and shape of each character, as well as provide
    statistical information that Tesseract uses to calculate the probability that
    a given character is one type or another.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Tesseract renames each of the compiled data folders to be prepended
    by the required language name (e.g., *shapetable* is renamed to *cap.shapetable*)
    and compiles all of those files into the final training data file *cap.traineddata*.
  prefs: []
  type: TYPE_NORMAL
- en: Using traineddata files with Tesseract
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *traineddata* file is the main output of this entire process. This file
    tells Tesseract how to identify characters in the training dataset you’ve given
    it. To use the file, you need to move it to your *tessdata* root folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find this folder using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This will provide some output like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Then set the `TESSDATA_PREFIX` environment variable to this directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, move your new *traineddata* file to the *languages* directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'After the new *traineddata* file is in place, Tesseract should recognize it
    automatically as a new language and be able to solve new CAPTCHAs it’s presented
    with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Success! A significant improvement over the previous interpretation of the image
    as `u& DS`.
  prefs: []
  type: TYPE_NORMAL
- en: This is just a quick overview of the full power of Tesseract’s font training
    and recognition capabilities. If you are interested in extensively training Tesseract,
    perhaps starting your own library of CAPTCHA training files, or sharing new font
    recognition capabilities with the world, I recommend checking out the [documentation](https://github.com/tesseract-ocr/tesseract).
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving CAPTCHAs and Submitting Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many popular content management systems are frequently spammed with registrations
    by bots that are preprogrammed with the well-known location of these user registration
    pages. On [*http://pythonscraping.com*](http://pythonscraping.com), for instance,
    even a CAPTCHA (admittedly, weak) does little to put a damper on the influx of
    registrations.
  prefs: []
  type: TYPE_NORMAL
- en: So how do these bots do it? You’ve successfully solved CAPTCHAs in images sitting
    around on your hard drive, but how do you make a fully functioning bot? This section
    ties together many techniques covered in previous chapters. If you haven’t already,
    you should at least skim [Chapter 13](ch13.html#c-13).
  prefs: []
  type: TYPE_NORMAL
- en: 'Most image-based CAPTCHAs have several properties:'
  prefs: []
  type: TYPE_NORMAL
- en: They are dynamically generated images, created by a server-side program. They
    might have image sources that do not look like traditional images, such as `<img
    src="WebForm.aspx?id=8AP85CQKE9TJ">`, but can be downloaded and manipulated like
    any other image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The solution to the image is stored in a server-side database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many CAPTCHAs time out if you take too long to solve them. This usually isn’t
    a problem for bots, but queuing CAPTCHA solutions for later use, or other practices
    that may delay the time between when the CAPTCHA was requested and when the solution
    is submitted, may not be successful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The general approach to this is to download the CAPTCHA image file to your hard
    drive, clean it, use Tesseract to parse the image, and return the solution under
    the appropriate form parameter.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve created a page at [*http://pythonscraping.com/humans-only*](http://pythonscraping.com/humans-only) with
    a CAPTCHA-protected comment form for the purpose of writing a bot to defeat. This
    bot uses the command-line Tesseract library, rather than the pytesseract wrapper,
    although either could be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, load the page and find the location of a hidden token that needs
    to be POSTed with the rest of the form data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This hidden token also happens to be the filename of the CAPTCHA image presented
    on the page, which makes writing the `getCaptchaSolution` function relatively
    straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that this script will fail under two conditions: if Tesseract did not
    extract exactly four characters from the image (because we know that all valid
    solutions to this CAPTCHA must have four characters), or if it submits the form
    but the CAPTCHA was solved incorrectly.'
  prefs: []
  type: TYPE_NORMAL
- en: In the first case, you can reload the page and try again, likely with no penalty
    from the web server. In the second case, the server might take note that you’re
    solving CAPTCHAs incorrectly and penalize you. Many servers, on multiple failed
    CAPTCHA attempts, will block the user or subject them to more rigorous screening.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, as the owner of this particular server I can attest to the fact that
    it’s extremely forgiving and unlikely to block you!
  prefs: []
  type: TYPE_NORMAL
- en: 'The form data itself is relatively lengthy and can be viewed in full in the
    GitHub repository or in your browser’s network inspector tools when submitting
    the form yourself. Checking the length of the CAPTCHA solution and submitting
    it using the Requests library is fairly straightforward, however:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If the CAPTCHA solution was correct (and it usually is), you should expect
    to see something like the following printed out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: While CAPTCHAs are not as common as they were 10 or 20 years ago, they are still
    used by many sites, and knowing how to handle them is important. In addition,
    the skills gained by working with CAPTCHA solving easily translate to other image-to-text
    scenarios you may encounter.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch16.html#id831-marker)) See Rhett Jones, “Google Has Finally Killed the
    CAPTCHA,” Gizmodo, March 11, 2017, [*https://gizmodo.com/google-has-finally-killed-the-captcha-1793190374*](https://gizmodo.com/google-has-finally-killed-the-captcha-1793190374).
  prefs: []
  type: TYPE_NORMAL
