- en: Chapter 10\. How Ray Powers Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。Ray如何驱动机器学习
- en: You now have a solid grasp of everything in Ray needed to get your data ready
    to train ML models. In this chapter, you will learn how to use the popular Ray
    libraries [scikit-learn](https://oreil.ly/2a56M), [XGBoost](https://oreil.ly/TAofd),
    and [PyTorch](https://oreil.ly/ziXhR). This chapter is not intended to introduce
    these libraries, so if you aren’t familiar with any of them, you should pick one
    (and we suggest scikit-learn) to read up on first. Even for those familiar with
    these libraries, refreshing your memory by consulting your favorite tools’ documentation
    will be beneficial. This chapter is about how Ray is used to power ML, rather
    than a tutorial on ML.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经牢固掌握了Ray中为准备数据以训练ML模型所需的一切。在本章中，您将学习如何使用流行的Ray库[scikit-learn](https://oreil.ly/2a56M)、[XGBoost](https://oreil.ly/TAofd)和[PyTorch](https://oreil.ly/ziXhR)。本章不旨在介绍这些库，因此如果您对其中任何一个不熟悉，建议首先选择一个（我们建议选择scikit-learn）进行阅读。即使对这些库熟悉的人也可以通过查阅自己喜欢的工具文档来刷新记忆。本章关注的是Ray如何用于驱动ML，而不是ML的教程。
- en: Note
  id: totrans-2
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you are interested in going deeper into ML with Ray, [*Learning Ray*](https://oreil.ly/k5ItW)
    by Max Pumperla et al. (O’Reilly) is a full-length book focused on ML with Ray
    that can expand your ML skillset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣深入学习Ray中的ML，[*学习Ray*](https://oreil.ly/k5ItW)由Max Pumperla等人（O’Reilly）撰写的全长书籍专注于ML与Ray，可以扩展您的ML技能组。
- en: Ray has two built-in libraries for ML. You will learn how to use Ray’s reinforcement
    learning library, [RLlib](https://oreil.ly/3Rv0B), with TensorFlow and use generic
    hyperparameter tuning via [Tune](https://oreil.ly/9ISlc), which can be used with
    any ML library.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Ray有两个内置的ML库。您将学习如何使用Ray的增强学习库[RLlib](https://oreil.ly/3Rv0B)，与TensorFlow一起使用，并通过[Tune](https://oreil.ly/9ISlc)进行通用超参数调整，可以与任何ML库一起使用。
- en: Using scikit-learn with Ray
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn与Ray
- en: scikit-learn is one of the most widely used tools in the ML community, offering
    dozens of easy-to-use ML algorithms. It was initially developed by David Cournapeau
    as a Google Summer of Code project in 2007\. It provides a wide range of supervised
    and unsupervised learning algorithms via a consistent interface.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn是ML社区中使用最广泛的工具之一，提供数十种易于使用的ML算法。它最初由David Cournapeau在2007年作为Google夏季代码项目开发。通过一致的接口提供广泛的监督和无监督学习算法。
- en: 'The scikit-learn ML algorithms include the following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn ML算法包括以下内容：
- en: Clustering
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类
- en: For grouping unlabeled data such as k-means
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 用于对未标记数据进行分组，如k均值
- en: Supervised models
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 监督模型
- en: Including generalized linear models, discriminant analysis, naive Bayes, lazy
    methods, neural networks, support vector machines, and decision trees
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 包括广义线性模型、判别分析、朴素贝叶斯、惰性方法、神经网络、支持向量机和决策树等
- en: Ensemble methods
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法
- en: For combining the predictions of multiple supervised models
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 用于组合多个监督模型的预测
- en: 'scikit-learn also contains important tooling to support ML:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn还包含重要的工具支持ML：
- en: Cross-validation
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证
- en: For estimating the performance of supervised models on unseen data
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估监督模型在未见数据上的表现
- en: Datasets
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集
- en: For test datasets and for generating datasets with specific properties for investigating
    model behavior
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用于测试数据集和生成具有特定属性的数据集，以研究模型行为
- en: Dimensionality reduction
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 维度减少
- en: For reducing the number of attributes in data for summarization, visualization,
    and feature selection such as principal component analysis
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 用于减少数据中属性数量，以进行总结、可视化和特征选择，例如主成分分析
- en: Feature extraction
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取
- en: For defining attributes in image and text data
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 用于定义图像和文本数据的属性
- en: Feature selection
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择
- en: For identifying meaningful attributes from which to create supervised models
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用于识别用于创建监督模型的有意义的属性
- en: Parameter tuning
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 参数调整
- en: For getting the most out of supervised models
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用监督模型
- en: Manifold learning
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 流形学习
- en: For summarizing and depicting complex multidimensional data
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 用于总结和描绘复杂的多维数据
- en: Although you can use most of the scikit-learn APIs directly with Ray for tuning
    the model’s hyperparameters, things get a bit more involved when you want to parallelize
    execution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以直接在Ray中使用大多数scikit-learn API来调整模型的超参数，但当您想要并行执行时情况会变得有些复杂。
- en: If we take the basic code used for the creation of the model in [Chapter 7](ch07.html#ch07),
    and try to optimize parameters for the decision tree, our code will look like
    [Example 10-1](#skex).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用用于创建模型的基本代码来优化决策树的参数，我们的代码将如[示例 10-1](#skex)所示。
- en: Example 10-1\. [Using scikit-learn to build our wine-quality model](https://oreil.ly/z1KPe)
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-1\. [使用scikit-learn构建我们的葡萄酒质量模型](https://oreil.ly/z1KPe)
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that here, in `GridSearchCV`, we are using the parameter `n_jobs=-1`, which
    instructs the implementation to run model evaluation in parallel using all available
    processors.^([1](ch10.html#idm45354765564752)) Running model evaluation in parallel,
    even on a single machine, can result in an order-of-magnitude performance improvement.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`GridSearchCV`中，我们使用参数`n_jobs=-1`，这会让实现在所有可用处理器上并行运行模型评估。^([1](ch10.html#idm45354765564752))
    即使在单机上并行运行模型评估也可以显著提高性能一个数量级。
- en: Unfortunately, this does not work out of the box with Ray clusters. `GridSearchCV`
    uses [Joblib](https://oreil.ly/s9x0Y) for parallel execution (as do many other
    scikit-learn algorithms). Joblib does not work with Ray out of the box.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这在Ray集群中并不能直接使用。`GridSearchCV`使用[Joblib](https://oreil.ly/s9x0Y)进行并行执行（和许多其他scikit-learn算法一样）。但是Joblib不能直接与Ray兼容。
- en: Ray [implements a backend for Joblib](https://oreil.ly/80Dwb) with a Ray actors
    pool (see [Chapter 4](ch04.html#ch04)) instead of local processes. This allows
    you to simply change the Joblib backend to switch scikit-learn from using local
    processes to Ray.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Ray [实现了一个Joblib后端](https://oreil.ly/80Dwb)，采用Ray actors池（见[第 4 章](ch04.html#ch04)），而不是本地进程。这允许你简单地将Joblib后端更改为使用Ray，从而使scikit-learn从使用本地进程切换到Ray。
- en: Concretely, to make [Example 10-1](#skex) run using Ray, you need to register
    the Ray backend for Joblib and use it for the `GridSearchCV` execution, as in
    [Example 10-2](#skex_joblib).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，要使[示例 10-1](#skex)在Ray上运行，你需要注册Ray的Joblib后端，并在`GridSearchCV`执行中使用它，就像在[示例 10-2](#skex_joblib)中一样。
- en: Example 10-2\. [Using a Ray Joblib backend with scikit-learn to build the wine-quality
    model](https://oreil.ly/cqR34)
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-2\. [使用Ray Joblib后端与scikit-learn构建葡萄酒质量模型](https://oreil.ly/cqR34)
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using Boosting Algorithms with Ray
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Boosting算法与Ray
- en: 'Boosting algorithms are well suited to parallel computing as they train multiple
    models. You can train each submodel independently and then train another model
    on how to combine the results. These are the two most popular boosting libraries
    today:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Boosting算法训练多个模型，因此非常适合并行计算。你可以独立训练每个子模型，然后再训练另一个模型来组合结果。目前最流行的两个Boosting库如下：
- en: XGBoost
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost
- en: An optimized distributed gradient boosting library designed to be highly efficient,
    flexible, and portable. It implements ML algorithms under the [gradient boosting
    framework](https://oreil.ly/ceOze). XGBoost provides a parallel tree boosting—also
    known as gradient boosting decision tree (GBDT) and gradient boosting machines
    (GBM)—that solves many data science problems quickly and accurately. The same
    code runs on many distributed environments—including Hadoop, Sun Grid Engine (SGE),
    and Message Passing Interface (MPI)—and can solve problems beyond billions of
    examples.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一个优化的分布式梯度提升库，旨在高效、灵活和可移植。它在[梯度提升框架](https://oreil.ly/ceOze)下实现了机器学习算法。XGBoost提供了并行树提升，也称为梯度提升决策树（GBDT）和梯度提升机（GBM），能够快速准确地解决许多数据科学问题。同样的代码可以运行在多种分布式环境上，包括Hadoop、Sun
    Grid Engine（SGE）和消息传递接口（MPI），可以处理数十亿个示例以上的问题。
- en: '[LightGBM](https://oreil.ly/PdV9o)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[LightGBM](https://oreil.ly/PdV9o)'
- en: A fast, distributed, high-performance [gradient boosting framework](https://oreil.ly/XZdQD)
    based on a decision tree algorithm, used for ranking, classification, and many
    other ML tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速、分布式、高性能的[梯度提升框架](https://oreil.ly/XZdQD)，基于决策树算法，用于排名、分类和许多其他机器学习任务。
- en: 'We will compare how Ray parallelizes training with XGBoost and LightGBM, but
    comparing the details of the libraries is beyond the scope of this book. If you’re
    interested in the difference between the libraries, a good comparison is found
    in [“XGBoost vs. LighGBM: How Are They Different”](https://oreil.ly/yk800) by
    Sumit Saha.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将比较Ray如何并行训练XGBoost和LightGBM，但是比较这两个库的细节超出了本书的范围。如果你对这两个库的区别感兴趣，可以参考Sumit
    Saha的[“XGBoost vs. LighGBM: How Are They Different”](https://oreil.ly/yk800)。'
- en: Using XGBoost
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用XGBoost
- en: Continuing with our wine-quality example, we build a model using XGBoost, and
    the code to do so is presented in [Example 10-3](#xgboost_example).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们的葡萄酒质量示例，我们使用XGBoost构建模型，并且相关代码在[示例 10-3](#xgboost_example)中展示。
- en: Example 10-3\. [Using XGBoost to build our wine-quality model](https://oreil.ly/s6ORf)
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-3\. [使用XGBoost构建我们的葡萄酒质量模型](https://oreil.ly/s6ORf)
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'One of the reasons XGBoost is so performant is that it uses [OpenMP](https://oreil.ly/saVa9)
    to create tree branches independently, which does not directly support Ray. Ray
    integrates with XGBoost by providing an xgboost-ray library that replaces OpenMP
    with Ray actor pools. You can use this library either with XGBoost or scikit-learn
    APIs. In the latter case, the library provides a drop-in replacement for the following
    estimators:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost之所以性能出色，部分原因在于它使用[OpenMP](https://oreil.ly/saVa9)来独立创建树分支，而这种方式并不直接支持Ray。Ray通过提供xgboost-ray库来与XGBoost集成，该库用Ray
    actor池替代了OpenMP。您可以将此库用于XGBoost或scikit-learn API。在后一种情况下，该库提供了以下估计器的一个插入式替代品：
- en: '`RayXGBClassifier`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayXGBClassifier`'
- en: '`RayXGRegressor`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayXGRegressor`'
- en: '`RayXGBRFClassifier`'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayXGBRFClassifier`'
- en: '`RayXGBRFRegressor`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayXGBRFRegressor`'
- en: '`RayXGBRanker`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayXGBRanker`'
- en: It also provides `RayParams`, which allows you to explicitly define the execution
    parameters for Ray. Using this library, we can modify [Example 10-3](#xgboost_example)
    to make it work with Ray as shown in [Example 10-4](#xgboost_ray).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 它还提供了`RayParams`，允许您显式定义Ray的执行参数。使用这个库，我们可以修改[示例 10-3](#xgboost_example)，使其能够与Ray一起工作，如同[示例 10-4](#xgboost_ray)。
- en: Example 10-4\. [Using the XGBoost Ray library to build our wine-quality model](https://oreil.ly/EgHdZ)
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-4\. [使用XGBoost Ray库构建我们的葡萄酒质量模型](https://oreil.ly/EgHdZ)
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here we used `RayParams` to specify the size of Ray’s actor pool used for parallelization.
    Alternatively, you can use the `n_jobs` parameter in `RayXGBClassifier` to achieve
    the same.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`RayParams`来指定用于并行化的Ray actor池的大小。或者，您可以使用`RayXGBClassifier`中的`n_jobs`参数来实现相同的效果。
- en: Using LightGBM
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LightGBM
- en: Building our wine-quality model using LightGBM is presented in [Example 10-5](#lightGBM).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了如何使用LightGBM构建我们的葡萄酒质量模型，详见[示例 10-5](#lightGBM)。
- en: Example 10-5\. [Using LightGBM to build our wine-quality model](https://oreil.ly/oHzxy)
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-5\. [使用LightGBM构建我们的葡萄酒质量模型](https://oreil.ly/oHzxy)
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Similar to XGBoost, LightGBM uses OpenMP for parallelization. As a result,
    Ray offers the [Distributed LightGBM on Ray library](https://oreil.ly/l6wuQ),
    which implements parallelization using Ray’s actor pool. Similar to the xgboost-ray
    library, this library supports both native and scikit-learn APIs. In the latter
    case, the library implements the following estimators:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于XGBoost，LightGBM使用OpenMP进行并行化。因此，Ray提供了[Distributed LightGBM on Ray library](https://oreil.ly/l6wuQ)，该库使用Ray的actor池来实现并行化。类似于xgboost-ray库，此库支持原生和scikit-learn
    API。在后一种情况下，该库实现了以下估计器的替代：
- en: '`RayLGBMClassifier`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayLGBMClassifier`'
- en: '`RayLGBMRegressor`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RayLGBMRegressor`'
- en: As with XGBoost, `RayParams` is provided, allowing you to define execution parameters
    for Ray. Using this library, we can modify [Example 10-5](#lightGBM) to make it
    work with Ray as in [Example 10-6](#lightGBM_ray).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与XGBoost类似，`RayParams`提供了执行Ray所需的参数，用于定义Ray的执行参数。使用这个库，我们可以修改[示例 10-5](#lightGBM)，使其能够与Ray一起工作，如同[示例 10-6](#lightGBM_ray)。
- en: Example 10-6\. [Using the LightGBM Ray library to build our wine-quality model](https://oreil.ly/pocKo)
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-6\. [使用LightGBM Ray库构建我们的葡萄酒质量模型](https://oreil.ly/pocKo)
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here we used `RayParams` to specify the size of Ray’s actor pool used for parallelization.
    Alternatively, you can use the `n_jobs` parameter in `RayLGBMClassifier` to achieve
    the same.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`RayParams`来指定用于并行化的Ray actor池的大小。或者，您可以使用`RayLGBMClassifier`中的`n_jobs`参数来实现相同的效果。
- en: Using PyTorch with Ray
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Ray与PyTorch
- en: Another very popular machine learning framework is [PyTorch](https://oreil.ly/fMTL8),
    an open source Python library for deep learning developed and maintained by Facebook.
    PyTorch is simple and flexible, making it a favorite for many academics and researchers
    in the development of new deep learning models and applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常流行的机器学习框架是[PyTorch](https://oreil.ly/fMTL8)，这是由Facebook开发和维护的开源Python深度学习库。PyTorch简单灵活，因此成为许多学术界和研究人员开发新的深度学习模型和应用的首选。
- en: Many extensions for specific applications (such as text, computer vision, and
    audio data) have been implemented for PyTorch. A lot of pretrained models also
    exist that you can use directly. If you are not familiar with PyTorch, take a
    look at Jason Brownlee’s [PyTorch tutorial](https://oreil.ly/zzXb6) for an introduction
    to its structure, capabilities, and usage for solving various problems.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PyTorch，已经实现了许多特定应用程序的扩展（如文本、计算机视觉和音频数据）。还有很多预训练模型可供直接使用。如果您对PyTorch不太熟悉，请参阅Jason
    Brownlee的[PyTorch教程](https://oreil.ly/zzXb6)，了解其结构、功能和解决各种问题的用法。
- en: We will continue with our wine-quality problem and show how to use PyTorch to
    build a multilayer perceptron (MLP) model for predicting wine quality. To do this,
    you need to start from creating a custom PyTorch [Dataset class](https://oreil.ly/E1MGh)
    that can be extended and customized to load your dataset. For our wine-quality
    example, the custom dataset class is shown in [Example 10-7](#torch_data).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续解决葡萄酒质量问题，并展示如何使用 PyTorch 构建一个用于预测葡萄酒质量的多层感知器（MLP）模型。为此，您需要从创建一个可以扩展和定制以加载您的数据集的自定义
    PyTorch [Dataset 类](https://oreil.ly/E1MGh) 开始。对于我们的葡萄酒质量示例，自定义数据集类在 [示例 10-7](#torch_data)
    中展示。
- en: Example 10-7\. [PyTorch dataset class for loading wine-quality data](https://oreil.ly/hkLLE)
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-7\. [用于加载葡萄酒质量数据的 PyTorch 数据集类](https://oreil.ly/hkLLE)
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that here, in addition to the minimum requirements, we have implemented
    `get_splits`, a method that splits an original dataset into two: one for training
    and one for testing.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了最低要求之外，我们还实现了 `get_splits`，一个将原始数据集分成两个部分（一个用于训练，一个用于测试）的方法。
- en: Once you have defined your data class, you can use PyTorch to make a model.
    To define a model in PyTorch, you extend the base PyTorch [Module class](https://oreil.ly/ShyFD).
    The model class for our purposes is presented in [Example 10-8](#torch_model).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您定义了数据类，就可以使用 PyTorch 制作模型。要在 PyTorch 中定义模型，您需要扩展基本的 PyTorch [Module 类](https://oreil.ly/ShyFD)。为了我们的目的，模型类在
    [示例 10-8](#torch_model) 中呈现。
- en: Example 10-8\. [PyTorch model class for wine quality](https://oreil.ly/CZX2A)
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-8\. [用于葡萄酒质量的 PyTorch 模型类](https://oreil.ly/CZX2A)
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This class constructor builds the model by defining its layers and their connectivity.
    The `forward` method defines how to forward-propagate input through the model.
    With these two classes in place, the overall code looks like [Example 10-9](#torch_train).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此类构造函数通过定义其层及其连接来构建模型。`forward` 方法定义了如何通过模型进行前向传播的方法。有了这两个类，整体代码看起来像是 [示例 10-9](#torch_train)。
- en: Example 10-9\. [PyTorch implementation of wine-quality model building](https://oreil.ly/6TIHG)
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-9\. [葡萄酒质量模型构建的 PyTorch 实现](https://oreil.ly/6TIHG)
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Example 10-9](#torch_train) works, but Ray is integrated with [Lightning](https://oreil.ly/SCakx)
    (formerly called PyTorch Lightning), not PyTorch. Lightning structures your PyTorch
    code so it can abstract the details of training. This makes AI research scalable
    and fast to iterate on.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 10-9](#torch_train) 可以运行，但 Ray 与 [Lightning](https://oreil.ly/SCakx)（之前称为
    PyTorch Lightning）集成，而不是 PyTorch。 Lightning 会结构化您的 PyTorch 代码，使其可以抽象出训练的细节。这使得
    AI 研究可扩展且快速迭代。'
- en: To convert [Example 10-9](#torch_train) to Lightning, we first need to modify
    [Example 10-8](#torch_model). In Lightning, it needs to be derived from [`lightning_module`](https://oreil.ly/sFSCd),
    not `module`, which means that we need to add two methods to our model ([Example 10-10](#ltorch_add)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 [示例 10-9](#torch_train) 转换为 Lightning，我们首先需要修改 [示例 10-8](#torch_model)。在
    Lightning 中，它需要派生自 [`lightning_module`](https://oreil.ly/sFSCd)，而不是 `module`，这意味着我们需要向我们的模型添加两种方法（[示例 10-10](#ltorch_add)）。
- en: Example 10-10\. [Lightning model’s additional functions for wine quality](https://oreil.ly/1eTnI)
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-10\. [Lightning 模型额外功能用于葡萄酒质量](https://oreil.ly/1eTnI)
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here the `training_step` method defines a single step, while `configure_optimized`
    defines which optimizer to use. When you compare this to [Example 10-8](#torch_model),
    you will notice that some of that example’s code is moved into these two methods
    (here instead of the `BCELoss` optimizer, we are using the `Adam` optimizer).
    With this updated model class, the model training looks like [Example 10-11](#ltorch_train).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 `training_step` 方法定义了一个单独的步骤，而 `configure_optimized` 定义了要使用的优化器。当您将此与 [示例 10-8](#torch_model)
    进行比较时，您会注意到某些例子的代码已经移到了这两个方法中（这里我们使用 `Adam` 优化器而不是 `BCELoss` 优化器）。有了这个更新的模型类，模型训练看起来像是
    [示例 10-11](#ltorch_train)。
- en: Example 10-11\. [Lightning implementation of wine-quality model building](https://oreil.ly/T7xza)
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-11\. [葡萄酒质量模型构建的 Lightning 实现](https://oreil.ly/T7xza)
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note that unlike [Example 10-9](#torch_train), where training is implemented
    programmatically, Lightning introduces a trainer class, which internally implements
    a trainer loop. This approach allows all required optimization to be in the training
    loop.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与 [示例 10-9](#torch_train) 不同，其中训练是以编程方式实现的，Lightning 引入了一个 trainer 类，该类在内部实现了一个
    trainer 循环。这种方法允许所有所需的优化都在训练循环中进行。
- en: Both PyTorch and Lightning are using Joblib to distribute training through the
    built-in [`ddp_cpu` backend](https://oreil.ly/RNLuq) or, more generally, [Horovod](https://oreil.ly/x8Ba2).
    As with other libraries, to allow distributed Lightning on Ray, Ray has a library
    [Distributed PyTorch Lightning Training](https://oreil.ly/Ii51T) that adds new
    Lightning plug-ins for distributed training using Ray. These plug-ins allow you
    to quickly and easily parallelize training while still getting all the benefits
    of Lightning and using your desired training protocol, either `ddp_cpu` or Horovod.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 和 Lightning 都使用 Joblib 通过内置的 [`ddp_cpu` 后端](https://oreil.ly/RNLuq)或更普遍地说，[Horovod](https://oreil.ly/x8Ba2)
    分发训练。与其他库一样，为了允许 Ray 上的分布式 Lightning，Ray 有一个库 [分布式 PyTorch Lightning 训练](https://oreil.ly/Ii51T)，它为使用
    Ray 进行分布式训练添加了新的 Lightning 插件。这些插件允许您快速轻松地并行化训练，同时仍然获得 Lightning 的所有好处，并使用您想要的训练协议，无论是
    `ddp_cpu` 还是 Horovod。
- en: Once you add the plug-ins to your Lightning trainer, you can configure them
    to parallelize training to all the cores in your laptop, or across a massive multinode,
    multi-GPU cluster with no additional code changes. This library also comes with
    integration with [Ray Tune](https://oreil.ly/ZJDeP) so you can perform distributed
    hyperparameter tuning experiments.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将插件添加到 Lightning 训练器中，您就可以将它们配置为将训练并行化到笔记本电脑的所有核心，或跨大规模多节点、多 GPU 集群，而无需额外的代码更改。此库还与
    [Ray Tune](https://oreil.ly/ZJDeP) 集成，因此您可以执行分布式超参数调整实验。
- en: The `RayPlugin` class provides Distributed Data Parallel (DDP) training on a
    Ray cluster. PyTorch DDP is used as the distributed training protocol by PyTorch,
    and Ray is used in this case to launch and manage the training worker processes.
    The base code using this plug-in is shown in [Example 10-12](#ltorch_train_2).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`RayPlugin` 类提供了在 Ray 集群上的分布式数据并行（DDP）训练。PyTorch DDP 被用作 PyTorch 的分布式训练协议，而在这种情况下，Ray
    被用于启动和管理训练工作进程。使用此插件的基本代码如 [示例 10-12](#ltorch_train_2) 所示。'
- en: Example 10-12\. [Enabling the Lightning implementation of our wine-quality model
    building to run on Ray](https://oreil.ly/oF44p)
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-12\. [使我们的葡萄酒质量模型构建的 Lightning 实现在 Ray 上运行](https://oreil.ly/oF44p)
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The two additional plug-ins included in the library are as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 该库中包含的另外两个插件如下：
- en: HorovodRayPlugin
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: HorovodRayPlugin
- en: Integrates with Horovod as the distributed training protocol.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Horovod 集成为分布式训练协议。
- en: RayShardedPlugin
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: RayShardedPlugin
- en: Integrates with [FairScale](https://oreil.ly/drOkZ) to provide sharded DDP training
    on a Ray cluster. With sharded training, you can leverage the scalability of data-parallel
    training while drastically reducing memory usage when training large models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与 [FairScale](https://oreil.ly/drOkZ) 集成，以在 Ray 集群上提供分片 DDP 训练。通过分片训练，您可以利用数据并行训练的可伸缩性，同时大大减少训练大型模型时的内存使用。
- en: Reinforcement Learning with Ray
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Ray 的强化学习
- en: Ray was initially created as a platform for *reinforcement learning* (RL), which
    is one of the hottest research topics in the field of modern artificial intelligence,
    and its popularity is only growing. RL is a type of machine learning technique
    that enables an agent to learn in an interactive environment by trial and error
    using feedback from its own actions and experiences; see [Figure 10-1](#different-types-of-machine-learning).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 最初是作为*强化学习*（RL）的平台而创建的，这是现代人工智能领域最热门的研究课题之一，其受欢迎程度仅增不减。RL 是一种机器学习技术，它使代理能够在交互式环境中通过试错学习，利用自身的行动和经验反馈；参见
    [图 10-1](#different-types-of-machine-learning)。
- en: '![spwr 1001](assets/spwr_1001.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![spwr 1001](assets/spwr_1001.png)'
- en: Figure 10-1\. Types of machine learning
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-1\. 机器学习的类型
- en: Both supervised and reinforcement learning create a mapping between input and
    output. But whereas supervised learning uses a set of known inputs and output
    for training, reinforcement learning uses rewards and punishments as signals for
    positive and negative behavior. Both unsupervised and reinforcement learning leverage
    experiment data, but they have different goals. While in unsupervised learning
    we are finding similarities and differences between data points, in reinforcement
    learning we are trying to find a suitable action model that would maximize the
    total cumulative reward and improve the model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习和强化学习都创建了输入和输出之间的映射。但是，监督学习使用一组已知的输入和输出进行训练，而强化学习使用奖励和惩罚作为正面和负面行为的信号。无监督学习和强化学习都利用实验数据，但它们有不同的目标。在无监督学习中，我们正在寻找数据点之间的相似性和差异，而在强化学习中，我们试图找到一个合适的动作模型，以最大化总累积奖励并改进模型。
- en: 'The key components of an RL implementation are as follows and are depicted
    in [Figure 10-2](#reinforcement-model-implementation):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: RL实现的关键组件如下，并且在[图 10-2](#reinforcement-model-implementation)中有所描绘：
- en: Environment
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 环境
- en: Physical world in which the agent operates
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代理操作的物理世界
- en: State
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 状态
- en: Current state of the agent
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的当前状态
- en: Reward
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励
- en: Feedback to the agent from the environment
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从环境中向代理提供的反馈
- en: Policy
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 策略
- en: Method to map the agent’s state to the actions
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 将代理状态映射到行动的方法
- en: Value
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 价值
- en: Future reward that an agent would receive by taking an action in a particular
    state
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 代理在特定状态下执行行动后会收到的未来奖励
- en: '![spwr 1002](assets/spwr_1002.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![spwr 1002](assets/spwr_1002.png)'
- en: Figure 10-2\. Reinforcement model implementation
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. 强化学习模型实现
- en: RL is a huge topic, and its details are beyond the scope of this book (we are
    just trying to explain how to start using the library with a simple example),
    but if you are interested in learning more about it, [“Reinforcement Learning
    101”](https://oreil.ly/YvgzA) by Shweta Bhatt is an excellent starting point.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: RL是一个广泛的主题，其详细信息超出了本书的范围（我们只是试图用一个简单的例子来解释如何开始使用该库），但如果您有兴趣了解更多，Shweta Bhatt的[“强化学习
    101”](https://oreil.ly/YvgzA) 是一个很好的起点。
- en: Ray’s RLlib is a library for RL, which allows for production-level, highly distributed
    RL workloads while providing unified and simple APIs for a large variety of applications
    for different industries. It supports both [model-free](https://oreil.ly/tA22j)
    and [model-based](https://oreil.ly/n7mB9) reinforcement learning.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Ray的RLlib是一个RL库，允许生产级高度分布式RL工作负载，同时为不同行业的各种应用提供统一且简单的API。它支持[无模型](https://oreil.ly/tA22j)和[基于模型](https://oreil.ly/n7mB9)的强化学习。
- en: As shown in [Figure 10-3](#rllib-components), RLlib is built on top of Ray and
    offers off-the-shelf, highly distributed algorithms, policies, loss functions,
    and default models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 10-3](#rllib-components)所示，RLlib是建立在Ray之上的，提供现成的高度分布式算法、策略、损失函数和默认模型。
- en: '![spwr 1003](assets/spwr_1003.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![spwr 1003](assets/spwr_1003.png)'
- en: Figure 10-3\. RLlib components
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-3\. RLlib组件
- en: A *policy* encapsulates the core numerical components of RL algorithms. It includes
    a policy model that determines actions based on environment changes and a loss
    function defining the result of the action based on the post-processed environment.
    Depending on the environment, RL can have a single agent and property, a single
    policy for multiple agents, or multiple policies, each controlling one or more
    agents.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*策略* 封装了RL算法的核心数值组件。它包括一个策略模型，根据环境变化确定行动，并且定义一个损失函数，根据后处理的环境确定行动的结果。根据环境的不同，RL可以有单个代理和属性，多个代理的单一策略，或多个策略，每个策略控制一个或多个代理。'
- en: Everything agents interact with is called an *environment*. The environment
    is the outside world and comprises everything outside the agent.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 代理与之交互的一切都称为*环境*。环境是外部世界，包括代理外的一切。
- en: Given an environment and policy, policy evaluation is done by the *worker*.
    RLlib provides a [RolloutWorker class](https://oreil.ly/WgnmE) that is used in
    most RLlib algorithms.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定环境和策略的情况下，策略评估由*工作器*完成。RLlib提供了一个[RolloutWorker类](https://oreil.ly/WgnmE)，在大多数RLlib算法中都会使用。
- en: At a high level, RLlib provides [trainer classes](https://oreil.ly/JRjMw) that
    hold a policy for environment interaction. Through the trainer interface, the
    policy can be trained, checkpointed, or an action computed. In multiagent training,
    the trainer manages the querying and optimization of multiple policies at once.
    The trainer classes coordinate the distributed workflow of running rollouts and
    optimizing policies. They do this by leveraging Ray [parallel iterators](https://oreil.ly/2TTeo).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，RLlib提供了[训练器类](https://oreil.ly/JRjMw)，用于持有环境交互的策略。通过训练器接口，可以训练策略、创建检查点或计算行动。在多代理训练中，训练器管理多个策略的查询和优化。训练器类通过利用Ray的[并行迭代器](https://oreil.ly/2TTeo)来协调运行回合和优化策略的分布式工作流程。
- en: Beyond environments defined in Python, Ray supports batch training on [offline
    datasets](https://oreil.ly/u88nx) through *input readers*. This is an important
    use case for RL when it’s not possible to run traditional training and roll out
    in a physical environment (like a chemical plant or assembly line) and a suitable
    simulator doesn’t exist. In this approach, data for past activity is used to train
    a policy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Python 中定义的环境外，Ray 还支持在 [离线数据集](https://oreil.ly/u88nx) 上进行批处理训练，通过 *输入读取器*。这对于
    RL 是一个重要的用例，当无法在传统的训练和模拟环境（如化工厂或装配线）中运行时，适当的模拟器不存在。在这种方法中，过去活动的数据用于训练策略。
- en: From single processes to large clusters, all data interchange in RLlib uses
    [sample batches](https://oreil.ly/kP0sH). Sample batches encode one or more fragments
    of data. Typically, RLlib collects batches of size `rollout_fragment_length` from
    rollout workers and concatenates one or more of these batches into a batch of
    size `train_batch_size` that is the input to stochastic gradient descent (SGD).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从单个进程到大型集群，RLlib 中所有数据交换都使用 [样本批次](https://oreil.ly/kP0sH)。样本批次编码一个或多个数据片段。通常，RLlib
    从 rollout workers 收集 `rollout_fragment_length` 大小的批次，并将其中一个或多个批次连接成 `train_batch_size`
    大小的批次，这是随机梯度下降（SGD）的输入。
- en: 'The main features of RLlib are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: RLlib 的主要特性如下：
- en: Support for the most popular deep-learning frameworks including PyTorch and
    TensorFlow.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持最流行的深度学习框架，包括 PyTorch 和 TensorFlow。
- en: Implementation of highly distributed learning, RLlib algorithms—[PPO](https://oreil.ly/5oJU8)
    or [IMPALA](https://oreil.ly/dkaNw)—allow you to set the `num_workers` config
    parameter, such that your workloads can run on hundreds of CPUs or nodes, thus
    parallelizing and speeding up learning.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施高度分布式学习时，RLlib 算法——[PPO](https://oreil.ly/5oJU8) 或 [IMPALA](https://oreil.ly/dkaNw)——允许您设置
    `num_workers` 配置参数，使得您的工作负载可以在数百个 CPU 或节点上运行，从而并行化并加速学习。
- en: 'Support for [multiagent RL](https://oreil.ly/wc9dO) allows for training your
    agents supporting any of the following strategies:'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 [多智能体 RL](https://oreil.ly/wc9dO)，允许训练支持以下任何策略的代理。
- en: Cooperative with [shared](https://oreil.ly/XZDTC) or [separate](https://oreil.ly/ofB4R)
    policies and/or value functions
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与共享或分离的策略和/或价值函数的合作性
- en: Adversarial scenarios using [self-play](https://oreil.ly/c7hyz) and [league-based
    training](https://oreil.ly/wBnHl)
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [自我对弈](https://oreil.ly/c7hyz) 和 [联赛训练](https://oreil.ly/wBnHl) 的对抗场景。
- en: '[Independent learning](https://oreil.ly/2RRS2) of neutral/coexisting agents'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[独立学习](https://oreil.ly/2RRS2) 的中性/共存代理'
- en: Support APIs for an external pluggable simulators environment that comes with
    a pluggable, off-the-shelf [client](https://oreil.ly/aaQ6s) ∕ [server](https://oreil.ly/eMn1j)
    setup that allows you to run hundreds of independent simulators on the “outside”
    connecting to a central RLlib policy-server that learns and serves actions.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持外部可插拔模拟器环境的 API，配备了一个可插拔的、现成的 [客户端](https://oreil.ly/aaQ6s) ∕ [服务器](https://oreil.ly/eMn1j)
    设置，允许您在“外部”运行数百个独立的模拟器，连接到中央的 RLlib 策略服务器，学习并提供动作。
- en: Additionally, RLlib provides simple APIs to customize all aspects of your training
    and experimental workflows. For example, you may code your own [environments](https://oreil.ly/15Cx0)
    in Python by using [OpenAI’s Gym](https://oreil.ly/ECLhC) or [DeepMind’s OpenSpiel](https://oreil.ly/eI9y9),
    provide custom [TensorFlow/Keras](https://oreil.ly/EQUpK) or [PyTorch](https://oreil.ly/nE4r3)
    models, and write your own [policy and loss definitions](https://oreil.ly/pbPyT)
    or define custom [exploratory behavior](https://oreil.ly/QUtq7).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，RLlib 提供了简单的 API 来定制训练和实验工作流的所有方面。例如，您可以通过使用 [OpenAI’s Gym](https://oreil.ly/ECLhC)
    或 [DeepMind’s OpenSpiel](https://oreil.ly/eI9y9) 编写自己的 Python 环境，提供自定义的 [TensorFlow/Keras](https://oreil.ly/EQUpK)
    或 [PyTorch](https://oreil.ly/nE4r3) 模型，并编写自己的 [策略和损失定义](https://oreil.ly/pbPyT)
    或定义自定义的 [探索行为](https://oreil.ly/QUtq7)。
- en: Simple code for implementing RL training to address the inverted pendulum—i.e.,
    [CartPole](https://oreil.ly/lJIDX)—problem (the environment exists in OpenAI’s
    Gym) is shown in [Example 10-13](#rl_train).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 RL 训练的简单代码，以解决倒立摆问题——即 [CartPole](https://oreil.ly/lJIDX)——（该环境存在于 OpenAI
    的 Gym 中），如 [Example 10-13](#rl_train) 所示。
- en: Example 10-13\. [CartPole reinforcement learning](https://oreil.ly/d6tHJ)
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-13\. [CartPole 强化学习](https://oreil.ly/d6tHJ)
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[Example 10-13](#rl_train) starts by creating a configuration for a trainer.
    The configuration defines an environment,^([3](ch10.html#idm45354762991600)) the
    number of workers (we use four), framework (we use TensorFlow 2), model, train
    batch size, and additional execution parameters. This configuration is used for
    the creation of the trainer. We then execute several training iterations and display
    results. That’s all it takes to implement simple RL.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 10-13](#rl_train) 从创建一个训练器的配置开始。配置定义了一个环境，^([3](ch10.html#idm45354762991600))，工作者数量（我们使用四个），框架（我们使用
    TensorFlow 2），模型，训练批量大小和其他执行参数。此配置用于创建训练器。然后我们执行几个训练迭代并显示结果。这就是实现简单 RL 所需要的全部。'
- en: You can easily extend this simple example by creating your specific [environment](https://oreil.ly/APjBE)
    or introducing your own [algorithms](https://oreil.ly/OFzk0).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过创建你自己的[环境](https://oreil.ly/APjBE)或引入你自己的[算法](https://oreil.ly/OFzk0)，轻松扩展这个简单的例子。
- en: Numerous examples of Ray RLlIB usage are described in [“Best Reinforcement Learning
    Talks from Ray Summit 2021”](https://oreil.ly/4I1Dv) by Michael Galarnyk.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Michael Galarnyk 在 [“Best Reinforcement Learning Talks from Ray Summit 2021”](https://oreil.ly/4I1Dv)
    中描述了 Ray RLlIB 的许多用法示例。
- en: Hyperparameter Tuning with Ray
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Ray 进行超参数调整
- en: When creating an ML model, you are often faced with a variety of choices, from
    the type of model to feature selection techniques. A natural extension of ML is
    to use similar techniques to find the right values (or parameters) for the choices
    in building our model. Parameters that define the model architecture are referred
    to as *hyperparameters*, and the process of searching for the ideal model architecture
    is referred to as *hyperparameter tuning*. Unlike the model parameters that specify
    how to transform the input data into the desired output, hyperparameters define
    how to structure the model.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 ML 模型时，你经常面临各种选择，从模型类型到特征选择技术。ML 的一个自然扩展是使用类似的技术来找到建立模型时的正确值（或参数）。定义模型架构的参数称为*超参数*，搜索理想模型架构的过程称为*超参数调整*。与指定如何将输入数据转换为期望输出的模型参数不同，超参数定义了如何构造模型。
- en: As with boosting algorithms, hyperparameter tuning is especially well suited
    to parallelization because it involves training and comparing many models. Depending
    on the search technique, training these separate models can be an “embarrassingly
    parallel” problem, as there is little to no communication needed between them.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 与提升算法一样，超参数调整特别适合并行化，因为它涉及训练和比较许多模型。根据搜索技术，训练这些单独的模型可能是一个“尴尬地并行”的问题，因为它们之间几乎不需要通信。
- en: 'Here are some examples of hyperparameters:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些超参数的示例：
- en: The degree of the polynomial feature that should be used for the linear model
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该为线性模型使用的多项式特征的程度
- en: The maximum depth allowed for a decision tree
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树允许的最大深度
- en: The minimum number of samples required at a leaf node in a decision tree
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树叶节点所需的最小样本数
- en: The number of neurons for a neural network layer
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络层的神经元数量
- en: The number of layers for a neural network
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的层数
- en: The learning rate for gradient descent
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降的学习率
- en: '[Ray Tune](https://oreil.ly/PzkxQ) is the Ray-based native library for hyperparameter
    tuning. The main features of Tune are as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ray Tune](https://oreil.ly/PzkxQ) 是基于 Ray 的超参数调整本地库。Tune 的主要特点如下：'
- en: It provides distributed, asynchronous optimization out of the box leveraging
    Ray.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了分布式、异步优化的功能，利用了 Ray。
- en: The same code can be scaled from a single machine to a large, distributed cluster.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样的代码可以从单机扩展到大型分布式集群。
- en: It offers state-of-the-art algorithms including (but not limited to) [ASHA](https://oreil.ly/lY6nX),
    [BOHB](https://oreil.ly/iAiK9), and [Population-Based Training](https://oreil.ly/PrsmS).
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了包括（但不限于）[ASHA](https://oreil.ly/lY6nX)、[BOHB](https://oreil.ly/iAiK9) 和
    [Population-Based Training](https://oreil.ly/PrsmS) 在内的最先进的算法。
- en: It integrates with [TensorBoard](https://oreil.ly/FM7uR) or [MLflow](https://oreil.ly/pzYA6)
    to visualize tuning results.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与 [TensorBoard](https://oreil.ly/FM7uR) 或 [MLflow](https://oreil.ly/pzYA6)
    集成以可视化调整结果。
- en: It integrates with many optimization libraries such as [Ax/Botorch](https://oreil.ly/25sEx),
    [Hyperopt](https://oreil.ly/gCJ2I), and [Bayesian Optimization](https://oreil.ly/xA9nC)
    and enables their transparently scaling.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与许多优化库集成，如 [Ax/Botorch](https://oreil.ly/25sEx)、[Hyperopt](https://oreil.ly/gCJ2I)
    和 [Bayesian Optimization](https://oreil.ly/xA9nC)，并使它们能够透明地扩展。
- en: It supports many ML frameworks, including PyTorch, TensorFlow, XGBoost, LightGBM,
    and Keras.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持许多ML框架，包括PyTorch、TensorFlow、XGBoost、LightGBM和Keras。
- en: 'The following are the main components of Tune:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是Tune的主要组件：
- en: Trainable
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Trainable
- en: 'A training function, with an objective function. Tune offers two interface
    APIs for a trainable: functional and class.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一个训练函数，具有一个目标函数。Tune为trainable提供了两个接口API：函数式和类式。
- en: Search space
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索空间
- en: Valid values for your hyperparameters, and you can specify how these values
    are sampled (e.g., from a uniform distribution or a normal distribution). Tune
    offers various functions to define search spaces and sampling methods.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您的超参数的有效值，可以指定这些值如何被采样（例如，从均匀分布或正态分布中）。Tune提供各种功能来定义搜索空间和采样方法。
- en: Search algorithm
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索算法
- en: An algorithm used for the optimization of hyperparameters. Tune has Search Algorithms
    that integrate with many popular optimization libraries, such as [Nevergrad](https://oreil.ly/x5oaM)
    and [Hyperopt](https://oreil.ly/G2bGl). Tune automatically converts the provided
    search space into the search spaces the search algorithms/underlying library expect.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 用于超参数优化的算法。Tune具有与许多流行优化库集成的搜索算法，例如[Nevergrad](https://oreil.ly/x5oaM)和[Hyperopt](https://oreil.ly/G2bGl)。Tune自动将提供的搜索空间转换为搜索算法/底层库期望的搜索空间。
- en: Trial
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Trial
- en: Execution or run of a logical representation of a single hyperparameter configuration.
    Each trial is associated with an instance of a trainable. And a collection of
    trials make up an experiment. Tune uses Ray actors as a worker node’s processes
    to run multiple trials in parallel.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 执行或运行一个单一超参数配置的逻辑表示。每个试验与trainable实例相关联。一组试验组成一个实验。Tune使用Ray actors作为工作节点的进程，以并行运行多个试验。
- en: Experiment analysis
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 实验分析
- en: An object, returned by Tune, that has methods that can be used for analyzing
    your training. It can be integrated with TensorBoard and MLflow for results visualization.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一个由Tune返回的对象，具有可用于分析训练的方法。它可以与TensorBoard和MLflow集成以进行结果可视化。
- en: 'To show how to use Tune, let’s optimize our PyTorch implementation of wine-quality
    model building ([Example 10-8](#torch_model)). We will try to optimize two parameters
    of the optimizer used to build the model: `lr` and `momentum`.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示如何使用Tune，让我们优化我们的PyTorch葡萄酒质量模型构建实现（[示例 10-8](#torch_model)）。我们将尝试优化用于构建模型的优化器的两个参数：`lr`和`momentum`。
- en: First we restructure our code ([Example 10-9](#torch_train)) to introduce three
    additional functions ([Example 10-14](#tune_additions)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们重新组织我们的代码（[示例 10-9](#torch_train)），引入了三个额外的函数（[示例 10-14](#tune_additions)）。
- en: Example 10-14\. [Implementing support functions for our PyTorch wine-quality
    model](https://oreil.ly/dEMDF)
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-14\. [为我们的PyTorch葡萄酒质量模型实现支持函数](https://oreil.ly/dEMDF)
- en: '[PRE13]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this code, we have introduced three supporting functions:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们引入了三个支持函数：
- en: '`model_train`'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_train`'
- en: Encapsulates model training.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 封装了模型训练。
- en: '`model_test`'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_test`'
- en: Encapsulates model-quality evaluation.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 封装了模型质量评估。
- en: '`train_winequality`'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_winequality`'
- en: Implements all steps for model training and reports them to Tune. This allows
    Tune to make decisions in the middle of training.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 实现了模型训练的所有步骤，并向Tune报告它们。这使得Tune能够在训练过程中做出决策。
- en: With these three functions in place, integration with Tune is very straightforward
    ([Example 10-15](#tune_additions_2)).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这三个函数，与Tune的集成非常简单（[示例 10-15](#tune_additions_2)）。
- en: Example 10-15\. [Integrating model building with Tune](https://oreil.ly/1zhR6)
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-15\. [将模型构建与Tune集成](https://oreil.ly/1zhR6)
- en: '[PRE14]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'After loading the dataset, the code defines a search space—​a space for possible
    hyperparameters—​and invokes tuning by using the `tune.run` method. The parameters
    here are as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据集后，代码定义了一个搜索空间——可能的超参数空间——并通过使用`train_winequality`方法进行调优。这里的参数如下：
- en: Callable
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 可调用的
- en: Defines a training function (`train_winequality`, in our case).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了一个训练函数（在我们的案例中是`train_winequality`）。
- en: '`num_samples`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`num_samples`'
- en: Indicates the maximum number of runs for Tune.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 指示Tune的最大运行次数。
- en: '`scheduler`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`scheduler`'
- en: Here we use [ASHA](https://oreil.ly/frU6p), a scalable algorithm for [principled
    early stopping](https://oreil.ly/ASVYC). To make the optimization process more
    efficient, the ASHA scheduler terminates trials that are less promising and allocates
    more time and resources to more promising trials.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用[ASHA](https://oreil.ly/frU6p)，一种用于[原则性提前停止](https://oreil.ly/ASVYC)的可扩展算法。为了使优化过程更有效，ASHA调度器终止不太有前途的试验，并为更有前途的试验分配更多时间和资源。
- en: '`config`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`config`'
- en: Contains the search space for the algorithm.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 包含算法的搜索空间。
- en: Running the preceding code produces the result shown in [Example 10-16](#tune_result).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码会生成 [示例 10-16](#tune_result) 中显示的结果。
- en: Example 10-16\. Tuning the model result
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-16\. 调整模型结果
- en: '[PRE15]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, although we have defined 50 iterations for the model search,
    using ASHA significantly improves performance because it uses significantly fewer
    runs on average (in this example, more than 50% used only one iteration).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，虽然我们为模型搜索定义了 50 次迭代，但使用 ASHA 显着提高了性能，因为平均使用的运行次数显著减少（在这个例子中，超过 50% 的情况下只使用了一次迭代）。
- en: Conclusion
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, you learned how Ray constructs are leveraged for scaling execution
    of the different ML libraries (scikit-learn, XGBoost, LightGBM, and Lightning)
    using the full capabilities of multimachine Ray clusters.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了如何利用 Ray 构建用于扩展执行不同 ML 库（scikit-learn、XGBoost、LightGBM 和 Lightning）的能力的多机器
    Ray 集群的方法。
- en: We showed you simple examples of porting your existing ML code to Ray, as well
    as some of the internals of how Ray extends ML libraries to scale. We also showed
    simple examples of using Ray-specific implementations of RL and hyperparameter
    tuning.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向您展示了将现有的 ML 代码移植到 Ray 的简单示例，以及 Ray 如何扩展 ML 库以实现扩展的内部工作原理。我们还展示了使用 Ray 特定实现的
    RL 和超参数调整的简单示例。
- en: We hope that looking at these relatively simple examples will give you a better
    idea of how to best use Ray in your day-to-day implementations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望通过查看这些相对简单的示例，您能更好地了解如何在日常实现中最好地使用 Ray。
- en: ^([1](ch10.html#idm45354765564752-marker)) In this example, we are using `GridSearchCV`,
    which implements an exhaustive search. Although this works for this simple example,
    scikit-learn currently provides a new library, [Tune-sklearn](https://oreil.ly/p5p8d),
    that provides more powerful [tune algorithms](https://oreil.ly/aQoEw) providing
    a significant tuning speedup. This said, the same Joblib backend works for these
    algorithms the same way.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.html#idm45354765564752-marker)) 在这个例子中，我们使用了 `GridSearchCV`，它实现了一种穷举搜索。虽然这对于这个简单的例子有效，但
    scikit-learn 目前提供了一个新的库，[Tune-sklearn](https://oreil.ly/p5p8d)，它提供了更强大的 [调整算法](https://oreil.ly/aQoEw)
    来显著提高调整速度。这意味着，相同的 Joblib 后端对这些算法的工作方式都是一样的。
- en: ^([2](ch10.html#idm45354764269024-marker)) In our testing, for XGBoost execution
    time was 0.15 versus 14.4 seconds, and for LightGBM it was 0.24 versus 12.4 seconds.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.html#idm45354764269024-marker)) 在我们的测试中，对于 XGBoost，执行时间为 0.15 秒，而对于
    LightGBM，执行时间为 0.24 秒。
- en: ^([3](ch10.html#idm45354762991600-marker)) Here we use an existing [OpenAI Gym
    environment](https://oreil.ly/BSXIK), so we can just use its name.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.html#idm45354762991600-marker)) 在这里，我们使用了现有的 [OpenAI Gym 环境](https://oreil.ly/BSXIK)，因此我们只需使用其名称即可。
