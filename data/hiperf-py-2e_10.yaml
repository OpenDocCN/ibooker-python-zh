- en: Chapter 10\. Clusters and Job Queues
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第十章。集群和作业队列
- en: A *cluster* is commonly recognized to be a collection of computers working together
    to solve a common task. It could be viewed from the outside as a larger single
    system.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*集群*通常被认为是一组共同工作以解决共同任务的计算机的集合。从外部看，它可以被视为一个更大的单一系统。'
- en: In the 1990s, the notion of using a cluster of commodity PCs on a local area
    network for clustered processing—known as a [Beowulf cluster](https://oreil.ly/2aNvw)—became
    popular. [Google](https://oreil.ly/V83g1) later gave the practice a boost by using
    clusters of commodity PCs in its own data centers, particularly for running MapReduce
    tasks. At the other end of the scale, the [TOP500 project](https://oreil.ly/rHOQO)
    ranks the most powerful computer systems each year; these typically have a clustered
    design, and the fastest machines all use Linux.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上世纪九十年代，使用本地区域网络上的廉价个人电脑集群进行集群处理的概念，即被称为[贝奥武夫集群](https://oreil.ly/2aNvw)，变得流行起来。后来，[Google](https://oreil.ly/V83g1)通过在自己的数据中心使用廉价个人电脑集群，特别是用于运行MapReduce任务，进一步推动了这一实践。在另一个极端，[TOP500项目](https://oreil.ly/rHOQO)每年排名最强大的计算机系统；这些系统通常采用集群设计，而最快的机器都使用Linux。
- en: Amazon Web Services (AWS) is commonly used both for engineering production clusters
    in the cloud and for building on-demand clusters for short-lived tasks like machine
    learning. With AWS you can rent tiny to huge machines with 10s of CPUs and up
    to 768 GB of RAM for $1 to $15 an hour. Multiple GPUs can be rented at extra cost.
    Look at [“Using IPython Parallel to Support Research”](#clustering-ipython) and
    the ElastiCluster package if you’d like to explore AWS or other providers for
    ad hoc clusters on compute-heavy or RAM-heavy tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Web Services（AWS）通常用于在云中构建工程生产集群以及为机器学习等短期任务构建按需集群。通过AWS，您可以租用从微型到大型机器，拥有10个CPU和高达768
    GB的RAM，每小时租金为1到15美元。可以额外支付租用多个GPU。如果您想要探索AWS或其他提供商在计算密集或内存密集任务上的临时集群，可以查看[“使用IPython并行支持研究”](#clustering-ipython)和ElastiCluster包。
- en: Different computing tasks require different configurations, sizes, and capabilities
    in a cluster. We’ll define some common scenarios in this chapter.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的计算任务在集群中需要不同的配置、大小和功能。我们将在本章中定义一些常见场景。
- en: '*Before* you move to a clustered solution, do make sure that you have done
    the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在您转移到集群解决方案之前，请确保您已经完成了以下工作：
- en: Profiled your system so you understand the bottlenecks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析您的系统，以了解瓶颈
- en: Exploited compiler solutions like Numba and Cython
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用像Numba和Cython这样的编译器解决方案
- en: Exploited multiple cores on a single machine (possibly a big machine with many
    cores) with Joblib or `multiprocessing`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用单台机器上的多个核心（可能是一台具有多个核心的大型机器），使用Joblib或`multiprocessing`
- en: Exploited techniques for using less RAM
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用技术来减少RAM使用
- en: Keeping your system to one machine will make your life easier (even if the “one
    machine” is a really beefy computer with lots of RAM and many CPUs). Move to a
    cluster if you really need a *lot* of CPUs or the ability to process data from
    disks in parallel, or if you have production needs like high resiliency and rapid
    speed of response. Most research scenarios do not need resilience or scalability
    and are limited to few people, so the simplest solution is often the most sensible.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 将系统保持在一台机器上可以让您的生活更加轻松（即使这台“一台机器”是一台配置非常强大、内存和CPU都很多的计算机）。如果您确实需要大量的CPU或者能够并行处理数据从磁盘读取的能力，或者您有高可靠性和快速响应的生产需求，请迁移到一个集群。大多数研究场景不需要弹性或可扩展性，并且仅限于少数人，因此通常最简单的解决方案是最明智的选择。
- en: A benefit of staying on one *large* machine is that a tool like Dask can quickly
    parallelize your Pandas or plain Python code with no networking complications.
    Dask can also control a cluster of machines to parallelize Pandas, NumPy, and
    pure Python problems. Swifter automatically parallelizes some multicore single-machine
    cases by piggybacking on Dask. We introduce both Dask and Swifter later in this
    chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 留在一个*大*机器上的好处是像Dask这样的工具可以快速并行化您的Pandas或纯Python代码，而无需网络复杂性。Dask还可以控制一组机器以并行化处理Pandas、NumPy和纯Python问题。Swifter通过在Dask上共享负载，自动并行化一些多核单机案例。我们稍后在本章介绍Dask和Swifter两者。
- en: Benefits of Clustering
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群的好处
- en: The most obvious benefit of a cluster is that you can easily scale computing
    requirements—if you need to process more data or to get an answer faster, you
    just add more machines (or *nodes*).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 集群最明显的好处是您可以轻松扩展计算需求 — 如果您需要处理更多数据或更快地获得答案，只需添加更多机器（或*节点*）。
- en: By adding machines, you can also improve reliability. Each machine’s components
    have a certain likelihood of failing, but with a good design, the failure of a
    number of components will not stop the operation of the cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加机器，您还可以提高可靠性。每台机器的组件有一定的故障可能性，但是通过良好的设计，多个组件的故障不会停止集群的运行。
- en: Clusters are also used to create systems that scale dynamically. A common use
    case is to cluster a set of servers that process web requests or associated data
    (e.g., resizing user photos, transcoding video, or transcribing speech) and to
    activate more servers as demand increases at certain times of the day.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 集群还用于创建动态扩展的系统。一个常见的用例是将一组处理网络请求或相关数据的服务器集群化（例如，调整用户照片大小、转码视频或转录语音），并在一天中某些时间段内随着需求增加而激活更多的服务器。
- en: Dynamic scaling is a very cost-effective way of dealing with nonuniform usage
    patterns, as long as the machine activation time is fast enough to deal with the
    speed of changing demand.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 动态扩展是处理非均匀使用模式的一种非常经济高效的方式，只要机器激活时间足够快以应对需求变化的速度。
- en: Tip
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Consider the effort versus the reward of building a cluster. Whilst the parallelization
    gains of a cluster can feel attractive, do consider the costs associated with
    constructing and maintaining a cluster. They fit well for long-running processes
    in a production environment or for well-defined and oft-repeated R&D tasks. They
    are less attractive for variable and short-lived R&D tasks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑建立集群的投入与回报。虽然集群的并行化增益可能会令人心动，但请考虑与构建和维护集群相关的成本。它们非常适合生产环境中长时间运行的流程或明确定义且经常重复的研发任务。对于变量和短期的研发任务，它们则不那么吸引人。
- en: A subtler benefit of clustering is that clusters can be separated geographically
    but still centrally controlled. If one geographic area suffers an outage (due
    to a flood or power loss, for example), the other cluster can continue to work,
    perhaps with more processing units being added to handle the demand. Clusters
    also allow you to run heterogeneous software environments (e.g., different versions
    of operating systems and processing software), which *might* improve the robustness
    of the overall system—note, though, that this is definitely an expert-level topic!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 集群的一个微妙的好处是，集群可以在地理上分开但仍然集中控制。如果一个地理区域遭受故障（例如洪水或停电），另一个集群可以继续工作，也许会增加更多处理单元来处理需求。集群还允许您运行异构软件环境（例如不同版本的操作系统和处理软件），这可能会提高整个系统的鲁棒性——但请注意，这绝对是一个高级话题！
- en: Drawbacks of Clustering
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群的缺点
- en: Moving to a clustered solution requires a change in thinking. This is an evolution
    of the change in thinking required when you move from serial to parallel code,
    as we introduced back in [Chapter 9](ch09_split_000.xhtml#multiprocessing). Suddenly
    you have to consider what happens when you have more than one machine—you have
    latency between machines, you need to know if your other machines are working,
    and you need to keep all the machines running the same version of your software.
    System administration is probably your biggest challenge.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到集群解决方案需要改变思维方式。这是从串行代码到并行代码所需的思维变革的进化，就像我们在[第9章](ch09_split_000.xhtml#multiprocessing)中介绍的那样。突然间，你不得不考虑当你有多台机器时会发生什么——你有机器之间的延迟，你需要知道你的其他机器是否在工作，并且你需要保持所有机器运行相同版本的软件。系统管理可能是你面临的最大挑战。
- en: In addition, you normally have to think hard about the algorithms you are implementing
    and what happens once you have all these additional moving parts that may need
    to stay in sync. This additional planning can impose a heavy mental tax; it is
    likely to distract you from your core task, and once a system grows large enough,
    you’ll probably need to add a dedicated engineer to your team.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通常你必须深思熟虑正在实施的算法，以及一旦所有这些额外的运动部分可能需要保持同步时会发生什么。这种额外的规划可能会带来沉重的心理负担；它很可能会让你分心，一旦系统变得足够大，你可能需要增加一个专门的工程师到你的团队中。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We’ve tried to focus on using one machine efficiently in this book because we
    believe that life is easier if you’re dealing with only one computer rather than
    a collection (though we confess it can be *way* more fun to play with a cluster—until
    it breaks). If you can scale vertically (by buying more RAM or more CPUs), it
    is worth investigating this approach in favor of clustering. Of course, your processing
    needs may exceed what’s possible with vertical scaling, or the robustness of a
    cluster may be more important than having a single machine. If you’re a single
    person working on this task, though, bear in mind also that running a cluster
    will suck up some of your time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们尝试专注于有效使用一台计算机，因为我们认为只处理一台计算机比处理集合更容易（尽管我们承认玩集群可能会更有趣——直到它出问题为止）。如果您可以垂直扩展（购买更多的RAM或更多的CPU），则值得调查这种方法是否优于集群。当然，您的处理需求可能超出了垂直扩展的可能性，或者集群的稳健性可能比拥有单一机器更重要。然而，如果您是一个单独的人在处理这个任务，也要记住运行一个集群将会占用您的一些时间。
- en: When designing a clustered solution, you’ll need to remember that each machine’s
    configuration might be different (each machine will have a different load and
    different local data). How will you get all the right data onto the machine that’s
    processing your job? Does the latency involved in moving the job and the data
    amount to a problem? Do your jobs need to communicate partial results to one another?
    What happens if a process fails or a machine dies or some hardware wipes itself
    when several jobs are running? Failures can be introduced if you don’t consider
    these questions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计集群解决方案时，您需要记住每台机器的配置可能不同（每台机器的负载和本地数据都不同）。您如何将所有正确的数据传送到正在处理作业的机器上？将作业和数据移动涉及的延迟是否会成为问题？您的作业是否需要相互通信部分结果？如果一个进程失败或者一台机器故障，或者一些硬件在多个作业运行时自行清除，会发生什么情况？如果您不考虑这些问题，可能会引入故障。
- en: You should also consider that failures *can be acceptable*. For example, you
    probably don’t need 99.999% reliability when you’re running a content-based web
    service—if on occasion a job fails (e.g., a picture doesn’t get resized quickly
    enough) and the user is required to reload a page, that’s something that everyone
    is already used to. It might not be the solution you want to give to the user,
    but accepting a little bit of failure typically reduces your engineering and management
    costs by a worthwhile margin. On the flip side, if a high-frequency trading system
    experiences failures, the cost of bad stock market trades could be considerable!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应考虑到故障*可以被接受*的可能性。例如，当您运行基于内容的网络服务时，可能不需要99.999%的可靠性——如果偶尔作业失败（例如，图片无法及时调整大小）并要求用户重新加载页面，那是每个人都已经习惯了的事情。这可能不是您想要给用户的解决方案，但通常接受一点失败可以显著降低工程和管理成本。另一方面，如果高频交易系统出现故障，糟糕的股市交易成本可能是可观的！
- en: Maintaining a fixed infrastructure can become expensive. Machines are relatively
    cheap to purchase, but they have an awful habit of going wrong—automatic software
    upgrades can glitch, network cards fail, disks have write errors, power supplies
    can give spikey power that disrupts data, cosmic rays can flip a bit in a RAM
    module. The more computers you have, the more time will be lost to dealing with
    these issues. Sooner or later you’ll want to bring in a system engineer who can
    deal with these problems, so add another $100,000 to the budget. Using a cloud-based
    cluster can mitigate a lot of these problems (it costs more, but you don’t have
    to deal with the hardware maintenance), and some cloud providers also offer a
    [spot-priced market](http://bit.ly/spot-instances) for cheap but temporary computing
    resources.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 维护固定基础设施可能会变得昂贵。购买机器相对便宜，但它们有一个令人头痛的毛病——自动软件升级可能会出现故障，网络卡故障，磁盘写入错误，电源供应器可能提供干扰数据的尖峰电源，宇宙射线可能会在
    RAM 模块中翻转位。您拥有的计算机越多，处理这些问题所需的时间就会越多。迟早您会想要引入一个能够处理这些问题的系统工程师，所以预算中要再增加$100,000。使用基于云的集群可以减少许多这些问题（成本更高，但无需处理硬件维护），一些云服务提供商还提供[按需市场定价](http://bit.ly/spot-instances)，用于获取便宜但临时的计算资源。
- en: An insidious problem with a cluster that grows organically over time is that
    it’s possible no one has documented how to restart it safely if everything gets
    turned off. If you don’t have a documented restart plan, you should assume you’ll
    have to write one at the worst possible time (one of your authors has been involved
    in debugging this sort of problem on Christmas Eve—this is not the Christmas present
    you want!). At this point you’ll also learn just how long it can take each part
    of a system to get up to speed—it might take minutes for each part of a cluster
    to boot and to start to process jobs, so if you have 10 parts that operate in
    succession, it might take an hour to get the whole system running from cold. The
    consequence is that you might have an hour’s worth of backlogged data. Do you
    then have the necessary capacity to deal with this backlog in a timely fashion?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，有机生长的集群中存在的一个阴险问题是，如果一切都关闭了，可能没有人记录如何安全地重新启动它。如果没有记录的重新启动计划，你应该假设在最糟糕的时候将不得不编写一个（我们的一位作者曾在圣诞前夕处理这种问题
    —— 这可不是你想要的圣诞礼物！）。此时，你还将了解系统中每个部分启动需要多长时间 —— 每个集群部分可能需要几分钟来启动和处理作业，因此如果有10个部分依次操作，整个系统从冷启动到运行可能需要一个小时。其结果是你可能有一个小时的积压数据。那么你是否有必要的容量及时处理这些积压数据呢？
- en: Slack behavior can be a cause of expensive mistakes, and complex and hard-to-anticipate
    behavior can cause unexpected and expensive outcomes. Let’s look at two high-profile
    cluster failures and see what lessons we can learn.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 懈怠的行为可能导致昂贵的错误，复杂和难以预料的行为可能导致意外和昂贵的后果。让我们看看两个高调的集群故障，并学习其中的教训。
- en: $462 Million Wall Street Loss Through Poor Cluster Upgrade Strategy
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过糟糕的集群升级策略导致的462亿美元华尔街损失
- en: In 2012, the high-frequency trading firm [Knight Capital lost $462 million](http://bit.ly/Wall_Street_crash)
    after a bug was introduced during a software upgrade in a cluster. The software
    made orders for more shares than customers had requested.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 2012年，高频交易公司Knight Capital在集群软件升级期间引入错误后，损失了4.62亿美元。软件下达了比客户要求的更多的股票订单。
- en: In the trading software, an older flag was repurposed for a new function. The
    upgrade was rolled out to seven of the eight live machines, but the eighth machine
    used older code to handle the flag, which resulted in the wrong trades being made.
    The Securities and Exchange Commission (SEC) noted that Knight Capital didn’t
    have a second technician review the upgrade and in fact had no established process
    for reviewing such an upgrade.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在交易软件中，一个旧的标志被重新用于新的功能。升级已经在八台实时机器中的七台上推出，但第八台机器使用旧代码处理标志，导致交易错误。证券交易委员会（SEC）指出，Knight
    Capital没有让第二位技术人员审查该升级，实际上也没有建立审查此类升级的流程。
- en: The underlying mistake seems to have had two causes. The first was that the
    software development process hadn’t removed an obsolete feature, so the stale
    code stayed around. The second was that no manual review process was in place
    to confirm that the upgrade was completed successfully.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个根本性错误似乎有两个原因。第一个原因是软件开发过程没有移除一个已过时的特性，因此陈旧的代码仍然存在。第二个原因是没有设置手动审查流程来确认升级是否成功完成。
- en: 'Technical debt adds a cost that eventually has to be paid—preferably by taking
    time when not under pressure to remove the debt. Always use unit tests, both when
    building and when refactoring code. The lack of a written checklist to run through
    during system upgrades, along with a second pair of eyes, could cost you an expensive
    failure. There’s a reason that airplane pilots have to work through a takeoff
    checklist: it means that nobody ever skips the important steps, no matter how
    many times they might have done them before!'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 技术债务会增加一笔成本，最终必须付清 —— 最好在无压力的时候花时间清除债务。无论是构建还是重构代码，始终使用单元测试。在系统升级过程中缺乏书面检查清单和第二双眼睛，可能会导致昂贵的失败。飞行员在起飞前要按照清单逐项检查是有原因的：这意味着无论之前做过多少次，都不会漏掉重要步骤！
- en: Skype’s 24-Hour Global Outage
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Skype全球24小时服务中断
- en: Skype suffered a [24-hour planetwide failure](http://bit.ly/Skype_outage) in
    2010. Behind the scenes, Skype is supported by a peer-to-peer network. An overload
    in one part of the system (used to process offline instant messages) caused delayed
    responses from Windows clients; some versions of the Windows client didn’t properly
    handle the delayed responses and crashed. In all, approximately 40% of the live
    clients crashed, including 25% of the public supernodes. Supernodes are critical
    to routing data in the network.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Skype在2010年经历了[24小时全球范围内的故障](http://bit.ly/Skype_outage)。在幕后，Skype由对等网络支持。系统的某一部分（用于处理离线即时消息）过载导致Windows客户端的响应延迟；某些版本的Windows客户端未能正确处理延迟响应而崩溃。总体而言，大约40%的活跃客户端崩溃，包括25%的公共超级节点。超级节点对网络中的数据路由至关重要。
- en: With 25% of the routing offline (it came back on, but slowly), the network overall
    was under great strain. The crashed Windows client nodes were also restarting
    and attempting to rejoin the network, adding a new volume of traffic on the already
    overloaded system. The supernodes have a back-off procedure if they experience
    too much load, so they started to shut down in response to the waves of traffic.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 路由的25%离线（它后来恢复了，但速度很慢），整个网络处于极大的压力之下。崩溃的Windows客户端节点也在重新启动并尝试重新加入网络，给已经过载的系统增加了新的流量。如果超级节点承受过多负载，它们会采取后退程序，因此它们开始响应波浪式流量而关闭。
- en: Skype became largely unavailable for 24 hours. The recovery process involved
    first setting up hundreds of new “mega-supernodes” configured to deal with the
    increased traffic, and then following up with thousands more. Over the coming
    days, the network recovered.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Skype在整整24小时内大部分时间都无法使用。恢复过程首先涉及设置数百个新的“超级节点”，配置以处理增加的流量，然后继续设置数千个节点。在接下来的几天里，网络逐渐恢复正常。
- en: This incident caused a lot of embarrassment for Skype; clearly, it also changed
    its focus to damage limitation for several tense days. Customers were forced to
    look for alternative solutions for voice calls, which was likely a marketing boon
    for competitors.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这一事件给Skype带来了很多尴尬；显然，它也改变了焦点，几天内主要集中在损害控制上。客户被迫寻找语音通话的替代解决方案，这可能成为竞争对手的市场优势。
- en: Given the complexity of the network and the escalation of failures that occurred,
    this failure likely would have been hard both to predict and to plan for. The
    reason that *all* of the nodes on the network didn’t fail was due to different
    versions of the software and different platforms—there’s a reliability benefit
    to having a heterogeneous network rather than a homogeneous system.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于网络的复杂性和失败的升级，这次故障很可能难以预测和计划。网络上没有所有节点失败的原因是软件的不同版本和不同平台——拥有异构网络而不是同构系统有可靠性的好处。
- en: Common Cluster Designs
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的集群设计
- en: It is common to start with a local ad hoc cluster of reasonably equivalent machines.
    You might wonder if you can add old computers to an ad hoc network, but typically
    older CPUs eat a lot of power and run very slowly, so they don’t contribute nearly
    as much as you might hope compared to one new, high-specification machine. An
    in-office cluster requires someone who can maintain it. A cluster on [Amazon’s
    EC2](http://aws.amazon.com/ec2) or [Microsoft’s Azure](http://azure.microsoft.com/en-us),
    or one run by an academic institution, offloads the hardware support to the provider’s
    team.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的做法是从一个局域的临时集群开始，使用相对等价的机器。你可能会想知道是否可以将旧计算机添加到临时网络中，但通常旧的CPU消耗大量电力并且运行非常慢，因此与一台新的高规格机器相比，它们贡献的远不如你希望的那么多。办公室内的集群需要有人来维护。在[Amazon的EC2](http://aws.amazon.com/ec2)或[Microsoft的Azure](http://azure.microsoft.com/en-us)，或者由学术机构运行的集群，硬件支持交给了服务提供商的团队。
- en: If you have well-understood processing requirements, it might make sense to
    design a custom cluster—perhaps one that uses an InfiniBand high-speed interconnect
    in place of gigabit Ethernet, or one that uses a particular configuration of RAID
    drives that support your read, write, or resiliency requirements. You might want
    to combine CPUs and GPUs on some machines, or just default to CPUs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经理解了处理需求，设计一个定制集群可能是明智的选择——也许使用InfiniBand高速互联代替千兆以太网，或者使用支持你的读写或容错要求的特定配置RAID驱动器。你可能希望在一些机器上结合CPU和GPU，或者只是默认使用CPU。
- en: You might want a massively decentralized processing cluster, like the ones used
    by projects such as *SETI@home* and *Folding@home* through [the Berkeley Open
    Infrastructure for Network Computing (BOINC) system](https://oreil.ly/jNCA9).
    They share a centralized coordination system, but the computing nodes join and
    leave the project in an ad hoc fashion.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要一个像*SETI@home*和*Folding@home*项目使用的大规模分散处理集群，通过[伯克利开放网络计算基础设施（BOINC）系统](https://oreil.ly/jNCA9)共享集中协调系统，但计算节点以临时方式加入和退出项目。
- en: On top of the hardware design, you can run different software architectures.
    Queues of work are the most common and easiest to understand. Typically, jobs
    are put onto a queue and consumed by a processor. The result of the processing
    might go onto another queue for further processing, or it might be used as a final
    result (e.g., being added into a database). Message-passing systems are slightly
    different—messages get put onto a message bus and are then consumed by other machines.
    The messages might time out and get deleted, and they might be consumed by multiple
    machines. In a more complex system, processes talk to each other using interprocess
    communication—this can be considered an expert-level configuration, as there are
    lots of ways that you can set it up badly, which will result in you losing your
    sanity. Go down the IPC route only if you really know that you need it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在硬件设计之上，您可以运行不同的软件架构。工作队列是最常见且最容易理解的。通常，作业被放入队列并由处理器消耗。处理的结果可能会进入另一个队列进行进一步处理，或者作为最终结果使用（例如，添加到数据库中）。消息传递系统略有不同——消息被放入消息总线，然后被其他机器消耗。消息可能会超时并被删除，并且可能会被多个机器消耗。在更复杂的系统中，进程通过进程间通信相互交流——这可以被认为是专家级别的配置，因为有很多方法可以设置得很糟糕，这将导致您失去理智。只有当您确实知道需要它时，才可以选择使用IPC路线。
- en: How to Start a Clustered Solution
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何启动一个集群解决方案
- en: The easiest way to start a clustered system is to begin with one machine that
    will run both the job server and a job processor (just one job processor for one
    CPU). If your tasks are CPU-bound, run one job processor per CPU; if your tasks
    are I/O-bound, run several per CPU. If they’re RAM-bound, be careful that you
    don’t run out of RAM. Get your single-machine solution working with one processor
    and then add more. Make your code fail in unpredictable ways (e.g., do a `1/0`
    in your code, use `kill -9` *`<pid>`* on your worker, pull the power plug from
    the socket so the whole machine dies) to check if your system is robust.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 启动集群系统的最简单方法是从一个机器开始，该机器将同时运行作业服务器和作业处理器（每个CPU只有一个作业处理器）。如果您的任务是CPU绑定的，请为每个CPU运行一个作业处理器；如果任务是I/O绑定的，请为每个CPU运行多个作业处理器。如果它们受RAM限制，请小心不要用完RAM。让您的单机解决方案使用一个处理器运行，并逐步增加更多处理器。通过不可预测的方式使您的代码失败（例如，在您的代码中执行`1/0`，在您的工作进程上使用`kill
    -9 <pid>`，从插座上拔下电源插头，使整个机器死机），以检查您的系统是否健壮。
- en: Obviously, you’ll want to do heavier testing than this—a unit test suite full
    of coding errors and artificial exceptions is good. Ian likes to throw in unexpected
    events, like having a processor run a set of jobs while an external process is
    systematically killing important processes and confirming that these all get restarted
    cleanly by whatever monitoring process is being used.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，您需要进行比这更严格的测试——一个充满编码错误和人为异常的单元测试套件很好。Ian喜欢引入意外事件，例如让一个处理器运行一组作业，同时一个外部进程正在系统地终止重要进程，并确认所有这些进程都能被使用的监控进程干净地重新启动。
- en: Once you have one running job processor, add a second. Check that you’re not
    using too much RAM. Do you process jobs twice as fast as before?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有一个正在运行的作业处理器，添加第二个。检查您是否没有使用太多RAM。您处理作业的速度是否比以前快两倍？
- en: Now introduce a second machine, with just one job processor on that new machine
    and no job processors on the coordinating machine. Does it process jobs as fast
    as when you had the processor on the coordinating machine? If not, why not? Is
    latency a problem? Do you have different configurations? Maybe you have different
    machine hardware, like CPUs, RAM, and cache sizes?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在引入第二台机器，该新机器上只有一个作业处理器，并且协调机器上没有作业处理器。它处理作业的速度是否与您在协调机器上有处理器时一样快？如果不是，为什么？延迟是否是问题？您是否有不同的配置？也许您有不同的机器硬件，如CPU、RAM和缓存大小？
- en: Now add another nine computers and test to see if you’re processing jobs 10
    times faster than before. If not, why not? Are network collisions now occurring
    that slow down your overall processing rate?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在再添加另外九台计算机，并测试看看你是否比以前处理作业快10倍。如果没有，为什么？是不是现在出现了网络冲突，导致整体处理速度变慢？
- en: To reliably start the cluster’s components when the machine boots, we tend to
    use either a `cron` job, [Circus](https://oreil.ly/MCUOQ), or [`supervisord`](http://supervisord.org).
    Circus and `supervisord` are both Python-based and have been around for years.
    `cron` is old but very reliable if you’re just starting scripts like a monitoring
    process that can start subprocesses as required.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在机器启动时可靠地启动集群的组件，我们倾向于使用`cron`任务，[Circus](https://oreil.ly/MCUOQ)，或者[`supervisord`](http://supervisord.org)。Circus和`supervisord`都是基于Python并且已经存在多年。`cron`虽然老旧，但如果你只是启动像监控进程这样的脚本，它非常可靠，可以根据需要启动子进程。
- en: Once you have a reliable cluster, you might want to introduce a random-killer
    tool like Netflix’s [Chaos Monkey](https://oreil.ly/sL5nG), which deliberately
    kills parts of your system to test them for resiliency. Your processes and your
    hardware will die eventually, and it doesn’t hurt to know that you’re likely to
    survive at least the errors you predict might happen.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拥有一个可靠的集群，你可能想引入像Netflix的[Chaos Monkey](https://oreil.ly/sL5nG)这样的随机杀手工具，它故意杀死系统的一部分来测试其弹性。你的进程和硬件最终会失败，了解你可能至少能够幸存你预测可能发生的错误，这不会伤害。
- en: Ways to Avoid Pain When Using Clusters
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在使用集群时避免痛苦的方法
- en: In one particularly painful experience Ian encountered, a series of queues in
    a clustered system ground to a halt. Later queues were not being consumed, so
    they filled up. Some of the machines ran out of RAM, so their processes died.
    Earlier queues were being processed but couldn’t pass their results to the next
    queue, so they crashed. In the end the first queue was being filled but not consumed,
    so it crashed. After that, we were paying for data from a supplier that ultimately
    was discarded. You must sketch out some notes to consider the various ways your
    cluster will die and what will happen when (not *if*) it does. Will you lose data
    (and is this a problem)? Will you have a large backlog that’s too painful to process?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在伊恩经历的一个特别痛苦的经历中，集群系统中一系列队列停顿了。后续队列未被消费，因此它们堆积起来。一些机器的RAM用尽，导致它们的进程死亡。先前的队列正在处理，但无法将结果传递给下一个队列，因此它们崩溃了。最终，第一个队列被填充但未被消费，因此它崩溃了。之后，我们为供应商的数据付费，最终被丢弃。你必须勾勒一些注意事项，考虑你的集群可能会死亡的各种方式，以及发生时会发生什么（不是*如果*）。你会丢失数据（这是一个问题吗）？你会有一个太痛苦无法处理的大后台任务吗？
- en: Having a system that’s easy to debug *probably* beats having a faster system.
    Engineering time and the cost of downtime are *probably* your largest expenses
    (this isn’t true if you’re running a missile defense program, but it is probably
    true for a start-up). Rather than shaving a few bytes by using a low-level compressed
    binary protocol, consider using human-readable text in JSON when passing messages.
    It does add an overhead for sending the messages and decoding them, but when you’re
    left with a partial database after a core computer has caught fire, you’ll be
    glad that you can read the important messages quickly as you work to bring the
    system back online.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个易于调试的系统*可能*比拥有一个更快的系统更重要。工程时间和停机成本*可能*是你最大的开支（如果你在运行导弹防御程序，这就不是真的，但对于初创公司来说可能是真的）。与其通过使用低级压缩的二进制协议来节省几个字节，不如在传递消息时考虑使用JSON中的人类可读文本。这确实会增加发送和解码消息的开销，但当核心计算机着火后，你留下的部分数据库能够快速阅读重要消息时，你会庆幸能够迅速将系统恢复在线。
- en: Make sure it is cheap in time and money to deploy updates to the system—both
    operating system updates and new versions of your software. Every time anything
    changes in the cluster, you risk the system responding in odd ways if it is in
    a schizophrenic state. Make sure you use a deployment system like [Fabric](http://www.fabfile.org),
    [Salt](https://oreil.ly/esyVt), [Chef](http://www.getchef.com), or [Puppet](http://puppetlabs.com),
    or a system image like a Debian *.deb*, a RedHat *.rpm*, or an [Amazon Machine
    Image](https://oreil.ly/5eLt4). Being able to robustly deploy an update that upgrades
    an entire cluster (with a report on any problems found) massively reduces stress
    during difficult times.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在时间和金钱上廉价地部署系统更新——无论是操作系统更新还是软件的新版本。每当集群中的任何变化发生时，如果处于分裂状态，系统就有可能以奇怪的方式响应。确保使用像[Fabric](http://www.fabfile.org)，[Salt](https://oreil.ly/esyVt)，[Chef](http://www.getchef.com)或[Puppet](http://puppetlabs.com)这样的部署系统，或者像Debian的*.deb*，RedHat的*.rpm*，或[Amazon
    Machine Image](https://oreil.ly/5eLt4)这样的系统映像。能够强大地部署一个更新并升级整个集群（并报告任何发现的问题）大大减轻了在困难时期的压力。
- en: Positive reporting is useful. Every day, send an email to someone detailing
    the performance of the cluster. If that email doesn’t turn up, that’s a useful
    clue that something’s happened. You’ll probably want other early warning systems
    that’ll notify you faster too; [Pingdom](https://www.pingdom.com) and [Server
    Density](https://www.serverdensity.com) are particularly useful here. A “dead
    man’s switch” that reacts to the absence of an event (e.g., [Dead Man’s Switch](http://www.deadmansswitch.net))
    is another useful backup.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 积极的报告很有用。每天给某人发送一封电子邮件，详细说明集群的性能。如果这封电子邮件没有送达，那是某事发生的有用线索。你可能还希望有其他更快通知你的早期警报系统；[Pingdom](https://www.pingdom.com)和[Server
    Density](https://www.serverdensity.com)在这方面尤为有用。一个反应于事件缺失的“死人开关”（例如，[Dead Man’s
    Switch](http://www.deadmansswitch.net)）是另一个有用的备份。
- en: Reporting to the team on the health of the cluster is very useful. This might
    be an admin page inside a web application, or a separate report. [Ganglia](http://ganglia.sourceforge.net)
    is great for this. Ian has seen a *Star Trek* LCARS-like interface running on
    a spare PC in an office that plays the “red alert” sound when problems are detected—that’s
    particularly effective at getting the attention of an entire office. We’ve even
    seen Arduinos driving analog instruments like old-fashioned boiler pressure gauges
    (they make a nice sound when the needle moves!) showing system load. This kind
    of reporting is important so that everyone understands the difference between
    “normal” and “this might ruin our Friday night!”
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 向团队报告集群健康情况非常有用。这可能是一个Web应用程序内的管理页面，或者一个单独的报告。[Ganglia](http://ganglia.sourceforge.net)在这方面非常棒。Ian看到过一个类似*星际迷航*
    LCARS界面的界面在办公室的一个备用PC上运行，当检测到问题时会播放“红色警报”声音——这对引起整个办公室的注意特别有效。我们甚至看到Arduinos驱动像老式锅炉压力表这样的模拟仪器（当指针移动时发出漂亮的声音！）显示系统负载。这种报告非常重要，以便每个人都明白“正常”和“可能会毁了我们周五晚上”的区别。
- en: Two Clustering Solutions
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两种聚类解决方案
- en: In this section we introduce IPython Parallel and NSQ.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍IPython Parallel和NSQ。
- en: IPython clusters are easy to use on one machine with multiple cores. Since many
    researchers use IPython as their shell or work through Jupyter Notebooks, it is
    natural to also use it for parallel job control. Building a cluster requires a
    little bit of system administration knowledge. A huge win with IPython Parallel
    is that you can use remote clusters (Amazon’s AWS and EC2, for example) just as
    easily as local clusters.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: IPython集群在一台具有多个核心的机器上易于使用。由于许多研究人员将IPython作为他们的shell或通过Jupyter Notebooks工作，自然也会用它来进行并行作业控制。构建一个集群需要一些系统管理知识。使用IPython
    Parallel的一个巨大优势是，你可以像使用本地集群一样轻松地使用远程集群（例如亚马逊的AWS和EC2）。
- en: NSQ is a production-ready queuing system. It has persistence (so if machines
    die, jobs can be picked up again by another machine) and strong mechanisms for
    scalability. With this greater power comes a slightly greater need for system
    administration and engineering skills. However, NSQ shines in its simplicity and
    ease of use. While many queuing systems exist (such as the popular [Kafka](https://kafka.apache.org)),
    none have such as low a barrier for entry as NSQ.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: NSQ是一个成熟的队列系统。它具有持久性（因此如果机器死机，作业可以由另一台机器继续进行）和强大的可伸缩机制。随着这种更强大的功能，对系统管理和工程技能的需求稍微增加。然而，NSQ在其简单性和易用性方面表现出色。虽然存在许多排队系统（如流行的[Kafka](https://kafka.apache.org)），但没有一个像NSQ那样具有如此低的准入门槛。
- en: Using IPython Parallel to Support Research
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用IPython Parallel支持研究
- en: The IPython clustering support comes via the [IPython Parallel](https://oreil.ly/SAV5i)
    project. IPython becomes an interface to local and remote processing engines where
    data can be pushed among the engines and jobs can be pushed to remote machines.
    Remote debugging is possible, and the message passing interface (MPI) is optionally
    supported. This same ZeroMQ communication mechanism powers the Jupyter Notebook
    interface.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 集群支持通过 [IPython 并行](https://oreil.ly/SAV5i) 项目实现。IPython 成为本地和远程处理引擎的接口，数据可以在引擎之间传递，作业可以推送到远程机器。远程调试是可能的，消息传递接口（MPI）也是可选支持的。这种相同的
    ZeroMQ 通信机制支持 Jupyter Notebook 接口。
- en: This is great for a research setting—you can push jobs to machines in a local
    cluster, interact and debug if there’s a problem, push data to machines, and collect
    results back, all interactively. Note also that PyPy runs IPython and IPython
    Parallel. The combination might be very powerful (if you don’t use `numpy`).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于研究环境非常有用——您可以将作业推送到本地集群中的机器，如果有问题，可以进行交互式调试，将数据推送到机器上，并收集结果，所有这些都是交互式的。请注意，PyPy
    运行 IPython 和 IPython 并行。结合起来可能非常强大（如果您不使用 `numpy`）。
- en: Behind the scenes, ZeroMQ is used as the messaging middleware—be aware that
    ZeroMQ provides no security by design. If you’re building a cluster on a local
    network, you can avoid SSH authentication. If you need security, SSH is fully
    supported, but it makes configuration a little more involved—start on a local
    trusted network and build out as you learn how each component works.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，ZeroMQ 被用作消息中间件——请注意，ZeroMQ 的设计不提供安全性。如果您在本地网络上构建一个集群，可以避免 SSH 认证。如果您需要安全性，SSH
    完全支持，但它使配置变得有点复杂——从一个本地可信网络开始，并随着学习每个组件的工作方式而逐步构建。
- en: The project is split into four components. An *engine* is an extension of the
    IPython kernel; it is a synchronous Python interpreter that runs your code. You’ll
    run a set of engines to enable parallel computing. A *controller* provides an
    interface to the engines; it is responsible for work distribution and supplies
    a *direct* interface and a *load-balanced* interface that provides a work scheduler.
    A *hub* keeps track of engines, schedulers, and clients. *Schedulers* hide the
    synchronous nature of the engines and provide an asynchronous interface.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目分为四个组件。*引擎*是 IPython 内核的扩展；它是一个同步的 Python 解释器，用于运行你的代码。您将运行一组引擎以启用并行计算。*控制器*提供了一个与引擎的接口；它负责工作分配并提供了一个*直接*接口和一个*负载平衡*接口，该接口提供了一个工作调度器。*中心*跟踪引擎、调度器和客户端。*调度器*隐藏了引擎的同步性质并提供了一个异步接口。
- en: On the laptop, we start four engines using `ipcluster start -n 4`. In [Example 10-1](#cluster-ipython-firsttest),
    we start IPython and check that a local `Client` can see our four local engines.
    We can address all four engines using `c[:]`, and we apply a function to each
    engine—`apply_sync` takes a callable, so we supply a zero-argument `lambda` that
    will return a string. Each of our four local engines will run one of these functions,
    returning the same result.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本电脑上，我们使用 `ipcluster start -n 4` 启动了四个引擎。在 [示例 10-1](#cluster-ipython-firsttest)
    中，我们启动了 IPython 并检查本地 `Client` 是否能够看到我们的四个本地引擎。我们可以使用 `c[:]` 来访问所有四个引擎，并且我们将一个函数应用到每个引擎上——`apply_sync`
    接受一个可调用对象，因此我们提供了一个不带参数的`lambda`，它将返回一个字符串。我们的四个本地引擎中的每一个都会运行这些函数，返回相同的结果。
- en: Example 10-1\. Testing that we can see the local engines in IPython
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-1\. 测试我们是否能够在 IPython 中看到本地引擎
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The engines we’ve constructed are now in an empty state. If we import modules
    locally, they won’t be imported into the remote engines.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建的引擎现在处于空状态。如果我们在本地导入模块，它们不会被导入到远程引擎中。
- en: A clean way to import both locally and remotely is to use the `sync_imports`
    context manager. In [Example 10-2](#cluster-ipython-secondtest), we’ll `import
    os` on both the local IPython and the four connected engines and then call `apply_sync`
    again on the four engines to fetch their PIDs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一种干净的方式来进行本地和远程导入是使用 `sync_imports` 上下文管理器。在 [示例 10-2](#cluster-ipython-secondtest)
    中，我们将在本地 IPython 和四个连接的引擎上都`import os`，然后再次在这四个引擎上调用`apply_sync`来获取它们的 PID。
- en: If we didn’t do the remote imports, we’d get a `NameError`, as the remote engines
    wouldn’t know about the `os` module. We can also use `execute` to run any Python
    command remotely on the engines.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有进行远程导入，我们将会得到一个 `NameError`，因为远程引擎不会知道 `os` 模块。我们也可以使用 `execute` 在引擎上远程运行任何
    Python 命令。
- en: Example 10-2\. Importing modules into our remote engines
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-2\. 将模块导入到我们的远程引擎中
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You’ll want to push data to the engines. The `push` command shown in [Example 10-3](#cluster-ipython-pushdata)
    lets you send a dictionary of items that are added to the global namespace of
    each engine. There’s a corresponding `pull` to retrieve items: you give it keys,
    and it’ll return the corresponding values from each of the engines.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您将希望将数据推送到引擎。在 [示例 10-3](#cluster-ipython-pushdata) 中展示的 `push` 命令允许您发送一个字典项，这些项会添加到每个引擎的全局命名空间中。有一个对应的
    `pull` 命令用于检索项目：您给它键，它会返回每个引擎对应的值。
- en: Example 10-3\. Pushing shared data to the engines
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-3\. 将共享数据推送到引擎
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In [Example 10-4](#cluster-ipython-pi), we use these four engines to estimate
    pi. This time we use the `@require` decorator to import the `random` module in
    the engines. We use a direct view to send our work out to the engines; this blocks
    until all the results come back. Then we estimate pi as we did in [Example 9-1](ch09_split_000.xhtml#code-pi-lists-calculation).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 10-4](#cluster-ipython-pi) 中，我们使用这四个引擎来估算圆周率。这次我们使用 `@require` 装饰器在引擎中导入
    `random` 模块。我们使用直接视图将工作发送到引擎；这会阻塞直到所有结果返回。然后我们像 [示例 9-1](ch09_split_000.xhtml#code-pi-lists-calculation)
    中那样估算圆周率。
- en: Example 10-4\. Estimating pi using our local cluster
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-4\. 使用我们的本地集群估算圆周率
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In [Example 10-5](#cluster-ipython-pi-2) we run this on our four local engines.
    As in [Figure 9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes),
    this takes approximately 20 seconds on the laptop.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 10-5](#cluster-ipython-pi-2) 中，我们在我们的四个本地引擎上运行这个。如同 [图 9-5](ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes)
    中所示，这在笔记本电脑上大约需要 20 秒。
- en: Example 10-5\. Estimating pi using our local cluster in IPython
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-5\. 在 IPython 中使用我们的本地集群估算圆周率
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: IPython Parallel offers much more than what’s shown here. Asynchronous jobs
    and mappings over larger input ranges are, of course, possible. MPI is supported,
    which can provide efficient data sharing. The Joblib library introduced in [“Replacing
    multiprocessing with Joblib”](ch09_split_000.xhtml#replacing-multiprocessing-with-joblib)
    can use IPython Parallel as a backend along with Dask (which we introduce in [“Parallel
    Pandas with Dask”](#clustering-dask)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: IPython Parallel 提供的远不止这里展示的功能。当然，还支持异步作业和在更大输入范围上的映射。支持 MPI，可以提供高效的数据共享。在 [“用
    Joblib 替换多处理”](ch09_split_000.xhtml#replacing-multiprocessing-with-joblib) 中介绍的
    Joblib 库可以与 IPython Parallel 一起作为后端使用，以及 Dask（我们在 [“使用 Dask 进行并行 Pandas”](#clustering-dask)
    中介绍）。
- en: One particularly powerful feature of IPython Parallel is that it allows you
    to use larger clustering environments, including supercomputers and cloud services
    like Amazon’s EC2\. The [ElastiCluster project](https://elasticluster.readthedocs.io)
    has support for common parallel environments such as IPython and for deployment
    targets, including AWS, Azure, and OpenStack.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: IPython Parallel 的一个特别强大的功能是允许您使用更大的集群环境，包括超级计算机和云服务，如亚马逊的 EC2\. [ElastiCluster
    项目](https://elasticluster.readthedocs.io) 支持常见的并行环境，如 IPython，以及包括 AWS、Azure 和
    OpenStack 在内的部署目标。
- en: Parallel Pandas with Dask
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Dask 进行并行 Pandas
- en: Dask aims to provide a suite of parallelization solutions that scales from a
    single core on a laptop to multicore machines to thousands of cores in a cluster.
    Think of it as “Apache Spark lite.” If you don’t need all of Apache Spark’s functionality
    (which includes replicated writes and multimachine failover) and you don’t want
    to support a second computation and storage environment, then Dask may provide
    the parallelized and bigger-than-RAM solution you’re after.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的目标是提供一套从笔记本上的单个核心到多核机器再到集群中数千个核心的并行化解决方案。把它想象成“Apache Spark 的精简版”。如果您不需要
    Apache Spark 的所有功能（包括复制写入和多机故障转移），并且不想支持第二个计算和存储环境，那么 Dask 可能提供您所需要的并行化和大于内存解决方案。
- en: 'A task graph is constructed for the lazy evaluation of a number of computation
    scenarios, including pure Python, scientific Python, and machine learning with
    small, medium, and big datasets:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了延迟评估多种计算场景，包括纯 Python、科学 Python 和使用小、中、大数据集的机器学习，构建了一个任务图：
- en: Bag
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Bag
- en: '`bag` enables parallelized computation on unstructured and semistructured data,
    including text files, JSON or user-defined objects. `map`, `filter`, and `groupby`
    are supported on generic Python objects, including lists and sets.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`bag` 可以对非结构化和半结构化数据进行并行计算，包括文本文件、JSON 或用户定义的对象。支持对通用 Python 对象进行 `map`、`filter`
    和 `groupby` 操作，包括列表和集合。'
- en: Array
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数组
- en: '`array` enables distributed and larger-than-RAM `numpy` operations. Many common
    operations are supported, including some linear algebra functions. Operations
    that are inefficient across cores (sorting, for example, and many linear algebra
    operations) are not supported. Threads are used, as NumPy has good thread support,
    so data doesn’t have to be copied during parallelized operations.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`array` 能够进行分布式和大于RAM的 `numpy` 操作。支持许多常见操作，包括一些线性代数函数。不支持跨核心效率低下的操作（例如排序和许多线性代数操作）。使用线程，因为
    NumPy 具有良好的线程支持，所以在并行化操作期间无需复制数据。'
- en: Distributed DataFrame
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式数据框
- en: '`dataframe` enables distributed and larger-than-RAM `Pandas` operations; behind
    the scenes, Pandas is used to represent partial DataFrames that have been partitioned
    using their index. Operations are lazily computed using `.compute()` and otherwise
    look very similar to their Pandas counterparts. Supported functions include `groupby-aggregate`,
    `groupby-apply`, `value_counts`, `drop_duplicates`, and `merge`. By default, threads
    are used, but as Pandas is more GIL-bound than NumPy, you may want to look at
    the Process or Distributed scheduler options.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataframe` 能够进行分布式和大于RAM的 `Pandas` 操作；在幕后，Pandas 用于表示使用其索引分区的部分数据框。操作使用 `.compute()`
    惰性计算，并且在其他方面与其 Pandas 对应物非常相似。支持的函数包括 `groupby-aggregate`、`groupby-apply`、`value_counts`、`drop_duplicates`
    和 `merge`。默认情况下使用线程，但由于 Pandas 比 NumPy 更受 GIL 限制，您可能需要查看进程或分布式调度器选项。'
- en: Delayed
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Delayed
- en: '`delayed` extends the idea we introduced with Joblib in [“Replacing multiprocessing
    with Joblib”](ch09_split_000.xhtml#replacing-multiprocessing-with-joblib) to parallelize
    *chains* of arbitrary Python functions in a lazy fashion. A `visualize()` function
    will draw the task graph to assist in diagnosing issues.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`delayed` 扩展了我们在 [“Replacing multiprocessing with Joblib”](ch09_split_000.xhtml#replacing-multiprocessing-with-joblib)
    中介绍的与 Joblib 类似的思想，以惰性方式并行化任意 Python 函数链。`visualize()` 函数将绘制任务图来帮助诊断问题。'
- en: Futures
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Futures
- en: The `Client` interface enables immediate execution and evolution of tasks, unlike
    `delayed`, which is lazy and doesn’t allow operations like adding or destroying
    tasks. The `Future` interface includes `Queue` and `Lock` to support task collaboration.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Client` 接口支持即时执行和任务演变，与 `delayed` 不同，后者是惰性的，不允许像添加或销毁任务这样的操作。`Future` 接口包括
    `Queue` 和 `Lock`，以支持任务协作。'
- en: Dask-ML
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Dask-ML
- en: A scikit-learn-like interface is provided for scalable machine learning. Dask-ML
    provides cluster support to some scikit-learn algorithms, and it reimplements
    some algorithms (e.g., the `linear_model` set) using Dask to enable learning on
    big data. It closes some of the gap to the Apache Spark distributed machine learning
    toolkit. It also provides support for XGBoost and TensorFlow to be used in a Dask
    cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了类似于 scikit-learn 的接口以进行可扩展的机器学习。Dask-ML 为一些 scikit-learn 算法提供了集群支持，并且使用 Dask
    重新实现了一些算法（例如 `linear_model` 集）以便在大数据上进行学习。它缩小了与 Apache Spark 分布式机器学习工具包之间的差距。还提供了支持
    XGBoost 和 TensorFlow 在 Dask 集群中使用的功能。
- en: 'For Pandas users, Dask can help in two use cases: larger-than-RAM datasets
    and a desire for multicore parallelization.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Pandas 用户，Dask 可以帮助解决两个用例：大于RAM的数据集和多核并行化的需求。
- en: If your dataset is larger than Pandas can fit into RAM, Dask can split the dataset
    by rows into a set of partitioned DataFrames called a *Distributed DataFrame*.
    These DataFrames are split by their index; a subset of operations can be performed
    across each partition. As an example, if you have a set of multi-GB CSV files
    and want to calculate `value_counts` across all the files, Dask will perform partial
    `value_counts` on each DataFrame (one per file) and then combine the results into
    a single set of counts.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据集比 Pandas 能够装入 RAM 的还要大，Dask 可以将数据集按行分割成一组分区数据框，称为 *分布式数据框*。这些数据框按其索引分割；可以在每个分区上执行一部分操作。例如，如果你有一组多GB的CSV文件，并且想要在所有文件上计算
    `value_counts`，Dask 将在每个数据框（每个文件一个）上执行部分 `value_counts`，然后将结果合并为单一的计数集。
- en: A second use case is to take advantage of the multiple cores on your laptop
    (and just as easily across a cluster); we’ll examine this use case here. Recall
    that in [Example 6-24](ch06_split_001.xhtml#pandas_ols_functions), we calculated
    the slope of the line across rows of values in a DataFrame with various approaches.
    Let’s use the two fastest approaches and parallelize them with Dask.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个用例是利用笔记本电脑上的多个核心（以及同样容易地在集群中使用）；我们将在这里研究这个用例。回想一下，在 [Example 6-24](ch06_split_001.xhtml#pandas_ols_functions)
    中，我们用不同的方法计算了数据框中值行的线斜率。让我们使用两种最快的方法，并使用 Dask 进行并行化。
- en: Tip
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: You can use Dask (and Swifter, discussed in the next section) to parallelize
    any side-effect-free function that you’d usually use in an `apply` call. Ian has
    done this for numeric calculations and for calculating text metrics on multiple
    columns of text in a large DataFrame.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Dask（以及下一节讨论的Swifter）并行化任何无副作用的函数，通常在`apply`调用中使用。Ian已经为大型DataFrame中的数字计算和计算文本列的多个文本度量执行了此操作。
- en: With Dask, we have to specify the number of *partitions* to make from our DataFrame;
    a good rule of thumb is to use at least as many partitions as cores so that each
    core can be used. In [Example 10-6](#calculate-ols-dask), we ask for eight partitions.
    We use `dd.from_pandas` to convert our regular Pandas DataFrame into a Dask Distributed
    DataFrame split into eight equal-sized sections.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Dask时，我们必须指定要从DataFrame中创建的*分区*数量；一个经验法则是至少使用与核心数相同的分区，以便每个核心都可以被使用。在[Example
    10-6](#calculate-ols-dask)中，我们请求了八个分区。我们使用`dd.from_pandas`将常规的Pandas DataFrame转换为一个Dask分布式DataFrame，分为八个大小相等的部分。
- en: We call our familiar `ddf.apply` on the Distributed DataFrame, specifying our
    function `ols_lstsq` and the optional expected return type via the `meta` argument.
    Dask requires us to specify when we should apply the computation with the `compute()`
    call; here, we specify the use of `processes` rather than the default `threads`
    to spread our work over multiple cores, avoiding Python’s GIL.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在分布式DataFrame上调用熟悉的`ddf.apply`，指定我们的函数`ols_lstsq`和通过`meta`参数指定的可选的预期返回类型。Dask要求我们使用`compute()`调用指定计算应该何时应用；在这里，我们指定使用`processes`而不是默认的`threads`来将工作分布到多个核心上，避免Python的GIL。
- en: Example 10-6\. Calculating line slopes with multiple cores using Dask
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 10-6\. 使用Dask在多个核心上计算线斜率
- en: '[PRE5]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Running `ols_lstsq_raw` in [Example 10-7](#calculate-ols-dask-raw) with the
    same eight partitions (on four cores with four hyperthreads) in Ian’s laptop,
    we go from the previous single-threaded `apply` result of 6.8 seconds to 1.5 seconds—almost
    a 5× speedup.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ian的笔记本电脑上，使用相同的八个分区（在四个核心和四个超线程的条件下）运行`ols_lstsq_raw`，从之前单线程的`apply`结果的6.8秒提高到1.5秒，速度几乎提升了5倍。
- en: Example 10-7\. Calculating line slopes with multiple cores using Dask
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 10-7\. 使用Dask在多个核心上计算线斜率
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Running `ols_lstsq_raw` with the same eight partitions takes us from the previous
    single-threaded `apply` result of 5.3 seconds with `raw=True` to 1.2 seconds—also
    almost a 5× speedup.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的八个分区运行`ols_lstsq_raw`，将我们从之前使用`raw=True`单线程`apply`结果的5.3秒提高到1.2秒，速度几乎提升了5倍。
- en: If we also use the compiled Numba function from [“Numba to Compile NumPy for
    Pandas”](ch07.xhtml#compiling-numba-for-pandas) with `raw=True`, our runtime drops
    from 0.58 seconds to 0.3 seconds—a further 2× speedup. Functions compiled with
    Numba using NumPy arrays on Pandas DataFrames work well with Dask for very little
    effort.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们还使用从[“Numba to Compile NumPy for Pandas”](ch07.xhtml#compiling-numba-for-pandas)中编译的Numba函数并使用`raw=True`，我们的运行时间从0.58秒降低到0.3秒，进一步提速了2倍。使用Numba在Pandas
    DataFrame上使用NumPy数组编译的函数非常适合与Dask配合使用，而且付出的努力很少。
- en: Parallelized apply with Swifter on Dask
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Dask上使用Swifter进行并行应用
- en: '[Swifter](https://oreil.ly/1SOcL) builds on Dask to provide three parallelized
    options with very simple calls—`apply`, `resample`, and `rolling`. Behind the
    scenes, it takes a subsample of your DataFrame and attempts to vectorize your
    function call. If that works, Swifter will apply it; if it works but it is slow,
    Swifter will run it on multiple cores using Dask.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[Swifter](https://oreil.ly/1SOcL)基于Dask提供了三个并行选项，只需简单的调用—`apply`、`resample`和`rolling`。在幕后，它会对DataFrame的子样本进行采样，并尝试向量化函数调用。如果成功，Swifter将应用它；如果成功但速度慢，Swifter将使用Dask在多个核心上运行它。'
- en: Since Swifter uses heuristics to determine how to run your code, it could run
    slower than if you didn’t use it at all—but the “cost” of trying it is one line
    of effort. It is well worth evaluating.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Swifter使用启发式方法确定如何运行您的代码，因此它可能比根本不使用它运行得慢，但尝试的“成本”仅为一行努力。评估它是非常值得的。
- en: Swifter makes its own decisions about how many cores to use with Dask and how
    many rows to sample for its evaluation; as a result, in [Example 10-8](#calculate-ols-swiftly)
    we see the call to `df.swifter...apply()` looks just like a regular call to `df.apply`.
    In this case, we’ve disabled the progress bar; the progress bar works fine in
    a Jupyter Notebook using the excellent `tqdm` library.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Swifter根据Dask决定使用多少个核心以及对其评估进行采样的行数；因此，在[Example 10-8](#calculate-ols-swiftly)中，我们看到对`df.swifter...apply()`的调用看起来就像对`df.apply`的常规调用。在这种情况下，我们已禁用进度条；在使用优秀的`tqdm`库的Jupyter
    Notebook中，进度条可以正常工作。
- en: Example 10-8\. Calculating line slopes with multiple cores using Dask
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-8\. 使用 Dask 使用多核计算线斜率
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Swifter with `ols_lstsq_raw` and no partitioning choices takes our previous
    single-threaded result of 5.3 seconds down to 1.6 seconds. For this particular
    function and dataset, this is not as fast as the slightly longer Dask solution
    we’ve just looked at, but it does offer a 3× speedup for only one line of code.
    For different functions and datasets, you’ll see different results; it is definitely
    worth an experiment to see whether you can achieve a very easy win.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `ols_lstsq_raw` 和没有分区选择的 Swifter，将我们之前的单线程结果从 5.3 秒降低到 1.6 秒。对于这个特定的函数和数据集，这并不像我们刚刚看过的稍长的
    Dask 解决方案那样快，但它确实只用了一行代码就提供了 3 倍的加速。对于不同的函数和数据集，你将会看到不同的结果；进行实验看看是否可以获得非常容易的成功。
- en: Vaex for bigger-than-RAM DataFrames
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于大于 RAM 的 DataFrame 的 Vaex
- en: '[Vaex](https://vaex.io) is an intriguing new library that provides a Pandas
    DataFrame–like structure that has built-in support for larger-than-RAM computations.
    It neatly combines the features of Pandas and Dask into a single package.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[Vaex](https://vaex.io) 是一个令人感兴趣的新库，提供了类似于 Pandas DataFrame 的结构，内置支持大于 RAM
    的计算。它将 Pandas 和 Dask 的功能整合到一个单独的包中。'
- en: Vaex uses lazy computation to compute column results just-in-time; it’ll compute
    on only the subset of rows required by the user. If, for example, you ask for
    a sum on a billion rows between two columns and you ask for only a *sample* of
    those rows as the result, Vaex will touch only the data for that sample and will
    not compute the sum for all of the nonsampled rows. For interactive work and visualization-driven
    investigation, this can be very efficient.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Vaex 使用惰性计算来按需计算列结果；它将仅计算用户需要的行子集。例如，如果你要求在两列之间的十亿行上进行求和，并且你只要求结果的*样本*，Vaex
    将仅触及那个样本的数据，不会计算所有未被抽样行的总和。对于交互式工作和基于可视化的探索，这可能非常高效。
- en: Pandas’s support of strings comes from CPython; it is GIL-bound, and the string
    objects are larger objects that are scattered in memory and do not support vectorized
    operations. Vaex uses its own custom string library, which enables significantly
    faster string-based operations with a similar Pandas-like interface.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 对字符串的支持来自于 CPython；它受到 GIL 的限制，并且字符串对象是散布在内存中的较大对象，不支持矢量化操作。Vaex 使用自己的自定义字符串库，这使得基于字符串的操作速度显著提高，并具有类似
    Pandas 的界面。
- en: If you’re working on string-heavy DataFrames or larger-than-RAM datasets, Vaex
    is an obvious choice for evaluation. If you commonly work on subsets of a DataFrame,
    the implicit lazy evaluation may make your workflow simpler than adding Dask to
    Pandas DataFrames.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理字符串密集的 DataFrame 或大于 RAM 的数据集，Vaex 是一个显而易见的评估选择。如果你通常在 DataFrame 的子集上工作，隐式的惰性评估可能会使你的工作流程比将
    Dask 添加到 Pandas DataFrame 更简单。
- en: NSQ for Robust Production Clustering
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于稳健生产聚类的 NSQ
- en: In a production environment, you will need a solution that is more robust than
    the other solutions we’ve talked about so far. This is because during the everyday
    operation of your cluster, nodes may become unavailable, code may crash, networks
    may go down, or one of the other thousands of problems that can happen may happen.
    The problem is that all the previous systems have had one computer where commands
    are issued, and a limited and static number of computers that read the commands
    and execute them. We would instead like a system that can have multiple actors
    communicating via a message bus—this would allow us to have an arbitrary and constantly
    changing number of message creators and consumers.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，你将需要比我们到目前为止谈论过的其他解决方案更健壮的解决方案。这是因为在集群的日常运行过程中，节点可能变得不可用，代码可能崩溃，网络可能中断，或者其他可能发生的成千上万的问题可能发生。问题在于，所有先前的系统都有一个发出命令的计算机，以及一定数量的读取命令并执行它们的计算机。相反，我们希望有一个可以通过消息总线进行多个参与者通信的系统——这将允许我们有任意数量且不断变化的消息创建者和消费者。
- en: 'One simple solution to these problems is [NSQ](https://github.com/nsqio/nsq),
    a highly performant distributed messaging platform. While it is written in GO,
    it is completely data format and language agnostic. As a result, there are libraries
    in many languages, and the basic interface into NSQ is a REST API that requires
    only the ability to make HTTP calls. Furthermore, we can send messages in any
    format we want: JSON, Pickle, `msgpack`, and so on. Most importantly, however,
    it provides fundamental guarantees regarding message delivery, and it does all
    of this using two simple design patterns: queues and pub/subs.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一个解决这些问题的简单方法是[NSQ](https://github.com/nsqio/nsq)，一个高性能的分布式消息平台。尽管它是用GO语言编写的，但完全是数据格式和语言无关的。因此，有许多语言的库，并且进入NSQ的基本接口是一个只需能够进行HTTP调用的REST
    API。此外，我们可以以任何格式发送消息：JSON，Pickle，`msgpack`等等。然而最重要的是，它提供了关于消息传递的基本保证，并且所有这些都是使用两种简单的设计模式完成的：队列和发布/订阅。
- en: Note
  id: totrans-132
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We picked NSQ to discuss because it is simple to use and generally performant.
    Most importantly for our purposes, it clearly highlights the considerations you
    must make when thinking about queuing and message passing in a cluster. However,
    other solutions such as ZeroMQ, Amazon’s SQS, Celery, or even Redis may be better
    suited for your application.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择NSQ来讨论，因为它易于使用并且通常表现良好。对于我们的目的而言，最重要的是，它清楚地突显了在考虑在集群中排队和传递消息时必须考虑的因素。然而，其他解决方案如ZeroMQ，Amazon的SQS，Celery，甚至Redis可能更适合您的应用程序。
- en: Queues
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 队列
- en: A *queue* is a type of buffer for messages. Whenever you want to send a message
    to another part of your processing pipeline, you send it to the queue, and it’ll
    wait there until a worker is available. A queue is most useful in distributed
    processing when an imbalance exists between production and consumption. When this
    imbalance occurs, we can simply scale horizontally by adding more data consumers
    until the message production rate and the consumption rate are equal. In addition,
    if the computers responsible for consuming messages go down, the messages are
    not lost but are simply queued until a consumer is available, thus giving us message
    delivery guarantees.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*队列* 是一种消息的缓冲区。每当您想将消息发送到处理管道的另一部分时，您将其发送到队列中，并且它将在那里等待，直到有可用的工作进程。当生产和消费之间存在不平衡时，队列在分布式处理中最为有用。当出现这种不平衡时，我们可以简单地通过增加更多的数据消费者来进行水平扩展，直到消息的生产速率和消费速率相等。此外，如果负责消费消息的计算机出现故障，则消息不会丢失，而是简单地排队，直到有消费者可用，从而为我们提供消息传递的保证。'
- en: For example, let’s say we would like to process new recommendations for a user
    every time that user rates a new item on our site. If we didn’t have a queue,
    the “rate” action would directly call the “recalculate-recommendations” action,
    regardless of how busy the servers dealing with recommendations were. If all of
    a sudden thousands of users decided to rate something, our recommendation servers
    could get so swamped with requests that they could start timing out, dropping
    messages, and generally becoming unresponsive!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们希望每当用户在我们的网站上对新项目进行评分时处理新的推荐。如果没有队列，"rate"操作将直接调用"recalculate-recommendations"操作，而不管处理推荐的服务器有多忙。如果突然间有成千上万的用户决定对某物品进行评分，我们的推荐服务器可能会被请求淹没，它们可能会开始超时，丢失消息，并且通常变得无响应！
- en: On the other hand, with a queue, the recommendation servers ask for more tasks
    when they are ready. A new “rate” action would put a new task on the queue, and
    when a recommendation server becomes ready to do more work, it would grab the
    task from the queue and process it. In this setup, if more users than normal start
    rating items, our queue would fill up and act as a buffer for the recommendation
    servers—their workload would be unaffected, and they could still process messages
    until the queue was empty.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，有了队列，推荐服务器在准备好时会请求更多的任务。新的"rate"操作会将新任务放入队列中，当推荐服务器准备好执行更多工作时，它将从队列中获取任务并处理它。在这种设置中，如果比正常情况下更多的用户开始对项目进行评分，我们的队列会填满并充当推荐服务器的缓冲区——它们的工作负载不会受影响，它们仍然可以处理消息，直到队列为空。
- en: One potential problem with this is that if a queue becomes completely overwhelmed
    with work, it will be storing quite a lot of messages. NSQ solves this by having
    multiple storage backends—when there aren’t many messages, they are stored in
    memory, and as more messages start coming in, the messages get put onto disk.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方式的一个潜在问题是，如果一个队列被工作完全压倒，它将会存储大量消息。NSQ通过具有多个存储后端来解决这个问题 —— 当消息不多时，它们存储在内存中，随着更多消息的到来，消息被放置到磁盘上。
- en: Note
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Generally, when working with queued systems, it is a good idea to try to have
    the downstream systems (i.e., the recommendation systems in the preceding example)
    be at 60% capacity with a normal workload. This is a good compromise between allocating
    too many resources for a problem and giving your servers enough extra power for
    when the amount of work increases beyond normal levels.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，在处理排队系统时，最好尝试使下游系统（例如上面示例中的推荐系统）在正常工作负载下处于60%的容量。这是在为问题分配过多资源和确保服务器有足够的额外能力以处理超出正常工作量的情况之间的一个很好的折衷方案。
- en: Pub/sub
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发布/订阅
- en: 'A *pub/sub* (short for *publisher/subscriber*), on the other hand, describes
    who gets what messages. A data publisher can push data out of a particular topic,
    and data subscribers can subscribe to different feeds of data. Whenever the publisher
    puts out a piece of information, it gets sent to all the subscribers—each gets
    an identical copy of the original information. You can think of this like a newspaper:
    many people can subscribe to a particular newspaper, and whenever a new edition
    of the newspaper comes out, every subscriber gets an identical copy of it. In
    addition, the producer of the newspaper doesn’t need to know all the people its
    papers are being sent to. As a result, publishers and subscribers are decoupled
    from each other, which allows our system to be more robust as our network changes
    while still in production.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*发布/订阅*（简称*发布者/订阅者*）描述了谁会接收到什么消息。数据发布者可以从特定主题推送数据，数据订阅者可以订阅不同的数据源。每当发布者发布一条信息时，它被发送给所有订阅者
    —— 每个订阅者都会得到原始信息的相同副本。你可以把它想象成报纸：很多人可以订阅同一份报纸，每当新版报纸出来时，每个订阅者都会得到相同的副本。此外，报纸的生产者不需要知道它的报纸被发送给了所有订阅者。因此，发布者和订阅者在系统中是解耦的，这使得我们的系统在网络变化时仍然可以保持更加健壮的生产状态。
- en: In addition, NSQ adds the notion of a *data consumer*; that is, multiple processes
    can be connected to the same data subscription. Whenever a new piece of data comes
    out, every subscriber gets a copy of the data; however, only one consumer of each
    subscription sees that data. In the newspaper analogy, you can think of this as
    having multiple people in the same household who read the newspaper. The publisher
    will deliver one paper to the house, since that house has only one subscription,
    and whoever in the house gets to it first gets to read that data. Each subscriber’s
    consumers do the same processing to a message when they see it; however, they
    can potentially be on multiple computers and thus add more processing power to
    the entire pool.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，NSQ还引入了*数据消费者*的概念；也就是说，可以将多个进程连接到同一个数据订阅中。每当新的数据出现时，每个订阅者都会收到数据的一份副本；然而，每个订阅的消费者只会看到这些数据中的一部分。在报纸的类比中，可以将其想象为同一户中有多个人在读同一份报纸。出版者会将一份报纸送到这户人家，因为这户只有一个订阅，那么谁先看到就可以阅读该数据。每个订阅的消费者在看到消息时会进行相同的处理；然而，它们可能位于多台计算机上，从而为整个池增加了更多的处理能力。
- en: We can see a depiction of this pub/sub/consumer paradigm in [Figure 10-1](#clustering_nsq_overview).
    If a new message gets published on the “clicks” topic, all the subscribers (or,
    in NSQ parlance, *channels*—i.e., “metrics,” “spam_analysis,” and “archive”) will
    get a copy. Each subscriber is composed of one or more consumers, which represent
    actual processes that react to the messages. In the case of the “metrics” subscriber,
    only one consumer will see the new message. The next message will go to another
    consumer, and so on.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 10-1](#clustering_nsq_overview)中看到这种发布/订阅/消费者范式的描绘。如果在“clicks”主题上发布了新消息，所有订阅者（或者在NSQ术语中，*通道*
    —例如，“metrics”，“spam_analysis”，和“archive”）将会收到一份副本。每个订阅者由一个或多个消费者组成，代表实际处理消息的进程。在“metrics”订阅者的情况下，只有一个消费者会看到新消息。接下来的消息将传递给另一个消费者，依此类推。
- en: '![hpp2 1001](Images/hpp2_1001.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![hpp2 1001](Images/hpp2_1001.png)'
- en: Figure 10-1\. NSQ’s pub/sub-like topology
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-1\. NSQ的发布/订阅式拓扑结构
- en: The benefit of spreading the messages among a potentially large pool of consumers
    is essentially automatic load balancing. If a message takes quite a long time
    to process, that consumer will not signal to NSQ that it is ready for more messages
    until it’s done, and thus the other consumers will get the majority of future
    messages (until that original consumer is ready to process again). In addition,
    it allows existing consumers to disconnect (whether by choice or because of failure)
    and new consumers to connect to the cluster while still maintaining processing
    power within a particular subscription group. For example, if we find that “metrics”
    takes quite a while to process and often is not keeping up with demand, we can
    simply add more processes to the consumer pool for that subscription group, giving
    us more processing power. On the other hand, if we see that most of our processes
    are idle (i.e., not getting any messages), we can easily remove consumers from
    this subscription pool.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 将消息分散到可能的大量消费者之间的好处在于自动负载均衡。如果一个消息需要很长时间来处理，那么该消费者在完成之前不会向 NSQ 发出已准备好接收更多消息的信号，因此其他消费者将获得未来大部分的消息（直到原始消费者再次准备好处理）。此外，它允许现有的消费者断开连接（无论是自愿还是由于故障），并允许新的消费者连接到集群，同时仍然在特定订阅组内保持处理能力。例如，如果我们发现“指标”需要相当长的时间来处理，并且通常无法满足需求，我们可以简单地为该订阅组的消费者池添加更多进程，从而为我们提供更多的处理能力。另一方面，如果我们看到大多数进程处于空闲状态（即，没有收到任何消息），我们可以轻松地从此订阅池中删除消费者。
- en: It is also important to note that anything can publish data. A consumer doesn’t
    simply need to be a consumer—it can consume data from one topic and then publish
    it to another topic. In fact, this chain is an important workflow when it comes
    to this paradigm for distributed computing. Consumers will read from a topic of
    data, transform the data in some way, and then publish the data onto a new topic
    that other consumers can further transform. In this way, different topics represent
    different data, subscription groups represent different transformations on the
    data, and consumers are the actual workers who transform individual messages.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 还需注意的是，任何东西都可以发布数据。消费者不仅仅需要是消费者，它可以从一个主题消费数据，然后将其发布到另一个主题。实际上，这种链条在涉及分布式计算范式时是一个重要的工作流程。消费者将从一个数据主题中读取数据，以某种方式转换数据，然后将数据发布到其他消费者可以进一步转换的新主题上。通过这种方式，不同的主题代表不同的数据，订阅组代表对数据的不同转换，而消费者则是实际转换个别消息的工作者。
- en: Furthermore, this system provides an incredible redundancy. There can be many
    `nsqd` processes that each consumer connects to, and there can be many consumers
    connected to a particular subscription. This makes it so that no single point
    of failure exists, and your system will be robust even if several machines disappear.
    We can see in [Figure 10-2](#clustering_nsq_spof) that even if one of the computers
    in the diagram goes down, the system is still able to deliver and process messages.
    In addition, since NSQ saves pending messages to disk when shutting down, unless
    the hardware loss is catastrophic, your data will most likely still be intact
    and be delivered. Last, if a consumer is shut down before responding to a particular
    message, NSQ will resend that message to another consumer. This means that even
    as consumers get shut down, we know that all the messages in a topic will be responded
    to at least once.^([1](ch10.xhtml#idm46122403968536))
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该系统提供了令人难以置信的冗余性。每个消费者连接的可能有许多 `nsqd` 进程，并且可能有许多消费者连接到特定的订阅。这样，即使出现多台机器消失，也不会存在单点故障，您的系统将是健壮的。我们可以在[图 10-2](#clustering_nsq_spof)
    中看到，即使图中的计算机之一宕机，系统仍能够交付和处理消息。此外，由于 NSQ 在关闭时将待处理消息保存到磁盘上，除非硬件丢失是灾难性的，否则您的数据很可能仍然完好无损并得到交付。最后，如果消费者在回复特定消息之前关闭，NSQ
    将将该消息重新发送给另一个消费者。这意味着即使消费者被关闭，我们也知道所有主题中的所有消息至少会被响应一次。^([1](ch10.xhtml#idm46122403968536))
- en: '![hpp2 1002](Images/hpp2_1002.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![hpp2 1002](Images/hpp2_1002.png)'
- en: Figure 10-2\. NSQ connection topology
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. NSQ 连接拓扑
- en: Distributed Prime Calculation
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式素数计算
- en: Code that uses NSQ is generally asynchronous (see [Chapter 8](ch08.xhtml#chapter-concurrency)
    for a full explanation), although it doesn’t necessarily have to be.^([2](ch10.xhtml#idm46122403960472))
    In the following example, we will create a pool of workers that read from a topic
    called *numbers* where the messages are simply JSON blobs with numbers in them.
    The consumers will read this topic, find out if the numbers are primes, and then
    write to another topic, depending on whether the numbers were prime. This will
    give us two new topics, *prime* and *non_prime*, that other consumers can connect
    to in order to do more calculations.^([3](ch10.xhtml#idm46122403957848))
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NSQ 的代码通常是异步的（详见 [Chapter 8](ch08.xhtml#chapter-concurrency) 进行完整的解释），尽管并不一定必须是。^([2](ch10.xhtml#idm46122403960472))
    在下面的例子中，我们将创建一个工作池，从一个名为 *numbers* 的主题中读取消息，这些消息只是简单的包含数字的 JSON。消费者将读取此主题，查找这些数字是否为质数，然后根据数字是否为质数将其写入另一个主题。这将给我们带来两个新主题，*prime*
    和 *non_prime*，其他消费者可以连接到这些主题以进行更多计算。^([3](ch10.xhtml#idm46122403957848))
- en: Note
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '`pynsq` (last release Nov 11, 2018) depends on a very outdated release of `tornado`
    (4.5.3, from Jan 6, 2018). This is a good example use case for Docker (discussed
    in [“Docker”](#docker)).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`pynsq`（最后发布于 2018 年 11 月 11 日）依赖于一个非常过时的 `tornado` 版本（4.5.3，于 2018 年 1 月 6
    日发布）。这是 Docker 的一个很好的使用案例（在 [“Docker”](#docker) 中讨论）。'
- en: As we’ve said before, there are many benefits to doing CPU-bound work like this.
    First, we have all the guarantees of robustness, which may or may not be useful
    for this project. More importantly, however, we get automatic load balancing.
    That means that if one consumer gets a number that takes a particularly long time
    to process, the other consumers will pick up the slack.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，像这样进行 CPU 绑定工作有很多好处。首先，我们拥有所有健壮性的保证，这对这个项目可能有用，也可能没用。然而更重要的是，我们获得了自动负载平衡。这意味着，如果一个消费者得到一个需要很长时间来处理的数字，其他消费者会填补空缺。
- en: We create a consumer by creating an `nsq.Reader` object with the topic and subscription
    group specified (as can be seen at the end of [Example 10-9](#clustering_nsq_example)).
    We also must specify the location of the running `nsqd` instance (or the `nsqlookupd`
    instance, which we will not get into in this section). In addition, we specify
    a *handler*, which is simply a function that gets called for each message from
    the topic. To create a producer, we create an `nsq.Writer` object and specify
    the location of one or more `nsqd` instances to write to. This gives us the ability
    to write to `nsq`, simply by specifying the topic name and the message.^([4](ch10.xhtml#idm46122403943144))
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个消费者，通过指定主题和订阅组来创建一个 `nsq.Reader` 对象（如在 [Example 10-9](#clustering_nsq_example)
    的最后部分可以看到）。我们还必须指定运行中的 `nsqd` 实例的位置（或者 `nsqlookupd` 实例，在本节中我们不会深入讨论）。此外，我们还必须指定一个
    *handler*，这只是一个用于处理从主题接收到的每条消息的函数。为了创建一个生产者，我们创建一个 `nsq.Writer` 对象，并指定一个或多个要写入的
    `nsqd` 实例的位置。这使我们能够通过指定主题名称和消息来写入到 `nsq`。
- en: Example 10-9\. Distributed prime calculation with NSQ
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-9\. 使用 NSQ 进行分布式质数计算
- en: '[PRE8]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](Images/1.png)](#co_clusters_and_job_queues_CO1-1)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_clusters_and_job_queues_CO1-1)'
- en: We must signal to NSQ when we are done with a message. This will make sure the
    message is not redelivered to another reader in case of failure.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理完一条消息时，我们必须通知 NSQ。这将确保在失败时消息不会重新传递给另一个读者。
- en: Note
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We can handle messages asynchronously by enabling `message.enable_async()` in
    the message handler after the message is received. However, note that NSQ uses
    the older callback mechanisms with `tornado`’s IOLoop (discussed in [“tornado”](ch08.xhtml#tornado)).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在消息接收后在消息处理程序中启用 `message.enable_async()` 来异步处理消息。但是请注意，NSQ 使用较旧的回调机制与
    `tornado` 的 IOLoop（在 [“tornado”](ch08.xhtml#tornado) 中讨论）。
- en: To set up the NSQ ecosystem, start an instance of `nsqd` on our local machine:^([5](ch10.xhtml#idm46122402448536))
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 NSQ 生态系统，在我们的本地机器上启动一个 `nsqd` 实例：^([5](ch10.xhtml#idm46122402448536))
- en: '[PRE9]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we can start as many instances of our Python code ([Example 10-9](#clustering_nsq_example))
    as we want. In fact, we can have these instances running on other computers as
    long as the reference to the `nsqd_tcp_address` in the instantiation of the `nsq.Reader`
    is still valid. These consumers will connect to `nsqd` and wait for messages to
    be published on the *numbers* topic.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以启动尽可能多的 Python 代码实例（[Example 10-9](#clustering_nsq_example)）。事实上，我们可以让这些实例在其他计算机上运行，只要
    `nsqd_tcp_address` 在 `nsq.Reader` 实例化中的引用仍然有效。这些消费者将连接到 `nsqd` 并等待在 *numbers*
    主题上发布的消息。
- en: 'Data can be published to the *numbers* topic in many ways. We will use command-line
    tools to do this, since knowing how to poke and prod a system goes a long way
    in understanding how to properly deal with it. We can simply use the HTTP interface
    to publish messages to the topic:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以通过多种方式发布到*numbers*主题。我们将使用命令行工具来完成这个任务，因为了解如何操作系统对于正确处理它至关重要。我们可以简单地使用HTTP接口将消息发布到主题：
- en: '[PRE10]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As this command starts running, we are publishing messages with different numbers
    in them to the *numbers* topic. At the same time, all of our producers will start
    outputting status messages indicating that they have seen and processed messages.
    In addition, these numbers are being published to either the *prime* or the *non_prime*
    topic. This allows us to have other data consumers that connect to either of these
    topics to get a filtered subset of our original data. For example, an application
    that requires only the prime numbers can simply connect to the *prime* topic and
    constantly have new primes for its calculation. We can see the status of our calculation
    by using the `stats` HTTP endpoint for `nsqd`:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当此命令开始运行时，我们正在向*numbers*主题中发布包含不同数字的消息。与此同时，我们所有的生产者将开始输出状态消息，指示它们已经看到并处理了消息。此外，这些数字正在发布到*prime*或*non_prime*主题中的一个。这使我们能够有其他数据消费者连接到这些主题中的任何一个来获取原始数据的过滤子集。例如，只需要质数的应用程序可以简单地连接到*prime*主题，并不断地获得其计算所需的新质数。我们可以使用`nsqd`的`stats`HTTP端点来查看我们的计算状态：
- en: '[PRE11]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see here that the *numbers* topic has one subscription group, *worker_group_a*,
    with one consumer. In addition, the subscription group has a large depth of 1,926
    messages, which means that we are putting messages into NSQ faster than we can
    process them. This would be an indication to add more consumers so that we have
    more processing power to get through more messages. Furthermore, we can see that
    this particular consumer has been connected for 15 seconds, has processed 1,083
    messages, and currently has 1 message in flight. This status endpoint gives quite
    a good deal of information for debugging your NSQ setup! Last, we see the *prime*
    and *non_prime* topics, which have no subscribers or consumers. This means that
    the messages will be stored until a subscriber comes requesting the data.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到*numbers*主题有一个订阅组，*worker_group_a*，有一个消费者。此外，订阅组有一个很大的深度，有1,926条消息，这意味着我们正在将消息放入NSQ的速度比我们处理它们的速度快。这将提示我们增加更多的消费者，以便我们有更多的处理能力来处理更多的消息。此外，我们可以看到此特定消费者已连接了15秒，已处理了1,083条消息，并且当前有1条消息正在传输中。此状态端点为调试您的NSQ设置提供了相当多的信息！最后，我们看到*prime*和*non_prime*主题，它们没有订阅者或消费者。这意味着消息将被存储，直到有订阅者请求数据为止。
- en: Note
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In production systems, you can use the even more powerful tool `nsqadmin`, which
    provides a web interface with very detailed overviews of all topics/subscribers
    and consumers. In addition, it allows you to easily pause and delete subscribers
    and topics.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产系统中，您可以使用更强大的工具`nsqadmin`，它提供了一个具有非常详细的所有主题/订阅者和消费者概览的Web界面。此外，它允许您轻松地暂停和删除订阅者和主题。
- en: 'To actually see the messages, we would create a new consumer for the *prime*
    (or *non_prime*) topic that simply archives the results to a file or database.
    Alternatively, we can use the `nsq_tail` tool to take a peek at the data and see
    what it contains:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要实际看到消息，我们将为*prime*（或*non_prime*）主题创建一个新的消费者，简单地将结果存档到文件或数据库中。或者，我们可以使用`nsq_tail`工具来窥探数据并查看其内容：
- en: '[PRE12]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Other Clustering Tools to Look At
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他要注意的集群工具
- en: Job processing systems using queues have existed since the start of the computer
    science industry, back when computers were very slow and lots of jobs needed to
    be processed. As a result, there are *many* libraries for queues, and many of
    these can be used in a cluster configuration. We strongly suggest that you pick
    a mature library with an active community behind it and supporting the same feature
    set that you’ll need without too many additional features.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用队列的作业处理系统自计算机科学行业开始就存在，当时计算机速度非常慢，需要处理大量作业。因此，有许多队列库，其中许多可以在集群配置中使用。我们强烈建议您选择一个成熟的库，并有一个活跃的社区支持它，并支持您需要的相同功能集而不包含太多其他功能。
- en: 'The more features a library has, the more ways you’ll find to misconfigure
    it and waste time on debugging. Simplicity is *generally* the right aim when dealing
    with clustered solutions. Here are a few of the more commonly used clustering
    solutions:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 库拥有的功能越多，你就会发现越多的方法来误配置它，并浪费时间进行调试。在处理集群解决方案时，简单性 *通常* 是正确的目标。以下是一些常用的集群解决方案：
- en: '[ZeroMQ](https://zeromq.org) is a low-level and performant messaging library
    that enables you to send messages between nodes. It natively supports pub/sub
    paradigms and can also communicate over multiple types of transports (TCP, UDP,
    WebSocket, etc). It is quite low level and doesn’t provide many useful abstractions,
    which can make its use a bit difficult. That being said, it’s in use in Jupyter,
    Auth0, Spotify, and many more places!'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ZeroMQ](https://zeromq.org) 是一个低级别且高效的消息传递库，可以在节点之间发送消息。它原生支持发布/订阅范式，并且可以通过多种传输方式进行通信（TCP、UDP、WebSocket
    等）。它相当底层，不提供太多有用的抽象，这可能会使其使用有些困难。尽管如此，它在 Jupyter、Auth0、Spotify 等许多地方都有使用！'
- en: '[Celery](http://www.celeryproject.org) (BSD license) is a widely used asynchronous
    task queue using a distributed messaging architecture, written in Python. It supports
    Python, PyPy, and Jython. It typically it uses RabbitMQ as the message broker,
    but it also supports Redis, MongoDB, and other storage systems. It is often used
    in web development projects. Andrew Godwin discusses Celery in [“Task Queues at
    Lanyrd.com (2014)”](ch12.xhtml#lessons-from-field-andrew).'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Celery](http://www.celeryproject.org)（BSD 许可证）是一个广泛使用的异步任务队列，采用分布式消息架构，用 Python
    编写。它支持 Python、PyPy 和 Jython。通常情况下，它使用 RabbitMQ 作为消息代理，但也支持 Redis、MongoDB 和其他存储系统。它经常用于
    Web 开发项目中。Andrew Godwin 在 [“Lanyrd.com 上的任务队列 (2014)”](ch12.xhtml#lessons-from-field-andrew)
    中讨论了 Celery。'
- en: '[Airflow](https://airflow.apache.org) and [Luigi](https://github.com/spotify/luigi)
    use directed acyclic graphs to chain dependent jobs into sequences that run reliably,
    with monitoring and reporting services. They’re widely used in industry for data
    science tasks, and we recommend reviewing these before you embark on a custom
    solution.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Airflow](https://airflow.apache.org) 和 [Luigi](https://github.com/spotify/luigi)
    使用有向无环图将依赖任务链接成可靠运行的序列，配备监控和报告服务。它们在数据科学任务中被广泛应用于工业界，我们建议在自定义解决方案之前先进行审查。'
- en: '[Amazon’s Simple Queue Service (SQS)](http://aws.amazon.com/sqs) is a job processing
    system integrated into AWS. Job consumers and producers can live inside AWS or
    can be external, so SQS is easy to start with and supports easy migration into
    the cloud. Library support exists for many languages.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[   [亚马逊简单队列服务 (SQS)](http://aws.amazon.com/sqs) 是集成到 AWS 中的作业处理系统。作业消费者和生产者可以位于
    AWS 内部，也可以是外部的，因此 SQS 容易上手，并支持轻松迁移到云端。许多语言都有对应的库支持。'
- en: Docker
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker
- en: '[Docker](https://docker.com) is a tool of general importance in the Python
    ecosystem. However, the problems it solves are particularly important when dealing
    with a large team or a cluster. In particular, Docker helps to create reproducible
    environments in which to run your code, share/control runtime environments, easily
    share runnable code between team members, and deploy code to a cluster of nodes
    based on resource needs.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[Docker](https://docker.com) 是 Python 生态系统中的一个重要工具。然而，它解决的问题在处理大型团队或集群时尤为重要。特别是
    Docker 有助于创建可复制的环境来运行代码，在其中共享/控制运行时环境，轻松地在团队成员之间共享可运行代码，并根据资源需求将代码部署到节点集群中。'
- en: Docker’s Performance
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker 的性能
- en: One common misconception about Docker is that it substantially slows down the
    runtime performance of the applications it is running. While this can be true
    in some cases, it generally is not. Furthermore, most of the performance degradations
    can almost always be removed with some easy configuration changes.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个关于 Docker 的常见误解，即它会大幅降低其运行应用程序的性能。虽然在某些情况下这可能是正确的，但通常并非如此。此外，大多数性能降低几乎总是可以通过一些简单的配置更改来消除。
- en: In terms of CPU and memory access, Docker (and all other container-based solutions)
    will *not* lead to any performance degradations. This is because Docker simply
    creates a special namespace within the host operating system where the code can
    run normally, albeit with separate constraints from other running programs. Essentially,
    Docker code accesses the CPU and memory in the same way that every other program
    on the computer does; however, it can have a separate set of configuration values
    to fine-tune resource limits.^([6](ch10.xhtml#idm46122402901784))
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 就 CPU 和内存访问而言，Docker（以及所有其他基于容器的解决方案）*不会*导致任何性能降级。这是因为 Docker 简单地在主机操作系统中创建一个特殊的命名空间，代码可以在其中正常运行，尽管受到与其他运行程序不同的约束。基本上，Docker
    代码以与计算机上的每个其他程序相同的方式访问 CPU 和内存；然而，它可以有一组单独的配置值来微调资源限制。^([6](ch10.xhtml#idm46122402901784))
- en: This is because Docker is an instance of OS-level virtualization, as opposed
    to hardware virtualization such as VMware or VirtualBox. With hardware virtualization,
    software runs on “fake” hardware that introduces overhead accessing all resources.
    On the other hand, OS virtualization uses the native hardware but runs on a “fake”
    operating system. Thanks to the `cgroups` Linux feature, this “fake” operating
    system can be tightly coupled to the running operating system, which gives the
    possibility of running with almost no overhead.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为 Docker 是操作系统级虚拟化的一个实例，而不是像 VMware 或 VirtualBox 这样的硬件虚拟化。在硬件虚拟化中，软件运行在“虚拟”硬件上，访问所有资源都会引入开销。另一方面，操作系统虚拟化使用本地硬件，但在“虚拟”操作系统上运行。由于
    `cgroups` Linux 功能，这种“虚拟”操作系统可以紧密耦合到正在运行的操作系统中，这使得几乎没有开销地运行成为可能。
- en: Warning
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: '`cgroups` is specifically a feature in the Linux kernel. As a result, performance
    implications discussed here are restricted to Linux systems. In fact, to run Docker
    on macOS or Windows, we first must run the Linux kernel in a hardware-virtualized
    environment. Docker Machine, the application helping streamline this process,
    uses VirtualBox to accomplish this. As a result, you will see performance overhead
    from the hardware-virtualized portion of the process. This overhead will be greatly
    reduced when running on a Linux system, where hardware virtualization is not needed.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`cgroups` 是 Linux 内核中的一个特定功能。因此，这里讨论的性能影响仅限于 Linux 系统。事实上，要在 macOS 或 Windows
    上运行 Docker，我们首先必须在硬件虚拟化环境中运行 Linux 内核。Docker Machine 是一个帮助简化此过程的应用程序，它使用 VirtualBox
    来完成这一过程。因此，在 Linux 系统上运行时，由硬件虚拟化部分引起的性能开销将大大减少。'
- en: 'As an example, let’s create a simple Docker container to run the 2D diffusion
    code from [Example 6-17](ch06_split_001.xhtml#matrix_numpy_memory2). As a baseline,
    we can run the code on the host system’s Python to get a benchmark:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以创建一个简单的 Docker 容器来运行来自[示例 6-17](ch06_split_001.xhtml#matrix_numpy_memory2)的二维扩散代码。作为基准，我们可以在主机系统的
    Python 上运行代码以获取基准：
- en: '[PRE13]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To create our Docker container, we have to make a directory that contains the
    Python file *diffusion_numpy_memory2.py*, a `pip` requirements file for dependencies,
    and a *Dockerfile*, as shown in [Example 10-10](#simple-docker).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建我们的 Docker 容器，我们必须创建一个包含 Python 文件 *diffusion_numpy_memory2.py*、一个用于依赖关系的
    `pip` 要求文件和一个 *Dockerfile* 的目录，如[示例 10-10](#simple-docker)所示。
- en: Example 10-10\. Simple Docker container
  id: totrans-194
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-10\. 简单的 Docker 容器
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The *Dockerfile* starts by stating what container we’d like to use as our base.
    These base containers can be a wide selection of Linux-based operating systems
    or a higher-level service. The Python Foundation provides [official containers
    for all major Python versions](https://hub.docker.com/_/python), which makes selecting
    the Python version you’d like to use incredibly simple. Next, we define the location
    of our working directory (the selection of `/usr/src/app` is arbitrary), copy
    our requirements file into it, and begin setting up our environment as we normally
    would on our local machine, using `RUN` commands.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dockerfile* 从指定我们希望用作基础的容器开始。这些基础容器可以是各种基于 Linux 的操作系统或更高级别的服务。Python 基金会为所有主要
    Python 版本提供[官方容器](https://hub.docker.com/_/python)，这使得选择要使用的 Python 版本非常简单。接下来，我们定义我们的工作目录的位置（选择
    `/usr/src/app` 是任意的），将我们的要求文件复制到其中，并开始设置我们的环境，就像我们在本地机器上使用 `RUN` 命令一样。'
- en: One major difference between setting up your development environment normally
    and on Docker are the `COPY` commands. They copy files from the local directory
    into the container. For example, the *requirements.txt* file is copied into the
    container so that it is there for the `pip install` command. Finally, at the end
    of the *Dockerfile*, we copy all the files from the current directory into the
    container and tell Docker to run `python ./diffusion_numpy_memory2.py` when the
    container starts.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常设置开发环境和在 Docker 上设置环境之间的一个主要区别是`COPY`命令。它们将文件从本地目录复制到容器中。例如，*requirements.txt*
    文件被复制到容器中，以便在`pip install`命令时使用。最后，在*Dockerfile*的末尾，我们将当前目录中的所有文件复制到容器中，并告诉 Docker
    在容器启动时运行`python ./diffusion_numpy_memory2.py`。
- en: Caution
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In the *Dockerfile* in [Example 10-10](#simple-docker), beginners often wonder
    why we first copy only the requirements file and then later copy the entire directory
    into the container. When building a container, Docker tries hard to cache each
    step in the build process. To determine whether the cache is still valid, the
    contents of the files being copied back and forth are checked. By first copying
    only the requirements file and *then* moving the rest of the directory, we will
    have to run `pip install` only if the requirements file changes. If only the Python
    source has changed, a new build will use cached build steps and skip straight
    to the second `COPY` command.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 10-10](#simple-docker) 的*Dockerfile*中，初学者经常会想知道为什么我们首先只复制需求文件，然后再将整个目录复制到容器中。在构建容器时，Docker
    会尝试缓存构建过程的每一步。为了确定缓存是否仍然有效，检查复制来回的文件的内容。通过首先只复制需求文件，然后再移动其余目录，如果需求文件未发生变化，则只需运行一次`pip
    install`。如果仅 Python 源代码发生了更改，新构建将使用缓存的构建步骤，并直接跳过第二个`COPY`命令。
- en: 'Now we are ready to build and run the container, which can be named and tagged.
    Container names generally take the format `*<username>*/*<project-name>*`,^([7](ch10.xhtml#idm46122403724904))
    while the optional tag generally is either descriptive of the current version
    of the code or simply the tag `latest` (this is the default and will be applied
    automatically if no tag is specified). To help with versioning, it is general
    convention to always tag the most recent build with `latest` (which will get overwritten
    when a new build is made) as well as a descriptive tag so that we can easily find
    this version again in the future:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好构建和运行容器了，可以为其命名和打标签。容器名称通常采用`*<username>*/*<project-name>*`的格式，^([7](ch10.xhtml#idm46122403724904))而可选的标签通常是描述当前代码版本的描述性标签，或者简单地是标签`latest`（这是默认的，如果未指定标签将自动应用）。为了帮助版本管理，通常的约定是始终将最新构建标记为`latest`（当进行新构建时将被覆盖），以及一个描述性标签，以便将来可以轻松找到这个版本：
- en: '[PRE15]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see that at its core, Docker is not slower than running on the host
    machine in any meaningful way when the task relies mainly on CPU/memory. However,
    as with anything, there is no free lunch, and at times Docker performance suffers.
    While a full discussion of optimizing Docker containers is outside the scope of
    this book, we offer the following list of considerations for when you are creating
    Docker containers for high performance code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在任务主要依赖于 CPU/内存时，Docker 的核心并不比在主机上运行慢。然而，与任何事物一样，没有免费的午餐，有时 Docker 的性能会受到影响。尽管优化
    Docker 容器的全面讨论超出了本书的范围，但在为高性能代码创建 Docker 容器时，我们提供以下考虑事项清单：
- en: Be wary of copying too much data into a Docker container or even having too
    much data in the same directory as a Docker build. If the `build context`, as
    advertised by the first line of the `docker build` command, is too large, performance
    can suffer (remedy this with a *.dockerignore* file).
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你将过多数据复制到 Docker 容器中，甚至是在 Docker 构建过程中同一个目录下的数据过多时，都要小心。如果`docker build`命令的第一行所标识的`build
    context`过大，性能可能会受到影响（通过 *.dockerignore* 文件可以解决这个问题）。
- en: Docker uses various filesystem tricks to layer filesystems on top of each other.
    This helps the caching of builds but can be slower than dealing with the host
    filesystem. Use host-level mounts when you need to access data quickly, and consider
    using `volumes` set as read-only to choose a volume driver that is fitting for
    your infrastructure.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 使用各种文件系统技巧在彼此之上层叠文件系统。这有助于构建缓存，但与主机文件系统交互可能会比较慢。当需要快速访问数据时，请使用主机级挂载，并考虑使用设置为只读的`volumes`，选择适合你基础设施的卷驱动程序。
- en: Docker creates a virtual network for all your containers to live behind. This
    can be great for keeping most of your services hidden behind a gateway, but it
    also adds slight network overhead. For most use cases, this overhead is negligible,
    but it can be mitigated by changing the network driver.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 为所有容器创建了一个虚拟网络，使大多数服务保持在网关后面，这对于隐匿大部分服务非常有用，但也增加了轻微的网络开销。对于大多数用例，这种开销可以忽略不计，但可以通过更改网络驱动程序来减轻。
- en: GPUs and other host-level devices can be accessed using special runtime drivers
    for Docker. For example, `nvidia-docker` allows Docker environments to easily
    use connected NVIDIA GPUs. In general, devices can be made available with the
    `--device` runtime flag.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特殊的 Docker 运行时驱动程序可以访问 GPU 和其他主机级设备。例如，`nvidia-docker` 允许 Docker 环境轻松使用连接的
    NVIDIA GPU。通常，设备可以通过 `--device` 运行时标志提供。
- en: As always, it is important to profile your Docker containers to know what the
    issues are and whether there are some easy wins in terms of efficiency. The `docker
    stats` command provides a good high-level view to help understand the current
    runtime performance of your containers.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，重要的是对你的 Docker 容器进行性能分析，以了解存在的问题及其在效率方面的简单解决方案。`docker stats` 命令提供了一个良好的高层视图，帮助理解容器当前的运行时性能。
- en: Advantages of Docker
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker 的优势
- en: So far it has seemed that Docker is simply adding a whole new host of issues
    to contend with in terms of performance. However, the gains to reproducibility
    and reliability of runtime environments far surpass any extra complexity.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，似乎 Docker 只是在性能方面增加了一系列新的问题。然而，运行时环境的可重现性和可靠性远远超过了任何额外复杂性。
- en: Locally, having access to all our previously run Docker containers allows us
    to quickly rerun and retest previous versions of our code without having to worry
    about changes to the runtime environment, such as dependencies and system packages
    ([Example 10-11](#docker_tags_runtime_env) shows a list of containers we can run
    with a simple `docker_run` command). This makes it incredibly easy to constantly
    be testing for performance regressions that otherwise would be difficult to reproduce.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地，可以访问我们之前运行的所有 Docker 容器，这使我们可以快速重新运行和重新测试我们代码的先前版本，而不必担心运行时环境的更改，比如依赖项和系统包（[示例 10-11](#docker_tags_runtime_env)
    显示了我们可以使用简单的 `docker_run` 命令运行的容器列表）。这使得持续测试性能回归变得非常容易，否则这将是难以复现的。
- en: Example 10-11\. Docker tags to keep track of previous runtime environments
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-11\. Docker 标签以跟踪先前的运行时环境
- en: '[PRE16]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Many more benefits come with the use of a [container registry](https://oreil.ly/BaJhI),
    which allows the storage and sharing of Docker images with the simple `docker`
    `pull` and `docker` `push` commands, in a similar way to `git`. This lets us put
    all our containers in a publicly available location, allowing team members to
    pull in changes or new versions and letting them immediately run the code.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[容器注册表](https://oreil.ly/BaJhI)带来了许多额外好处，它允许使用简单的 `docker` `pull` 和 `docker`
    `push` 命令存储和共享 Docker 镜像，类似于 `git` 的方式。这使我们可以将所有容器放在公共可用的位置，允许团队成员拉取变更或新版本，并立即运行代码。
- en: Note
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: This book is a great example of the benefits of sharing a Docker container for
    standardizing a runtime environment. To convert this book from `asciidoc`, the
    markup language it was written in, into PDF, a Docker container was shared between
    us so we could reliably and reproducibly build book artifacts. This standardization
    saved us countless hours that were spent in the first edition as one of us would
    have a build issue that the other couldn’t reproduce or help debug.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是使用 Docker 容器共享的一个很好的例子，用于标准化运行时环境。为了将这本书从其编写的标记语言 `asciidoc` 转换为 PDF，我们之间共享了一个
    Docker 容器，这样我们可以可靠且可重复地构建书籍工件。这种标准化节省了我们无数小时，在第一版中我们会遇到一个构建问题，而另一个人却无法复制或帮助调试。
- en: Running `docker pull highperformance/diffusion2d:latest` is much easier than
    having to clone a repository and doing all the associated setup that may be necessary
    to run a project. This is particularly true for research code, which may have
    some very fragile system dependencies. Having all of this inside an easily pullable
    Docker container means all of these setup steps can be skipped and the code can
    be run easily. As a result, code can be shared more easily, and a coding team
    can work more effectively together.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `docker pull highperformance/diffusion2d:latest` 要比克隆存储库并执行可能必需的所有相关设置容易得多。对于研究代码来说，这一点尤为真实，因为可能存在一些非常脆弱的系统依赖性。将所有内容放入一个可以轻松拉取的
    Docker 容器中意味着可以跳过所有这些设置步骤，并且可以轻松运行代码。因此，代码可以更轻松地共享，编码团队可以更有效地协同工作。
- en: Finally, in conjunction with [`kubernetes`](https://kubernetes.io) and other
    similar technologies, Dockerizing your code helps with actually running it with
    the resources it needs. Kubernetes allows you to create a cluster of nodes, each
    labeled with resources it may have, and to orchestrate running containers on the
    nodes. It will take care of making sure the correct number of instances are being
    run, and thanks to the Docker virtualization, the code will be run in the same
    environment that you saved it to. One of the biggest pains of working with a cluster
    is making sure that the cluster nodes have the correct runtime environment as
    your workstation, and using Docker virtualization completely resolves this.^([8](ch10.xhtml#idm46122403689192))
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，结合 [`kubernetes`](https://kubernetes.io) 和其他类似的技术，将您的代码 Docker 化有助于确保其能够使用所需的资源进行运行。Kubernetes
    允许您创建一个节点集群，每个节点都标记有其可能具备的资源，并在节点上协调运行容器。它会确保正确数量的实例在运行，而由于 Docker 虚拟化的作用，代码将在您保存它时相同的环境中运行。在使用集群时，最大的问题之一是确保集群节点具有与您工作站相同的运行环境，使用
    Docker 虚拟化完全解决了这个问题。^([8](ch10.xhtml#idm46122403689192))
- en: Wrap-Up
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: So far in the book, we’ve looked at profiling to understand slow parts of your
    code, compiling and using `numpy` to make your code run faster, and various approaches
    to multiple processes and computers. In addition, we surveyed container virtualization
    to manage code environments and help in cluster deployment. In the penultimate
    chapter, we’ll look at ways of using less RAM through different data structures
    and probabilistic approaches. These lessons could help you keep all your data
    on one machine, avoiding the need to run a cluster.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们已经了解了性能分析来理解代码中的缓慢部分，使用 `numpy` 进行编译并加快代码运行速度，以及多进程和多计算机的各种方法。此外，我们还调查了容器虚拟化来管理代码环境并帮助集群部署。在倒数第二章中，我们将探讨通过不同的数据结构和概率方法减少内存使用的方法。这些课程可以帮助您将所有数据保存在一台计算机上，避免运行集群的需要。
- en: ^([1](ch10.xhtml#idm46122403968536-marker)) This can be quite advantageous when
    we’re working in AWS, where we can have our `nsqd` processes running on a reserved
    instance and our consumers working on a cluster of spot instances.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.xhtml#idm46122403968536-marker)) 在 AWS 工作时，我们可以将我们的 `nsqd` 进程运行在预留实例上，而我们的消费者则在一组竞价实例上运行，这样做有很大的优势。
- en: ^([2](ch10.xhtml#idm46122403960472-marker)) This asynchronicity comes from NSQ’s
    protocol for sending messages to consumers being push-based. This makes it so
    our code can have an asynchronous read from our connection to NSQ happen in the
    background and wake up when a message is found.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.xhtml#idm46122403960472-marker)) 这种异步性来自于 NSQ 的发送消息给消费者的推送式协议。这使得我们的代码可以在后台进行异步读取
    NSQ 连接，并在发现消息时唤醒。
- en: ^([3](ch10.xhtml#idm46122403957848-marker)) This sort of chaining of data analysis
    is called *pipelining* and can be an effective way to perform multiple types of
    analysis on the same data efficiently.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.xhtml#idm46122403957848-marker)) 这种数据分析的链接被称为*流水线处理*，可以有效地对同一组数据执行多种类型的分析。
- en: ^([4](ch10.xhtml#idm46122403943144-marker)) You can also easily publish a message
    manually with an HTTP call; however, this `nsq.Writer` object simplifies much
    of the error handling.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch10.xhtml#idm46122403943144-marker)) 您还可以通过 HTTP 调用手动发布消息；但是，这个 `nsq.Writer`
    对象简化了大部分的错误处理。
- en: ^([5](ch10.xhtml#idm46122402448536-marker)) For this example, we installed NSQ
    straight onto our system by unpacking the provided binaries into our `PATH` environment
    variable. Alternatively, you can use Docker, discussed in [“Docker”](#docker),
    to easily run the latest versions.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch10.xhtml#idm46122402448536-marker)) 例如，我们可以将 NSQ 直接安装到系统上，通过将提供的二进制文件解压缩到我们的
    `PATH` 环境变量中。或者，您可以使用 Docker，在[“Docker”](#docker)中讨论的方式来轻松运行最新版本。
- en: ^([6](ch10.xhtml#idm46122402901784-marker)) This fine-tuning can, for example,
    be used to adjust the amount of memory a process has access to, or which CPUs
    or even how much of the CPU it can use.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch10.xhtml#idm46122402901784-marker)) 这种微调可以用来调整进程可以访问的内存量，或者可以使用的 CPU
    核心数量，甚至可以控制 CPU 使用量的大小。
- en: ^([7](ch10.xhtml#idm46122403724904-marker)) The `*username*` portion of the
    container name is useful when also pushing built containers to a repository.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch10.xhtml#idm46122403724904-marker)) 当将构建的容器推送到存储库时，容器名称中的`*username*`部分非常有用。
- en: ^([8](ch10.xhtml#idm46122403689192-marker)) A great tutorial to get started
    with Docker and Kubernetes can be found at [*https://oreil.ly/l9jXD*](https://oreil.ly/l9jXD).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch10.xhtml#idm46122403689192-marker)) 一个很棒的入门教程，可以在[*https://oreil.ly/l9jXD*](https://oreil.ly/l9jXD)找到。
