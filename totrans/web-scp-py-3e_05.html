<html><head></head><body><section data-pdf-bookmark="Chapter 4. Writing Your First Web Scraper" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-4">&#13;
<h1><span class="label">Chapter 4. </span>Writing Your First Web Scraper</h1>&#13;
&#13;
<p>Once you start web scraping, you start to appreciate all the little things that browsers do for you. The web, without its layers of HTML formatting, CSS styling, JavaScript execution, and image rendering, can look a little intimidating at first. In this chapter, we’ll begin to look at how to format and interpret this bare data without the help of a web browser.</p>&#13;
&#13;
<p>This chapter starts with the basics of sending a <code>GET</code> request (a request to fetch, or “get,” the content of a web page) to a web server for a specific page, reading the HTML output from that page, and doing some simple data extraction in order to isolate the content you are looking for.</p>&#13;
&#13;
<section data-pdf-bookmark="Installing and Using Jupyter" data-type="sect1"><div class="sect1" id="id30">&#13;
<h1>Installing and Using Jupyter</h1>&#13;
&#13;
<p>The code for this course can <a contenteditable="false" data-primary="Jupyter" data-secondary="installing" data-type="indexterm" id="jpytsl"/><a contenteditable="false" data-primary="Jupyter" data-secondary="Notebooks" data-tertiary=".ipynb files" data-type="indexterm" id="id362"/>be found at <a href="https://github.com/REMitchell/python-scraping"><em class="hyperlink">https://github.com/REMitchell/python-scraping</em></a>. In most cases, code samples are in the form of Jupyter Notebook files, with an <em>.ipynb</em> extension.</p>&#13;
&#13;
<p>If you haven’t used them already, Jupyter Notebooks are an excellent way to organize and work with many small but related pieces of Python code, as shown in <a data-type="xref" href="#fig0401">Figure 4-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="fig0401"><img alt="" class="iimageswsp3_0401png" src="assets/wsp3_0401.png"/>&#13;
<h6><span class="label">Figure 4-1. </span>A Jupyter Notebook running in the browser</h6>&#13;
</div></figure>&#13;
&#13;
<p>Each piece of code is contained in <a contenteditable="false" data-primary="Jupyter" data-secondary="Notebooks" data-tertiary="cells" data-type="indexterm" id="id363"/>a box called a <em>cell</em>. The code within each cell can be run by typing Shift + Enter, or by clicking the Run button at the top of the page.</p>&#13;
&#13;
<p>Project Jupyter began as a spin-off <a contenteditable="false" data-primary="Project Jupyter" data-type="indexterm" id="id364"/><a contenteditable="false" data-primary="Jupyter" data-secondary="Project Jupyter" data-type="indexterm" id="id365"/><a contenteditable="false" data-primary="IPython (Interactive Python)" data-type="indexterm" id="id366"/>project from the IPython (Interactive Python) project in 2014. These notebooks were designed to run Python code in the browser in an accessible and interactive way that would lend itself to teaching and presenting.</p>&#13;
&#13;
<p>To install Jupyter Notebooks:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>notebook<code class="w"/></pre>&#13;
&#13;
<p>After installation, you should have <a contenteditable="false" data-primary="Jupyter" data-secondary="installing" data-startref="jpytsl" data-type="indexterm" id="id367"/>access to the <code>jupyter</code> command, which will allow you to start the web server. Navigate to the directory containing the downloaded exercise files for this book, and run:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>jupyter<code class="w"> </code>notebook<code class="w"/></pre>&#13;
&#13;
<p>This will start the web server on port 8888. If you have a web browser running, a new tab should open automatically. If it doesn’t, copy the URL shown in the terminal, with the provided token, to your web browser.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Connecting" data-type="sect1"><div class="sect1" id="id31">&#13;
<h1>Connecting</h1>&#13;
&#13;
<p>In the first section of this book, we took a deep dive into how the internet sends packets of data across <a contenteditable="false" data-primary="networks" data-secondary="packets" data-type="indexterm" id="id368"/><a contenteditable="false" data-primary="packets" data-type="indexterm" id="id369"/>wires from a browser to a web server and back again. When you open a browser, type in <code><strong>google.com</strong></code>, and hit Enter, that’s exactly what’s happening—data, in the form of an HTTP request, is being transferred from your computer, and Google’s web server is responding with an HTML file that represents the data at the root of <em>google.com</em>.</p>&#13;
&#13;
<p>But where, in this exchange of packets and frames, does the web browser actually come into play? Absolutely nowhere. In fact, ARPANET (the first public packet-switched network) <a contenteditable="false" data-primary="ARPANET" data-type="indexterm" id="id370"/>predated the first web browser, Nexus, by at least 20 years.</p>&#13;
&#13;
<p>Yes, the web browser is a useful application for creating these packets of information, telling your operating system to send them off and interpreting the data you get back as pretty pictures, sounds, videos, and text. However, a web browser is just code, and code can be taken apart, broken into its basic components, rewritten, reused, and made to do anything you want. A web browser can tell the processor to send data to the application that handles your wireless (or wired) interface, but you can do the same thing in Python with just three lines of code:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/pages/page1.html'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">())</code></pre>&#13;
&#13;
<p>To run this, you can use the <a href="https://github.com/REMitchell/python-scraping/blob/master/Chapter01_BeginningToScrape.ipynb">IPython notebook</a> for <a data-type="xref" href="ch01.html#c-1">Chapter 1</a> in the GitHub repository, or you can save it locally as <em>scrapetest.py</em> and run it in your terminal by using this command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python<code class="w"> </code>scrapetest.py<code class="w"/></pre>&#13;
&#13;
<p>Note that if you also <a contenteditable="false" data-primary="Python 2.x" data-type="indexterm" id="id371"/><a contenteditable="false" data-primary="Python 3.x" data-type="indexterm" id="id372"/>have Python 2.x installed on your machine and are running both versions of Python side by side, you may need to explicitly call Python 3.x by running the command this way:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python3<code class="w"> </code>scrapetest.py<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>This command outputs the complete HTML code for <em>page1</em> located at the URL <em>http://pythonscraping.com/pages/page1.html</em>. More accurately, this outputs the HTML file <em>page1.html</em>, found in the directory <em>&lt;web root&gt;/pages</em>, on the server located at the domain name <a class="link" href="http://pythonscraping.com"><em>http://pythonscraping.com</em></a>.</p>&#13;
&#13;
<p>Why is it important to start <a contenteditable="false" data-primary="web pages versus files" data-type="indexterm" id="id373"/><a contenteditable="false" data-primary="files" data-secondary="versus web pages" data-type="indexterm" id="id374"/>thinking of these addresses as “files” rather than “pages”? Most modern web pages have many resource files associated with them. These could be image files, JavaScript files, CSS files, or any other content that the page you are requesting is linked to. When a web browser hits a tag such as <code>&lt;img src="cute​Kit⁠ten.jpg"&gt;</code>, the browser knows that it needs to make another request to the server to get the data at the location <em>cuteKitten.jpg</em> in order to fully render the page for the user.</p>&#13;
&#13;
<p>Of course, your Python script doesn’t have the logic to go back and request multiple files (yet); it can read only the single HTML file that you’ve directly requested.</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code></pre>&#13;
&#13;
<p>means what it looks like it means: it looks at the Python module request (found within the <em>urllib</em> library) and imports only the function <code>urlopen</code>.</p>&#13;
&#13;
<p><em>urllib</em> is a standard <a contenteditable="false" data-primary="urllib library" data-type="indexterm" id="id375"/><a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="urllib" data-type="indexterm" id="id376"/>Python library (meaning you don’t have to install anything extra to run this example) and contains functions for requesting data across the web, handling cookies, and even changing metadata such as headers and your user agent. We will be using urllib extensively throughout the book, so I recommend you read the <a href="https://docs.python.org/3/library/urllib.html">Python documentation for the library</a>.</p>&#13;
&#13;
<p><code>urlopen</code> is used to open a remote <a contenteditable="false" data-primary="remote objects, opening" data-type="indexterm" id="id377"/>object across a network and read it. Because it is a fairly generic function (it can read HTML files, image files, or any other file stream with ease), we will be using it quite frequently throughout the book.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="An Introduction to BeautifulSoup" data-type="sect1"><div class="sect1" id="id176">&#13;
<h1>An Introduction to BeautifulSoup</h1>&#13;
&#13;
<blockquote>&#13;
<p>Beautiful Soup, so rich and green,<br/>&#13;
Waiting in a hot tureen!<br/>&#13;
Who for such dainties would not stoop?<br/>&#13;
Soup of the evening, beautiful Soup!</p>&#13;
</blockquote>&#13;
&#13;
<p>The <em>BeautifulSoup</em> library was <a contenteditable="false" data-primary="libraries" data-secondary="Python" data-tertiary="installing" data-type="indexterm" id="lbpystl"/><a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="installing" data-type="indexterm" id="pylbrrs"/>named after a Lewis Carroll poem of the same name in <em>Alice’s Adventures in Wonderland</em>. In the story, this poem is sung by a character called the Mock Turtle (itself a pun on the popular Victorian dish Mock Turtle Soup made not of turtle but of cow).</p>&#13;
&#13;
<p>Like its Wonderland namesake, BeautifulSoup tries to make sense of the nonsensical; it helps format and organize the messy web by fixing bad HTML and presenting us with easily traversable Python objects representing XML structures.</p>&#13;
&#13;
<section data-pdf-bookmark="Installing BeautifulSoup" data-type="sect2"><div class="sect2" id="id32">&#13;
<h2>Installing BeautifulSoup</h2>&#13;
&#13;
<p>Because the BeautifulSoup library <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="installing" data-type="indexterm" id="btfpby"/>is not a default Python library, it must be installed. If you’re already experienced at installing Python libraries, please use your favorite installer and skip ahead to the next section, <a data-type="xref" href="#runningBsoup">“Running BeautifulSoup”</a>.</p>&#13;
&#13;
<p>For those who have not installed Python libraries (or need a refresher), this general method will be used for installing multiple libraries throughout the book, so you may want to reference this section in the future.</p>&#13;
&#13;
<p>We will be using the <a contenteditable="false" data-primary="BS4 library" data-see="BeautifulSoup library" data-type="indexterm" id="id378"/>BeautifulSoup 4 library (also known as BS4) throughout this book. The complete documentation, as well as installation instructions, for BeautifulSoup 4 can be found at <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Crummy.com</a>.</p>&#13;
&#13;
<p>If you’ve spent <a contenteditable="false" data-primary="Python" data-secondary="pip" data-see="pip (package installer for python)" data-type="indexterm" id="id379"/><a contenteditable="false" data-primary="pip (package installer for python)" data-type="indexterm" id="id380"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="pip (package installer for python)" data-type="indexterm" id="id381"/>much time writing Python, you’ve probably used the package installer for Python (<a href="https://pypi.org/project/pip/">pip</a>). If you haven’t, I highly recommend that you install pip in order to install BeautifulSoup and other Python packages used throughout this book.</p>&#13;
&#13;
<p>Depending on the Python installer you used, pip may already be installed on your computer. To check, try:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip<code class="w"/></pre>&#13;
&#13;
<p>This command should result in the pip help text being printed to your terminal. If the command isn’t recognized, you may need to <a contenteditable="false" data-primary="pip (package installer for python)" data-secondary="installing" data-type="indexterm" id="id382"/>install pip. Pip can be installed in a variety of ways, such as with <code>apt-get</code> on Linux or <code>brew</code> on macOS. Regardless of your operating system, you can also download the pip bootstrap file at <a href="https://bootstrap.pypa.io/get-pip.py"><em class="hyperlink">https://bootstrap.pypa.io/get-pip.py</em></a>, save this file as <em>get-pip.py</em>, and run it with Python:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python<code class="w"> </code>get-pip.py<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>Again, note that if you have both Python 2.x and 3.x installed on your machine, you might need to call <code>python3</code> explicitly:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python3<code class="w"> </code>get-pip.py<code class="w"/></pre>&#13;
&#13;
<p>Finally, use pip to install BeautifulSoup:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>bs4<code class="w"/></pre>&#13;
&#13;
<p>If you have two versions of Python, along <a contenteditable="false" data-primary="Python" data-secondary="pip3" data-type="indexterm" id="id383"/><a contenteditable="false" data-primary="pip3" data-type="indexterm" id="id384"/>with two versions of pip, you may need to call <code>pip3</code> to install the Python 3.x versions of packages:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip3<code class="w"> </code>install<code class="w"> </code>bs4<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>And that’s it! BeautifulSoup will now be recognized as a Python library on your machine. You can test this by opening a Python terminal and importing it:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="err">$</code> <code class="n">python</code>&#13;
<code class="o">&gt;</code> <code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
</pre>&#13;
&#13;
<p>The import should complete without errors.</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="KLSwVE_01">&#13;
<h1>Keeping Libraries Straight with Virtual Environments</h1>&#13;
&#13;
<p>If you intend to work on multiple Python projects, or <a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="virtual environments and" data-type="indexterm" id="pybvv"/><a contenteditable="false" data-primary="libraries" data-secondary="Python" data-tertiary="virtual environments and" data-type="indexterm" id="lbpyvev"/><a contenteditable="false" data-primary="virtual environments" data-secondary="Python libraries" data-type="indexterm" id="vvrpybb"/>you need a way to easily bundle projects with all associated libraries, or you’re worried about potential conflicts between installed libraries, you can install a Python virtual environment to keep everything separated and easy to manage.</p>&#13;
&#13;
<p>When you install a Python library without a <a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="global installation" data-type="indexterm" id="id385"/><a contenteditable="false" data-primary="libraries" data-secondary="Python" data-tertiary="global installation" data-type="indexterm" id="id386"/>virtual environment, you are installing it <em>globally</em>. This usually requires that you be an administrator, or run as root, and that the Python library exists for every user and every project on the machine. Fortunately, creating a virtual environment is easy:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>virtualenv<code class="w"> </code>scrapingEnv<code class="w"/></pre>&#13;
&#13;
<p>This creates a new environment called <code>scrapingEnv</code>, which you must activate to use:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code><code class="nb">cd</code><code class="w"> </code>scrapingEnv/<code class="w"/>&#13;
$<code class="w"> </code><code class="nb">source</code><code class="w"> </code>bin/activate<code class="w"/></pre>&#13;
&#13;
<p>After you have activated the environment, you will see that environment’s name in your command-line prompt, reminding you that you’re currently working with it. Any libraries you install or scripts you run will be under that virtual environment only.</p>&#13;
&#13;
<p>Working in the newly created <code>scrapingEnv</code> environment, you can install and use BeautifulSoup; for instance:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
(scrapingEnv)ryan$ pip install beautifulsoup4&#13;
(scrapingEnv)ryan$ python&#13;
&gt; from bs4 import BeautifulSoup&#13;
&gt;</pre>&#13;
&#13;
<p>You can leave the environment <a contenteditable="false" data-primary="virtual environments" data-secondary="deactivate command" data-type="indexterm" id="id387"/><a contenteditable="false" data-primary="deactivate command, virtual environments" data-type="indexterm" id="id388"/>with the <code>deactivate</code> command, after which you can no longer access any libraries that were installed inside the virtual environment:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
(scrapingEnv)ryan$ deactivate&#13;
ryan$ python&#13;
&gt; from bs4 import BeautifulSoup&#13;
Traceback (most recent call last):&#13;
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;&#13;
ImportError: No module named 'bs4'&#13;
</pre>&#13;
&#13;
<p>Keeping all your libraries separated by project also makes it easy to zip up the entire environment folder and send it to someone else. As long as they have the same version of Python installed on their machine, your code will work from the virtual environment without requiring them to install any libraries themselves.</p>&#13;
&#13;
<p>Although I won’t explicitly instruct you to use a virtual environment in all of this book’s examples, keep in mind that you can <a contenteditable="false" data-primary="libraries" data-secondary="Python" data-startref="lbpystl" data-tertiary="installing" data-type="indexterm" id="id389"/><a contenteditable="false" data-primary="Python" data-secondary="libraries" data-startref="pylbrrs" data-tertiary="installing" data-type="indexterm" id="id390"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="installing" data-startref="btfpby" data-type="indexterm" id="id391"/>apply a virtual environment anytime simply by activating it beforehand.</p>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Running BeautifulSoup" data-type="sect2"><div class="sect2" id="runningBsoup">&#13;
<h2>Running BeautifulSoup</h2>&#13;
&#13;
<p>The most commonly used object in the BeautifulSoup library is, appropriately, the <code>BeautifulSoup</code> object. Let’s take a look at it in action, modifying the example found in the beginning of this chapter:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page1.html'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">bs</code><code class="o">.</code><code class="n">h1</code><code class="p">)</code></pre>&#13;
&#13;
<p>The output is as follows:</p>&#13;
&#13;
<pre data-code-language="html" data-type="programlisting">&#13;
<code class="p">&lt;</code><code class="nt">h1</code><code class="p">&gt;</code>An Interesting Title<code class="p">&lt;/</code><code class="nt">h1</code><code class="p">&gt;</code>&#13;
</pre>&#13;
&#13;
<p>Note that this returns only the first instance of the <code>h1</code> tag found on the page. By convention, only one <code>h1</code> tag should be used on a single page, but conventions are often broken on the web, so you should be aware that this will retrieve only the first instance of the tag, and not necessarily the one that you’re looking for.</p>&#13;
&#13;
<p>As in previous web scraping examples, you are importing the <code>urlopen</code> function and calling <code>html.read()</code> to get the HTML content of the page. In addition to the text string, BeautifulSoup can use the file object directly returned by <code>urlopen</code>, without needing to call <code>.read()</code> first:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs = BeautifulSoup(html, 'html.parser')</pre>&#13;
&#13;
<p>This HTML content is then transformed into a <code>BeautifulSoup</code> object with the following structure:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p><strong>html</strong> → <em>&lt;html&gt;&lt;head&gt;...&lt;/head&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;</em></p>&#13;
&#13;
	<ul>&#13;
		<li>&#13;
		<p><strong>head</strong> → <em>&lt;head&gt;&lt;title&gt;A Useful Page&lt;title&gt;&lt;/head&gt;</em></p>&#13;
&#13;
		<ul>&#13;
			<li><strong>title</strong> → <em>&lt;title&gt;A Useful Page&lt;/t</em><em>itle&gt;</em></li>&#13;
		</ul>&#13;
		</li>&#13;
		<li>&#13;
		<p><strong>body</strong> → <em>&lt;body&gt;&lt;h1&gt;An Int...&lt;/h1&gt;&lt;div&gt;Lorem ip...&lt;/div&gt;&lt;/body&gt;</em></p>&#13;
&#13;
		<ul>&#13;
			<li><strong>h1</strong> → <em>&lt;h1&gt;An Interesting Title&lt;/h1&gt;</em></li>&#13;
			<li><strong>div</strong> → <em>&lt;div&gt;Lorem Ipsum dolor...&lt;/div&gt;</em></li>&#13;
		</ul>&#13;
		</li>&#13;
	</ul>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Note that the <code>h1</code> tag that you extract from the page is nested two layers deep into your <code>BeautifulSoup</code> object structure (<code>html</code> → <code>body</code> → <code>h1</code>). However, when you actually fetch it from the object, you call the <code>h1</code> tag directly:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">h1</code></pre>&#13;
&#13;
<p>In fact, any of the following function calls would produce the same output:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">html</code><code class="o">.</code><code class="n">body</code><code class="o">.</code><code class="n">h1</code>&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">body</code><code class="o">.</code><code class="n">h1</code>&#13;
<code class="n">bs</code><code class="o">.</code><code class="n">html</code><code class="o">.</code><code class="n">h1</code></pre>&#13;
&#13;
<p>When you create a <code>BeautifulSoup</code> object, two arguments are passed in:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'html.parser'</code><code class="p">)</code></pre>&#13;
&#13;
<p>The first is the HTML <a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="parser" data-type="indexterm" id="id392"/><a contenteditable="false" data-primary="HTML (HyperText Markup Language)" data-secondary="parsers" data-type="indexterm" id="id393"/>string that the object is based on, and the second specifies the parser that you want BeautifulSoup to use to create that object. In the majority of cases, it makes no difference which parser you choose.</p>&#13;
&#13;
<p><code>html.parser</code> is a parser <a contenteditable="false" data-primary="html.parser" data-type="indexterm" id="id394"/>that is included with Python 3 and requires no extra installations to use. Except where required, we will use this parser throughout the book.</p>&#13;
&#13;
<p>Another popular parser is <a href="http://lxml.de/parsing.html"><code>lxml</code></a>. This <a contenteditable="false" data-primary="lxml parser" data-type="indexterm" id="id395"/>can be installed through pip:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="err">$</code> <code class="n">pip</code> <code class="n">install</code> <code class="n">lxml</code></pre>&#13;
&#13;
<p><code>lxml</code> can be used with BeautifulSoup by changing the parser string provided:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'lxml'</code><code class="p">)</code></pre>&#13;
&#13;
<p><code>lxml</code> has some advantages over <code>html.parser</code> in that it is generally better at parsing “messy” or malformed HTML code. It is forgiving and fixes problems like unclosed tags, tags that are improperly nested, and missing head or body tags.</p>&#13;
&#13;
<p><code>lxml</code> is also somewhat faster than <code>html.parser</code>, although speed is not necessarily <span class="keep-together">an advantage</span> in web scraping, given that the speed of the network itself will almost<a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="running" data-startref="bspubr" data-type="indexterm" id="id396"/> always be your largest bottleneck.</p>&#13;
&#13;
<div data-type="warning" epub:type="warning">&#13;
<h1>Avoid Over-Optimizing Web Scraping Code</h1>&#13;
&#13;
<p>Elegant algorithms are lovely to behold, but when <a contenteditable="false" data-primary="code optimization" data-type="indexterm" id="id397"/>it comes to web scraping, they may not have a practical impact. A few microseconds of processing time will likely be dwarfed by the—sometimes <em>actual</em>—seconds of network latency that a network request takes.</p>&#13;
&#13;
<p>Good web scraping code generally focuses on robust and easily readable implementations, rather than clever processing optimizations.</p>&#13;
</div>&#13;
&#13;
<p>One of the disadvantages of <code>lxml</code> is that it needs to be installed separately and depends on third-party C libraries to function. This can cause problems for portability and ease of use, compared to <code>html.parser</code>.</p>&#13;
&#13;
<p>Another popular HTML parser <a contenteditable="false" data-primary="html5lib parser" data-type="indexterm" id="id398"/>is <code>html5lib</code>. Like <code>lxml</code>, <code>html5lib</code> is an extremely forgiving parser that takes even more initiative with correcting broken HTML. It also depends on an external dependency and is slower than both <code>lxml</code> and <code>html.parser</code>. Despite this, it may be a good choice if you are working with messy or handwritten HTML sites.</p>&#13;
&#13;
<p>It can be used by installing and passing the string <code>html5lib</code> to the BeautifulSoup object:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
bs = BeautifulSoup(html.read(), 'html5lib')</pre>&#13;
&#13;
<p>I hope this small taste of BeautifulSoup has given you an idea of the power and simplicity of this library. Virtually any information can be extracted from any HTML (or XML) file, as long as it has an identifying tag surrounding it or near it. <a data-type="xref" href="ch05.html#c-5">Chapter 5</a> delves more deeply into more-complex BeautifulSoup function calls and presents regular expressions and how they can be used with BeautifulSoup in order to extract information from websites.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Connecting Reliably and Handling Exceptions" data-type="sect2"><div class="sect2" id="id34">&#13;
<h2>Connecting Reliably and Handling Exceptions</h2>&#13;
&#13;
<p>The web is messy. Data is poorly <a contenteditable="false" data-primary="exception handling" data-type="indexterm" id="xcphdg"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="exception handling" data-type="indexterm" id="blsbpxp"/>formatted, websites go down, and closing tags go missing. One of the most frustrating experiences in web scraping is to go to sleep with a scraper running, dreaming of all the data you’ll have in your database the next day—only to find that the scraper hit an error on some unexpected data format and stopped execution shortly after you stopped looking at the screen.</p>&#13;
&#13;
<p>In situations like these, you might be tempted to curse the name of the developer who created the website (and the oddly formatted data), but the person you should really be kicking is yourself for not anticipating the exception in the first place!</p>&#13;
&#13;
<p>Let’s look at the first line of our scraper, after the import statements, and figure out how to handle any exceptions this might throw:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page1.html'</code><code class="p">)</code> </pre>&#13;
&#13;
<p>Two main things can go wrong in this line:</p>&#13;
&#13;
<ul>&#13;
	<li>The page is not found on the server (or there was an error in retrieving it).</li>&#13;
	<li>The server is not found at all.</li>&#13;
</ul>&#13;
&#13;
<p>In the first situation, an HTTP error will be <a contenteditable="false" data-primary="HTTP (HyperText Transfer Protocol)" data-secondary="error codes" data-type="indexterm" id="id399"/>returned. This HTTP error may be “404 Page Not Found,” “500 Internal Server Error,” and so forth. In all of these cases, the <code>urlopen</code> function will throw the generic exception <code>HTTPError</code>. You can handle this exception in the following way:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.error</code> <code class="kn">import</code> <code class="n">HTTPError</code>&#13;
&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page1.html'</code><code class="p">)</code>&#13;
<code class="k">except</code> <code class="n">HTTPError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">e</code><code class="p">)</code>&#13;
    <code class="c1"># return null, break, or do some other "Plan B"</code>&#13;
<code class="k">else</code><code class="p">:</code>&#13;
    <code class="c1"># program continues. Note: If you return or break in the  </code>&#13;
    <code class="c1"># exception catch, you do not need to use the "else" statement</code></pre>&#13;
&#13;
<p>If an HTTP error code is returned, the program now prints the error and does not execute the rest of the program under the <code>else</code> statement.</p>&#13;
&#13;
<p>If the server is not found at all (if, for example, <em>http://www.pythonscraping.com</em> is down, or the URL is mistyped), <code>urlopen</code> will throw an <code>URLError</code>. This indicates that no server could be reached at all, and, because the remote server is responsible for returning HTTP status codes, an <code>HTTPError</code> cannot be thrown, and the more serious <code>URLError</code> must be caught. You can add a check to see whether this is the case:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.error</code> <code class="kn">import</code> <code class="n">HTTPError</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.error</code> <code class="kn">import</code> <code class="n">URLError</code>&#13;
&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'https://pythonscrapingthisurldoesnotexist.com'</code><code class="p">)</code>&#13;
<code class="k">except</code> <code class="n">HTTPError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">e</code><code class="p">)</code>&#13;
<code class="k">except</code> <code class="n">URLError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'The server could not be found!'</code><code class="p">)</code>&#13;
<code class="k">else</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'It Worked!'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Of course, if the page is retrieved successfully from the server, there is still the issue of the content on the page not being quite what you expected. Every time you access a tag in a <code>BeautifulSoup</code> object, it’s smart to add a check to make sure the tag actually exists. If you <a contenteditable="false" data-primary="None object" data-type="indexterm" id="id400"/>attempt to access a tag that does not exist, BeautifulSoup will return a <code>None</code> object. The problem is, attempting to access a tag on a <code>None</code> object itself will result in an <code>AttributeError</code> being thrown.</p>&#13;
&#13;
<p>The following line (where <code>nonExistentTag</code> is a made-up tag, not the name of a real BeautifulSoup function):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">bs</code><code class="o">.</code><code class="n">nonExistentTag</code><code class="p">)</code></pre>&#13;
&#13;
<p>returns a <code>None</code> object. This object is perfectly reasonable to handle and check for. The trouble comes if you don’t check for it but instead go on and try to call another function on the <code>None</code> object, as illustrated here:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">bs</code><code class="o">.</code><code class="n">nonExistentTag</code><code class="o">.</code><code class="n">someTag</code><code class="p">)</code></pre>&#13;
&#13;
<p>This returns an exception:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="ne">AttributeError</code><code class="p">:</code> <code class="s1">'NoneType'</code> <code class="nb">object</code> <code class="n">has</code> <code class="n">no</code> <code class="n">attribute</code> <code class="s1">'someTag'</code></pre>&#13;
&#13;
<p>So how can you guard against these two situations? The easiest way is to explicitly check for both situations:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="n">badContent</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">nonExistingTag</code><code class="o">.</code><code class="n">anotherTag</code>&#13;
<code class="k">except</code> <code class="ne">AttributeError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Tag was not found'</code><code class="p">)</code>&#13;
<code class="k">else</code><code class="p">:</code>&#13;
    <code class="k">if</code> <code class="n">badContent</code> <code class="o">==</code> <code class="kc">None</code><code class="p">:</code>&#13;
        <code class="nb">print</code> <code class="p">(</code><code class="s1">'Tag was not found'</code><code class="p">)</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="n">badContent</code><code class="p">)</code></pre>&#13;
&#13;
<p>This checking and handling of every error does seem laborious at first, but it’s easy to add a little reorganization to this code to make it less difficult to write (and, more important, much less difficult to read). This code, for example, is our same scraper written in a slightly different way:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">urllib.error</code> <code class="kn">import</code> <code class="n">HTTPError</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">getTitle</code><code class="p">(</code><code class="n">url</code><code class="p">):</code>&#13;
    <code class="k">try</code><code class="p">:</code>&#13;
        <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="n">url</code><code class="p">)</code>&#13;
    <code class="k">except</code> <code class="n">HTTPError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="kc">None</code>&#13;
    <code class="k">try</code><code class="p">:</code>&#13;
        <code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
        <code class="n">title</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">body</code><code class="o">.</code><code class="n">h1</code>&#13;
    <code class="k">except</code> <code class="ne">AttributeError</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="kc">None</code>&#13;
    <code class="k">return</code> <code class="n">title</code>&#13;
&#13;
<code class="n">title</code> <code class="o">=</code> <code class="n">getTitle</code><code class="p">(</code><code class="s1">'http://www.pythonscraping.com/pages/page1.html'</code><code class="p">)</code>&#13;
<code class="k">if</code> <code class="n">title</code> <code class="o">==</code> <code class="kc">None</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Title could not be found'</code><code class="p">)</code>&#13;
<code class="k">else</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">title</code><code class="p">)</code></pre>&#13;
&#13;
<p>In this example, you’re creating a function <code>getTitle</code>, which returns either the title of the page, or a <code>None</code> object if there was a problem retrieving it. Inside <code>getTitle</code>, you check for an <code>HTTPError</code>, as in the previous example, and encapsulate two of the BeautifulSoup lines inside one <code>try</code> statement. An <code>AttributeError</code> might be thrown from either of these lines (if the server did not exist, <code>html</code> would be a <code>None</code> object, and <code>html.read()</code> would throw an <code>AttributeError</code>). You could, in fact, encompass as many lines as you want inside one <code>try</code> statement or call another function entirely, which can throw an <code>AttributeError</code> at any point.</p>&#13;
&#13;
<p>When writing scrapers, it’s important to think about the overall pattern of your code in order to handle exceptions and make it readable at the same time. You’ll also likely want to heavily reuse code. Having generic functions such as <code>getSiteHTML</code> and <span class="keep-together"><code>getTitle</code></span> (complete with thorough exception handling) makes <a contenteditable="false" data-primary="Python" data-secondary="libraries" data-startref="pybvv" data-tertiary="virtual environments and" data-type="indexterm" id="id401"/><a contenteditable="false" data-primary="libraries" data-secondary="Python" data-startref="lbpyvev" data-tertiary="virtual environments and" data-type="indexterm" id="id402"/><a contenteditable="false" data-primary="virtual environments" data-secondary="Python libraries" data-startref="vvrpybb" data-type="indexterm" id="id403"/><a contenteditable="false" data-primary="exception handling" data-startref="xcphdg" data-type="indexterm" id="id404"/><a contenteditable="false" data-primary="BeautifulSoup library" data-secondary="exception handling" data-startref="blsbpxp" data-type="indexterm" id="id405"/>it easy to quickly—and reliably—scrape the web.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section></body></html>