- en: 12\. Text Analysis and Generation#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12\. 文本分析与生成#
- en: 原文：[https://allendowney.github.io/ThinkPython/chap12.html](https://allendowney.github.io/ThinkPython/chap12.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://allendowney.github.io/ThinkPython/chap12.html](https://allendowney.github.io/ThinkPython/chap12.html)
- en: 'At this point we have covered Python’s core data structures – lists, dictionaries,
    and tuples – and some algorithms that use them. In this chapter, we’ll use them
    to explore text analysis and Markov generation:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 此时我们已经涵盖了Python的核心数据结构——列表、字典和元组——以及一些使用它们的算法。在本章中，我们将利用它们来探索文本分析和马尔科夫生成：
- en: Text analysis is a way to describe the statistical relationships between the
    words in a document, like the probability that one word is followed by another,
    and
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分析是一种描述文档中单词之间统计关系的方法，比如一个单词后面跟着另一个单词的概率，以及
- en: Markov generation is a way to generate new text with words and phrases similar
    to the original text.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马尔科夫生成是一种使用与原始文本相似的单词和短语生成新文本的方法。
- en: These algorithms are similar to parts of a Large Language Model (LLM), which
    is the key component of a chatbot.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法类似于大型语言模型（LLM）的部分内容，LLM是聊天机器人的关键组成部分。
- en: We’ll start by counting the number of times each word appears in a book. Then
    we’ll look at pairs of words, and make a list of the words that can follow each
    word. We’ll make a simple version of a Markov generator, and as an exercise, you’ll
    have a chance to make a more general version.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从计算每个单词在书中出现的次数开始。然后我们将查看单词对，并列出每个单词后面可以跟随的单词。我们将制作一个简单版本的马尔科夫生成器，作为练习，你将有机会制作一个更通用的版本。
- en: 12.1\. Unique words[#](#unique-words "Link to this heading")
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1\. 唯一单词[#](#unique-words "Link to this heading")
- en: As a first step toward text analysis, let’s read a book – *The Strange Case
    Of Dr. Jekyll And Mr. Hyde* by Robert Louis Stevenson – and count the number of
    unique words. Instructions for downloading the book are in the notebook for this
    chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作为文本分析的第一步，让我们阅读一本书——罗伯特·路易斯·史蒂文森的《化身博士》——并统计唯一单词的数量。下载这本书的说明可以在本章的笔记本中找到。
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We’ll use a `for` loop to read lines from the file and `split` to divide the
    lines into words. Then, to keep track of unique words, we’ll store each word as
    a key in a dictionary.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`for`循环从文件中读取行，并使用`split`将行分割成单词。然后，为了跟踪唯一单词，我们将每个单词作为字典中的一个键进行存储。
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The length of the dictionary is the number of unique words – about `6000` by
    this way of counting. But if we inspect them, we’ll see that some are not valid
    words.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 字典的长度是唯一单词的数量——按照这种计算方式大约是`6000`。但如果我们检查它们，会发现有些并不是有效的单词。
- en: For example, let’s look at the longest words in `unique_words`. We can use `sorted`
    to sort the words, passing the `len` function as a keyword argument so the words
    are sorted by length.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看`unique_words`中最长的单词。我们可以使用`sorted`来排序单词，将`len`函数作为关键字参数传入，以便按单词长度排序。
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The slice index, `[-5:]`, selects the last `5` elements of the sorted list,
    which are the longest words.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 切片索引`[-5:]`选择排序后列表中的最后`5`个元素，即最长的单词。
- en: The list includes some legitimately long words, like “circumscription”, and
    some hyphenated words, like “chocolate-coloured”. But some of the longest “words”
    are actually two words separated by a dash. And other words include punctuation
    like periods, exclamation points, and quotation marks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表包括一些合法的长单词，比如“circumscription”，以及一些带连字符的单词，比如“chocolate-coloured”。但一些最长的“单词”实际上是由连字符分隔的两个单词。而其他单词则包含像句号、感叹号和引号等标点符号。
- en: So, before we move on, let’s deal with dashes and other punctuation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在我们继续之前，让我们处理一下连字符和其他标点符号。
- en: 12.2\. Punctuation[#](#punctuation "Link to this heading")
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2\. 标点符号[#](#punctuation "Link to this heading")
- en: 'To identify the words in the text, we need to deal with two issues:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别文本中的单词，我们需要解决两个问题：
- en: When a dash appears in a line, we should replace it with a space – then when
    we use `split`, the words will be separated.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当行中出现连字符时，我们应该将其替换为空格——然后当我们使用`split`时，单词就会被分开。
- en: After splitting the words, we can use `strip` to remove punctuation.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割单词后，我们可以使用`strip`来移除标点符号。
- en: To handle the first issue, we can use the following function, which takes a
    string, replaces dashes with spaces, splits the string, and returns the resulting
    list.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理第一个问题，我们可以使用以下函数，它接受一个字符串，将连字符替换为空格，分割字符串，并返回结果列表。
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice that `split_line` only replaces dashes, not hyphens. Here’s an example.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`split_line`只会替换连字符，而不会替换破折号。这里有一个例子。
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, to remove punctuation from the beginning and end of each word, we can use
    `strip`, but we need a list of characters that are considered punctuation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了去除每个单词开头和结尾的标点符号，我们可以使用 `strip`，但是我们需要一个标点符号的字符列表。
- en: Characters in Python strings are in Unicode, which is an international standard
    used to represent letters in nearly every alphabet, numbers, symbols, punctuation
    marks, and more. The `unicodedata` module provides a `category` function we can
    use to tell which characters are punctuation. Given a letter, it returns a string
    with information about what category the letter is in.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Python 字符串中的字符使用 Unicode，这是一个国际标准，用于表示几乎所有字母表中的字母、数字、符号、标点符号等。`unicodedata`
    模块提供了一个 `category` 函数，我们可以用它来判断字符是否为标点符号。给定一个字母，它会返回一个字符串，指示该字母属于哪个类别。
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The category string of `'A'` is `'Lu'` – the `'L'` means it is a letter and
    the `'u'` means it is uppercase.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 字符 `'A'` 的类别字符串是 `'Lu'` —— `'L'` 表示它是一个字母，`'u'` 表示它是大写字母。
- en: The category string of `'.'` is `'Po'` – the `'P'` means it is punctuation and
    the `'o'` means its subcategory is “other”.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 字符 `'.'` 的类别字符串是 `'Po'` —— `'P'` 表示它是标点符号，`'o'` 表示它的子类别是“其他”。
- en: '[PRE10]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can find the punctuation marks in the book by checking for characters with
    categories that begin with `'P'`. The following loop stores the unique punctuation
    marks in a dictionary.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查类别以 `'P'` 开头的字符，来找出书中的标点符号。下面的循环将唯一的标点符号存储在字典中。
- en: '[PRE12]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To make a list of punctuation marks, we can join the keys of the dictionary
    into a string.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了制作一个标点符号的列表，我们可以将字典的键连接成一个字符串。
- en: '[PRE13]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now that we know which characters in the book are punctuation, we can write
    a function that takes a word, strips punctuation from the beginning and end, and
    converts it to lower case.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道书中哪些字符是标点符号，我们可以编写一个函数，接受一个单词，去除开头和结尾的标点符号，并将其转换为小写。
- en: '[PRE15]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here’s an example.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例。
- en: '[PRE16]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Because `strip` removes characters from the beginning and end, it leaves hyphenated
    words alone.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 `strip` 会删除字符串开头和结尾的字符，所以它不会影响带有连字符的单词。
- en: '[PRE18]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now here’s a loop that uses `split_line` and `clean_word` to identify the unique
    words in the book.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是一个使用 `split_line` 和 `clean_word` 来识别书中唯一单词的循环。
- en: '[PRE20]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: With this stricter definition of what a word is, there are about 4000 unique
    words. And we can confirm that the list of longest words has been cleaned up.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 根据对单词定义的严格标准，约有4000个唯一单词。我们可以确认最长单词的列表已经清理干净。
- en: '[PRE22]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now let’s see how many times each word is used.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看每个单词的使用频率。
- en: 12.3\. Word frequencies[#](#word-frequencies "Link to this heading")
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3\. 单词频率[#](#word-frequencies "跳转到此标题")
- en: The following loop computes the frequency of each unique word.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下循环计算每个唯一单词的频率。
- en: '[PRE24]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The first time we see a word, we initialize its frequency to `1`. If we see
    the same word again later, we increment its frequency.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们第一次遇到一个单词时，我们将其频率初始化为 `1`。如果之后再遇到相同的单词，我们就将其频率加一。
- en: To see which words appear most often, we can use `items` to get the key-value
    pairs from `word_counter`, and sort them by the second element of the pair, which
    is the frequency. First we’ll define a function that selects the second element.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看哪些单词最常出现，我们可以使用 `items` 从 `word_counter` 获取键值对，并按对中的第二个元素（即频率）进行排序。首先，我们将定义一个函数来选择第二个元素。
- en: '[PRE25]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now we can use `sorted` with two keyword arguments:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `sorted` 和两个关键字参数：
- en: '`key=second_element` means the items will be sorted according to the frequencies
    of the words.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`key=second_element` 表示项目将根据单词的频率进行排序。'
- en: '`reverse=True` means they items will be sorted in reverse order, with the most
    frequent words first.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reverse=True` 表示项目将按反向顺序排序，最频繁的单词排在最前面。'
- en: '[PRE26]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Here are the five most frequent words.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是五个最常见的单词。
- en: '[PRE27]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In the next section, we’ll encapsulate this loop in a function. And we’ll use
    it to demonstrate a new feature – optional parameters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将把这个循环封装在一个函数中。我们还将用它来演示一个新功能——可选参数。
- en: 12.4\. Optional parameters[#](#optional-parameters "Link to this heading")
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4\. 可选参数[#](#optional-parameters "跳转到此标题")
- en: We’ve used built-in functions that take optional parameters. For example, `round`
    takes an optional parameters called `ndigits` that indicates how many decimal
    places to keep.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了带有可选参数的内置函数。例如，`round` 有一个名为 `ndigits` 的可选参数，用于指示保留多少位小数。
- en: '[PRE29]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: But it’s not just built-in functions – we can write functions with optional
    parameters, too. For example, the following function takes two parameters, `word_counter`
    and `num`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 但这不仅仅是内置函数——我们也可以编写带有可选参数的函数。例如，下面的函数接受两个参数，`word_counter` 和 `num`。
- en: '[PRE31]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The second parameter looks like an assignment statement, but it’s not – it’s
    an optional parameter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数看起来像一个赋值语句，但其实它不是——它是一个可选参数。
- en: If you call this function with one argument, `num` gets the **default value**,
    which is `5`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用一个参数调用这个函数，`num`将获得**默认值**，即`5`。
- en: '[PRE32]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: If you call this function with two arguments, the second argument gets assigned
    to `num` instead of the default value.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用两个参数调用这个函数，第二个参数将被赋值给`num`，而不是默认值。
- en: '[PRE34]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In that case, we would say the optional argument **overrides** the default value.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以说可选参数**覆盖**了默认值。
- en: If a function has both required and optional parameters, all of the required
    parameters have to come first, followed by the optional ones.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个函数既有必需参数又有可选参数，所有必需的参数必须排在前面，后面跟着可选参数。
- en: '## 12.5\. Dictionary subtraction[#](#dictionary-subtraction "Link to this heading")'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '## 12.5\. 字典减法[#](#dictionary-subtraction "链接到这个标题")'
- en: Suppose we want to spell-check a book – that is, find a list of words that might
    be misspelled. One way to do that is to find words in the book that don’t appear
    in a list of valid words. In previous chapters, we’ve used a list of words that
    are considered valid in word games like Scrabble. Now we’ll use this list to spell-check
    Robert Louis Stevenson.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想进行拼写检查——也就是说，找出可能拼写错误的单词列表。做这个的方法之一是找出书中那些不在有效单词列表中的单词。在之前的章节中，我们使用了一个在类似拼字游戏（如拼字游戏）中被认为有效的单词列表。现在我们将使用这个列表来进行罗伯特·路易斯·史蒂文森的拼写检查。
- en: We can think of this problem as set subtraction – that is, we want to find all
    the words from one set (the words in the book) that are not in the other (the
    words in the list).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个问题看作集合减法——也就是说，我们想找出一个集合（书中的单词）中不在另一个集合（列表中的单词）中的所有单词。
- en: As we’ve done before, we can read the contents of `words.txt` and split it into
    a list of strings.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前做过的，我们可以读取`words.txt`的内容，并将其分割成一个字符串列表。
- en: '[PRE36]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The we’ll store the words as keys in a dictionary so we can use the `in` operator
    to check quickly whether a word is valid.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将把单词作为键存储在字典中，以便我们可以使用`in`运算符快速检查一个单词是否有效。
- en: '[PRE37]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now, to identify words that appear in the book but not in the word list, we’ll
    use `subtract`, which takes two dictionaries as parameters and returns a new dictionary
    that contains all the keys from one that are not in the other.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了识别书中出现但不在单词列表中的单词，我们将使用`subtract`，它接受两个字典作为参数，并返回一个新的字典，其中包含第一个字典中不在第二个字典中的所有键。
- en: '[PRE38]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Here’s how we use it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们如何使用它的方法。
- en: '[PRE39]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: To get a sample of words that might be misspelled, we can print the most common
    words in `diff`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取可能拼写错误的单词样本，我们可以打印出`diff`中最常见的单词。
- en: '[PRE40]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The most common “misspelled” words are mostly names and a few single-letter
    words (Mr. Utterson is Dr. Jekyll’s friend and lawyer).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的“拼写错误”单词大多是人名和一些单字母的单词（乌特森先生是杰基尔博士的朋友和律师）。
- en: If we select words that only appear once, they are more likely to be actual
    misspellings. We can do that by looping through the items and making a list of
    words with frequency `1`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择那些只出现一次的单词，它们更有可能是拼写错误。我们可以通过遍历项目，并列出频率为`1`的单词来做到这一点。
- en: '[PRE42]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here are the last few elements of the list.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是列表中的最后几个元素。
- en: '[PRE43]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Most of them are valid words that are not in the word list. But `'reindue'`
    appears to be a misspelling of `'reinduce'`, so at least we found one legitimate
    error.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 它们中的大多数是有效的单词，但不在单词列表中。不过，`'reindue'`似乎是`'reinduce'`的拼写错误，所以至少我们发现了一个真正的错误。
- en: 12.6\. Random numbers[#](#random-numbers "Link to this heading")
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6\. 随机数[#](#random-numbers "链接到这个标题")
- en: As a step toward Markov text generation, next we’ll choose a random sequence
    of words from `word_counter`. But first let’s talk about randomness.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 作为迈向马尔科夫文本生成的一步，接下来我们将从`word_counter`中选择一个随机的单词序列。但首先，让我们谈谈随机性。
- en: Given the same inputs, most computer programs are **deterministic**, which means
    they generate the same outputs every time. Determinism is usually a good thing,
    since we expect the same calculation to yield the same result. For some applications,
    though, we want the computer to be unpredictable. Games are one example, but there
    are more.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 给定相同的输入，大多数计算机程序是**确定性的**，这意味着它们每次生成相同的输出。确定性通常是好事，因为我们希望相同的计算产生相同的结果。然而，对于某些应用程序，我们希望计算机能够不可预测。游戏就是一个例子，但还有更多。
- en: Making a program truly nondeterministic turns out to be difficult, but there
    are ways to fake it. One is to use algorithms that generate **pseudorandom** numbers.
    Pseudorandom numbers are not truly random because they are generated by a deterministic
    computation, but just by looking at the numbers it is all but impossible to distinguish
    them from random.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让程序真正做到非确定性是很困难的，但有一些方法可以伪装成非确定性。一个方法是使用生成**伪随机**数的算法。伪随机数并不是真正的随机数，因为它们是通过确定性计算生成的，但仅凭查看这些数字，几乎无法将它们与真正的随机数区分开。
- en: The `random` module provides functions that generate pseudorandom numbers –
    which I will simply call “random” from here on. We can import it like this.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`random` 模块提供了生成伪随机数的函数——我将在这里简单地称其为“随机数”。我们可以这样导入它。'
- en: '[PRE45]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `random` module provides a function called `choice` that chooses an element
    from a list at random, with every element having the same probability of being
    chosen.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`random` 模块提供了一个名为 `choice` 的函数，可以从列表中随机选择一个元素，每个元素被选中的概率相同。'
- en: '[PRE46]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: If you call the function again, you might get the same element again, or a different
    one.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你再次调用该函数，你可能会得到相同的元素，或者得到不同的元素。
- en: '[PRE48]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the long run, we expect to get every element about the same number of times.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，我们希望每个元素出现的次数大致相同。
- en: If you use `choice` with a dictionary, you get a `KeyError`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用字典调用 `choice`，你会得到一个 `KeyError`。
- en: '[PRE50]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: To choose a random key, you have to put the keys in a list and then call `choice`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择一个随机键，你必须先将键放入列表中，然后调用 `choice`。
- en: '[PRE52]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: If we generate a random sequence of words, it doesn’t make much sense.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们生成一个随机的单词序列，它没有太大的意义。
- en: '[PRE54]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Part of the problem is that we are not taking into account that some words are
    more common than others. The results will be better if we choose words with different
    “weights”, so that some are chosen more often than others.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的一部分是我们没有考虑到某些单词比其他单词更常见。如果我们选择具有不同“权重”的单词，结果会更好，这样有些单词会比其他单词更频繁地被选中。
- en: If we use the values from `word_counter` as weights, each word is chosen with
    a probability that depends on its frequency.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用来自 `word_counter` 的值作为权重，每个单词的选择概率将取决于它的频率。
- en: '[PRE56]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The `random` module provides another function called `choices` that takes weights
    as an optional argument.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`random` 模块还提供了另一个名为 `choices` 的函数，接受权重作为一个可选参数。'
- en: '[PRE57]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: And it takes another optional argument, `k`, that specifies the number of words
    to select.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它还接受另一个可选参数 `k`，该参数指定要选择的单词数。
- en: '[PRE59]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The result is a list of strings that we can join into something that’s looks
    more like a sentence.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个字符串的列表，我们可以将其连接成更像句子的东西。
- en: '[PRE61]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: If you choose words from the book at random, you get a sense of the vocabulary,
    but a series of random words seldom makes sense because there is no relationship
    between successive words. For example, in a real sentence you expect an article
    like “the” to be followed by an adjective or a noun, and probably not a verb or
    adverb. So the next step is to look at these relationships between words.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从书中随机选择单词，你可以感知到词汇量，但一系列随机单词通常没有意义，因为连续单词之间没有关系。例如，在一个真实的句子中，你期望像“the”这样的冠词后面跟着形容词或名词，而可能不是动词或副词。所以，下一步是查看单词之间的这些关系。
- en: 12.7\. Bigrams[#](#bigrams "Link to this heading")
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.7\. 二元组[#](#bigrams "链接到此标题")
- en: Instead of looking at one word at a time, now we’ll look at sequences of two
    words, which are called **bigrams**. A sequence of three words is called a **trigram**,
    and a sequence with some unspecified number of words is called an **n-gram**.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不再逐个单词查看，而是查看由两个单词组成的序列，这叫做**二元组**。由三个单词组成的序列叫做**三元组**，由若干个单词组成的序列叫做**n-元组**。
- en: Let’s write a program that finds all of the bigrams in the book and the number
    of times each one appears. To store the results, we’ll use a dictionary where
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来写一个程序，找出书中的所有二元组以及每个二元组出现的次数。为了存储结果，我们将使用一个字典，其中
- en: The keys are tuples of strings that represent bigrams, and
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键是表示二元组的大写字母字符串的元组，
- en: The values are integers that represent frequencies.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些值是表示频率的整数。
- en: Let’s call it `bigram_counter`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称之为 `bigram_counter`。
- en: '[PRE63]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The following function takes a list of two strings as a parameter. First it
    makes a tuple of the two strings, which can be used as a key in a dictionary.
    Then it adds the key to `bigram_counter`, if it doesn’t exist, or increments the
    frequency if it does.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数接受两个字符串组成的列表作为参数。首先，它将这两个字符串组成一个元组，可以作为字典中的键。然后，如果该键不存在，它会将其添加到 `bigram_counter`
    中；如果已经存在，它会增加该键的频率。
- en: '[PRE64]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: As we go through the book, we have to keep track of each pair of consecutive
    words. So if we see the sequence “man is not truly one”, we would add the bigrams
    “man is”, “is not”, “not truly”, and so on.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本书的过程中，我们必须跟踪每一对连续的单词。因此，如果我们看到“man is not truly one”这一序列，我们将添加“大词组”：“man
    is”，“is not”，“not truly”等等。
- en: To keep track of these bigrams, we’ll use a list called `window`, because it
    is like a window that slides over the pages of the book, showing only two words
    at a time. Initially, `window` is empty.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪这些大词组，我们将使用一个名为`window`的列表，因为它就像一本书的窗口，一次只显示两个单词。最初，`window`是空的。
- en: '[PRE65]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: We’ll use the following function to process the words one at a time.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下函数逐个处理单词。
- en: '[PRE66]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The first time this function is called, it appends the given word to `window`.
    Since there is only one word in the window, we don’t have a bigram yet, so the
    function ends.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当第一次调用此函数时，它会将给定的单词附加到`window`中。由于窗口中只有一个单词，我们还没有形成一个大词组，因此函数结束。
- en: The second time it’s called – and every time thereafter – it appends a second
    word to `window`. Since there are two words in the window, it calls `count_bigram`
    to keep track of how many times each bigram appears. Then it uses `pop` to remove
    the first word from the window.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次调用时——以及以后每次调用——它会将第二个单词添加到`window`中。由于窗口中有两个单词，它会调用`count_bigram`来跟踪每个大词组出现的次数。然后，它使用`pop`移除窗口中的第一个单词。
- en: The following program loops through the words in the book and processes them
    one at a time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下程序循环遍历书中的单词并逐一处理它们。
- en: '[PRE67]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The result is a dictionary that maps from each bigram to the number of times
    it appears. We can use `print_most_common` to see the most common bigrams.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个字典，将每个大词组映射到它出现的次数。我们可以使用`print_most_common`来查看最常见的大词组。
- en: '[PRE68]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Looking at these results, we can get a sense of which pairs of words are most
    likely to appear together. We can also use the results to generate random text,
    like this.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这些结果，我们可以感知哪些单词对最可能一起出现。我们还可以利用这些结果生成随机文本，像这样。
- en: '[PRE70]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '`bigrams` is a list of the bigrams that appear in the books. `weights` is a
    list of their frequencies, so `random_bigrams` is a sample where the probability
    a bigram is selected is proportional to its frequency.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigrams`是书中出现的大词组列表。`weights`是它们的频率列表，因此`random_bigrams`是一个样本，其中大词组被选中的概率与它的频率成正比。'
- en: Here are the results.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果。
- en: '[PRE71]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: This way of generating text is better than choosing random words, but still
    doesn’t make a lot of sense.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这种生成文本的方式比选择随机单词要好，但仍然没有太多意义。
- en: 12.8\. Markov analysis[#](#markov-analysis "Link to this heading")
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.8. 马尔科夫分析[#](#markov-analysis "跳转到此部分")
- en: 'We can do better with Markov chain text analysis, which computes, for each
    word in a text, the list of words that come next. As an example, we’ll analyze
    these lyrics from the Monty Python song *Eric, the Half a Bee*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过马尔科夫链文本分析做得更好，它为文本中的每个单词计算接下来会出现的单词列表。作为示例，我们将分析《蒙提·派森》歌曲 *Eric, the Half
    a Bee* 的歌词：
- en: '[PRE73]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: To store the results, we’ll use a dictionary that maps from each word to the
    list of words that follow it.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了存储结果，我们将使用一个字典，它将每个单词映射到跟随它的单词列表。
- en: '[PRE74]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: As an example, let’s start with the first two words of the song.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们从歌曲的前两个单词开始。
- en: '[PRE75]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: If the first word is not in `successor_map`, we have to add a new item that
    maps from the first word to a list containing the second word.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一个单词不在`successor_map`中，我们必须添加一个新项，将第一个单词映射到包含第二个单词的列表。
- en: '[PRE76]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: If the first word is already in the dictionary, we can look it up to get the
    list of successors we’ve seen so far, and append the new one.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一个单词已经在字典中，我们可以查找它，获取我们到目前为止看到的后继单词列表，并附加新的单词。
- en: '[PRE78]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: The following function encapsulates these steps.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数封装了这些步骤。
- en: '[PRE80]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: If the same bigram appears more that once, the second word is added to the list
    more than once. In this way, `successor_map` keeps track of how many times each
    successor appears.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果相同的大词组出现多次，第二个单词会被多次添加到列表中。通过这种方式，`successor_map`会跟踪每个后继单词出现的次数。
- en: As we did in the previous section, we’ll use a list called `window` to store
    pairs of consecutive words. And we’ll use the following function to process the
    words one at a time.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中所做的，我们将使用一个名为`window`的列表来存储连续单词对。我们将使用以下函数逐个处理单词。
- en: '[PRE81]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Here’s how we use it to process the words in the song.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们如何用它来处理歌曲中的单词。
- en: '[PRE82]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: And here are the results.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果。
- en: '[PRE83]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: The word `'half'` can be followed by `'a'`, `'not'`, or `'the'`. The word `'a'`
    can be followed by `'bee'` or `'vis'`. Most of the other words appear only once,
    so they are followed by only a single word.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 单词`'half'`可以跟随`'a'`、`'not'`或`'the'`。单词`'a'`可以跟随`'bee'`或`'vis'`。大多数其他单词只出现一次，因此它们只跟随一个单词。
- en: Now let’s analyze the book.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们分析这本书。
- en: '[PRE85]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We can look up any word and find the words that can follow it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查找任何单词，并找到可以跟随它的单词。
- en: '[PRE86]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: In this list of successors, notice that the word `'to'` appears three times
    – the other successors only appear once.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个后继列表中，请注意单词`'to'`出现了三次，而其他后继只出现了一次。
- en: 12.9\. Generating text[#](#generating-text "Link to this heading")
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.9\. 生成文本[#](#generating-text "Link to this heading")
- en: 'We can use the results from the previous section to generate new text with
    the same relationships between consecutive words as in the original. Here’s how
    it works:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用前一部分的结果，生成与原文中连续单词之间关系相同的新文本。它是如何工作的：
- en: Starting with any word that appears in the text, we look up its possible successors
    and choose one at random.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中出现的任何一个单词开始，我们查找它的可能后继，并随机选择一个。
- en: Then, using the chosen word, we look up its possible successors, and choose
    one at random.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，使用选中的单词，我们查找它的可能后继，并随机选择一个。
- en: We can repeat this process to generate as many words as we want. As an example,
    let’s start with the word `'although'`. Here are the words that can follow it.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复这个过程，生成我们想要的任意多个单词。举个例子，让我们从单词`'although'`开始。以下是可以跟随它的单词。
- en: '[PRE88]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: We can use `choice` to choose from the list with equal probability.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`choice`从列表中以相等的概率选择。
- en: '[PRE90]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: If the same word appears more than once in the list, it is more likely to be
    selected.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果同一个单词在列表中出现多次，它被选中的概率更大。
- en: Repeating these steps, we can use the following loop to generate a longer series.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 重复这些步骤，我们可以使用以下循环生成更长的序列。
- en: '[PRE92]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The result sounds more like a real sentence, but it still doesn’t make much
    sense.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 结果听起来更像一个真实的句子，但它仍然没有太大意义。
- en: We can do better using more than one word as a key in `successor_map`. For example,
    we can make a dictionary that maps from each bigram – or trigram – to the list
    of words that come next. As an exercise, you’ll have a chance to implement this
    analysis and see what the results look like.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多个单词作为`successor_map`中的键，我们可以做得更好。例如，我们可以创建一个字典，将每个二元组（bigram）或三元组（trigram）映射到后续单词的列表。作为一个练习，你将有机会实现这个分析，并查看结果是什么样的。
- en: '## 12.10\. Debugging[#](#debugging "Link to this heading")'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '## 12.10\. 调试[#](#debugging "Link to this heading")'
- en: 'At this point we are writing more substantial programs, and you might find
    that you are spending more time debugging. If you are stuck on a difficult bug,
    here are a few things to try:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 到这个阶段，我们正在编写更复杂的程序，你可能会发现你花更多时间进行调试。如果你在调试一个难题时卡住了，下面是一些可以尝试的办法：
- en: 'Reading: Examine your code, read it back to yourself, and check that it says
    what you meant to say.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读：检查你的代码，自己读一遍，确认它是否表达了你想表达的意思。
- en: 'Running: Experiment by making changes and running different versions. Often
    if you display the right thing at the right place in the program, the problem
    becomes obvious, but sometimes you have to build scaffolding.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行：通过进行更改并运行不同的版本进行实验。通常，如果你在程序中的正确位置显示正确的内容，问题会变得明显，但有时你需要构建一些支架。
- en: 'Ruminating: Take some time to think! What kind of error is it: syntax, runtime,
    or semantic? What information can you get from the error messages, or from the
    output of the program? What kind of error could cause the problem you’re seeing?
    What did you change last, before the problem appeared?'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沉思：花点时间思考一下！这是哪种错误：语法错误、运行时错误，还是语义错误？你能从错误信息或者程序的输出中获取哪些信息？是什么样的错误可能导致你看到的问题？在问题出现之前，你最后修改了什么？
- en: 'Rubberducking: If you explain the problem to someone else, you sometimes find
    the answer before you finish asking the question. Often you don’t need the other
    person; you could just talk to a rubber duck. And that’s the origin of the well-known
    strategy called **rubber duck debugging**. I am not making this up – see [https://en.wikipedia.org/wiki/Rubber_duck_debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 橡皮鸭调试：如果你将问题解释给别人听，你有时会在还没问完问题之前就找到答案。通常你不需要另一个人；你可以只和一只橡皮鸭交谈。这就是著名的策略——**橡皮鸭调试**的来源。我不是在编造这个——请看
    [https://en.wikipedia.org/wiki/Rubber_duck_debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging)。
- en: 'Retreating: At some point, the best thing to do is back up – undoing recent
    changes – until you get to a program that works. Then you can start rebuilding.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后退：在某些时候，最好的做法是后退——撤销最近的更改——直到你回到一个正常工作的程序。然后你可以重新开始构建。
- en: 'Resting: If you give your brain a break, sometime it will find the problem
    for you.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 休息：如果你给大脑休息，有时候它会自己找到问题所在。
- en: Beginning programmers sometimes get stuck on one of these activities and forget
    the others. Each activity comes with its own failure mode.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者程序员有时会在某个活动上卡住，忘记其他的活动。每个活动都有它自己的失败模式。
- en: For example, reading your code works if the problem is a typographical error,
    but not if the problem is a conceptual misunderstanding. If you don’t understand
    what your program does, you can read it 100 times and never see the error, because
    the error is in your head.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，读取你的代码如果问题是拼写错误的话是有效的，但如果问题是概念性误解，则无效。如果你不理解你的程序是做什么的，即使你读它100遍也看不出错误，因为错误在你的脑海里。
- en: Running experiments can work, especially if you run small, simple tests. But
    if you run experiments without thinking or reading your code, it can take a long
    time to figure out what’s happening.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 运行实验是有效的，特别是当你运行小的、简单的测试时。但如果你没有思考或阅读代码就去实验，可能会花费很长时间才能搞清楚发生了什么。
- en: You have to take time to think. Debugging is like an experimental science. You
    should have at least one hypothesis about what the problem is. If there are two
    or more possibilities, try to think of a test that would eliminate one of them.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须抽时间思考。调试就像是实验科学。你应该对问题至少有一个假设。如果有两个或更多的可能性，尝试想出一个可以排除其中一个的测试。
- en: But even the best debugging techniques will fail if there are too many errors,
    or if the code you are trying to fix is too big and complicated. Sometimes the
    best option is to retreat, simplifying the program until you get back to something
    that works.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 但即使是最好的调试技术，也会因为错误太多，或者你试图修复的代码过于庞大复杂而失败。有时候最好的选择是退一步，简化程序，直到恢复到一个能正常工作的版本。
- en: Beginning programmers are often reluctant to retreat because they can’t stand
    to delete a line of code (even if it’s wrong). If it makes you feel better, copy
    your program into another file before you start stripping it down. Then you can
    copy the pieces back one at a time.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者程序员通常不愿意后退，因为他们无法忍受删除一行代码（即使它是错的）。如果这样能让你感觉好一点，可以在开始简化程序之前，把你的程序复制到另一个文件中。然后你可以逐个复制回来。
- en: Finding a hard bug requires reading, running, ruminating, retreating, and sometimes
    resting. If you get stuck on one of these activities, try the others.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 找到一个棘手的bug需要阅读、运行、沉思、退步，有时候还需要休息。如果你在某个活动中遇到困难，尝试其他的方法。
- en: 12.11\. Glossary[#](#glossary "Link to this heading")
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.11\. 词汇表[#](#glossary "Link to this heading")
- en: '**default value:** The value assigned to a parameter if no argument is provided.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**默认值（default value）：** 如果没有提供参数，将赋给参数的值。'
- en: '**override:** To replace a default value with an argument.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**覆盖（override）：** 用一个参数替换默认值。'
- en: '**deterministic:** A deterministic program does the same thing each time it
    runs, given the same inputs.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**确定性（deterministic）：** 一个确定性的程序每次运行时，只要输入相同，就会做相同的事情。'
- en: '**pseudorandom:** A pseudorandom sequence of numbers appears to be random,
    but is generated by a deterministic program.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**伪随机（pseudorandom）：** 伪随机数列看起来像是随机的，但它是由一个确定性的程序生成的。'
- en: '**bigram:** A sequence of two elements, often words.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**二元组（bigram）：** 一个包含两个元素的序列，通常是单词。'
- en: '**trigram:** A sequence of three elements.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**三元组（trigram）：** 一个包含三个元素的序列。'
- en: '**n-gram:** A sequence of an unspecified number of elements.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**n元组（n-gram）：** 一个包含不确定数量元素的序列。'
- en: '**rubber duck debugging:** A way of debugging by explaining a problem aloud
    to an inanimate object.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**橡皮鸭调试（rubber duck debugging）：** 通过大声向一个无生命物体解释问题来进行调试的一种方法。'
- en: 12.12\. Exercises[#](#exercises "Link to this heading")
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.12\. 练习[#](#exercises "Link to this heading")
- en: '[PRE94]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 12.12.1\. Ask a virtual assistant[#](#ask-a-virtual-assistant "Link to this
    heading")
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.12.1\. 向虚拟助手询问[#](#ask-a-virtual-assistant "Link to this heading")
- en: In `add_bigram`, the `if` statement creates a new list or appends an element
    to an existing list, depending on whether the key is already in the dictionary.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在`add_bigram`中，`if`语句根据字典中是否已存在该键，来创建一个新的列表或将元素添加到现有列表中。
- en: '[PRE95]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Dictionaries provide a method called `setdefault` that we can use to do the
    same thing more concisely. Ask a virtual assistant how it works, or copy `add_word`
    into a virtual assistant and ask “Can you rewrite this using `setdefault`?”
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 字典提供了一种叫做`setdefault`的方法，我们可以用它更简洁地做同样的事情。你可以向虚拟助手询问它是如何工作的，或者把`add_word`复制到虚拟助手中并问：“你能用`setdefault`重写这个吗？”
- en: In this chapter we implemented Markov chain text analysis and generation. If
    you are curious, you can ask a virtual assistant for more information on the topic.
    One of the things you might learn is that virtual assistants use algorithms that
    are similar in many ways – but also different in important ways. Ask a VA, “What
    are the differences between large language models like GPT and Markov chain text
    analysis?”
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们实现了马尔科夫链文本分析和生成。如果你感兴趣，可以向虚拟助手询问更多关于该主题的信息。你可能学到的一件事是，虚拟助手使用的算法在许多方面是相似的——但在重要方面也有所不同。问一个虚拟助手：“像GPT这样的语言模型和马尔科夫链文本分析有什么区别？”
- en: 12.12.2\. Exercise[#](#exercise "Link to this heading")
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.12.2\. 练习[#](#exercise "链接到此标题")
- en: Write a function that counts the number of times each trigram (sequence of three
    words) appears. If you test your function with the text of *Dr. Jekyll and Mr.
    Hyde*, you should find that the most common trigram is “said the lawyer”.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个函数，计算每个三元组（由三个单词组成的序列）出现的次数。如果你使用《*化身博士*》的文本来测试你的函数，你应该会发现最常见的三元组是“said
    the lawyer”。
- en: 'Hint: Write a function called `count_trigram` that is similar to `count_bigram`.
    Then write a function called `process_word_trigram` that is similar to `process_word_bigram`.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：编写一个名为`count_trigram`的函数，它类似于`count_bigram`。然后编写一个名为`process_word_trigram`的函数，它类似于`process_word_bigram`。
- en: 12.12.3\. Exercise[#](#id1 "Link to this heading")
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.12.3\. 练习[#](#id1 "链接到此标题")
- en: Now let’s implement Markov chain text analysis with a mapping from each bigram
    to a list of possible successors.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过从每个二元组映射到可能的后继词列表来实现马尔科夫链文本分析。
- en: Starting with `add_bigram`, write a function called `add_trigram` that takes
    a list of three words and either adds or updates an item in `successor_map`, using
    the first two words as the key and the third word as a possible successor.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 从`add_bigram`开始，编写一个名为`add_trigram`的函数，该函数接收一个包含三个单词的列表，并使用前两个单词作为键，第三个单词作为可能的后继词，在`successor_map`中添加或更新一个条目。
- en: Here’s a version of `process_word_trigram` that calls `add_trigram`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个调用`add_trigram`的`process_word_trigram`版本。
- en: '[PRE96]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: You can use the following loop to test your function with the words from the
    book.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下循环来测试你的函数，使用来自书本的单词。
- en: '[PRE97]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: In the next exercise, you’ll use the results to generate new random text.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将使用这些结果生成新的随机文本。
- en: 12.12.4\. Exercise[#](#id2 "Link to this heading")
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.12.4\. 练习[#](#id2 "链接到此标题")
- en: For this exercise, we’ll assume that `successor_map` is a dictionary that maps
    from each bigram to the list of words that follow it.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们假设`successor_map`是一个字典，它将每个二元组映射到后继词的列表。
- en: To generate random text, we’ll start by choosing a random key from `successor_map`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成随机文本，我们将从`successor_map`中随机选择一个键。
- en: '[PRE98]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Now write a loop that generates 50 more words following these steps:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在编写一个循环，按照这些步骤生成更多的50个单词：
- en: In `successor_map`, look up the list of words that can follow `bigram`.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`successor_map`中查找可以跟随`bigram`的单词列表。
- en: Choose one of them at random and print it.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机选择其中一个并打印出来。
- en: For the next iteration, make a new bigram that contains the second word from
    `bigram` and the chosen successor.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于下一个迭代，创建一个新的二元组，该二元组包含`bigram`中的第二个单词和所选的后继词。
- en: For example, if we start with the bigram `('doubted', 'if')` and choose `'from'`
    as its successor, the next bigram is `('if', 'from')`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们从二元组`('doubted', 'if')`开始，并选择`'from'`作为其后继词，则下一个二元组是`('if', 'from')`。
- en: If everything is working, you should find that the generated text is recognizably
    similar in style to the original, and some phrases make sense, but the text might
    wander from one topic to another.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，你应该会发现生成的文本在风格上与原文相似，一些短语是有意义的，但文本可能会从一个话题跳到另一个话题。
- en: As a bonus exercise, modify your solution to the last two exercises to use trigrams
    as keys in `successor_map`, and see what effect it has on the results.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 作为附加练习，修改你对最后两个练习的解决方案，使用三元组作为`successor_map`中的键，看看它对结果产生了什么影响。
- en: '[Think Python: 3rd Edition](https://allendowney.github.io/ThinkPython/index.html)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[Think Python: 第3版](https://allendowney.github.io/ThinkPython/index.html)'
- en: Copyright 2024 [Allen B. Downey](https://allendowney.com)
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 版权所有 2024 [Allen B. Downey](https://allendowney.com)
- en: 'Code license: [MIT License](https://mit-license.org/)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 代码许可证：[MIT 许可证](https://mit-license.org/)
- en: 'Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 文本许可证：[知识共享署名-非商业性使用-相同方式共享 4.0 国际](https://creativecommons.org/licenses/by-nc-sa/4.0/)
