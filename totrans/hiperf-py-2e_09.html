<html><head></head><body><div id="sbo-rt-content" class="calibre2"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. The multiprocessing Module" class="calibre3"><div class="preface" id="multiprocessing">
<h1 class="calibre23"><span class="publishername">Chapter 9. </span>The multiprocessing Module</h1>

<aside data-type="sidebar" epub:type="sidebar" class="calibre40"><div class="sidebar" id="idm46122410329288">
<h5 class="calibre41">Questions You’ll Be Able to Answer After This Chapter</h5>
<ul class="printings">
<li class="calibre21">
<p class="calibre42">What does the <code class="calibre26">multiprocessing</code> module offer?</p>
</li>
<li class="calibre21">
<p class="calibre42">What’s the difference between processes and threads?</p>
</li>
<li class="calibre21">
<p class="calibre42">How do I choose the right size for a process pool?</p>
</li>
<li class="calibre21">
<p class="calibre42">How do I use nonpersistent queues for work processing?</p>
</li>
<li class="calibre21">
<p class="calibre42">What are the costs and benefits of interprocess communication?</p>
</li>
<li class="calibre21">
<p class="calibre42">How can I process <code class="calibre26">numpy</code> data with many CPUs?</p>
</li>
<li class="calibre21">
<p class="calibre42">How would I use Joblib to simplify parallelized and cached scientific work?</p>
</li>
<li class="calibre21">
<p class="calibre42">Why do I need locking to avoid data loss?</p>
</li>
</ul>
</div></aside>

<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="multiprocessing and" id="idm46122410608792" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multiprocessing" id="mp_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>CPython doesn’t use multiple CPUs by default. This is partly because Python was
designed back in a single-core era, and partly because parallelizing can actually
be quite difficult to do efficiently. Python gives us the tools to do it but
leaves us to make our own choices. It is painful to see your multicore machine
using just one CPU on a long-running process, though, so in this chapter we’ll review ways
of using all the machine’s cores at once.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">We just mentioned <em class="hyperlink">CPython</em>—the common implementation that we all use. Nothing in the Python language stops it from using multicore systems. CPython’s implementation cannot efficiently use multiple cores, but future implementations may not be bound by this restriction.</p>
</div>

<p class="author1">We live in a multicore world—4 cores are common in laptops, and 32-core
desktop configurations are available. If your job can be split to run on multiple CPUs <em class="hyperlink">without</em> too
much engineering effort, this is a wise direction to consider.</p>

<p class="author1">When Python is used to parallelize a problem over a set of CPUs, you can expect <em class="hyperlink">up to</em> an
<em class="hyperlink">n</em>-times (<em class="hyperlink">n</em>×) speedup with <em class="hyperlink">n</em> cores. If you have a quad-core machine and you can use
all four cores for your task, it might run in a quarter of the original runtime. You
are unlikely to see a greater than 4× speedup; in practice, you’ll probably see gains of 3–4×.</p>

<p class="author1">Each additional process will increase the
communication overhead and decrease the available RAM, so you rarely get a full <em class="hyperlink">n</em>-times
speedup.  Depending on which problem you are solving, the communication
overhead can even get so large that you can see very significant slowdowns.
These sorts of problems are often where the complexity lies for any sort of parallel
programming and normally require a change in algorithm.  This is why
<a data-type="indexterm" data-primary="parallel programming" id="idm46122410599720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>parallel programming is often considered an art.</p>

<p class="author1">If you’re not familiar with <a data-type="indexterm" data-primary="Amdahl's law" id="idm46122410598504" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/GC2CK" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Amdahl’s law</a>, it is worth doing some background reading. The law shows that if only a small part of your code can be parallelized, it doesn’t matter how many CPUs you throw at it; it still won’t run much faster overall. Even if a large fraction of your runtime could be parallelized, there’s a finite number of CPUs that can be used efficiently to make the overall process run faster before you get to a point of diminishing returns.</p>

<p class="author1">The <code class="calibre26">multiprocessing</code> module lets you use process- and thread-based parallel
processing, share work over queues, and share data among processes. It is
mostly focused on single-machine multicore <span class="publishername">parallelism</span> (there are better
options for multimachine parallelism). A very common use is to parallelize a
task over a set of processes for a CPU-bound problem. You might also use <a data-type="indexterm" data-primary="OpenMP" id="idm46122410594536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>OpenMP to
parallelize an I/O-bound problem, but as we saw in <a data-type="xref" href="ch08.xhtml#chapter-concurrency" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 8</a>, there are better tools for this (e.g., the
new <code class="calibre26">asyncio</code> module in Python 3 and <code class="calibre26">tornado</code>).</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">OpenMP is a low-level interface to multiple cores—you might wonder whether to focus on it rather than <code class="calibre26">multiprocessing</code>. We introduced it with Cython back in <a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>, but we don’t cover it in this chapter. <code class="calibre26">multiprocessing</code> works at a higher level, sharing Python data structures, while OpenMP works with C primitive objects (e.g., integers and floats) once you’ve compiled to C. Using it makes sense only if you’re compiling your code; if you’re not compiling (e.g., if you’re using efficient <code class="calibre26">numpy</code> code and you want to run on many cores), then sticking with <code class="calibre26">multiprocessing</code> is probably the right <span class="publishername">approach</span>.</p>
</div>

<p class="author1">To parallelize your task, you have to think a little differently from the normal
way of writing a serial process. You must also accept that debugging a
parallelized task is <em class="hyperlink">harder</em>—often, it can be very frustrating. We’d recommend
keeping the parallelism as simple as possible (even if you’re not squeezing
every last drop of power from your machine) so that your development velocity is
kept high.</p>

<p class="author1">One particularly difficult topic is the sharing of state in a parallel system—it feels like it should be easy, but it incurs lots of overhead and can be hard
to get right. There are many use cases, each with different trade-offs, so
there’s definitely no one solution for everyone. In
<a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Verifying Primes Using Interprocess Communication”</a>, we’ll go
through state sharing with an eye on the synchronization costs. Avoiding shared
state will make your life far easier.</p>

<p class="author1">In fact, an algorithm can be analyzed to see how well it’ll perform in a
parallel environment almost entirely by how much state must be shared.  For
example, if we can have multiple Python processes all solving the same problem
without communicating with one another (a situation known as <em class="hyperlink">embarrassingly
parallel</em>), not much of a penalty will be incurred as we add more and
more Python processes.</p>

<p class="author1">On the other hand, if each process needs to communicate with every other Python
process, the communication overhead will slowly overwhelm the processing and slow
things down.  This means that as we add more and more Python processes, we can
actually slow down our overall performance.</p>

<p class="author1">As a result, sometimes some counterintuitive algorithmic changes must be made to
efficiently solve a problem in parallel.  For example, when solving the diffusion
equation (<a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>) in parallel, each process actually does some
redundant work that another process also does.  This redundancy reduces the
amount of communication required and speeds up the overall calculation!</p>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="uses for" id="idm46122409971016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Here are some typical jobs for the <code class="calibre26">multiprocessing</code> module:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Parallelize a CPU-bound task with <code class="calibre26">Process</code> or <code class="calibre26">Pool</code> objects</p>
</li>
<li class="calibre21">
<p class="calibre27">Parallelize an I/O-bound task in a <code class="calibre26">Pool</code> with threads using the (oddly named) <code class="calibre26">dummy</code> module</p>
</li>
<li class="calibre21">
<p class="calibre27">Share pickled work via a <code class="calibre26">Queue</code></p>
</li>
<li class="calibre21">
<p class="calibre27">Share state between parallelized workers, including bytes, primitive datatypes, dictionaries, and lists</p>
</li>
</ul>

<p class="author1">If you come from a language where threads are used for CPU-bound tasks (e.g., C++
or Java), you should know that while threads in Python are OS-native
(they’re not simulated—they are actual operating system threads), they are bound
by the <a data-type="indexterm" data-primary="global interpreter lock (GIL)" id="idm46122409962568" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="GIL (global interpreter lock)" id="idm46122409961800" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>GIL, so only one thread may interact with Python objects at a time.</p>

<p class="author1">By using processes, we run a number of Python interpreters in
parallel, each with a private memory space with its own GIL, and each runs in
series (so there’s no competition for each GIL). This is the easiest way to
speed up a CPU-bound task in Python. If we need to <a data-type="indexterm" data-primary="sharing of state" id="idm46122409960312" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>share state, we need to
add some communication overhead; we’ll explore that in
<a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-verifying-primes-using-inter-process-communication" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Verifying Primes Using Interprocess Communication”</a>.</p>

<p class="author1">If you work with <a data-type="indexterm" data-primary="multiprocessing" data-secondary="numpy and" id="idm46122409958296" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="in multiprocessing" id="idm46122409957288" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">numpy</code> arrays, you might wonder if you can create a larger
array (e.g., a large 2D matrix) and ask processes to work on segments of the
array in parallel. You can, but it is hard to discover how by trial and error, so in
<a data-type="xref" href="ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Sharing numpy Data with multiprocessing”</a> we’ll work through
sharing a 25 GB <code class="calibre26">numpy</code> array across four CPUs. Rather than sending partial
copies of the data (which would at least double the working size required in
RAM and create a massive communication overhead), we share the underlying bytes
of the array among the processes. This is an ideal approach to sharing a large
array among local workers on one machine.</p>

<p class="author1">In this chapter we also introduce the <a href="https://oreil.ly/RqQXD" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Joblib</a> library—this builds on the <code class="calibre26">multiprocessing</code> library
and offers improved cross-platform compatibility, a simple API for parallelization, and
convenient persistence of cached results. Joblib is designed for scientific use, and we urge you to
check it out.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Here, we discuss <code class="calibre26">multiprocessing</code> on *nix-based machines (this chapter is
written using Ubuntu; the code should run unchanged on a Mac). Since Python 3.4, the quirks that appeared on Windows have been dealt with. Joblib has stronger cross-platform support than <code class="calibre26">multiprocessing</code>, and we recommend you review it ahead of <code class="calibre26">multiprocessing</code>.</p>
</div>

<p class="author1">In this chapter we’ll hardcode the number of processes
(<code class="calibre26">NUM_PROCESSES=4</code>) to match the four physical cores on Ian’s laptop. By default,
<code class="calibre26">multiprocessing</code> will use as many cores as it can see (the machine presents
eight—four CPUs and four hyperthreads). Normally you’d avoid hardcoding the
number of processes to create unless you were specifically managing your
resources.</p>






<section data-type="sect1" data-pdf-bookmark="An Overview of the multiprocessing Module" class="calibre3"><div class="preface" id="idm46122410575816">
<h1 class="calibre25">An Overview of the multiprocessing Module</h1>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="overview" id="mp_ov" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <code class="calibre26">multiprocessing</code> module provides a low-level interface to process- and thread-based parallelism. Its
main components are as follows<a data-type="indexterm" data-primary="Process component, in multiprocessing module" id="idm46122410572328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Pool component, in multiprocessing module" id="idm46122410571656" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="synchronization primitives" id="idm46122410571016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Queue component, in multiprocessing module" id="idm46122410570328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Pipe component, in multiprocessing module" id="idm46122410569688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Manager" id="idm46122410569048" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="ctypes" id="idm46122410568376" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>:</p>
<dl class="calibre28">
<dt class="calibre29"><code class="calibre26">Process</code></dt>
<dd class="calibre30">
<p class="calibre31">A forked copy of the current process; this creates a new process identifier, and the task runs as an independent child process in the operating system. You can start and query the state of the <code class="calibre26">Process</code> and provide it with a <code class="calibre26">target</code> method to run.</p>
</dd>
<dt class="calibre29"><code class="calibre26">Pool</code></dt>
<dd class="calibre30">
<p class="calibre31">Wraps the <code class="calibre26">Process</code> or <code class="calibre26">threading.Thread</code> API into a convenient pool of workers that share a chunk of work and return an aggregated result.</p>
</dd>
<dt class="calibre29"><code class="calibre26">Queue</code></dt>
<dd class="calibre30">
<p class="calibre31">A FIFO queue allowing multiple producers and consumers.</p>
</dd>
<dt class="calibre29"><code class="calibre26">Pipe</code></dt>
<dd class="calibre30">
<p class="calibre31">A uni- or bidirectional communication channel between two processes.</p>
</dd>
<dt class="calibre29"><code class="calibre26">Manager</code></dt>
<dd class="calibre30">
<p class="calibre31">A high-level managed interface to share Python objects between processes.</p>
</dd>
<dt class="calibre29"><code class="calibre26">ctypes</code></dt>
<dd class="calibre30">
<p class="calibre31">Allows sharing of primitive datatypes (e.g., integers, floats, and bytes) between processes after they have forked.</p>
</dd>
<dt class="calibre29">Synchronization primitives</dt>
<dd class="calibre30">
<p class="calibre31">Locks and semaphores to synchronize control flow between processes.</p>
</dd>
</dl>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">In Python 3.2, the <code class="calibre26">concurrent.futures</code> module was introduced (via <a href="http://bit.ly/concurrent_add" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PEP 3148</a>); this provides the core behavior of <code class="calibre26">multiprocessing</code>, with a simpler interface based on Java’s <code class="calibre26">java.util.concurrent</code>. It is available as a <a href="https://oreil.ly/G9e5e" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">backport to earlier versions of Python</a>. We expect <code class="calibre26">multiprocessing</code> to continue to be preferred for CPU-intensive work and won’t be surprised if <code class="calibre26">concurrent.futures</code> becomes more popular for I/O-bound tasks.</p>
</div>

<p class="author1">In the rest of the chapter, we’ll introduce a set of examples to demonstrate common ways of using the <code class="calibre26">multiprocessing</code> module.</p>

<p class="author1">We’ll <a data-type="indexterm" data-primary="Monte Carlo method" id="idm46122410700152" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multiprocessing" data-secondary="estimating with Monte Carlo method" id="idm46122410699416" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>estimate pi using a Monte Carlo approach with a <code class="calibre26">Pool</code> of processes or threads, using normal Python and <code class="calibre26">numpy</code>. This is a simple problem with well-understood complexity, so it parallelizes easily; we can also see an unexpected result from using threads with <code class="calibre26">numpy</code>. Next, we’ll search for primes using the same <code class="calibre26">Pool</code> approach; we’ll investigate the nonpredictable complexity of searching for primes and look at how we can efficiently (and inefficiently!) split the workload to best use our computing resources. We’ll finish the primes search by switching to queues, where we introduce <code class="calibre26">Process</code> objects in place of a <code class="calibre26">Pool</code> and use a list of work and poison pills to control the lifetime of workers.</p>

<p class="author1">Next, we’ll tackle interprocess communication (IPC) to validate a small set of possible primes. By splitting each number’s workload across multiple CPUs, we use IPC to end the search early if a factor is found so that we can significantly beat the speed of a single-CPU search process. We’ll cover shared Python objects, OS primitives, and a Redis server to investigate the complexity and capability trade-offs of each approach.</p>

<p class="author1">We can share a 25 GB <code class="calibre26">numpy</code> array across four CPUs to split a large workload
<em class="hyperlink">without</em> copying data.  If you have large arrays with parallelizable operations, this <span class="publishername">technique</span> should buy you a great speedup, since you have to allocate
less space in RAM and copy less data. Finally, we’ll look at synchronizing access
to a file and a variable (as a <code class="calibre26">Value</code>) between processes without
corrupting data to illustrate how to correctly lock shared state.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1"><a data-type="indexterm" data-primary="PyPy" data-secondary="multiprocessing and" id="idm46122410691128" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multiprocessing" data-secondary="PyPy and" id="idm46122410689928" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PyPy (discussed in <a data-type="xref" href="ch07.xhtml#chapter-compiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 7</a>) has full support for the <code class="calibre26">multiprocessing</code> library, and the following CPython examples (though not the <code class="calibre26">numpy</code> examples, at the time of this writing) all run far quicker using PyPy. If you’re using only <a data-type="indexterm" data-primary="CPython" data-secondary="multiprocessing and" id="idm46122410687112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>CPython code (no C extensions or more complex libraries) for <a data-type="indexterm" data-primary="parallel processing" id="idm46122410686008" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>parallel processing, PyPy might be a quick win for you.<a data-type="indexterm" data-primary="" data-startref="mp_ov" id="idm46122410685208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Estimating Pi Using the Monte Carlo Method" class="calibre3"><div class="preface" id="idm46122410684136">
<h1 class="calibre25">Estimating Pi Using the Monte Carlo Method</h1>

<p class="author1">We can estimate pi by throwing thousands of imaginary darts into a “dartboard” represented by a unit circle. The relationship between the number of darts falling inside the circle’s edge and the number falling outside it will allow us to approximate pi.</p>

<p class="author1">This is an ideal first problem, as we can split the total workload evenly across a number of processes, each one running on a separate CPU. Each process will end at the same time since the workload for each is equal, so we can investigate the speedups available as we add new CPUs and hyperthreads to the problem.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_estimate" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-1</a>, we throw 10,000 darts into the unit square, and a percentage of them fall into the quarter of the unit circle that’s drawn. This estimate is rather bad—10,000 dart throws does not reliably give us a three-decimal-place result. If you ran your own code, you’d see this estimate vary between 3.0 and 3.2 on each run.</p>

<p class="author1">To be confident of the first three decimal places, we need to generate 10,000,000 random dart <a data-type="indexterm" data-primary="Foster, Brett" id="idm46122410679688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>throws.<sup class="calibre44"><a data-type="noteref" id="idm46122410678856-marker" href="ch09_split_001.xhtml#idm46122410678856" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> This is massively inefficient (and better methods for pi’s estimation exist), but it is rather convenient to demonstrate the benefits of parallelization using <code class="calibre26">multiprocessing</code>.</p>

<p class="author1">With the Monte Carlo method, we use the<a data-type="indexterm" data-primary="Pythagorean theorem" id="idm46122410676472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/toFkX" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Pythagorean theorem</a> to test if a dart has landed inside our circle:</p>
<div data-type="equation" class="calibre56">
<math alttext="dollar-sign x squared plus y squared less-than-or-equal-to 1 squared equals 1 dollar-sign">
  <mrow>
    <mrow>
      <msup><mi>x</mi> <mn>2</mn> </msup>
      <mo>+</mo>
      <msup><mi>y</mi> <mn>2</mn> </msup>
    </mrow>
    <mo>≤</mo>
    <msup><mn>1</mn> <mn>2</mn> </msup>
    <mo>=</mo>
    <mn>1</mn>
  </mrow>
</math>
</div>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_estimate" class="figure">
<img src="Images/hpp2_0901.png" alt="Estimating Pi using the Monte Carlo method" class="calibre106"/>
<h6 class="calibre47"><span class="publishername">Figure 9-1. </span>Estimating pi using the Monte Carlo method</h6>
</div></figure>

<p class="author1">We’ll look at a loop version of this in <a data-type="xref" href="ch09_split_000.xhtml#code-pi-lists-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-1</a>. We’ll implement both a normal Python version and, later, a <code class="calibre26">numpy</code> version, and we’ll use both threads and processes to parallelize the problem.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Estimating Pi Using Processes and Threads" class="calibre3"><div class="preface" id="multiprocessing-estimating-pi">
<h1 class="calibre25">Estimating Pi Using Processes and Threads</h1>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="estimating with processes and threads" id="mp_ept" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="processes and threads" id="pt_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="threads and processes" id="tp_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>It is easier to understand a normal Python implementation, so we’ll start with that in this section, using float objects in a loop. We’ll parallelize this using processes to use all of our available CPUs, and we’ll visualize the state of the machine as we use more CPUs.</p>








<section data-type="sect2" data-pdf-bookmark="Using Python Objects" class="calibre3"><div class="preface" id="idm46122410833096">
<h2 class="calibre43">Using Python Objects</h2>

<p class="author1"><a data-type="indexterm" data-primary="processes and threads" data-secondary="Python objects and" id="pt_po" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Python objects" id="po_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="threads and processes" data-secondary="Python objects and" id="tp_po" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The Python implementation is easy to follow, but it carries an overhead, as each Python float object has to be managed, referenced, and synchronized in turn. This overhead slows down our runtime, but it has bought us thinking time, as the implementation was quick to put together. By parallelizing this version, we get additional speedups for very little extra work.</p>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-2</a> shows three implementations of the Python example:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">No use of <code class="calibre26">multiprocessing</code> (named “Serial”)—one <code class="calibre26">for</code> loop in the main process</p>
</li>
<li class="calibre21">
<p class="calibre27">Using threads</p>
</li>
<li class="calibre21">
<p class="calibre27">Using processes</p>
</li>
</ul>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_threads_and_processes_lists" class="figure">
<img src="Images/hpp2_0902.png" alt="not set" class="calibre107"/>
<h6 class="calibre47"><span class="publishername">Figure 9-2. </span>Working in series, with threads, and with processes</h6>
</div></figure>

<p class="author1">When we use more than one thread or process, we’re asking Python to calculate the same total number of dart throws and to divide the work evenly between workers. If we want 100,000,000 dart throws in total using our Python implementation and we use two workers, we’ll be asking both threads or both processes to generate 50,000,000 dart throws per worker.</p>

<p class="author1">Using one thread takes approximately 71 seconds, with no speedup when using more threads. By using two or more processes, we make the runtime <em class="hyperlink">shorter</em>. The cost of using no processes or threads (the series implementation) is the same as running with one process.</p>

<p class="author1">By using processes, we get a linear speedup when using two or four cores on Ian’s laptop. For the eight-worker case, we’re using Intel’s Hyper-Threading Technology—the laptop has only four physical cores, so we get barely any change in speedup by running eight processes.</p>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#code-pi-lists-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-1</a> shows the Python version of our pi estimator. If we’re using threads, each instruction is bound by the GIL, so although each thread could run on a separate CPU, it will execute only when no other threads are running. The process version is not bound by this restriction, as each forked process has a private Python interpreter running as a single thread—there’s no GIL contention, as no objects are shared. We use Python’s built-in random number generator, but see <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-random-numbers" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Random Numbers in Parallel Systems”</a> for some notes about the dangers of parallelized random number sequences.</p>
<div id="code-pi-lists-calculation" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-1. </span>Estimating pi using a loop in Python</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">estimate_nbr_points_in_quarter_circle</code><code class="p">(</code><code class="n">nbr_estimates</code><code class="p">):</code>
    <code class="sd">"""Monte Carlo estimate of the number of points in a</code>
<code class="sd">       quarter circle using pure Python"""</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"Executing estimate_nbr_points_in_quarter_circle  </code><code class="se">\</code>
<code class="s">            with {nbr_estimates:,} on pid {os.getpid()}"</code><code class="p">)</code>
    <code class="n">nbr_trials_in_quarter_unit_circle</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="kn">for</code> <code class="n">step</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">nbr_estimates</code><code class="p">)):</code>
        <code class="n">x</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
        <code class="n">y</code> <code class="o">=</code> <code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
        <code class="n">is_in_unit_circle</code> <code class="o">=</code> <code class="n">x</code> <code class="o">*</code> <code class="n">x</code> <code class="o">+</code> <code class="n">y</code> <code class="o">*</code> <code class="n">y</code> <code class="o">&lt;=</code> <code class="mi">1.0</code>
        <code class="n">nbr_trials_in_quarter_unit_circle</code> <code class="o">+=</code> <code class="n">is_in_unit_circle</code>

    <code class="kn">return</code> <code class="n">nbr_trials_in_quarter_unit_circle</code></pre></div>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#code-pi-lists-main" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-2</a> shows the <code class="calibre26">__main__</code> block. Note that we build the <code class="calibre26">Pool</code> before we start the timer. Spawning threads is relatively instant; spawning processes involves a fork, and this takes a measurable fraction of a second. We ignore this overhead in <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-2</a>, as this cost will be a tiny fraction of the overall execution time.</p>
<div id="code-pi-lists-main" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-2. </span>main for estimating pi using a loop</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">multiprocessing</code> <code class="kn">import</code> <code class="n">Pool</code>
<code class="o">...</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">nbr_samples_in_total</code> <code class="o">=</code> <code class="mi">1e8</code>
    <code class="n">nbr_parallel_blocks</code> <code class="o">=</code> <code class="mi">4</code>
    <code class="n">pool</code> <code class="o">=</code> <code class="n">Pool</code><code class="p">(</code><code class="n">processes</code><code class="o">=</code><code class="n">nbr_parallel_blocks</code><code class="p">)</code>
    <code class="n">nbr_samples_per_worker</code> <code class="o">=</code> <code class="n">nbr_samples_in_total</code> <code class="o">/</code> <code class="n">nbr_parallel_blocks</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Making {:,} samples per {} worker"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">nbr_samples_per_worker</code><code class="p">,</code>
                                                     <code class="n">nbr_parallel_blocks</code><code class="p">))</code>
    <code class="n">nbr_trials_per_process</code> <code class="o">=</code> <code class="p">[</code><code class="n">nbr_samples_per_worker</code><code class="p">]</code> <code class="o">*</code> <code class="n">nbr_parallel_blocks</code>
    <code class="n">t1</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">nbr_in_quarter_unit_circles</code> <code class="o">=</code> <code class="n">pool</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">estimate_nbr_points_in_quarter_circle</code><code class="p">,</code>
                                           <code class="n">nbr_trials_per_process</code><code class="p">)</code>
    <code class="n">pi_estimate</code> <code class="o">=</code> <code class="nb">sum</code><code class="p">(</code><code class="n">nbr_in_quarter_unit_circles</code><code class="p">)</code> <code class="o">*</code> <code class="mi">4</code> <code class="o">/</code> <code class="nb">float</code><code class="p">(</code><code class="n">nbr_samples_in_total</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Estimated pi"</code><code class="p">,</code> <code class="n">pi_estimate</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Delta:"</code><code class="p">,</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">t1</code><code class="p">)</code></pre></div>

<p class="author1">We create a list containing <code class="calibre26">nbr_estimates</code> divided by the number of workers. This new argument will be sent to each worker. After execution, we’ll receive the same number of results back; we’ll sum these to estimate the number of darts in the unit circle.</p>

<p class="author1">We import the process-based <code class="calibre26">Pool</code> from <code class="calibre26">multiprocessing</code>. We also could have used <code class="calibre26">from multiprocessing.dummy import Pool</code> to get a threaded version. The “dummy” name is rather misleading (we confess to not understanding why it is named this way); it is simply a light wrapper around the <code class="calibre26">threading</code> module to present the same interface as the process-based <code class="calibre26">Pool</code>.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">Each process we create consumes some RAM from the system. You can expect a forked process using the standard libraries to take on the order of 10–20 MB of RAM; if you’re using many libraries and lots of data, you might expect each forked copy to take hundreds of megabytes. On a system with a RAM constraint, this might be a significant issue—if you run out of RAM and the system reverts to using the disk’s swap space, any parallelization advantage will be massively lost to the slow paging of RAM back and forth to disk!</p>
</div>

<p class="author1"><a data-type="indexterm" data-primary="hyperthreads" id="idm46122409785480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="processes and threads" data-secondary="hyperthreads" id="idm46122409784776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="threads and processes" data-secondary="hyperthreads" id="idm46122409783832" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The following figures plot the average CPU utilization of Ian’s laptop’s four physical cores and their four associated hyperthreads (each hyperthread runs on unutilized silicon in a physical core). The data gathered for these figures <em class="hyperlink">includes</em> the startup time of the first Python process and the cost of starting subprocesses. The CPU sampler records the entire state of the laptop, not just the CPU time used by this task.</p>

<p class="author1">Note that the following diagrams are created using a different timing method with a slower sampling rate than <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_lists" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-2</a>, so the overall runtime is a little longer.</p>

<p class="author1">The execution behavior in <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-3</a> with one process in the <code class="calibre26">Pool</code> (along with the parent process) shows some overhead in the first seconds as the <code class="calibre26">Pool</code> is created, and then a consistent close-to-100% CPU utilization throughout the run. With one process, we’re efficiently using one core.</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_lists_1_processes" class="figure">
<img src="Images/hpp2_0903.png" alt="Estimating pi using lists and 1 process" class="calibre108"/>
<h6 class="calibre47"><span class="publishername">Figure 9-3. </span>Estimating pi using Python objects and one process</h6>
</div></figure>

<p class="author1">Next we’ll add a second process, effectively saying <code class="calibre26">Pool(processes=2)</code>. As you can see in <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-4</a>, adding a second process roughly halves the execution time to 37 seconds, and two CPUs are fully occupied. This is the best result we can expect—we’ve efficiently used all the new computing resources, and we’re not losing any speed to other overheads like communication, paging to disk, or contention with competing processes that want to use the same CPUs.</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_lists_2_processes" class="figure">
<img src="Images/hpp2_0904.png" alt="Estimating Pi using lists and 2 processes" class="calibre109"/>
<h6 class="calibre47"><span class="publishername">Figure 9-4. </span>Estimating pi using Python objects and two processes</h6>
</div></figure>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-5</a> shows the results when using all four physical CPUs—now we are using all of the raw power of this laptop. Execution time is roughly a quarter that of the single-process version, at 19 seconds.</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_lists_4_processes" class="figure">
<img src="Images/hpp2_0905.png" alt="Estimating Pi using lists and 4 processes" class="calibre109"/>
<h6 class="calibre47"><span class="publishername">Figure 9-5. </span>Estimating pi using Python objects and four processes</h6>
</div></figure>

<p class="author1">By switching to eight processes, as seen in <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-6</a>, we cannot achieve more than a tiny speedup compared to the four-process version. That is because the four hyperthreads are able to squeeze only a little extra processing power out of the spare silicon on the CPUs, and the four CPUs are already maximally utilized.</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_lists_8_processes" class="figure">
<img src="Images/hpp2_0906.png" alt="Estimating Pi using lists and 8 processes" class="calibre109"/>
<h6 class="calibre47"><span class="publishername">Figure 9-6. </span>Estimating pi using Python objects and eight processes, with little <span class="publishername">additional gain</span></h6>
</div></figure>

<p class="author1">These diagrams show that we’re efficiently using more of the available CPU resources at each step, and that the hyperthread resources are a poor addition. The biggest problem when using hyperthreads is that CPython is using a lot of RAM—hyperthreading is not cache friendly, so the spare resources on each chip are very poorly utilized. As we’ll see in the next section, <code class="calibre26">numpy</code> makes better use of these resources.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">In our experience, hyperthreading can give up to a 30% performance gain <em class="hyperlink">if</em> there are enough spare computing resources. This works if, for example, you have a mix of floating-point and integer arithmetic rather than just the floating-point operations we have here. By mixing the resource requirements, the hyperthreads can schedule more of the CPU’s silicon to be working concurrently. Generally, we see hyperthreads as an added bonus and not a resource to be optimized against, as adding more CPUs is probably more economical than tuning your code (which adds a support overhead).</p>
</div>

<p class="author1">Now we’ll switch to using threads in one process, rather than multiple processes.</p>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_threads" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-7</a> shows the results of running the same code that we used in <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-5</a>, but with threads in place of processes. Although a number of CPUs are being used, they each share the workload lightly. If each thread was running without the GIL, then we’d see 100% CPU utilization on the four CPUs. Instead, each CPU is partially utilized (because of the GIL).</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_lists_4_threads" class="figure">
<img src="Images/hpp2_0907.png" alt="Estimating Pi using lists and 4 threads" class="calibre108"/>
<h6 class="calibre47"><span class="publishername">Figure 9-7. </span>Estimating pi using Python objects and four threads</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Replacing multiprocessing with Joblib" class="calibre3"><div class="preface" id="replacing-multiprocessing-with-joblib">
<h2 class="calibre43">Replacing multiprocessing with Joblib</h2>

<p class="author1"><a data-type="indexterm" data-primary="Joblib" id="idm46122409753704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Joblib is an improvement on <code class="calibre26">multiprocessing</code> that enables lightweight pipelining with a focus on easy parallel computing and transparent disk-based caching of results. It focuses on NumPy arrays for scientific computing. It may offer a quick win for you if you’re</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Using pure Python, with or without NumPy, to process a loop that could be embarrassingly parallel</p>
</li>
<li class="calibre21">
<p class="calibre27">Calling expensive functions that have no side effects, where the output could be cached to disk between sessions</p>
</li>
<li class="calibre21">
<p class="calibre27">Able to share NumPy data between processes but don’t know how (and you haven’t yet read <a data-type="xref" href="ch09_split_001.xhtml#multiprocessing-sharing-numpy-data-with-multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Sharing numpy Data with multiprocessing”</a>)</p>
</li>
</ul>

<p class="author1">Joblib builds on the <a data-type="indexterm" data-primary="Loky library" id="idm46122409747592" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Loky library (itself an improvement over Python’s <code class="calibre26">concurrent.futures</code>) and uses <code class="calibre26">cloudpickle</code> to enable the pickling of functions defined in the interactive scope. This solves a couple of common issues that are encountered with the built-in <code class="calibre26">multiprocessing</code> library.</p>

<p class="author1">For parallel computing, we need the <code class="calibre26">Parallel</code> class and the <code class="calibre26">delayed</code> decorator. The <code class="calibre26">Parallel</code> class sets up a process pool, similar to the <code class="calibre26">multiprocessing</code> <code class="calibre26">pool</code> we used in the previous section. The <code class="calibre26">delayed</code> decorator wraps our target function so it can be applied to the instantiated <code class="calibre26">Parallel</code> object via an iterator.</p>

<p class="author1">The syntax is a little confusing to read—take a look at <a data-type="xref" href="ch09_split_000.xhtml#code-pi-joblib" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-3</a>. The call is written on one line; this includes our target function <code class="calibre26">estimate_nbr_points_in_quarter_circle</code> and the iterator <code class="calibre26">(delayed(...)(nbr_samples_per_worker) for sample_idx in range(nbr_parallel_blocks))</code>. Let’s break this down.</p>
<div id="code-pi-joblib" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-3. </span>Using Joblib to parallelize pi estimation</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="o">...</code>
<code class="kn">from</code> <code class="nn">joblib</code> <code class="kn">import</code> <code class="n">Parallel</code><code class="p">,</code> <code class="n">delayed</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="o">...</code>
    <code class="n">nbr_in_quarter_unit_circles</code> <code class="o">=</code> <code class="n">Parallel</code><code class="p">(</code><code class="n">n_jobs</code><code class="o">=</code><code class="n">nbr_parallel_blocks</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code> \
          <code class="p">(</code><code class="n">delayed</code><code class="p">(</code><code class="n">estimate_nbr_points_in_quarter_circle</code><code class="p">)(</code><code class="n">nbr_samples_per_worker</code><code class="p">)</code> \
           <code class="kn">for</code> <code class="n">sample_idx</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">nbr_parallel_blocks</code><code class="p">))</code>
    <code class="o">...</code></pre></div>

<p class="author1"><code class="calibre26">Parallel</code> is a class; we can set parameters such as <code class="calibre26">n_jobs</code> to dictate how many processes will run, along with optional arguments like <code class="calibre26">verbose</code> for debugging information. Other arguments can set time-outs, change between threads or processes, change the backends (which can help speed up certain edge cases), and configure memory mapping.</p>

<p class="author1"><code class="calibre26">Parallel</code> has a <code class="calibre26">__call__</code> callable method that takes an iterable. We supply the iterable in the following round brackets <code class="calibre26">(... for sample_idx in range(...))</code>. The callable iterates over each <code class="calibre26">delayed(estimate_nbr_points_in_quarter_circle)</code> function, batching the execution of these functions to their arguments (in this case, <code class="calibre26">nbr_samples_per_worker</code>). Ian has found it helpful to build up a parallelized call one step at a time, starting from a function with no arguments and building up arguments as needed. This makes diagnosing missteps much easier.</p>

<p class="author1"><code class="calibre26">nbr_in_quarter_unit_circles</code> will be a list containing the count of positive cases for each call as before. <a data-type="xref" href="ch09_split_000.xhtml#code-pi-joblib-output" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-4</a> shows the console output for eight parallel blocks; each process ID (PID) is freshly created, and a summary is printed in a progress bar at the end of the output. In total this takes 19 seconds, the same amount of time as when we created our own <code class="calibre26">Pool</code> in the previous section.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Avoid passing large structures; passing large pickled objects to each process may be expensive. Ian had a case with a prebuilt cache of Pandas DataFrames in a dictionary object; the cost of serializing these via the <a data-type="indexterm" data-primary="Pickle module" id="idm46122409613384" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">Pickle</code> module negated the gains from parallelization, and the serial version actually worked faster overall. The solution in this case was to build the<a data-type="indexterm" data-primary="DataFrame cache" id="idm46122409612136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> DataFrame cache using Python’s built-in <a href="https://oreil.ly/e9dJs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">shelve</code> module</a>, storing the dictionary to a file. A single DataFrame was loaded with <code class="calibre26">shelve</code> on each call to the target function; hardly anything had to be passed to the functions, and then the parallelized benefit of 
<span class="publishername"><code class="calibre26">Joblib</code></span> was clear.</p>
</div>
<div id="code-pi-joblib-output" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-4. </span>Output of <code class="calibre26">Joblib</code> calls</h5>

<pre data-type="programlisting" class="calibre59">Making 12,500,000 samples per 8 worker
[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10313
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10315
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10311
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10316
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10312
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10314
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10317
Executing estimate_nbr_points_in_quarter_circle with 12,500,000 on pid 10318
[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   18.9s remaining:   56.6s
[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   19.3s finished
Estimated pi 3.14157744
Delta: 19.32842755317688</pre></div>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">To simplify debugging, we can set<a data-type="indexterm" data-primary="n_jobs=1" id="idm46122409604472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">n_jobs=1</code>, and the parallelized code is dropped. You don’t have to modify your code any further, and you can drop a call to <a data-type="indexterm" data-primary="breakpoint()" id="idm46122409603096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">breakpoint()</code> in your function to ease your debugging.</p>
</div>










<section data-type="sect3" data-pdf-bookmark="Intelligent caching of function call results" class="calibre3"><div class="preface" id="idm46122409601688">
<h3 class="calibre51">Intelligent caching of function call results</h3>

<p class="author1"><a data-type="indexterm" data-primary="caching, intelligent" id="cach_int" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="intelligent caching" id="int_cach" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A useful feature in Joblib is the<a data-type="indexterm" data-primary="Memory cache" id="idm46122409598024" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">Memory</code> cache; this is a decorator that caches function results based on the input arguments to a disk cache. This cache persists between Python sessions, so if you turn off your machine and then run the same code the next day, the cached results will be used.</p>

<p class="author1">For our pi estimation, this presents a small problem. We don’t pass in unique arguments to <code class="calibre26">estimate_nbr_points_in_quarter_circle</code>; for each call we pass in <code class="calibre26">nbr_estimates</code>, so the call signature is the same, but we’re after different results.</p>

<p class="author1">In this situation, once the first call has completed (taking around 19 seconds), any subsequent call with the same argument will get the cached result. This means that if we rerun our code a second time, it completes instantly, but it uses only one of the eight sample results as the result for each call—this obviously breaks our Monte Carlo sampling! If the last process to complete resulted in <code class="calibre26">9815738</code> points in the quarter circle, the cache for the function call would always answer this. Repeating the call eight times would generate <code class="calibre26">[9815738, 9815738, 9815738, 9815738, 9815738, 9815738, 9815738, 9815738]</code> rather than eight unique estimates.</p>

<p class="author1">The solution in <a data-type="xref" href="ch09_split_000.xhtml#code-pi-joblib-cache" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-5</a> is to pass in a second argument, <code class="calibre26">idx</code>, which takes on a value between 0 and <code class="calibre26">nbr_parallel_blocks-1</code>. This unique combination of arguments will let the cache store each positive count, so that on the second run we get the same result as on the first run, but without the wait.</p>

<p class="author1">This is configured using <code class="calibre26">Memory</code>, which takes a folder for persisting the function results. This persistence is kept between Python sessions; it is refreshed if you change the function that is being called, or if you empty the files in the cache folder.</p>

<p class="author1">Note that this refresh applies only to a change to the function that’s been decorated (in this case, <code class="calibre26">estimate_nbr_points_in_quarter_circle_with_idx</code>), not to any sub-functions that are called from inside that function.</p>
<div id="code-pi-joblib-cache" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-5. </span>Caching results with Joblib</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="o">...</code>
<code class="kn">from</code> <code class="nn">joblib</code> <code class="kn">import</code> <code class="n">Memory</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">Memory</code><code class="p">(</code><code class="s">"./joblib_cache"</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>

<code class="nd">@memory.cache</code>
<code class="kn">def</code> <code class="nf">estimate_nbr_points_in_quarter_circle_with_idx</code><code class="p">(</code><code class="n">nbr_estimates</code><code class="p">,</code> <code class="n">idx</code><code class="p">):</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"Executing estimate_nbr_points_in_quarter_circle with </code><code class="se">\</code>
<code class="s">            {nbr_estimates} on sample {idx} on pid {os.getpid()}"</code><code class="p">)</code>
    <code class="o">...</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="o">...</code>
    <code class="n">nbr_in_quarter_unit_circles</code> <code class="o">=</code> <code class="n">Parallel</code><code class="p">(</code><code class="n">n_jobs</code><code class="o">=</code><code class="n">nbr_parallel_blocks</code><code class="p">)</code> \
       <code class="p">(</code><code class="n">delayed</code><code class="p">(</code>
	    <code class="n">estimate_nbr_points_in_quarter_circle_with_idx</code><code class="p">)</code> \
        <code class="p">(</code><code class="n">nbr_samples_per_worker</code><code class="p">,</code> <code class="n">idx</code><code class="p">)</code> <code class="kn">for</code> <code class="n">idx</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">nbr_parallel_blocks</code><code class="p">))</code>
    <code class="o">...</code></pre></div>

<p class="author1">In <a data-type="xref" href="ch09_split_000.xhtml#code-pi-joblib-cache-output" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-6</a>, we can see that while the first call costs 19 seconds, the second call takes only a fraction of a second and has the same estimated pi. In this run, the estimates were <code class="calibre26">[9817605, 9821064, 9818420, 9817571, 9817688, 9819788, 9816377, 9816478]</code>.</p>
<div id="code-pi-joblib-cache-output" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-6. </span>The zero-cost second call to the code thanks to cached results</h5>

<pre data-type="programlisting" class="calibre59">$ python pi_lists_parallel_joblib_cache.py
Making 12,500,000 samples per 8 worker
Executing estimate_nbr_points_in_... with 12500000 on sample 0 on pid 10672
Executing estimate_nbr_points_in_... with 12500000 on sample 1 on pid 10676
Executing estimate_nbr_points_in_... with 12500000 on sample 2 on pid 10677
Executing estimate_nbr_points_in_... with 12500000 on sample 3 on pid 10678
Executing estimate_nbr_points_in_... with 12500000 on sample 4 on pid 10679
Executing estimate_nbr_points_in_... with 12500000 on sample 5 on pid 10674
Executing estimate_nbr_points_in_... with 12500000 on sample 6 on pid 10673
Executing estimate_nbr_points_in_... with 12500000 on sample 7 on pid 10675
Estimated pi 3.14179964
Delta: 19.28862953186035

$ python %run pi_lists_parallel_joblib_cache.py
Making 12,500,000 samples per 8 worker
Estimated pi 3.14179964
Delta: 0.02478170394897461</pre></div>

<p class="author1"><a data-type="indexterm" data-primary="Joblib" id="idm46122409498328" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Joblib wraps up a lot of <code class="calibre26">multiprocessing</code> functionality with a simple (if slightly hard to read) interface. Ian has moved to<a data-type="indexterm" data-primary="" data-startref="cach_int" id="idm46122409497112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="int_cach" id="idm46122409496136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> using Joblib in favor of <code class="calibre26">multiprocessing</code>; he recommends you try it too.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Random Numbers in Parallel Systems" class="calibre3"><div class="preface" id="multiprocessing-random-numbers">
<h2 class="calibre43">Random Numbers in Parallel Systems</h2>

<p class="author1"><a data-type="indexterm" data-primary="parallel systems, random numbers in" id="idm46122409493048" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="processes and threads" data-secondary="random number sequences" id="idm46122409492280" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="random numbers" id="idm46122409491336" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="threads and processes" data-secondary="random number sequences" id="idm46122409490664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Generating good random number sequences is a hard problem, and it is easy to get it wrong if you try to do it yourself. Getting a good sequence quickly in parallel is even harder—suddenly you have to worry about whether you’ll get repeating or correlated sequences in the parallel processes.</p>

<p class="author1">We used Python’s built-in random number generator in <a data-type="xref" href="ch09_split_000.xhtml#code-pi-lists-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-1</a>, and we’ll use the <code class="calibre26">numpy</code> random number generator in <a data-type="xref" href="ch09_split_000.xhtml#code-pi-numpy-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-7</a> in the next section. In both cases, the random number generators are seeded in their forked process. For the Python <code class="calibre26">random</code> example, the seeding is handled internally by <code class="calibre26">multiprocessing</code>—if during a fork it sees that <code class="calibre26">random</code> is in the namespace, it will force a call to seed the generators in each of the new processes.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Set the numpy seed when parallelizing your function calls. In the forthcoming <code class="calibre26">numpy</code> example, we have to explicitly set the random number seed. If you forget to seed the random number sequence with <code class="calibre26">numpy</code>, each of your forked processes will generate an identical sequence of random numbers—it’ll appear to be working as you wanted it to, but behind the scenes each parallel process will evolve with identical results!</p>
</div>

<p class="author1">If you care about the quality of the random numbers used in the parallel processes, we urge you to research this topic. <em class="hyperlink">Probably</em> the <code class="calibre26">numpy</code> and Python random number generators are good enough, but if significant outcomes depend on the quality of the random sequences (e.g., for medical or financial systems), then you must read up on this area.</p>

<p class="author1">In Python 3,<a data-type="indexterm" data-primary="Mersenne Twister algorithm" id="idm46122409480776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> the <a href="https://oreil.ly/yNINO" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Mersenne Twister algorithm</a> is used—it has a long period, so the sequence won’t repeat for a long time. It is heavily tested, as it is used in other languages, and it is thread-safe. It is probably not suitable for cryptographic purposes.<a data-type="indexterm" data-primary="" data-startref="pt_po" id="idm46122409478984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="po_ab" id="idm46122409478040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="tp_po" id="idm46122409477096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using numpy" class="calibre3"><div class="preface" id="multiprocessing-estimating-pi-using-numpy">
<h2 class="calibre43">Using numpy</h2>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="numpy and" id="mp_num" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="in multiprocessing" id="num_mp" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="processes and threads" data-secondary="numpy with" id="pt_num" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="threads and processes" data-secondary="numpy with" id="tp_num" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In this section, we switch to using <code class="calibre26">numpy</code>. Our dart-throwing problem is ideal for <code class="calibre26">numpy</code> vectorized operations—we generate the same estimate 25 times faster than the previous Python examples.</p>

<p class="author1">The main reason that <code class="calibre26">numpy</code> is faster than pure Python when solving the same problem is that <code class="calibre26">numpy</code> is creating and manipulating the same object types at a very low level in contiguous blocks of RAM, rather than creating many higher-level Python objects that each require individual management and addressing.</p>

<p class="author1">As <code class="calibre26">numpy</code> is far more cache friendly, we’ll also get a small speed boost when using the four hyperthreads. We didn’t get this in the pure Python version, as caches aren’t used efficiently by larger Python objects.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_threads_and_processes_numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-8</a>, we see three scenarios:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">No use of <code class="calibre26">multiprocessing</code> (named “Serial”)</p>
</li>
<li class="calibre21">
<p class="calibre27">Using threads</p>
</li>
<li class="calibre21">
<p class="calibre27">Using processes</p>
</li>
</ul>

<p class="author1">The serial and single-worker versions execute at the same speed—there’s no overhead to using threads with <code class="calibre26">numpy</code> (and with only one worker, there’s also no gain).</p>

<p class="author1">When using multiple processes, we see a classic 100% utilization of each additional CPU. The result mirrors the plots shown in Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_1_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">9-3</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_2_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">9-4</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_4_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">9-5</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09_split_000.xhtml#FIG-pi_monte_carlo_lists_8_processes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">9-6</a>, but the code is much faster using <code class="calibre26">numpy</code>.</p>

<p class="author1">Interestingly, the threaded version runs <em class="hyperlink">faster</em> with more threads. As discussed on the <a href="https://oreil.ly/XXKNo" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">SciPy wiki</a>, by working outside the GIL, <code class="calibre26">numpy</code> can achieve some level of additional speedup around threads.</p>

<figure class="calibre46"><div id="FIG-pi_monte_carlo_threads_and_processes_numpy" class="figure">
<img src="Images/hpp2_0908.png" alt="Working in series, with threads, and with processes" class="calibre107"/>
<h6 class="calibre47"><span class="publishername">Figure 9-8. </span>Working in series, with threads, and with processes using numpy</h6>
</div></figure>

<p class="author1">Using processes gives us a predictable speedup, just as it did in the pure Python example. A second CPU doubles the speed, and using four CPUs quadruples the speed.</p>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#code-pi-numpy-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-7</a> shows the vectorized form of our code. Note that the random number generator is seeded when this function is called. For the threaded version, this isn’t necessary, as each thread shares the same random number generator and they access it in series. For the process version, as each new process is a fork, all the forked 
<span class="publishername">versions</span> will share the <em class="hyperlink">same state</em>. This means the random number calls in each will return the same sequence!</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Remember to call <code class="calibre26">seed()</code> per process with <code class="calibre26">numpy</code> <a data-type="indexterm" data-primary="seed()" id="idm46122409443800" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> to ensure that each of the forked processes generates a unique sequence of random numbers, as a random source is used to set the seed for each call. Look back at <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-random-numbers" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Random Numbers in Parallel Systems”</a> for some notes about the dangers of parallelized random number sequences.</p>
</div>
<div id="code-pi-numpy-calculation" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-7. </span>Estimating pi using <code class="calibre26">numpy</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">estimate_nbr_points_in_quarter_circle</code><code class="p">(</code><code class="n">nbr_samples</code><code class="p">):</code>
    <code class="sd">"""Estimate pi using vectorized numpy arrays"""</code>
    <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">()</code> <code class="c"># remember to set the seed per process</code>
    <code class="n">xs</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">nbr_samples</code><code class="p">)</code>
    <code class="n">ys</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">nbr_samples</code><code class="p">)</code>
    <code class="n">estimate_inside_quarter_unit_circle</code> <code class="o">=</code> <code class="p">(</code><code class="n">xs</code> <code class="o">*</code> <code class="n">xs</code> <code class="o">+</code> <code class="n">ys</code> <code class="o">*</code> <code class="n">ys</code><code class="p">)</code> <code class="o">&lt;=</code> <code class="mi">1</code>
    <code class="n">nbr_trials_in_quarter_unit_circle</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sum</code><code class="p">(</code><code class="n">estimate_inside_quarter_unit_circle</code><code class="p">)</code>
    <code class="kn">return</code> <code class="n">nbr_trials_in_quarter_unit_circle</code></pre></div>

<p class="author1">A short code analysis shows that the calls to <code class="calibre26">random</code> run a little slower on this machine when executed with multiple threads, and the call to <code class="calibre26">(xs * xs + ys * ys) &lt;= 1</code> parallelizes well. Calls to the random number generator are GIL-bound, as the internal state variable is a Python object.</p>

<p class="author1">The process to understand this was basic but reliable:</p>
<ol class="calibre4">
<li class="calibre5">
<p class="calibre27">Comment out all of the <code class="calibre26">numpy</code> lines, and run with <em class="hyperlink">no</em> threads using the serial version. Run several times and record the execution times using <code class="calibre26">time.time()</code> in <code class="calibre26">__main__</code>.</p>
</li>
<li class="calibre5">
<p class="calibre27">Add a line back (we added <code class="calibre26">xs = np.random.uniform(...)</code> first) and run several times, again recording completion times.</p>
</li>
<li class="calibre5">
<p class="calibre27">Add the next line back (now adding <code class="calibre26">ys = ...</code>), run again, and record completion time.</p>
</li>
<li class="calibre5">
<p class="calibre27">Repeat, including the <code class="calibre26">nbr_trials_in_quarter_unit_circle = np.sum(...)</code> line.</p>
</li>
<li class="calibre5">
<p class="calibre27">Repeat this process again, but this time with four threads. Repeat line by line.</p>
</li>
<li class="calibre5">
<p class="calibre27">Compare the difference in runtime at each step for no threads and four threads.</p>
</li>

</ol>

<p class="author1">Because we’re running code in parallel, it becomes harder to use tools like<a data-type="indexterm" data-primary="line_profiler" id="idm46122409275784" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="cProfile" id="idm46122409275080" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">line_profiler</code> or <code class="calibre26">cProfile</code>. Recording the raw runtimes and observing the differences in behavior with different configurations takes patience but gives solid evidence from which to draw conclusions.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">If you want to understand the serial behavior of the <code class="calibre26">uniform</code> call, take a look at the<a data-type="indexterm" data-primary="numpy" data-secondary="source code" id="idm46122409271608" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="mtrand code" id="idm46122409270632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/HxHQD" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">mtrand</code> code</a> in the <code class="calibre26">numpy</code> source and follow the call to <code class="calibre26">def uniform</code> in <em class="hyperlink">mtrand.pyx</em>. This is a useful exercise if you haven’t looked at the <code class="calibre26">numpy</code> source code before.</p>
</div>

<p class="author1">The libraries used when building <code class="calibre26">numpy</code> are important for some of the parallelization opportunities. Depending on the underlying libraries used when building <code class="calibre26">numpy</code> (e.g., whether Intel’s <a data-type="indexterm" data-primary="Math Kernel Library" id="idm46122409265672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Math Kernel Library or <a data-type="indexterm" data-primary="OpenBLAS" id="idm46122409264840" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>OpenBLAS were included or not), you’ll see different speedup behavior.</p>

<p class="author1">You can check your <code class="calibre26">numpy</code> configuration using <code class="calibre26">numpy.show_config()</code>. Stack Overflow has some <a href="http://bit.ly/BLAS_benchmarking" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">example timings</a> if you’re curious about the possibilities. Only some <code class="calibre26">numpy</code> calls will benefit from parallelization by external libraries.<a data-type="indexterm" data-primary="" data-startref="mp_ept" id="idm46122409261336" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pt_abt" id="idm46122409260360" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="tp_abt" id="idm46122409259416" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mp_num" id="idm46122409258472" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="num_mp" id="idm46122409257528" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pt_num" id="idm46122409256584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="tp_num" id="idm46122409255640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Finding Prime Numbers" class="calibre3"><div class="preface" id="multiprocessing-finding-prime-numbers">
<h1 class="calibre25">Finding Prime Numbers</h1>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="parallel problems" id="mp_pp" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="parallel problems" id="pp_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="multiprocessing" data-secondary="finding prime numbers" id="mp_fpn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="prime numbers" data-secondary="testing for" id="pn_t" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="queues" data-secondary="queue support" id="q_qs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Next, we’ll look at testing for prime numbers over a large number range. This is
a different problem from estimating pi, as the workload varies depending on your
location in the number range, and each individual number’s check has an
unpredictable complexity. We can create a serial routine that checks for
primality and then pass sets of possible factors to each process for checking.
This problem is embarrassingly parallel, which means there is no state that needs
to be shared.</p>

<p class="author1">The <code class="calibre26">multiprocessing</code> module makes it easy to control the workload, so we shall investigate how we can tune the work queue to use (and misuse!) our computing resources, and we will explore an easy way to use our resources slightly more efficiently. This means we’ll be looking at<a data-type="indexterm" data-primary="load balancing" id="idm46122409245368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">load balancing</em> to try to efficiently distribute our varying-complexity tasks to our fixed set of resources.</p>

<p class="author1">We’ll use an algorithm that is slightly removed from the one earlier in the book (see <a data-type="xref" href="ch01_split_000.xhtml#understanding-performance-idealized-computing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Idealized Computing Versus the Python Virtual Machine”</a>); it exits early if we have an even number—see <a data-type="xref" href="ch09_split_000.xhtml#code-primes-serial-generation-calculation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-8</a>.</p>
<div id="code-primes-serial-generation-calculation" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-8. </span>Finding prime numbers using Python</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">):</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code><code class="p">))</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">):</code>
        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">How much variety in the workload do we see when testing for a prime with this approach? <a data-type="xref" href="ch09_split_000.xhtml#FIG-primes-cost-to-check-primality" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-9</a> shows the increasing time cost to check for primality as the possibly prime <code class="calibre26">n</code> increases from <code class="calibre26">10,000</code> to <code class="calibre26">1,000,000</code>.</p>

<p class="author1">Most numbers are nonprime; they’re drawn with a dot. Some can be cheap to check for, while others require the checking of many factors. Primes are drawn with an <code class="calibre26">x</code> and form the thick darker band; they’re the most expensive to check for. The time cost of checking a number increases as <code class="calibre26">n</code> increases, as the range of possible factors to check increases with the square root of <code class="calibre26">n</code>. The sequence of primes is not predictable, so we can’t determine the expected cost of a range of numbers (we could estimate it, but we can’t be sure of its complexity).</p>

<p class="author1">For the figure, we test each <code class="calibre26">n</code> two hundred times and take the fastest result to remove jitter from the results. If we took only one result, we’d see wide variance in timing that would be caused by system load from other processes; by taking many readings and keeping the fastest, we get to see the expected best-case timing.</p>

<figure class="calibre46"><div id="FIG-primes-cost-to-check-primality" class="figure">
<img src="Images/hpp2_0909.png" alt="Time to check primality" class="calibre110"/>
<h6 class="calibre47"><span class="publishername">Figure 9-9. </span>Time required to check primality as <code class="calibre26">n</code> increases</h6>
</div></figure>

<p class="author1">When we distribute work to a <code class="calibre26">Pool</code> of processes, we can specify how much work is passed to each worker. We could divide all of the work evenly and aim for one pass, or we could make many chunks of work and pass them out whenever a CPU is free. This is controlled using the <code class="calibre26">chunksize</code> parameter. Larger chunks of work mean less <span class="publishername">communication</span> overhead, while smaller chunks of work mean more control over how resources are allocated.</p>

<p class="author1">For our prime finder, a single piece of work is a number <code class="calibre26">n</code> that is checked by <code class="calibre26">check_prime</code>. A <code class="calibre26">chunksize</code> of <code class="calibre26">10</code> would mean that each process handles a list of 10 integers, one list at a time.</p>

<p class="author1"><a data-type="indexterm" data-primary="chunksize parameter" id="cp_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="prime numbers" data-secondary="chunksizing" id="pn_chu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In <a data-type="xref" href="ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-10</a>, we can see the effect of varying the <code class="calibre26">chunksize</code> from <code class="calibre26">1</code> (every job is a single piece of work) to <code class="calibre26">64</code> (every job is a list of 64 numbers). Although having many tiny jobs gives us the greatest flexibility, it also imposes the greatest communication overhead. All four CPUs will be utilized efficiently, but the communication pipe will become a bottleneck as each job and result is passed through this single channel. If we double the <code class="calibre26">chunksize</code> to <code class="calibre26">2</code>, our task gets solved twice as quickly, as we have less contention on the communication pipe. We might naively assume that by increasing the <code class="calibre26">chunksize</code>, we will continue to improve the execution time. However, as you can see in the figure, we will again come to a point of diminishing returns.</p>

<figure class="calibre46"><div id="FIG-primes-pool-plot-chunksizetimes-type2" class="figure">
<img src="Images/hpp2_0910.png" alt="notset" class="calibre111"/>
<h6 class="calibre47"><span class="publishername">Figure 9-10. </span>Choosing a sensible <code class="calibre26">chunksize</code> value</h6>
</div></figure>

<p class="author1">We can continue to increase the <code class="calibre26">chunksize</code> until we start to see a worsening of behavior. In <a data-type="xref" href="ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-11</a>, we expand the range of chunksizes, making them not just tiny but also huge. At the larger end of the scale, the worst result shown is 1.08 seconds, where we’ve asked for <code class="calibre26">chunksize</code> to be <code class="calibre26">50000</code>—this means our 100,000 items are divided into two work chunks, leaving two CPUs idle for that entire pass. With a <code class="calibre26">chunksize</code> of <code class="calibre26">10000</code> items, we are creating ten chunks of work; this means that four chunks of work will run twice in parallel, followed by the two remaining chunks. This leaves two CPUs idle in the third round of work, which is an inefficient usage of resources.</p>

<p class="author1">An optimal solution in this case is to divide the total number of jobs by the number of CPUs. This is the default behavior in <code class="calibre26">multiprocessing</code>, shown as the “default” blue dot in the figure.</p>

<p class="author1">As a general rule, the default behavior is sensible; tune it only if you expect to see a real gain, and definitely confirm your hypothesis against the default behavior.</p>

<p class="author1">Unlike the Monte Carlo pi problem, our prime testing calculation has varying complexity—sometimes a job exits quickly (an even number is detected the fastest), and sometimes the number is large and a prime (this takes a much longer time to check).</p>

<figure class="calibre46"><div id="FIG-primes-pool-plot-chunksizetimes-type1" class="figure">
<img src="Images/hpp2_0911.png" alt="notset" class="calibre112"/>
<h6 class="calibre47"><span class="publishername">Figure 9-11. </span>Choosing a sensible <code class="calibre26">chunksize</code> value (continued)</h6>
</div></figure>

<p class="author1">What happens if we randomize our job sequence? For this problem, we squeeze out a 2% performance gain, as you can see in <a data-type="xref" href="ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-type1-shuffled" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-12</a>. By randomizing, we reduce the likelihood of the final job in the sequence taking longer than the others, leaving all but one CPU active.</p>

<p class="author1">As our earlier example using a <code class="calibre26">chunksize</code> of <code class="calibre26">10000</code> demonstrated, misaligning the workload with the number of available resources leads to inefficiency. In that case, we created three rounds of work: the first two rounds used 100% of the resources, and the last round used only 50%.</p>

<figure class="calibre46"><div id="FIG-primes-pool-plot-chunksizetimes-type1-shuffled" class="figure">
<img src="Images/hpp2_0912.png" alt="notset" class="calibre112"/>
<h6 class="calibre47"><span class="publishername">Figure 9-12. </span>Randomizing the job sequence</h6>
</div></figure>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#FIG-primes-pool-plot-chunksizetimes-by-nbrchunks-sawtoothpattern" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-13</a> shows the odd effect that occurs when we misalign the number of chunks of work against the number of processors. Mismatches will underutilize the available resources. The slowest overall runtime occurs when only one chunk of work is created: this leaves three unutilized. Two work chunks leave two CPUs unutilized, and so on; only when we have four work chunks are we using all of our resources. But if we add a fifth work chunk, we’re underutilizing our resources again—four CPUs will work on their chunks, and then one CPU will run to calculate the fifth chunk.</p>

<p class="author1">As we increase the number of chunks of work, we see that the inefficiencies decrease—the difference in runtime between 29 and 32 work chunks is approximately 0.03 seconds. The general rule is to make lots of small jobs for efficient resource utilization if your jobs have varying runtimes.</p>

<figure class="calibre46"><div id="FIG-primes-pool-plot-chunksizetimes-by-nbrchunks-sawtoothpattern" class="figure">
<img src="Images/hpp2_0913.png" alt="notset" class="calibre107"/>
<h6 class="calibre47"><span class="publishername">Figure 9-13. </span>The danger of choosing an inappropriate number of chunks</h6>
</div></figure>

<p class="author1">Here are some strategies for efficiently using <code class="calibre26">multiprocessing</code> for embarrassingly parallel problems:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Split your jobs into independent units of work.</p>
</li>
<li class="calibre21">
<p class="calibre27">If your workers take varying amounts of time, consider randomizing the sequence of work (another example would be for processing variable-sized files).</p>
</li>
<li class="calibre21">
<p class="calibre27">Sorting your work queue so that the slowest jobs go first may be an equally useful strategy.</p>
</li>
<li class="calibre21">
<p class="calibre27">Use the default <code class="calibre26">chunksize</code> unless you have verified reasons for adjusting it.</p>
</li>
<li class="calibre21">
<p class="calibre27">Align the number of jobs with the number of physical CPUs. (Again, the default <code class="calibre26">chunksize</code> takes care of this for you, although it will use any hyperthreads by default, which may not offer any additional gain.)</p>
</li>
</ul>

<p class="author1">Note that by default <code class="calibre26">multiprocessing</code> will see hyperthreads as additional CPUs. This means that on Ian’s laptop, it will allocate eight processes when only four will really be running at 100% speed. The additional four processes could be taking up valuable RAM while barely offering any additional speed gain.</p>

<p class="author1">With a <code class="calibre26">Pool</code>, we can split up a chunk of predefined work up front among the available CPUs. This is less helpful if we have dynamic workloads, though, and particularly if we have workloads that arrive over time. For this sort of workload, we might want to use a <code class="calibre26">Queue</code>, introduced in the next section.<a data-type="indexterm" data-primary="" data-startref="mp_pp" id="idm46122409085032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pp_abt" id="idm46122409084184" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cp_ab" id="idm46122409083336" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pn_chu" id="idm46122409082488" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>








<section data-type="sect2" data-pdf-bookmark="Queues of Work" class="calibre3"><div class="preface" id="idm46122409081512">
<h2 class="calibre43">Queues of Work</h2>

<p class="author1"><a data-type="indexterm" data-primary="pickled work" id="pw_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">multiprocessing.Queue</code> objects give us nonpersistent queues that can send any pickleable Python objects between processes. They carry an overhead, as each object must be pickled to be sent and then unpickled in the consumer (along with some locking operations). In the following example, we’ll see that this cost is not negligible. However, if your workers are processing larger jobs, the communication overhead is probably acceptable.</p>

<p class="author1">Working with the queues is fairly easy. In this example, we’ll check for primes by consuming a list of candidate numbers and posting confirmed primes back to a <code class="calibre26">definite_primes_queue</code>. We’ll run this with one, two, four, and eight processes and confirm that the latter three approaches all take longer than just running a single process that checks the same range.</p>

<p class="author1">A <code class="calibre26">Queue</code> gives us the ability to perform lots of interprocess communication using native Python objects. This can be useful if you’re passing around objects with lots of state. Since the <code class="calibre26">Queue</code> lacks persistence, though, you probably don’t want to use queues for jobs that might require robustness in the face of failure (e.g., if you lose power or a hard drive gets corrupted).</p>

<p class="author1"><a data-type="xref" href="ch09_split_000.xhtml#code-queues-of-work-fullwork-check-prime" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-9</a> shows the <a data-type="indexterm" data-primary="check_prime function" id="idm46122409074504" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">check_prime</code> function. We’re already familiar with the basic primality test. We run in an infinite loop, blocking (waiting until work is available) on <code class="calibre26">possible_primes_queue.get()</code> to consume an item from the queue. Only one process can get an item at a time, as the <code class="calibre26">Queue</code> object takes care of synchronizing the accesses. If there’s no work in the queue, the <code class="calibre26">.get()</code> blocks until a task is available. When primes are found, they are <code class="calibre26">put</code> back on the <code class="calibre26">definite_primes_queue</code> for consumption by the parent process.</p>
<div id="code-queues-of-work-fullwork-check-prime" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-9. </span>Using two queues for interprocess communication (IPC)</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">FLAG_ALL_DONE</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">"WORK_FINISHED"</code>
<code class="n">FLAG_WORKER_FINISHED_PROCESSING</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">"WORKER_FINISHED_PROCESSING"</code>


<code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">possible_primes_queue</code><code class="p">,</code> <code class="n">definite_primes_queue</code><code class="p">):</code>
    <code class="kn">while</code> <code class="nb">True</code><code class="p">:</code>
        <code class="n">n</code> <code class="o">=</code> <code class="n">possible_primes_queue</code><code class="o">.</code><code class="n">get</code><code class="p">()</code>
        <code class="kn">if</code> <code class="n">n</code> <code class="o">==</code> <code class="n">FLAG_ALL_DONE</code><code class="p">:</code>
            <code class="c"># flag that our results have all been pushed to the results queue</code>
            <code class="n">definite_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">FLAG_WORKER_FINISHED_PROCESSING</code><code class="p">)</code>
            <code class="kn">break</code>
        <code class="kn">else</code><code class="p">:</code>
            <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
                <code class="kn">continue</code>
            <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">3</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code><code class="p">))</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">):</code>
                <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
                    <code class="kn">break</code>
            <code class="kn">else</code><code class="p">:</code>
                <code class="n">definite_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">n</code><code class="p">)</code></pre></div>

<p class="author1">We define two flags: one is fed by the parent process as a poison pill to indicate that no more work is available, while the second is fed by the worker to confirm that it has seen the poison pill and has closed itself down.  The first poison pill is also known as a<a data-type="indexterm" data-primary="sentinel" id="idm46122409068040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/mfR2s" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">sentinel</em></a>, as it guarantees the termination of the processing loop.</p>

<p class="author1">When dealing with queues of work and remote workers, it can be helpful to use flags like these to record that the poison pills were sent and to check that responses were sent from the children in a sensible time window, indicating that they are shutting down. We don’t handle that process here, but adding some timekeeping is a fairly simple addition to the code. The receipt of these flags can be logged or printed during debugging.</p>

<p class="author1">The <code class="calibre26">Queue</code> objects are created out of a <code class="calibre26">Manager</code> in <a data-type="xref" href="ch09_split_000.xhtml#code-queues-of-work-fullwork-main1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-10</a>. We’ll use the familiar process of building a list of <code class="calibre26">Process</code> objects that each contain a forked process. The two queues are sent as arguments, and <code class="calibre26">multiprocessing</code> handles their synchronization. Having started the new processes, we hand a list of jobs to the <code class="calibre26">possible_primes_queue</code> and end with one poison pill per process. The jobs will be consumed in FIFO order, leaving the poison pills for last. In <code class="calibre26">check_prime</code> we use a blocking <code class="calibre26">.get()</code>, as the new processes will have to wait for work to appear in the queue. Since we use flags, we could add some work, deal with the results, and then iterate by adding more work, and signal the end of life of the workers by adding the poison pills later.</p>
<div id="code-queues-of-work-fullwork-main1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-10. </span>Building two queues for IPC</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">parser</code> <code class="o">=</code> <code class="n">argparse</code><code class="o">.</code><code class="n">ArgumentParser</code><code class="p">(</code><code class="n">description</code><code class="o">=</code><code class="s">"Project description"</code><code class="p">)</code>
    <code class="n">parser</code><code class="o">.</code><code class="n">add_argument</code><code class="p">(</code>
        <code class="s">"nbr_workers"</code><code class="p">,</code> <code class="nb">type</code><code class="o">=</code><code class="nb">int</code><code class="p">,</code> <code class="n">help</code><code class="o">=</code><code class="s">"Number of workers e.g. 1, 2, 4, 8"</code>
    <code class="p">)</code>
    <code class="n">args</code> <code class="o">=</code> <code class="n">parser</code><code class="o">.</code><code class="n">parse_args</code><code class="p">()</code>
    <code class="n">primes</code> <code class="o">=</code> <code class="p">[]</code>

    <code class="n">manager</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Manager</code><code class="p">()</code>
    <code class="n">possible_primes_queue</code> <code class="o">=</code> <code class="n">manager</code><code class="o">.</code><code class="n">Queue</code><code class="p">()</code>
    <code class="n">definite_primes_queue</code> <code class="o">=</code> <code class="n">manager</code><code class="o">.</code><code class="n">Queue</code><code class="p">()</code>

    <code class="n">pool</code> <code class="o">=</code> <code class="n">Pool</code><code class="p">(</code><code class="n">processes</code><code class="o">=</code><code class="n">args</code><code class="o">.</code><code class="n">nbr_workers</code><code class="p">)</code>
    <code class="n">processes</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="kn">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">args</code><code class="o">.</code><code class="n">nbr_workers</code><code class="p">):</code>
        <code class="n">p</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Process</code><code class="p">(</code>
            <code class="n">target</code><code class="o">=</code><code class="n">check_prime</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">possible_primes_queue</code><code class="p">,</code>
                                      <code class="n">definite_primes_queue</code><code class="p">)</code>
        <code class="p">)</code>
        <code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">p</code><code class="p">)</code>
        <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>

    <code class="n">t1</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">number_range</code> <code class="o">=</code> <code class="nb">range</code><code class="p">(</code><code class="mi">100</code><code class="n">_000_000</code><code class="p">,</code> <code class="mi">101</code><code class="n">_000_000</code><code class="p">)</code>

    <code class="c"># add jobs to the inbound work queue</code>
    <code class="kn">for</code> <code class="n">possible_prime</code> <code class="ow">in</code> <code class="n">number_range</code><code class="p">:</code>
        <code class="n">possible_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">possible_prime</code><code class="p">)</code>

    <code class="c"># add poison pills to stop the remote workers</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">args</code><code class="o">.</code><code class="n">nbr_workers</code><code class="p">):</code>
        <code class="n">possible_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">FLAG_ALL_DONE</code><code class="p">)</code></pre></div>

<p class="author1">To consume the results, we start another infinite loop in <a data-type="xref" href="ch09_split_000.xhtml#code-queues-of-work-fullwork-main2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-11</a>, using a blocking <code class="calibre26">.get()</code> on the <code class="calibre26">definite_primes_queue</code>. If the <code class="calibre26">finished-processing</code> flag is found, we take a count of the number of processes that have signaled their exit. If not, we have a new prime, and we add this to the <code class="calibre26">primes</code> list. We exit the infinite loop when all of our processes have signaled their exit.</p>
<div id="code-queues-of-work-fullwork-main2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-11. </span>Using two queues for IPC</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59">    <code class="n">processors_indicating_they_have_finished</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="kn">while</code> <code class="nb">True</code><code class="p">:</code>
        <code class="n">new_result</code> <code class="o">=</code> <code class="n">definite_primes_queue</code><code class="o">.</code><code class="n">get</code><code class="p">()</code>  <code class="c"># block while waiting for results</code>
        <code class="kn">if</code> <code class="n">new_result</code> <code class="o">==</code> <code class="n">FLAG_WORKER_FINISHED_PROCESSING</code><code class="p">:</code>
            <code class="n">processors_indicating_they_have_finished</code> <code class="o">+=</code> <code class="mi">1</code>
            <code class="kn">if</code> <code class="n">processors_indicating_they_have_finished</code> <code class="o">==</code> <code class="n">args</code><code class="o">.</code><code class="n">nbr_workers</code><code class="p">:</code>
                <code class="kn">break</code>
        <code class="kn">else</code><code class="p">:</code>
            <code class="n">primes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">new_result</code><code class="p">)</code>
    <code class="kn">assert</code> <code class="n">processors_indicating_they_have_finished</code> <code class="o">==</code> <code class="n">args</code><code class="o">.</code><code class="n">nbr_workers</code>

    <code class="kn">print</code><code class="p">(</code><code class="s">"Took:"</code><code class="p">,</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">t1</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">primes</code><code class="p">),</code> <code class="n">primes</code><code class="p">[:</code><code class="mi">10</code><code class="p">],</code> <code class="n">primes</code><code class="p">[</code><code class="o">-</code><code class="mi">10</code><code class="p">:])</code></pre></div>

<p class="author1">There is quite an overhead to using a <code class="calibre26">Queue</code>, due to the pickling and synchronization. As you can see in <a data-type="xref" href="ch09_split_000.xhtml#FIG-queues-of-work-fullwork" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-14</a>, using a <code class="calibre26">Queue</code>-less single-process solution is significantly faster than using two or more processes. The reason in this case is because our workload is very light—the communication cost dominates the overall time for this task. With <code class="calibre26">Queue</code>s, two processes complete this example a little faster than one process, while four and eight processes are both slower.</p>

<figure class="calibre46"><div id="FIG-queues-of-work-fullwork" class="figure">
<img src="Images/hpp2_0914.png" alt="notset" class="calibre110"/>
<h6 class="calibre47"><span class="publishername">Figure 9-14. </span>Cost of using Queue objects</h6>
</div></figure>

<p class="author1">If your task has a long completion time (at least a sizable fraction of a second) with a small amount of communication, a <code class="calibre26">Queue</code> approach might be the right answer. You will have to verify whether the communication cost makes this approach useful enough.</p>

<p class="author1">You might wonder what happens if we remove the redundant half of the job queue (all the even numbers—these are rejected very quickly in <code class="calibre26">check_prime</code>). Halving the size of the input queue halves our execution time in each case, but it still doesn’t beat the single-process non-<code class="calibre26">Queue</code> example! This helps to illustrate that the communication cost is the dominating factor in this problem.<a data-type="indexterm" data-primary="" data-startref="pw_ab" id="idm46122408558584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>










<section data-type="sect3" data-pdf-bookmark="Asynchronously adding jobs to the Queue" class="calibre3"><div class="preface" id="idm46122408557480">
<h3 class="calibre51">Asynchronously adding jobs to the Queue</h3>

<p class="author1"><a data-type="indexterm" data-primary="asynchronous job feeding" id="asjf_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="queues" data-secondary="asynchronous job feeding" id="q_asjf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>By adding a <code class="calibre26">Thread</code> into the main process, we can feed jobs asynchronously into the <code class="calibre26">possible_primes_queue</code>. In <a data-type="xref" href="ch09_split_000.xhtml#code-queues-of-work-fullwork-jobs-feeder-thread" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-12</a>, we define a <a data-type="indexterm" data-primary="feed_new_jobs function" id="idm46122408734888" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">feed_new_jobs</code> function: it performs the same job as the job setup routine that we had in <code class="calibre26">__main__</code> before, but it does it in a separate thread.</p>
<div id="code-queues-of-work-fullwork-jobs-feeder-thread" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-12. </span>Asynchronous job-feeding function</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">feed_new_jobs</code><code class="p">(</code><code class="n">number_range</code><code class="p">,</code> <code class="n">possible_primes_queue</code><code class="p">,</code> <code class="n">nbr_poison_pills</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">possible_prime</code> <code class="ow">in</code> <code class="n">number_range</code><code class="p">:</code>
        <code class="n">possible_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">possible_prime</code><code class="p">)</code>
    <code class="c"># add poison pills to stop the remote workers</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">nbr_poison_pills</code><code class="p">):</code>
        <code class="n">possible_primes_queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">FLAG_ALL_DONE</code><code class="p">)</code></pre></div>

<p class="author1">Now, in <a data-type="xref" href="ch09_split_000.xhtml#code-queues-of-work-fullwork-main" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-13</a>, our <code class="calibre26">__main__</code> will set up the <code class="calibre26">Thread</code> using the <code class="calibre26">possible_primes_queue</code> and then move on to the result-collection phase <em class="hyperlink">before</em> any work has been issued. The asynchronous job feeder could consume work from external sources (e.g., from a database or I/O-bound communication) while the <code class="calibre26">__main__</code> thread handles each processed result. This means that the input sequence and output sequence do not need to be created in advance; they can both be handled on the fly.</p>
<div id="code-queues-of-work-fullwork-main" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-13. </span>Using a thread to set up an asynchronous job feeder</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">primes</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">manager</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Manager</code><code class="p">()</code>
    <code class="n">possible_primes_queue</code> <code class="o">=</code> <code class="n">manager</code><code class="o">.</code><code class="n">Queue</code><code class="p">()</code>

    <code class="o">...</code>

    <code class="kn">import</code> <code class="nn">threading</code>
    <code class="n">thrd</code> <code class="o">=</code> <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">feed_new_jobs</code><code class="p">,</code>
                            <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">number_range</code><code class="p">,</code>
                                  <code class="n">possible_primes_queue</code><code class="p">,</code>
                                  <code class="n">NBR_PROCESSES</code><code class="p">))</code>
    <code class="n">thrd</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>

    <code class="c"># deal with the results</code></pre></div>

<p class="author1">If you want robust asynchronous systems, you should almost
certainly look to using<a data-type="indexterm" data-primary="asynchronous programming" data-secondary="AsyncIO (module)" id="idm46122408534520" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="AsyncIO (module)" id="idm46122408502008" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="asynchronous programming" data-secondary="tornado" id="idm46122408501400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="tornado" id="idm46122408500520" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">asyncio</code> or an external library such as <code class="calibre26">tornado</code>.
For a full discussion of these approaches, check out <a data-type="xref" href="ch08.xhtml#chapter-concurrency" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 8</a>.
The examples we’ve looked at here will get you started, but pragmatically they
are more useful for very simple systems and education than for production
systems.</p>

<p class="author1">Be <em class="hyperlink">very aware</em> that <a data-type="indexterm" data-primary="asynchronous systems" id="idm46122408497112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>asynchronous systems require a special level of patience—you will end up tearing out your hair while you are debugging. We suggest the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Applying the “Keep It Simple, Stupid” principle</p>
</li>
<li class="calibre21">
<p class="calibre27">Avoiding asynchronous self-contained systems (like our example) if possible, as they will grow in complexity and quickly become hard to maintain</p>
</li>
<li class="calibre21">
<p class="calibre27">Using mature libraries like <a data-type="indexterm" data-primary="gevent" id="idm46122408493112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="asynchronous programming" data-secondary="gevent" id="idm46122408492408" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">gevent</code> (described in the previous chapter) that give you tried-and-tested approaches to dealing with certain problem sets</p>
</li>
</ul>

<p class="author1">Furthermore, we strongly suggest using an external queue system that gives you external visibility on the state of the queues <a data-type="indexterm" data-primary="NSQ" data-secondary="about" id="idm46122408490072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="ZeroMQ" id="idm46122408489096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Celery" id="idm46122408488424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>(e.g., NSQ,
discussed in <a data-type="xref" href="ch10.xhtml#nsq" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“NSQ for Robust Production Clustering”</a>; ZeroMQ; or Celery). This requires more thought but is likely to save you
time because of increased debug efficiency and better system visibility for
production systems.<a data-type="indexterm" data-startref="ix_multiprocessprimes" id="idm46122408486632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-startref="ix_primes" id="idm46122408485960" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Consider using a task graph for resilience. Data science tasks requiring long-running queues are frequently served well by specifying pipelines of work in acyclic graphs. Two strong libraries are<a data-type="indexterm" data-primary="Airflow" id="idm46122408483880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Luigi" id="idm46122408483176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://airflow.apache.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Airflow</a> and <a href="https://oreil.ly/rBfGh" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Luigi</a>. These are very frequently used in industrial settings and enable arbitrary task chaining, online monitoring, and flexible 
<span class="publishername">scaling</span>.<a data-type="indexterm" data-primary="" data-startref="mp_fpn" id="idm46122408480120" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pn_t" id="idm46122408479112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="q_qs" id="idm46122408478168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="asjf_ab" id="idm46122408477224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="q_asjf" id="idm46122408476280" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Verifying Primes Using Interprocess Communication" class="calibre3"><div class="preface" id="multiprocessing-verifying-primes-using-inter-process-communication">
<h1 class="calibre25">Verifying Primes Using Interprocess Communication</h1>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" id="ipc_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Prime numbers are numbers that have no factor other than themselves and 1. It stands to reason that the most common factor is 2 (every even number cannot be a prime). After that, the low prime numbers (e.g., 3, 5, 7) become common factors of larger nonprimes (e.g., 9, 15, and 21, respectively).</p>

<p class="author1">Let’s say that we are given a large number and are asked to verify if it is prime. We will probably have a large space of factors to search. <a data-type="xref" href="ch09_split_000.xhtml#FIG-verifying-primes-count-of-factors-of-nonprimes" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-15</a> shows the frequency of each factor for nonprimes up to 10,000,000. Low factors are far more likely to occur than high factors, but there’s no predictable pattern.</p>

<figure class="calibre46"><div id="FIG-verifying-primes-count-of-factors-of-nonprimes" class="figure">
<img src="Images/hpp2_0915.png" alt="notset" class="calibre111"/>
<h6 class="calibre47"><span class="publishername">Figure 9-15. </span>The frequency of factors of nonprimes</h6>
</div></figure>

<p class="author1">Let’s define a new problem—suppose we have a <em class="hyperlink">small</em> set of numbers, and our task is to efficiently use our CPU resources to figure out if each number is a prime, one number at a time. Possibly we’ll have just one large number to test. It no longer makes sense to use one CPU to do the check; we want to coordinate the work across many CPUs.</p>

<p class="author1">For this section we’ll look at some larger numbers, one with 15 digits and four with 18 digits:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Small nonprime: 112,272,535,095,295</p>
</li>
<li class="calibre21">
<p class="calibre27">Large nonprime 1: 100,109,100,129,100,369</p>
</li>
<li class="calibre21">
<p class="calibre27">Large nonprime 2: 100,109,100,129,101,027</p>
</li>
<li class="calibre21">
<p class="calibre27">Prime 1: 100,109,100,129,100,151</p>
</li>
<li class="calibre21">
<p class="calibre27">Prime 2: 100,109,100,129,162,907</p>
</li>
</ul>

<p class="author1">By using a smaller nonprime and some larger nonprimes, we get to verify that our chosen process not only is faster at checking for primes but also is not getting slower at checking nonprimes. We’ll assume that we don’t know the size or type of numbers that we’re being given, so we want the fastest possible result for all our use cases.</p>
</div></section>













</div></section></div>



  

<div id="sbo-rt-content" class="calibre2">
<section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. The multiprocessing Module" class="calibre3">
<div class="preface" id="multiprocessing">
<section data-type="sect1" data-pdf-bookmark="Verifying Primes Using Interprocess Communication" class="calibre3">
<div class="preface" id="multiprocessing-verifying-primes-using-inter-process-communication">
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="multiprocessing and" id="idm46122408460488" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>If you own the previous edition of the book, you might be surprised to see that these runtimes with CPython 3.7 are <em class="hyperlink">slightly slower</em> than the CPython 2.7 runtimes in the last edition, which ran on a slower laptop. The code here is one edge case where Python 3.<em class="hyperlink">x</em> is currently slower than CPython 2.7. This code depends on integer operations; CPython 2.7 had system integers mixed with “long” integers (which can store arbitrarily sized numbers but at a cost in speed). CPython 3.<em class="hyperlink">x</em> uses only “long” integers for all 
<span class="publishername">operations</span>. This implementation is optimized but is still slower in some cases compared to the old (and more complicated) 
<span class="publishername">implementation</span>.</p>

<p class="author1">We never have to worry about which “kind” of integer is being used, and in CPython 3.7 we take a small speed hit as a consequence. This is a microbenchmark that is incredibly unlikely to affect your own code, as CPython 3.<em class="hyperlink">x</em> is faster than CPython 2.<em class="hyperlink">x</em> in so many other ways. Our recommendation is not to worry about this, unless you depend on integer operations for most of your execution time—and in that case, we’d strongly suggest you look at PyPy, which doesn’t suffer from this slowdown.</p>
</div>

<p class="author1">Cooperation comes at a cost—the cost of synchronizing data and checking the shared data can be quite high. We’ll work through several approaches here that can be used in different ways for task coordination.</p>

<p class="author1"><a data-type="indexterm" data-primary="MPI (message passing interface)" id="idm46122408417080" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Note that we’re <em class="hyperlink">not</em> covering the somewhat <span class="publishername">specialized</span> message passing interface (MPI) here; we’re looking at batteries-included modules and <a data-type="indexterm" data-primary="Redis" id="idm46122408414872" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Redis (which is very common). If you want to use MPI, we assume you already know what you’re doing. The <a href="http://bit.ly/MPI4PY_proj" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">MPI4PY project</a> would be a good place to start. It is an ideal technology if you want to control latency when lots of processes are collaborating, whether you have one or many <span class="publishername">machines.</span></p>

<p class="author1">For the following runs, each test is performed 20 times, and the minimum time is taken to show the fastest speed that is possible for that method. In these examples we’re using various techniques to share a flag (often as 1 byte). We could use a basic object like a <code class="calibre26">Lock</code>, but then we’d be able to share only 1 bit of state. We’re choosing to show you how to share a primitive type so that more expressive state sharing is possible (even though we don’t need a more expressive state for this example).</p>

<p class="author1">We must emphasize that sharing state tends to make things <em class="hyperlink">complicated</em>—you can easily end up in another hair-pulling state. Be careful and try to keep things as simple as they can be. It might be the case that less efficient resource usage is trumped by developer time spent on other challenges.</p>

<p class="author1">First we’ll discuss the results and then we’ll work through the code.</p>

<p class="author1"><a data-type="xref" href="ch09_split_001.xhtml#FIG-validating-primes-slower-results" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-16</a> shows the first approaches to trying to use interprocess communication to test for primality faster. The benchmark is the serial version, which does not use any interprocess communication; each attempt to speed up our code must at least be faster than this.</p>

<figure class="calibre46"><div id="FIG-validating-primes-slower-results" class="figure">
<img src="Images/hpp2_0916.png" alt="notset" class="calibre113"/>
<h6 class="calibre47"><span class="publishername">Figure 9-16. </span>The slower ways to use IPC to validate primality</h6>
</div></figure>

<p class="author1">The <a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Less Naive Pool solution" id="idm46122408406072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Less Naive Pool version has a predictable (and good) speed. It is good enough to be rather hard to beat. Don’t overlook the obvious in your search for high-speed solutions—sometimes a dumb and good-enough solution is all you need.</p>

<p class="author1">The approach for the Less Naive Pool solution is to take our number under test, divide its possible-factor range evenly among the available CPUs, and then push the work out to each CPU. If any CPU finds a factor, it will exit early, but it won’t communicate this fact; the other CPUs will continue to work through their part of the range. This means for an 18-digit number (our four larger examples), the search time is the same whether it is prime or nonprime.</p>

<p class="author1">The <a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Redis version" id="idm46122408403416" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Redis" id="idm46122408402392" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Manager version" id="idm46122408401720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Manager" id="idm46122408400760" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Redis and <code class="calibre26">Manager</code> solutions are slower when it comes to testing a larger number of factors for primality because of the communication overhead. They use a shared flag to indicate that a factor has been found and the search should be called off.</p>

<p class="author1">Redis lets you share state not just with other Python processes but also with other tools and other machines, and even to expose that state over a web-browser interface (which might be useful for remote monitoring). The <code class="calibre26">Manager</code> is a part of <code class="calibre26">multiprocessing</code>; it provides a high-level synchronized set of Python objects (including primitives, the <code class="calibre26">list</code>, and the <code class="calibre26">dict</code>).</p>

<p class="author1">For the larger nonprime cases, although there is a cost to checking the shared flag, this is dwarfed by the savings in search time gained by signaling early that a factor has been found.</p>

<p class="author1">For the prime cases, though, there is no way to exit early, as no factor will be found, so the cost of checking the shared flag will become the dominating cost.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">A little bit of thought is often enough. Here we explore various IPC-based solutions to making the prime-validation task faster. In terms of “minutes of typing” versus “gains made,” the first step—introducing naive parallel processing—gave us the largest win for the smallest effort. Subsequent gains took a lot of extra experimentation. Always think about the ultimate run-time, especially for ad hoc tasks. Sometimes it is just easier to let a loop run all weekend for a one-off task than to optimize the code so it runs quicker.</p>
</div>

<p class="author1"><a data-type="xref" href="ch09_split_001.xhtml#FIG-validating-primes-faster-results" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-17</a> shows that we can get a considerably faster result with a bit of effort. The Less Naive Pool result is still our benchmark, but the <a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="RawValue version" id="idm46122408392584" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="RawValue" id="idm46122408391624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="MMap version" id="idm46122408390952" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="MMap" id="idm46122408389992" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">RawValue</code> and MMap (memory map) results are much faster than the previous Redis and <code class="calibre26">Manager</code> results. The real magic comes from taking the fastest solution and performing some less-obvious code manipulations to make a near-optimal MMap solution—this final version is faster than the Less Naive Pool solution for nonprimes and almost as fast for primes.</p>

<p class="author1">In the following sections, we’ll work through various ways of using IPC in Python to solve our cooperative search problem. We hope you’ll see that IPC is fairly easy but generally comes with a cost.</p>

<figure class="calibre46"><div id="FIG-validating-primes-faster-results" class="figure">
<img src="Images/hpp2_0917.png" alt="notset" class="calibre113"/>
<h6 class="calibre47"><span class="publishername">Figure 9-17. </span>The faster ways to use IPC to validate primality</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Serial Solution" class="calibre3"><div class="preface" id="idm46122408385432">
<h2 class="calibre43">Serial Solution</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="serial solution" id="idm46122408384232" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="serial solution" id="idm46122408383240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>We’ll start with the same serial factor-checking code that we used before, shown again in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-serial" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-14</a>. As noted earlier, for any nonprime with a large factor, we could more efficiently search the space of factors in parallel. Still, a serial sweep will give us a sensible baseline to work from.</p>
<div id="code-verifying-primes-serial" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-14. </span>Serial verification</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">):</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code><code class="p">)</code> <code class="o">+</code> <code class="mi">1</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Naive Pool Solution" class="calibre3"><div class="preface" id="idm46122408285064">
<h2 class="calibre43">Naive Pool Solution</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Naive Pool solution" id="idm46122408329560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Naive Pool" id="idm46122408328424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The Naive Pool solution works with a <code class="calibre26">multiprocessing.Pool</code>, similar to what we saw in <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-finding-prime-numbers" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Finding Prime Numbers”</a> and <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-estimating-pi" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Estimating Pi Using Processes and Threads”</a> with four forked processes. We have a number to test for primality, and we divide the range of possible factors into four tuples of subranges and send these into the <code class="calibre26">Pool</code>.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-pool1-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-15</a>, we use a new method, <code class="calibre26">create_range.create</code>
(which we won’t show—it’s quite boring), that splits the work space into
equal-sized regions. Each item in <code class="calibre26">ranges_to_check</code> is a pair of lower and
upper bounds to search between. For the first 18-digit nonprime
(100,109,100,129,100,369), with four processes we’ll have the factor ranges
<code class="calibre26">ranges_to_check == [(3, 79_100_057), (79_100_057, 158_200_111), (158_200_111,
237_300_165), (237_300_165, 316_400_222)]</code> (where 316,400,222 is the square root of
100,109,100,129,100,369 plus 1). In <code class="calibre26">__main__</code> we first establish a <code class="calibre26">Pool</code>;
<code class="calibre26">check_prime</code> then splits the <code class="calibre26">ranges_to_check</code> for each possibly prime number
<code class="calibre26">n</code> via a <code class="calibre26">map</code>. If the result is <code class="calibre26">False</code>, we have found a factor and we do
not have a prime.</p>
<div id="code-verifying-primes-pool1-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-15. </span>Naive Pool solution</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">pool</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">):</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code><code class="p">))</code> <code class="o">+</code> <code class="mi">1</code>
    <code class="n">ranges_to_check</code> <code class="o">=</code> <code class="n">create_range</code><code class="o">.</code><code class="n">create</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">)</code>
    <code class="n">ranges_to_check</code> <code class="o">=</code> <code class="nb">zip</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">ranges_to_check</code><code class="p">)</code> <code class="o">*</code> <code class="p">[</code><code class="n">n</code><code class="p">],</code> <code class="n">ranges_to_check</code><code class="p">)</code>
    <code class="kn">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">ranges_to_check</code><code class="p">)</code> <code class="o">==</code> <code class="n">nbr_processes</code>
    <code class="n">results</code> <code class="o">=</code> <code class="n">pool</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">check_prime_in_range</code><code class="p">,</code> <code class="n">ranges_to_check</code><code class="p">)</code>
    <code class="kn">if</code> <code class="nb">False</code> <code class="ow">in</code> <code class="n">results</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">NBR_PROCESSES</code> <code class="o">=</code> <code class="mi">4</code>
    <code class="n">pool</code> <code class="o">=</code> <code class="n">Pool</code><code class="p">(</code><code class="n">processes</code><code class="o">=</code><code class="n">NBR_PROCESSES</code><code class="p">)</code>
    <code class="o">...</code></pre></div>

<p class="author1">We modify the previous <code class="calibre26">check_prime</code> in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-pool1-2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-16</a> to take a lower and upper bound for the range to check. There’s no value in passing a complete list of possible factors to check, so we save time and memory by passing just two numbers that define our range.</p>
<div id="code-verifying-primes-pool1-2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-16. </span><code class="calibre26">check_prime_in_range</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">For the “small nonprime” case, the verification time via the <code class="calibre26">Pool</code> is 0.1 seconds, a significantly longer time than the original 0.000002 seconds in the Serial solution. Despite this one worse result, the overall result is a speedup across the board. We could perhaps accept that one slower result isn’t a problem—but what if we might get lots of smaller nonprimes to check? It turns out we can avoid this slowdown; we’ll see that next with the Less Naive Pool solution.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="A Less Naive Pool Solution" class="calibre3"><div class="preface" id="idm46122408043992">
<h2 class="calibre43">A Less Naive Pool Solution</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Less Naive Pool solution" id="idm46122408042744" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Less Naive Pool" id="idm46122408041832" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The previous solution was inefficient at validating the smaller nonprime. For any smaller (fewer than 18 digits) nonprime, it is likely to be slower than the serial method, because of the overhead of sending out partitioned work and not knowing if a very small factor (which is a more likely factor) will be found. If a small factor is found, the process will still have to wait for the other larger factor searches to 
<span class="publishername">complete</span>.</p>

<p class="author1">We could start to signal between the processes that a small factor has been found, but since this happens so frequently, it will add a lot of communication overhead. The <span class="publishername">solution</span> presented in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-pool2-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-17</a> is a more pragmatic approach—a serial check is performed quickly for likely small factors, and if none are found, then a parallel search is started. Combining a serial precheck before launching a relatively more expensive parallel operation is a common approach to avoiding some of the costs of parallel <span class="publishername">computing</span>.</p>
<div id="code-verifying-primes-pool2-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-17. </span>Improving the Naive Pool solution for the small-nonprime case</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">pool</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">):</code>
    <code class="c"># cheaply check high-probability set of possible factors</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="mi">21</code>
    <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_prime_in_range</code><code class="p">((</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))):</code>
        <code class="kn">return</code> <code class="nb">False</code>

    <code class="c"># continue to check for larger factors in parallel</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="n">to_i</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">math</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">n</code><code class="p">))</code> <code class="o">+</code> <code class="mi">1</code>
    <code class="n">ranges_to_check</code> <code class="o">=</code> <code class="n">create_range</code><code class="o">.</code><code class="n">create</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">)</code>
    <code class="n">ranges_to_check</code> <code class="o">=</code> <code class="nb">zip</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">ranges_to_check</code><code class="p">)</code> <code class="o">*</code> <code class="p">[</code><code class="n">n</code><code class="p">],</code> <code class="n">ranges_to_check</code><code class="p">)</code>
    <code class="kn">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">ranges_to_check</code><code class="p">)</code> <code class="o">==</code> <code class="n">nbr_processes</code>
    <code class="n">results</code> <code class="o">=</code> <code class="n">pool</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">check_prime_in_range</code><code class="p">,</code> <code class="n">ranges_to_check</code><code class="p">)</code>
    <code class="kn">if</code> <code class="nb">False</code> <code class="ow">in</code> <code class="n">results</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">The speed of this solution is equal to or better than that of the original serial search for each of our test numbers. This is our new benchmark.</p>

<p class="author1">Importantly, this <code class="calibre26">Pool</code> approach gives us an optimal case for the prime-checking situation. If we have a prime, there’s no way to exit early; we have to manually check all possible factors before we can exit.</p>

<p class="author1">There’s no faster way to check though these factors: any approach that adds complexity will have more instructions, so the check-all-factors case will cause the most instructions to be executed. See the various <code class="calibre26">mmap</code> solutions covered in  <a data-type="xref" href="ch09_split_001.xhtml#multiprocessing-mmap" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using mmap as a Flag”</a> for a discussion on how to get as close to this current result for primes as possible.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using Manager.Value as a Flag" class="calibre3"><div class="preface" id="idm46122407903464">
<h2 class="calibre43">Using Manager.Value as a Flag</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Manager.Value as flag" id="ipc_mv" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Manager.Value" id="mv_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <code class="calibre26">multiprocessing.Manager()</code> lets us share higher-level Python objects between processes as managed shared objects; the lower-level objects are wrapped in proxy objects. The wrapping and safety have a speed cost but also offer great flexibility. You can share both lower-level objects (e.g., integers and floats) and lists and dictionaries.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-managervalue1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-18</a>, we create a <code class="calibre26">Manager</code> and then create a 1-byte (character) <code class="calibre26">manager.Value(b"c", FLAG_CLEAR)</code> flag. You could create any of the <code class="calibre26">ctypes</code> primitives (which are the same as the <code class="calibre26">array.array</code> primitives) if you wanted to share strings or numbers.</p>

<p class="author1">Note that <code class="calibre26">FLAG_CLEAR</code> and <code class="calibre26">FLAG_SET</code> are assigned a byte (<code class="calibre26">b'0'</code> and <code class="calibre26">b'1'</code>, respectively). We chose to use the leading <code class="calibre26">b</code> to be very explicit (it might default to a Unicode or string object if left as an implicit string, depending on your environment and Python version).</p>

<p class="author1">Now we can flag across all of our processes that a factor has been found, so the search can be called off early. The difficulty is balancing the cost of reading the flag against the speed savings that is possible. Because the flag is synchronized, we don’t want to check it too frequently—this adds more overhead.</p>
<div id="code-verifying-primes-managervalue1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-18. </span>Passing a <code class="calibre26">Manager.Value</code> object as a flag</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">SERIAL_CHECK_CUTOFF</code> <code class="o">=</code> <code class="mi">21</code>
<code class="n">CHECK_EVERY</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">FLAG_CLEAR</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">'0'</code>
<code class="n">FLAG_SET</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">'1'</code>
<code class="kn">print</code><code class="p">(</code><code class="s">"CHECK_EVERY"</code><code class="p">,</code> <code class="n">CHECK_EVERY</code><code class="p">)</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">NBR_PROCESSES</code> <code class="o">=</code> <code class="mi">4</code>
    <code class="n">manager</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Manager</code><code class="p">()</code>
    <code class="n">value</code> <code class="o">=</code> <code class="n">manager</code><code class="o">.</code><code class="n">Value</code><code class="p">(</code><code class="calibre26">b</code><code class="s">'c'</code><code class="p">,</code> <code class="n">FLAG_CLEAR</code><code class="p">)</code>  <code class="c"># 1-byte character</code>
    <code class="o">...</code></pre></div>

<p class="author1"><code class="calibre26">check_prime_in_range</code> will now be aware of the shared flag, and the routine will be checking to see if a prime has been spotted by another process. Even though we’ve yet to begin the parallel search, we must clear the flag as shown in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-managervalue2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-19</a> before we start the serial check. Having completed the serial check, if we haven’t found a factor, we know that the flag must still be false.</p>
<div id="code-verifying-primes-managervalue2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-19. </span>Clearing the flag with a <code class="calibre26">Manager.Value</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">pool</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">,</code> <code class="n">value</code><code class="p">):</code>
    <code class="c"># cheaply check high-probability set of possible factors</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="n">SERIAL_CHECK_CUTOFF</code>
    <code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">=</code> <code class="n">FLAG_CLEAR</code>
    <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_prime_in_range</code><code class="p">((</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">),</code> <code class="n">value</code><code class="p">)):</code>
        <code class="kn">return</code> <code class="nb">False</code>

    <code class="n">from_i</code> <code class="o">=</code> <code class="n">to_i</code>
    <code class="o">...</code></pre></div>

<p class="author1">How frequently should we check the shared flag? Each check has a cost, both because we’re adding more instructions to our tight inner loop and because checking requires a lock to be made on the shared variable, which adds more cost. The solution we’ve chosen is to check the flag every one thousand iterations. Every time we check, we look to see if <code class="calibre26">value.value</code> has been set to <code class="calibre26">FLAG_SET</code>, and if so, we exit the search. If in the search the process finds a factor, then it sets <code class="calibre26">value.value = FLAG_SET</code> and exits (see <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-managervalue3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-20</a>).</p>
<div id="code-verifying-primes-managervalue3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-20. </span>Passing a <code class="calibre26">Manager.Value</code> object as a flag</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">),</code> <code class="n">value</code><code class="p">)</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="n">check_every</code> <code class="o">-=</code> <code class="mi">1</code>
        <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_every</code><code class="p">:</code>
            <code class="kn">if</code> <code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">==</code> <code class="n">FLAG_SET</code><code class="p">:</code>
                <code class="kn">return</code> <code class="nb">False</code>
            <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>

        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">=</code> <code class="n">FLAG_SET</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">The thousand-iteration check in this code is performed using a <code class="calibre26">check_every</code> local counter. It turns out that this approach, although readable, is suboptimal for speed. By the end of this section, we’ll replace it with a less readable but significantly faster approach.</p>

<p class="author1">You might be curious about the total number of times we check for the shared flag. In the case of the two large primes, with four processes we check for the flag 316,405 times (we check it this many times in all of the following examples). Since each check has an overhead due to locking, this cost really adds up.<a data-type="indexterm" data-primary="" data-startref="ipc_mv" id="idm46122407614680" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mv_ab" id="idm46122407614056" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using Redis as a Flag" class="calibre3"><div class="preface" id="multiprocessing-using-redis-as-a-flag">
<h2 class="calibre43">Using Redis as a Flag</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Redis version" id="ipc_red" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Redis" id="red_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">Redis</em> is a key/value in-memory storage engine. It provides its own locking and each operation is atomic, so we don’t have to worry about using locks from inside Python (or from any other interfacing language).</p>

<p class="author1">By using Redis, we make the data storage language-agnostic—any language or tool with an interface to Redis can share data in a compatible way. You could share data between Python, Ruby, C++, and PHP equally easily. You can share data on the local machine or over a network; to share to other machines, all you need to do is change the Redis default of sharing only on <code class="calibre26">localhost</code>.</p>

<p class="author1">Redis lets you store the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Lists of strings</p>
</li>
<li class="calibre21">
<p class="calibre27">Sets of strings</p>
</li>
<li class="calibre21">
<p class="calibre27">Sorted sets of strings</p>
</li>
<li class="calibre21">
<p class="calibre27">Hashes of strings</p>
</li>
</ul>

<p class="author1">Redis stores everything in RAM and snapshots to disk (optionally using journaling) and supports master/slave replication to a cluster of instances. One possibility with Redis is to use it to share a workload across a cluster, where other machines read and write state and Redis acts as a fast centralized data repository.</p>

<p class="author1">We can read and write a flag as a text string (all values in Redis are strings) in just the same way as we have been using Python flags previously. We create a <code class="calibre26">StrictRedis</code> interface as a global object, which talks to the external Redis server. We could create a new connection inside <code class="calibre26">check_prime_in_range</code>, but this is slower and can exhaust the limited number of Redis handles that are available.</p>

<p class="author1">We talk to the Redis server using a dictionary-like access. We can set a value using <code class="calibre26">rds[SOME_KEY] = SOME_VALUE</code> and read the string back using <code class="calibre26">rds[SOME_KEY]</code>.</p>

<p class="author1"><a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-redis1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-21</a> is very similar to the previous <code class="calibre26">Manager</code> example—we’re using Redis as a substitute for the local <code class="calibre26">Manager</code>. It comes with a similar access cost. You should note that Redis supports other (more complex) data structures; it is a powerful storage engine that we’re using just to share a flag for this example. We encourage you to familiarize yourself with its features.</p>
<div id="code-verifying-primes-redis1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-21. </span>Using an external Redis server for our flag</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">FLAG_NAME</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">'redis_primes_flag'</code>
<code class="n">FLAG_CLEAR</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">'0'</code>
<code class="n">FLAG_SET</code> <code class="o">=</code> <code class="calibre26">b</code><code class="s">'1'</code>

<code class="n">rds</code> <code class="o">=</code> <code class="n">redis</code><code class="o">.</code><code class="n">StrictRedis</code><code class="p">()</code>

<code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="n">check_every</code> <code class="o">-=</code> <code class="mi">1</code>
        <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_every</code><code class="p">:</code>
            <code class="n">flag</code> <code class="o">=</code> <code class="n">rds</code><code class="p">[</code><code class="n">FLAG_NAME</code><code class="p">]</code>
            <code class="kn">if</code> <code class="n">flag</code> <code class="o">==</code> <code class="n">FLAG_SET</code><code class="p">:</code>
                <code class="kn">return</code> <code class="nb">False</code>
            <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>

        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">rds</code><code class="p">[</code><code class="n">FLAG_NAME</code><code class="p">]</code> <code class="o">=</code> <code class="n">FLAG_SET</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code>


<code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">pool</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">):</code>
    <code class="c"># cheaply check high-probability set of possible factors</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="n">SERIAL_CHECK_CUTOFF</code>
    <code class="n">rds</code><code class="p">[</code><code class="n">FLAG_NAME</code><code class="p">]</code> <code class="o">=</code> <code class="n">FLAG_CLEAR</code>
    <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_prime_in_range</code><code class="p">((</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))):</code>
        <code class="kn">return</code> <code class="nb">False</code>

    <code class="o">...</code>
    <code class="kn">if</code> <code class="nb">False</code> <code class="ow">in</code> <code class="n">results</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">To confirm that the data is stored outside these Python instances, we can invoke <code class="calibre26">redis-cli</code> at the command line, as in <a data-type="xref" href="ch09_split_001.xhtml#code-08-redis-cli" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-22</a>, and get the value stored in the key <code class="calibre26">redis_primes_flag</code>. You’ll note that the returned item is a string (not an integer). All values returned from Redis are strings, so if you want to manipulate them in Python, you’ll have to convert them to an appropriate datatype first.</p>
<div data-type="example" id="code-08-redis-cli" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-22. </span><code class="calibre26">redis-cli</code></h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">redis-cli</strong>
redis 127.0.0.1:6379&gt; GET "redis_primes_flag"
"0"</pre>
</div>

<p class="author1">One powerful argument in favor of the use of Redis for data sharing is that it lives outside the Python world—non-Python developers on your team will understand it, and many tools exist for it. They’ll be able to look at its state while reading (but not necessarily running and debugging) your code and follow what’s happening. From a team-velocity perspective, this might be a big win for you, despite the communication overhead of using Redis. While Redis is an additional dependency on your project, you should note that it is a very commonly deployed tool, and one that is well debugged and well understood. Consider it a powerful tool to add to your armory.</p>

<p class="author1">Redis has many configuration options. By default it uses a TCP interface (that’s what we’re using), although the benchmark documentation notes that sockets might be much faster. It also states that while TCP/IP lets you share data over a network between different types of OS, other configuration options are likely to be faster (but also are likely to limit your communication options):</p>
<blockquote class="calibre69 pcalibre5 pcalibre6">
<p class="calibre70"><a data-type="indexterm" data-primary="TCP/IP" id="idm46122407393496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>When the server and client benchmark programs run on the same box, both the TCP/IP loopback and unix domain sockets can be used. It depends on the platform, but unix domain sockets can achieve around 50% more throughput than the TCP/IP loopback (on Linux for instance). The default behavior of redis-benchmark is to use the TCP/IP loopback.
The performance benefit of unix domain sockets compared to TCP/IP loopback tends to decrease when pipelining is heavily used (i.e., long 
<span class="publishername">pipelines</span>).</p>
<p data-type="attribution" class="calibre71 pcalibre7"><a href="http://redis.io/topics/benchmarks" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Redis documentation</a></p>
</blockquote>

<p class="author1">Redis is widely used in industry and is mature and well trusted. If you’re not familiar with the tool, we strongly suggest you take a look at it; it has a place in your high performance toolkit.<a data-type="indexterm" data-primary="" data-startref="ipc_red" id="idm46122407389544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="red_ab" id="idm46122407388568" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using RawValue as a Flag" class="calibre3"><div class="preface" id="idm46122407612520">
<h2 class="calibre43">Using RawValue as a Flag</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="Raw" id="idm46122407386248" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="RawValue" id="idm46122407385208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">multiprocessing.RawValue</code> is a thin wrapper around a <code class="calibre26">ctypes</code> block of bytes. It lacks synchronization primitives, so there’s little to get in our way in our search for the fastest way to set a flag between processes. It will be almost as fast as the following <code class="calibre26">mmap</code> example (it is slower only because a few more instructions get in the way).</p>

<p class="author1">Again, we could use any<a data-type="indexterm" data-primary="ctypes" id="idm46122407382440" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">ctypes</code> primitive; there’s also a <code class="calibre26">RawArray</code> option for sharing an array of primitive objects (which will behave similarly to <code class="calibre26">array.array</code>). <code class="calibre26">RawValue</code> avoids any locking—it is faster to use, but you don’t get atomic operations.</p>

<p class="author1">Generally, if you avoid the synchronization that Python provides during IPC, you’ll come unstuck (once again, back to that pulling-your-hair-out situation). <em class="hyperlink">However</em>, in this problem it doesn’t matter if one or more processes set the flag at the same time—the flag gets switched in only one direction, and every other time it is read, it is just to learn if the search can be called off.</p>

<p class="author1">Because we never reset the state of the flag during the parallel search, we don’t need synchronization. Be aware that this may not apply to your problem. If you avoid synchronization, please make sure you are doing it for the right reasons.</p>

<p class="author1">If you want to do things like update a shared counter, look at the documentation for the <code class="calibre26">Value</code> and use a context manager with <code class="calibre26">value.get_lock()</code>, as the implicit locking on a <code class="calibre26">Value</code> doesn’t allow for atomic operations.</p>

<p class="author1">This example looks very similar to the previous <code class="calibre26">Manager</code> example. The only difference is that in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-value1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-23</a> we create the <code class="calibre26">RawValue</code> as a one-character (byte) flag.</p>
<div id="code-verifying-primes-value1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-23. </span>Creating and passing a <code class="calibre26">RawValue</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">NBR_PROCESSES</code> <code class="o">=</code> <code class="mi">4</code>
    <code class="n">value</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">RawValue</code><code class="p">(</code><code class="s">'b'</code><code class="p">,</code> <code class="n">FLAG_CLEAR</code><code class="p">)</code>  <code class="c"># 1-byte character</code>
    <code class="n">pool</code> <code class="o">=</code> <code class="n">Pool</code><code class="p">(</code><code class="n">processes</code><code class="o">=</code><code class="n">NBR_PROCESSES</code><code class="p">)</code>
    <code class="o">...</code></pre></div>

<p class="author1">The flexibility to use managed and raw values is a benefit of the clean design for data sharing in <code class="calibre26">multiprocessing</code>.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using mmap as a Flag" class="calibre3"><div class="preface" id="multiprocessing-mmap">
<h2 class="calibre43">Using mmap as a Flag</h2>

<p class="author1"><a data-type="indexterm" data-primary="IPC (interprocess communication)" data-secondary="MMap version" id="ipc_mm" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="MMap" id="mm_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Finally, we get to the fastest way of sharing bytes. <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-mmap1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-24</a> shows a memory-mapped (shared memory) solution using the <code class="calibre26">mmap</code> module. The bytes in a shared <span class="publishername">memory</span> block are not synchronized, and they come with very little overhead. They act like a file—in this case, they are a block of memory with a file-like interface. We have to <code class="calibre26">seek</code> to a location and read or write sequentially. Typically, <code class="calibre26">mmap</code> is used to give a short (memory-mapped) view into a larger file, but in our case, rather than specifying a file number as the first argument, we instead pass <code class="calibre26">-1</code> to indicate that we want an anonymous block of memory. We could also specify whether we want read-only or write-only access (we want both, which is the default).</p>
<div id="code-verifying-primes-mmap1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-24. </span>Using a shared memory flag via <code class="calibre26">mmap</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">sh_mem</code> <code class="o">=</code> <code class="n">mmap</code><code class="o">.</code><code class="n">mmap</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>  <code class="c"># memory map 1 byte as a flag</code>


<code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="n">check_every</code> <code class="o">-=</code> <code class="mi">1</code>
        <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_every</code><code class="p">:</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
            <code class="n">flag</code> <code class="o">=</code> <code class="n">sh_mem</code><code class="o">.</code><code class="n">read_byte</code><code class="p">()</code>
            <code class="kn">if</code> <code class="n">flag</code> <code class="o">==</code> <code class="n">FLAG_SET</code><code class="p">:</code>
                <code class="kn">return</code> <code class="nb">False</code>
            <code class="n">check_every</code> <code class="o">=</code> <code class="n">CHECK_EVERY</code>

        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">write_byte</code><code class="p">(</code><code class="n">FLAG_SET</code><code class="p">)</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code>



<code class="kn">def</code> <code class="nf">check_prime</code><code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="n">pool</code><code class="p">,</code> <code class="n">nbr_processes</code><code class="p">):</code>
    <code class="c"># cheaply check high-probability set of possible factors</code>
    <code class="n">from_i</code> <code class="o">=</code> <code class="mi">3</code>
    <code class="n">to_i</code> <code class="o">=</code> <code class="n">SERIAL_CHECK_CUTOFF</code>
    <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
    <code class="n">sh_mem</code><code class="o">.</code><code class="n">write_byte</code><code class="p">(</code><code class="n">FLAG_CLEAR</code><code class="p">)</code>
    <code class="kn">if</code> <code class="ow">not</code> <code class="n">check_prime_in_range</code><code class="p">((</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))):</code>
        <code class="kn">return</code> <code class="nb">False</code>

    <code class="o">...</code>
    <code class="kn">if</code> <code class="nb">False</code> <code class="ow">in</code> <code class="n">results</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1"><code class="calibre26">mmap</code> supports a number of methods that can be used to move around in the file that it represents (including <code class="calibre26">find</code>, <code class="calibre26">readline</code>, and <code class="calibre26">write</code>). We are using it in the most basic way—we <code class="calibre26">seek</code> to the start of the memory block before each read or write, and since we’re sharing just 1 byte, we use <code class="calibre26">read_byte</code> and <code class="calibre26">write_byte</code> to be explicit.</p>

<p class="author1">There is no Python overhead for locking and no interpretation of the data; we’re dealing with bytes directly with the operating system, so this is our fastest communication method.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using mmap as a Flag Redux" class="calibre3"><div class="preface" id="idm46122407023784">
<h2 class="calibre43">Using mmap as a Flag Redux</h2>

<p class="author1">While the previous <code class="calibre26">mmap</code> result was the best overall, we couldn’t help but think that we should be able to get back to the Naive Pool result for the most expensive case of having primes. The goal is to accept that there is no early exit from the inner loop and to minimize the cost of anything extraneous.</p>

<p class="author1">This section presents a slightly more complex solution. The same changes can be made to the other flag-based approaches we’ve seen, although this <code class="calibre26">mmap</code> result will still be fastest.</p>

<p class="author1">In our previous examples, we’ve used <code class="calibre26">CHECK_EVERY</code>. This means we have the <code class="calibre26">check_next</code> local variable to track, decrement, and use in Boolean tests—and each operation adds a bit of extra time to every iteration. In the case of validating a large prime, this extra management overhead occurs over 300,000 times.</p>

<p class="author1">The first optimization, shown in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-mmap2-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-25</a>, is to realize that we can replace the decremented counter with a look-ahead value, and then we only have to do a Boolean comparison on the inner loop. This removes a decrement, which, because of Python’s interpreted style, is quite slow. This optimization works in this test in CPython 3.7, but it is unlikely to offer any benefit in a smarter compiler (e.g., PyPy or Cython). This step saved 0.1 seconds when checking one of our large primes.</p>
<div id="code-verifying-primes-mmap2-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-25. </span>Starting to optimize away our expensive logic</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="n">check_next</code> <code class="o">=</code> <code class="n">from_i</code> <code class="o">+</code> <code class="n">CHECK_EVERY</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="mi">2</code><code class="p">):</code>
        <code class="kn">if</code> <code class="n">check_next</code> <code class="o">==</code> <code class="n">i</code><code class="p">:</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
            <code class="n">flag</code> <code class="o">=</code> <code class="n">sh_mem</code><code class="o">.</code><code class="n">read_byte</code><code class="p">()</code>
            <code class="kn">if</code> <code class="n">flag</code> <code class="o">==</code> <code class="n">FLAG_SET</code><code class="p">:</code>
                <code class="kn">return</code> <code class="nb">False</code>
            <code class="n">check_next</code> <code class="o">+=</code> <code class="n">CHECK_EVERY</code>

        <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
            <code class="n">sh_mem</code><code class="o">.</code><code class="n">write_byte</code><code class="p">(</code><code class="n">FLAG_SET</code><code class="p">)</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">We can also entirely replace the logic that the counter represents, as shown in <a data-type="xref" href="ch09_split_001.xhtml#code-verifying-primes-mmap3-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-26</a>, by unrolling our loop into a two-stage process. First, the outer loop covers the expected range, but in steps, on <code class="calibre26">CHECK_EVERY</code>. Second, a new inner loop replaces the <code class="calibre26">check_every</code> logic—it checks the local range of factors and then finishes. This is equivalent to the <code class="calibre26">if not check_every:</code> test. We follow this with the previous <code class="calibre26">sh_mem</code> logic to check the early-exit flag.</p>
<div id="code-verifying-primes-mmap3-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-26. </span>Optimizing away our expensive logic</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">check_prime_in_range</code><code class="p">(</code><code class="n">n_from_i_to_i</code><code class="p">):</code>
    <code class="p">(</code><code class="n">n</code><code class="p">,</code> <code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="n">to_i</code><code class="p">))</code> <code class="o">=</code> <code class="n">n_from_i_to_i</code>
    <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">assert</code> <code class="n">from_i</code> <code class="o">%</code> <code class="mi">2</code> <code class="o">!=</code> <code class="mi">0</code>
    <code class="kn">for</code> <code class="n">outer_counter</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">from_i</code><code class="p">,</code> <code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="n">CHECK_EVERY</code><code class="p">):</code>
        <code class="n">upper_bound</code> <code class="o">=</code> <code class="nb">min</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">to_i</code><code class="p">),</code> <code class="n">outer_counter</code> <code class="o">+</code> <code class="n">CHECK_EVERY</code><code class="p">)</code>
        <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">outer_counter</code><code class="p">,</code> <code class="n">upper_bound</code><code class="p">,</code> <code class="mi">2</code><code class="p">):</code>
            <code class="kn">if</code> <code class="n">n</code> <code class="o">%</code> <code class="n">i</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
                <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
                <code class="n">sh_mem</code><code class="o">.</code><code class="n">write_byte</code><code class="p">(</code><code class="n">FLAG_SET</code><code class="p">)</code>
                <code class="kn">return</code> <code class="nb">False</code>
        <code class="n">sh_mem</code><code class="o">.</code><code class="n">seek</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>
        <code class="n">flag</code> <code class="o">=</code> <code class="n">sh_mem</code><code class="o">.</code><code class="n">read_byte</code><code class="p">()</code>
        <code class="kn">if</code> <code class="n">flag</code> <code class="o">==</code> <code class="n">FLAG_SET</code><code class="p">:</code>
            <code class="kn">return</code> <code class="nb">False</code>
    <code class="kn">return</code> <code class="nb">True</code></pre></div>

<p class="author1">The speed impact is dramatic. Our nonprime case improves even further, but more importantly, our prime-checking case is nearly as fast as the Less Naive Pool version (it is now just 0.1 seconds slower). Given that we’re doing a lot of extra work with interprocess communication, this is an interesting result. Do note, though, that it is specific to CPython and unlikely to offer any gains when run through a compiler.</p>

<p class="author1">In the last edition of the book we went even further with a final example that used loop unrolling and local references to global objects and eked out a further performance gain at the expense of readability. This example in Python 3 yields a minor slowdown, so we’ve removed it. We’re happy about this—fewer hoops needed jumping through to get the most performant example, and the preceding code is more likely to be supported correctly in a team than one that makes implementation-specific code changes.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="multiprocessing and" id="idm46122406826760" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyPy" data-secondary="CPython versus" id="idm46122406723944" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>These examples work just fine with PyPy, where they run around seven times faster than in CPython. Sometimes the better solution will be to investigate other runtimes rather than to go down rabbit holes with CPython.<a data-type="indexterm" data-primary="" data-startref="ipc_ab" id="idm46122406722632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ipc_mm" id="idm46122406721688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mm_ab" id="idm46122406720744" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Sharing numpy Data with multiprocessing" class="calibre3"><div class="preface" id="multiprocessing-sharing-numpy-data-with-multiprocessing">
<h1 class="calibre25">Sharing numpy Data with multiprocessing</h1>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="numpy data sharing" id="mp_nds" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="sharing data with multiprocessing" id="num_sd" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>When working with large <code class="calibre26">numpy</code> arrays, you’re bound to wonder if you can share the data for read and write access, without a copy, between processes. It is possible, though a little fiddly. We’d like to acknowledge Stack Overflow user <em class="hyperlink">pv</em> for the inspiration for this demo.<sup class="calibre44"><a data-type="noteref" id="idm46122406714360-marker" href="ch09_split_001.xhtml#idm46122406714360" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup></p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1"><a data-type="indexterm" data-primary="MKI" id="idm46122406712136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Stack Overflow" id="idm46122406711432" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Basic Linear Algebra Subprograms (BLAS)" id="idm46122406710760" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="BLAS (Basic Linear Algebra Subprograms)" id="idm46122406710072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Accelerate" id="idm46122406709384" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="ATLAS" id="idm46122406708712" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Do not use this method to re-create the behaviors of BLAS, MKL, Accelerate, and ATLAS. These libraries all have multithreading support in their primitives, and they likely are better-debugged than any new routine that you create. They can require some configuration to enable multithreading support, but it would be wise to see if these libraries can give you free speedups before you invest time (and lose time to debugging!) writing your own.</p>
</div>

<p class="author1">Sharing a large matrix between processes has several benefits:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Only one copy means no wasted RAM.</p>
</li>
<li class="calibre21">
<p class="calibre27">No time is wasted copying large blocks of RAM.</p>
</li>
<li class="calibre21">
<p class="calibre27">You gain the possibility of sharing partial results between the processes.</p>
</li>
</ul>

<p class="author1">Thinking back to the pi estimation demo using <code class="calibre26">numpy</code> in <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-estimating-pi-using-numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using numpy”</a>, we had the problem that the random number generation was a serial process. Here, we can imagine forking processes that share one large array, each one using a differently seeded random number generator to fill in a section of the array with random numbers, and therefore completing the generation of a large random block faster than is possible with a single process.</p>

<p class="author1">To verify this, we modified the forthcoming demo to create a large random matrix (10,000 × 320,000 elements) as a serial process and by splitting the matrix into four segments where <code class="calibre26">random</code> is called in parallel (in both cases, one row at a time). The serial process took 53 seconds, and the parallel version took 29 seconds. Refer back to <a data-type="xref" href="ch09_split_000.xhtml#multiprocessing-random-numbers" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Random Numbers in Parallel Systems”</a> to understand some of the dangers of parallelized random number generation.</p>

<p class="author1">For the rest of this section, we’ll use a simplified demo that illustrates the point while remaining easy to verify.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#FIG-numpy-shared-multiprocessing-htop" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 9-18</a>, you can see the output from <code class="calibre26">htop</code> on Ian’s laptop. It shows four child processes of the parent (with PID 27628), where all five processes are sharing a single 10,000-by-320,000-element <code class="calibre26">numpy</code> array of doubles. One copy of this array costs <span class="publishername">25.6 GB</span>, and the laptop has only 32 GB—you can see in <code class="calibre26">htop</code> by the process meters that the <code class="calibre26">Mem</code> reading shows a maximum of 31.1 GB RAM.</p>

<figure class="calibre46"><div id="FIG-numpy-shared-multiprocessing-htop" class="figure">
<img src="Images/hpp2_0918.png" alt="notset" class="calibre97"/>
<h6 class="calibre47"><span class="publishername">Figure 9-18. </span><code class="calibre26">htop</code> showing RAM and swap usage</h6>
</div></figure>

<p class="author1">To understand this demo, we’ll first walk through the console output, and then we’ll look at the code. In <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-setup" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-27</a>, we start the parent process: it allocates a 25.6 GB double array of dimensions 10,000 × 320,000, filled with the value zero. The 10,000 rows will be passed out as indices to the worker function, and the worker will operate on each column of 320,000 items in turn. Having allocated the array, we fill it with the answer to life, the universe, and everything (<code class="calibre26">42</code>!). We can test in the worker function that we’re receiving this modified array and not a filled-with-0s version to confirm that this code is behaving as expected.</p>
<div data-type="example" id="code-sharing-numpy-array-using-multiprocessing-run-setup" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-27. </span>Setting up the shared array</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python np_shared.py</strong>
Created shared array with 25,600,000,000 nbytes
Shared array id is 139636238840896 in PID 27628
Starting with an array of 0 values:
[[ 0.  0.  0. ...,  0.  0.  0.]
 ...,
 [ 0.  0.  0. ...,  0.  0.  0.]]

Original array filled with value 42:
[[ 42.  42.  42. ...,  42.  42.  42.]
 ...,
 [ 42.  42.  42. ...,  42.  42.  42.]]
Press a key to start workers using multiprocessing...</pre>
</div>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-worker-fn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-28</a>, we’ve started four processes working on this shared array. No copy of the array was made; each process is looking at the same large block of memory, and each process has a different set of indices to work from. Every few thousand lines, the worker outputs the current index and its PID, so we can observe its behavior. The worker’s job is trivial—it will check that the current element is still set to the default (so we know that no other process has modified it already), and then it will overwrite this value with the current PID. Once the workers have completed, we return to the parent process and print the array again. This time, we see that it is filled with PIDs rather than <code class="calibre26">42</code>.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-run-worker-fn" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-28. </span>Running <code class="calibre26">worker_fn</code> on the shared array</h5>

<pre data-type="programlisting" class="calibre59"> worker_fn: with idx 0
  id of local_nparray_in_process is 139636238840896 in PID 27751
 worker_fn: with idx 2000
  id of local_nparray_in_process is 139636238840896 in PID 27754
 worker_fn: with idx 1000
  id of local_nparray_in_process is 139636238840896 in PID 27752
 worker_fn: with idx 4000
  id of local_nparray_in_process is 139636238840896 in PID 27753
 ...
 worker_fn: with idx 8000
  id of local_nparray_in_process is 139636238840896 in PID 27752

The default value has been overwritten with worker_fn's result:
[[27751. 27751. 27751. ... 27751. 27751. 27751.]
 ...
 [27751. 27751. 27751. ... 27751. 27751. 27751.]]</pre></div>

<p class="author1">Finally, in <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-verify" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-29</a> we use a <code class="calibre26">Counter</code> to confirm the frequency of each PID in the array. As the work was evenly divided, we expect to see each of the four PIDs represented an equal number of times. In our 3,200,000,000-element array, we see four sets of 800,000,000 PIDs. The table output is presented using <a href="https://oreil.ly/tXL3a" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PrettyTable</a>.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-run-verify" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-29. </span>Verifying the result on the shared array</h5>

<pre data-type="programlisting" class="calibre59">Verification - extracting unique values from 3,200,000,000 items
in the numpy array (this might be slow)...
Unique values in main_nparray:
+---------+-----------+
|   PID   |   Count   |
+---------+-----------+
| 27751.0 | 800000000 |
| 27752.0 | 800000000 |
| 27753.0 | 800000000 |
| 27754.0 | 800000000 |
+---------+-----------+
Press a key to exit...</pre></div>

<p class="author1">Having completed, the program now exits, and the array is deleted.</p>

<p class="author1">We can take a peek inside each process under Linux by using <code class="calibre26">ps</code> and <code class="calibre26">pmap</code>. <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-run-pmap" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-30</a> shows the result of calling <code class="calibre26">ps</code>. Breaking apart this command line:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27"><code class="calibre26">ps</code> tells us about the process.</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">-A</code> lists all processes.</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">-o pid,size,vsize,cmd</code> outputs the PID, size information, and the command name.</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">grep</code> is used to filter all other results and leave only the lines for our demo.</p>
</li>
</ul>

<p class="author1">The parent process (PID 27628) and its four forked children are shown in the output. The result is similar to what we saw in <code class="calibre26">htop</code>. We can use <code class="calibre26">pmap</code> to look at the memory map of each process, requesting extended output with <code class="calibre26">-x</code>. We <code class="calibre26">grep</code> for the pattern <code class="calibre26">s-</code> to list blocks of memory that are marked as being shared. In the parent process and the child processes, we see a 25,000,000 KB (25.6 GB) block that is shared between them.</p>
<div data-type="example" id="code-sharing-numpy-array-using-multiprocessing-run-pmap" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-30. </span>Using <code class="calibre26">pmap</code> and <code class="calibre26">ps</code> to investigate the operating system’s view of the <span class="publishername">processes</span></h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">ps -A -o pid,size,vsize,cmd | grep np_shared</strong>
27628 279676 25539428 python np_shared.py
27751 279148 25342688 python np_shared.py
27752 279148 25342688 python np_shared.py
27753 279148 25342688 python np_shared.py
27754 279148 25342688 python np_shared.py

ian@ian-Latitude-E6420 $ <strong class="calibre83">pmap -x 27628 | grep s-</strong>
Address           Kbytes     RSS   Dirty Mode   Mapping
00007ef9a2853000 25000000 25000000 2584636 rw-s- pym-27628-npfjsxl6 (deleted)
...
ian@ian-Latitude-E6420 $ <strong class="calibre83">pmap -x 27751 | grep s-</strong>
Address           Kbytes     RSS   Dirty Mode   Mapping
00007ef9a2853000 25000000 6250104 1562508 rw-s- pym-27628-npfjsxl6 (deleted)
...</pre>
</div>

<p class="author1">We’ll use a <a data-type="indexterm" data-primary="multiprocessing arrays" id="idm46122406659640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">multprocessing.Array</code> to allocate a shared block of memory as a 1D array and then instantiate a <code class="calibre26">numpy</code> array from this object and reshape it to a 2D array. Now we have a <code class="calibre26">numpy</code>-wrapped block of memory that can be shared between processes and addressed as though it were a normal <code class="calibre26">numpy</code> array. <code class="calibre26">numpy</code> is not managing the RAM; <code class="calibre26">multiprocessing.Array</code> is managing it.</p>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-worker-fn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-31</a>, you can see that each forked process has access to a global <code class="calibre26">main_nparray</code>. While the forked process has a copy of the <code class="calibre26">numpy</code> object, the underlying bytes that the object accesses are stored as shared memory. Our <code class="calibre26">worker_fn</code> will overwrite a chosen row (via <code class="calibre26">idx</code>) with the current process identifier.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-worker-fn" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-31. </span><code class="calibre26">worker_fn</code> for sharing <code class="calibre26">numpy</code> arrays using <code class="calibre26">multiprocessing</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">os</code>
<code class="kn">import</code> <code class="nn">multiprocessing</code>
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">Counter</code>
<code class="kn">import</code> <code class="nn">ctypes</code>
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="kn">from</code> <code class="nn">prettytable</code> <code class="kn">import</code> <code class="n">PrettyTable</code>

<code class="n">SIZE_A</code><code class="p">,</code> <code class="n">SIZE_B</code> <code class="o">=</code> <code class="mi">10</code><code class="n">_000</code><code class="p">,</code> <code class="mi">320</code><code class="n">_000</code>  <code class="c"># 24GB</code>

<code class="kn">def</code> <code class="nf">worker_fn</code><code class="p">(</code><code class="n">idx</code><code class="p">):</code>
    <code class="sd">"""Do some work on the shared np array on row idx"""</code>
    <code class="c"># confirm that no other process has modified this value already</code>
    <code class="kn">assert</code> <code class="n">main_nparray</code><code class="p">[</code><code class="n">idx</code><code class="p">,</code> <code class="mi">0</code><code class="p">]</code> <code class="o">==</code> <code class="n">DEFAULT_VALUE</code>
    <code class="c"># inside the subprocess print the PID and ID of the array</code>
    <code class="c"># to check we don't have a copy</code>
    <code class="kn">if</code> <code class="n">idx</code> <code class="o">%</code> <code class="mi">1000</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="kn">print</code><code class="p">(</code><code class="s">" {}: with idx {}</code><code class="se">\n</code><code class="s">  id of local_nparray_in_process is {} in PID {}"</code>\
            <code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">worker_fn</code><code class="o">.</code><code class="calibre26">__name__</code><code class="p">,</code> <code class="n">idx</code><code class="p">,</code> <code class="nb">id</code><code class="p">(</code><code class="n">main_nparray</code><code class="p">),</code> <code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">()))</code>
    <code class="c"># we can do any work on the array; here we set every item in this row to</code>
    <code class="c"># have the value of the process ID for this process</code>
    <code class="n">main_nparray</code><code class="p">[</code><code class="n">idx</code><code class="p">,</code> <code class="p">:]</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">()</code></pre></div>

<p class="author1">In our <code class="calibre26">__main__</code> in <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-32</a>, we’ll work through three major stages:</p>
<ol class="calibre4">
<li class="calibre5">
<p class="calibre27">Build a shared <code class="calibre26">multiprocessing.Array</code> and convert it into a <code class="calibre26">numpy</code> array.</p>
</li>
<li class="calibre5">
<p class="calibre27">Set a default value into the array, and spawn four processes to work on the array in parallel.</p>
</li>
<li class="calibre5">
<p class="calibre27">Verify the array’s contents after the processes return.</p>
</li>

</ol>

<p class="author1">Typically, you’d set up a <code class="calibre26">numpy</code> array and work on it in a single process, probably doing something like <code class="calibre26">arr = np.array((100, 5), dtype=np.float_)</code>. This is fine in a single process, but you can’t share this data across processes for both reading and writing.</p>

<p class="author1">The trick is to make a shared block of bytes. One way is to create a <code class="calibre26">multiprocessing.Array</code>. By default the <code class="calibre26">Array</code> is wrapped in a lock to prevent concurrent edits, but we don’t need this lock as we’ll be careful about our access patterns. To communicate this clearly to other team members, it is worth being explicit and setting <code class="calibre26">lock=False</code>.</p>

<p class="author1">If you don’t set <code class="calibre26">lock=False</code>, you’ll have an object rather than a reference to the bytes, and you’ll need to call <code class="calibre26">.get_obj()</code> to get to the bytes. By calling <code class="calibre26">.get_obj()</code>, you bypass the lock, so there’s no value in not being explicit about this in the first place.</p>

<p class="author1">Next, we take this block of shareable bytes and wrap a <code class="calibre26">numpy</code> array around them using <code class="calibre26">frombuffer</code>. The <code class="calibre26">dtype</code> is optional, but since we’re passing bytes around, it is always sensible to be explicit. We <code class="calibre26">reshape</code> so we can address the bytes as a 2D array. By default the array values are set to <code class="calibre26">0</code>.  <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-32</a> shows our <code class="calibre26">__main__</code> in full.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-main1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-32. </span><code class="calibre26">__main__</code> to set up <code class="calibre26">numpy</code> arrays for sharing</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">'__main__'</code><code class="p">:</code>
    <code class="n">DEFAULT_VALUE</code> <code class="o">=</code> <code class="mi">42</code>
    <code class="n">NBR_OF_PROCESSES</code> <code class="o">=</code> <code class="mi">4</code>

    <code class="c"># create a block of bytes, reshape into a local numpy array</code>
    <code class="n">NBR_ITEMS_IN_ARRAY</code> <code class="o">=</code> <code class="n">SIZE_A</code> <code class="o">*</code> <code class="n">SIZE_B</code>
    <code class="n">shared_array_base</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Array</code><code class="p">(</code><code class="n">ctypes</code><code class="o">.</code><code class="n">c_double</code><code class="p">,</code>
                                              <code class="n">NBR_ITEMS_IN_ARRAY</code><code class="p">,</code> <code class="n">lock</code><code class="o">=</code><code class="nb">False</code><code class="p">)</code>
    <code class="n">main_nparray</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">frombuffer</code><code class="p">(</code><code class="n">shared_array_base</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">ctypes</code><code class="o">.</code><code class="n">c_double</code><code class="p">)</code>
    <code class="n">main_nparray</code> <code class="o">=</code> <code class="n">main_nparray</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">SIZE_A</code><code class="p">,</code> <code class="n">SIZE_B</code><code class="p">)</code>
    <code class="c"># assert no copy was made</code>
    <code class="kn">assert</code> <code class="n">main_nparray</code><code class="o">.</code><code class="n">base</code><code class="o">.</code><code class="n">base</code> <code class="ow">is</code> <code class="n">shared_array_base</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Created shared array with {:,} nbytes"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">main_nparray</code><code class="o">.</code><code class="n">nbytes</code><code class="p">))</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Shared array id is {} in PID {}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="nb">id</code><code class="p">(</code><code class="n">main_nparray</code><code class="p">),</code> <code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">()))</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Starting with an array of 0 values:"</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">main_nparray</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">()</code></pre></div>

<p class="author1">To confirm that our processes are operating on the same block of data that we started with, we set each item to a new <code class="calibre26">DEFAULT_VALUE</code> (we again use <code class="calibre26">42</code>, the answer to life, the universe, and everything)—you’ll see that at the top of <a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-33</a>. Next, we build a <code class="calibre26">Pool</code> of processes (four in this case) and then send batches of row indices via the call to <code class="calibre26">map</code>.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-main2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-33. </span><code class="calibre26">__main__</code> for sharing <code class="calibre26">numpy</code> arrays using <code class="calibre26">multiprocessing</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59">    <code class="c"># Modify the data via our local numpy array</code>
    <code class="n">main_nparray</code><code class="o">.</code><code class="n">fill</code><code class="p">(</code><code class="n">DEFAULT_VALUE</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Original array filled with value {}:"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">DEFAULT_VALUE</code><code class="p">))</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">main_nparray</code><code class="p">)</code>

    <code class="nb">input</code><code class="p">(</code><code class="s">"Press a key to start workers using multiprocessing..."</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">()</code>

    <code class="c"># create a pool of processes that will share the memory block</code>
    <code class="c"># of the global numpy array, share the reference to the underlying</code>
    <code class="c"># block of data so we can build a numpy array wrapper in the new processes</code>
    <code class="n">pool</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Pool</code><code class="p">(</code><code class="n">processes</code><code class="o">=</code><code class="n">NBR_OF_PROCESSES</code><code class="p">)</code>
    <code class="c"># perform a map where each row index is passed as a parameter to the</code>
    <code class="c"># worker_fn</code>
    <code class="n">pool</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">worker_fn</code><code class="p">,</code> <code class="nb">range</code><code class="p">(</code><code class="n">SIZE_A</code><code class="p">))</code></pre></div>

<p class="author1">Once we’ve completed the parallel processing, we return to the parent process to verify the result (<a data-type="xref" href="ch09_split_001.xhtml#code-sharing-numpy-array-using-multiprocessing-main3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-34</a>). The verification step runs through a flattened view on the array (note that the view does <em class="hyperlink">not</em> make a copy; it just creates a 1D iterable view on the 2D array), counting the frequency of each PID. Finally, we perform some <code class="calibre26">assert</code> checks to make sure we have the expected counts.</p>
<div id="code-sharing-numpy-array-using-multiprocessing-main3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-34. </span><code class="calibre26">__main__</code> to verify the shared result</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59">    <code class="kn">print</code><code class="p">(</code><code class="s">"Verification - extracting unique values from {:,} items</code><code class="se">\n</code><code class="s"> in the numpy </code><code class="se">\</code>
<code class="s">           array (this might be slow)..."</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">NBR_ITEMS_IN_ARRAY</code><code class="p">))</code>
    <code class="c"># main_nparray.flat iterates over the contents of the array, it doesn't</code>
    <code class="c"># make a copy</code>
    <code class="n">counter</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">(</code><code class="n">main_nparray</code><code class="o">.</code><code class="n">flat</code><code class="p">)</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Unique values in main_nparray:"</code><code class="p">)</code>
    <code class="n">tbl</code> <code class="o">=</code> <code class="n">PrettyTable</code><code class="p">([</code><code class="s">"PID"</code><code class="p">,</code> <code class="s">"Count"</code><code class="p">])</code>
    <code class="kn">for</code> <code class="n">pid</code><code class="p">,</code> <code class="n">count</code> <code class="ow">in</code> <code class="nb">list</code><code class="p">(</code><code class="n">counter</code><code class="o">.</code><code class="n">items</code><code class="p">()):</code>
        <code class="n">tbl</code><code class="o">.</code><code class="n">add_row</code><code class="p">([</code><code class="n">pid</code><code class="p">,</code> <code class="n">count</code><code class="p">])</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">tbl</code><code class="p">)</code>

    <code class="n">total_items_set_in_array</code> <code class="o">=</code> <code class="nb">sum</code><code class="p">(</code><code class="n">counter</code><code class="o">.</code><code class="n">values</code><code class="p">())</code>

    <code class="c"># check that we have set every item in the array away from DEFAULT_VALUE</code>
    <code class="kn">assert</code> <code class="n">DEFAULT_VALUE</code> <code class="ow">not</code> <code class="ow">in</code> <code class="nb">list</code><code class="p">(</code><code class="n">counter</code><code class="o">.</code><code class="n">keys</code><code class="p">())</code>
    <code class="c"># check that we have accounted for every item in the array</code>
    <code class="kn">assert</code> <code class="n">total_items_set_in_array</code> <code class="o">==</code> <code class="n">NBR_ITEMS_IN_ARRAY</code>
    <code class="c"># check that we have NBR_OF_PROCESSES of unique keys to confirm that every</code>
    <code class="c"># process did some of the work</code>
    <code class="kn">assert</code> <code class="nb">len</code><code class="p">(</code><code class="n">counter</code><code class="p">)</code> <code class="o">==</code> <code class="n">NBR_OF_PROCESSES</code>

    <code class="nb">input</code><code class="p">(</code><code class="s">"Press a key to exit..."</code><code class="p">)</code></pre></div>

<p class="author1"><a data-type="indexterm" data-primary="data" data-secondary="sharing" id="idm46122406315560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>We’ve just created a 1D array of bytes, converted it into a 2D array, shared the array among four processes, and allowed them to process concurrently on the same block of memory. This recipe will help you parallelize over many cores. Be careful with concurrent access to the <em class="hyperlink">same</em> data points, though—you’ll have to use the locks in <code class="calibre26">multiprocessing</code> if you want to avoid synchronization problems, and this will slow down your code.<a data-type="indexterm" data-primary="" data-startref="mp_nds" id="idm46122406097848" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="num_sd" id="idm46122406096904" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Synchronizing File and Variable Access" class="calibre3"><div class="preface" id="idm46122406718888">
<h1 class="calibre25">Synchronizing File and Variable Access</h1>

<p class="author1"><a data-type="indexterm" data-primary="multiprocessing" data-secondary="synchronizing file and variable access" id="mp_syn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="synchronization methods" id="syn_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In the following examples, we’ll look at multiple processes sharing and manipulating a state—in this case, four processes incrementing a shared counter a set number of times. Without a synchronization process, the counting is incorrect. If you’re sharing data in a coherent way you’ll always need a method to synchronize the reading and writing of data, or you’ll end up with errors.</p>

<p class="author1">Typically, the synchronization methods are specific to the OS you’re using, and they’re often specific to the language you use. Here, we look at file-based synchronization using a Python library and sharing an integer object between Python 
<span class="publishername">processes</span>.</p>








<section data-type="sect2" data-pdf-bookmark="File Locking" class="calibre3"><div class="preface" id="idm46122406090792">
<h2 class="calibre43">File Locking</h2>

<p class="author1"><a data-type="indexterm" data-primary="file locking" id="fl_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Reading and writing to a file will be the slowest example of data sharing in this 
<span class="publishername">section</span>.</p>

<p class="author1">You can see our first <a data-type="indexterm" data-primary="work function" id="idm46122406087240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">work</code> function in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-work" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-35</a>. The function iterates over a local counter. In each iteration it opens a file and reads the existing value, increments it by one, and then writes the new value over the old one. On the first iteration the file will be empty or won’t exist, so it will catch an exception and assume the value should be zero.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">The examples given here are simplified—in practice it is safer to use a context manager to open a file using <code class="calibre26">with open(<em class="calibre66">filename</em>, "r") as f:</code>. If an exception is raised inside the context, the file <code class="calibre26">f</code> will correctly be closed.</p>
</div>
<div id="code-08-syncronization-filelocking-nolock-1-work" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-35. </span><code class="calibre26">work</code> function without a lock</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">work</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="n">max_count</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">max_count</code><code class="p">):</code>
        <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s">"r"</code><code class="p">)</code>
        <code class="kn">try</code><code class="p">:</code>
            <code class="n">nbr</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">f</code><code class="o">.</code><code class="n">read</code><code class="p">())</code>
        <code class="kn">except</code> <code class="ne">ValueError</code> <code class="kn">as</code> <code class="n">err</code><code class="p">:</code>
            <code class="kn">print</code><code class="p">(</code><code class="s">"File is empty, starting to count from 0, error: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">err</code><code class="p">))</code>
            <code class="n">nbr</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s">"w"</code><code class="p">)</code>
        <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">nbr</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="s">'</code><code class="se">\n</code><code class="s">'</code><code class="p">)</code>
        <code class="n">f</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre></div>

<p class="author1">Let’s run this example with one process. You can see the output in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-36</a>. <code class="calibre26">work</code> is called one thousand times, and as expected it counts correctly without losing any data. On the first read, it sees an empty file. This raises the <code class="calibre26">invalid literal for int()</code> error for <code class="calibre26">int()</code> (as <code class="calibre26">int()</code> is called on an empty string). This error occurs only once; afterward, we always have a valid value to read and convert into an integer.</p>
<div data-type="example" id="code-08-syncronization-filelocking-nolock-1-console1" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-36. </span>Timing of file-based counting without a lock and with one process</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python ex1_nolock1.py</strong>
Starting 1 process(es) to count to 1000
File is empty, starting to count from 0,
error: invalid literal for int() with base 10: ''
Expecting to see a count of 1000
count.txt contains:
1000</pre>
</div>

<p class="author1">Now we’ll run the same <code class="calibre26">work</code> function with four concurrent processes.  We don’t have any locking code, so we’ll expect some odd results.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Before you look at the following code, what <em class="hyperlink">two</em> types of error can you expect to see when two processes simultaneously read from or write to the same file? Think about the two main states of the code (the start of execution for each process and the normal running state of each process).</p>
</div>

<p class="author1">Take a look at <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-console2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-37</a> to see the problems. First, when each process starts, the file is empty, so each tries to start counting from zero. Second, as one process writes, the other can read a partially written result that can’t be parsed. This causes an exception, and a zero will be written back. This, in turn, causes our counter to keep getting reset! Can you see how <code class="calibre26">\n</code> and two values have been written by two concurrent processes to the same open file, causing an invalid entry to be read by a third process?</p>
<div data-type="example" id="code-08-syncronization-filelocking-nolock-1-console2" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-37. </span>Timing of file-based counting without a lock and with four processes</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python ex1_nolock4.py</strong>
Starting 4 process(es) to count to 4000
File is empty, starting to count from 0,
error: invalid literal for int() with base 10: ''
<em class="calibre66"># many errors like these</em>
File is empty, starting to count from 0,
error: invalid literal for int() with base 10: ''
Expecting to see a count of 4000
count.txt contains:
112

$ <strong class="calibre83">python -m timeit -s "import ex1_nolock4" "ex1_nolock4.run_workers()"</strong>
2 loops, best of 5: 158 msec per loop</pre>
</div>

<p class="author1"><a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-nolock-1-main" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-38</a> shows the <code class="calibre26">multiprocessing</code> code that calls <code class="calibre26">work</code> with four processes. Note that rather than using a <code class="calibre26">map</code>, we’re building a list of <code class="calibre26">Process</code> objects. Although we don’t use the functionality here, the <code class="calibre26">Process</code> object gives us the power to introspect the state of each <code class="calibre26">Process</code>. We encourage you to <a href="https://oreil.ly/B4_G7" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">read the documentation</a> to learn about why you might want to use a <code class="calibre26">Process</code>.</p>
<div id="code-08-syncronization-filelocking-nolock-1-main" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-38. </span><code class="calibre26">run_workers</code> setting up four processes</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">multiprocessing</code>
<code class="kn">import</code> <code class="nn">os</code>

<code class="o">...</code>
<code class="n">MAX_COUNT_PER_PROCESS</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">FILENAME</code> <code class="o">=</code> <code class="s">"count.txt"</code>
<code class="o">...</code>

<code class="kn">def</code> <code class="nf">run_workers</code><code class="p">():</code>
    <code class="n">NBR_PROCESSES</code> <code class="o">=</code> <code class="mi">4</code>
    <code class="n">total_expected_count</code> <code class="o">=</code> <code class="n">NBR_PROCESSES</code> <code class="o">*</code> <code class="n">MAX_COUNT_PER_PROCESS</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"Starting {} process(es) to count to {}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">NBR_PROCESSES</code><code class="p">,</code>

														                                            <code class="n">total_expected_count</code><code class="p">))</code>
    <code class="c"># reset counter</code>
    <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="n">FILENAME</code><code class="p">,</code> <code class="s">"w"</code><code class="p">)</code>
    <code class="n">f</code><code class="o">.</code><code class="n">close</code><code class="p">()</code>

    <code class="n">processes</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="kn">for</code> <code class="n">process_nbr</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">NBR_PROCESSES</code><code class="p">):</code>
        <code class="n">p</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">work</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">FILENAME</code><code class="p">,</code>

													                                          <code class="n">MAX_COUNT_PER_PROCESS</code><code class="p">))</code>
        <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>
        <code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">p</code><code class="p">)</code>

    <code class="kn">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">:</code>
        <code class="n">p</code><code class="o">.</code><code class="n">join</code><code class="p">()</code>

    <code class="kn">print</code><code class="p">(</code><code class="s">"Expecting to see a count of {}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">total_expected_count</code><code class="p">))</code>
    <code class="kn">print</code><code class="p">(</code><code class="s">"{} contains:"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">FILENAME</code><code class="p">))</code>
    <code class="n">os</code><code class="o">.</code><code class="n">system</code><code class="p">(</code><code class="s">'more '</code> <code class="o">+</code> <code class="n">FILENAME</code><code class="p">)</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">run_workers</code><code class="p">()</code></pre></div>

<p class="author1">Using the<a data-type="indexterm" data-primary="fasteners module" id="idm46122405925400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/n8ZlV" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">fasteners</code> module</a>, we can introduce a synchronization method so only one process gets to write at a time and the others each await their turn. The overall process therefore runs more slowly, but it doesn’t make mistakes. You can see the correct output in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1-console" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-39</a>. Be aware that the locking mechanism is specific to Python, so other processes that are looking at this file will <em class="hyperlink">not</em> care about the “locked” nature of this file.</p>
<div data-type="example" id="code-08-syncronization-filelocking-lock-1-console" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-39. </span>Timing of file-based counting with a lock and four processes</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python ex1_lock.py</strong>
Starting 4 process(es) to count to 4000
File is empty, starting to count from 0,
error: invalid literal for int() with base 10: ''
Expecting to see a count of 4000
count.txt contains:
4000
$ <strong class="calibre83">python -m timeit -s "import ex1_lock" "ex1_lock.run_workers()"</strong>
10 loops, best of 3: 401 msec per loop</pre>
</div>

<p class="author1">Using <code class="calibre26">fasteners</code> adds a single line of code in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-filelocking-lock-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-40</a> with the <code class="calibre26">@fasteners.interprocess_locked</code> decorator; the filename can be anything, but using a similar name as the file you want to lock probably makes debugging from the command line easier. Note that we haven’t had to change the inner function; the decorator gets the lock on each call, and it will wait until it can get the lock before the call into <code class="calibre26">work</code> proceeds.<a data-type="indexterm" data-primary="" data-startref="fl_ab" id="idm46122405766984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
<div id="code-08-syncronization-filelocking-lock-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-40. </span><code class="calibre26">work</code> function with a lock</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="nd">@fasteners.interprocess_locked</code><code class="p">(</code><code class="s">'/tmp/tmp_lock'</code><code class="p">)</code>
<code class="kn">def</code> <code class="nf">work</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="n">max_count</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">max_count</code><code class="p">):</code>
        <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s">"r"</code><code class="p">)</code>
        <code class="kn">try</code><code class="p">:</code>
            <code class="n">nbr</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">f</code><code class="o">.</code><code class="n">read</code><code class="p">())</code>
        <code class="kn">except</code> <code class="ne">ValueError</code> <code class="kn">as</code> <code class="n">err</code><code class="p">:</code>
            <code class="kn">print</code><code class="p">(</code><code class="s">"File is empty, starting to count from 0, error: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">err</code><code class="p">))</code>
            <code class="n">nbr</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s">"w"</code><code class="p">)</code>
        <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">nbr</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="s">'</code><code class="se">\n</code><code class="s">'</code><code class="p">)</code>
        <code class="n">f</code><code class="o">.</code><code class="n">close</code><code class="p">()</code></pre></div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Locking a Value" class="calibre3"><div class="preface" id="idm46122406090136">
<h2 class="calibre43">Locking a Value</h2>

<p class="author1"><a data-type="indexterm" data-primary="data sharing" id="ds_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="locking a value" id="lv_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <code class="calibre26">multiprocessing</code> module offers several options for sharing Python objects between processes. We can share primitive objects with a low communication overhead, and we can also share higher-level Python objects (e.g., dictionaries and lists) using a <code class="calibre26">Manager</code> (but note that the synchronization cost will significantly slow down the data sharing).</p>

<p class="author1">Here, we’ll use a <a href="https://oreil.ly/nGKnY" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">multiprocessing.Value</code> object</a> to share an integer between processes. While a <code class="calibre26">Value</code> has a lock, the lock doesn’t do quite what you might expect—it prevents simultaneous reads or writes but does <em class="hyperlink">not</em> provide an atomic increment. <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1-console" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-41</a> illustrates this. You can see that we end up with an incorrect count; this is similar to the file-based unsynchronized example we looked at earlier.</p>
<div data-type="example" id="code-08-syncronization-valuelocking-nolock-1-console" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-41. </span>No locking leads to an incorrect count</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python ex2_nolock.py</strong>
Expecting to see a count of 4000
We have counted to 2340
$ <strong class="calibre83">python -m timeit -s "import ex2_nolock" "ex2_nolock.run_workers()"</strong>
20 loops, best of 5: 9.97 msec per loop</pre>
</div>

<p class="author1">No corruption occurs to the data, but we do miss some of the updates. This approach might be suitable if you’re writing to a <code class="calibre26">Value</code> from one process and consuming (but not modifying) that <code class="calibre26">Value</code> in other processes.</p>

<p class="author1">The code to share the <code class="calibre26">Value</code> is shown in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-nolock-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-42</a>. We have to specify a datatype and an initialization value—using <code class="calibre26">Value("i", 0)</code>, we request a signed integer with a default value of <code class="calibre26">0</code>. This is passed as a regular argument to our <code class="calibre26">Process</code> object, which takes care of sharing the same block of bytes between processes behind the scenes. To access the primitive object held by our <code class="calibre26">Value</code>, we use <code class="calibre26">.value</code>. Note that we’re asking for an in-place addition—we’d expect this to be an atomic operation, but that’s not supported by <code class="calibre26">Value</code>, so our final count is lower than expected.</p>
<div id="code-08-syncronization-valuelocking-nolock-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-42. </span>The counting code without a <code class="calibre26">Lock</code></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">multiprocessing</code>

<code class="kn">def</code> <code class="nf">work</code><code class="p">(</code><code class="n">value</code><code class="p">,</code> <code class="n">max_count</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">max_count</code><code class="p">):</code>
        <code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">+=</code> <code class="mi">1</code>

<code class="kn">def</code> <code class="nf">run_workers</code><code class="p">():</code>
<code class="o">...</code>
    <code class="n">value</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Value</code><code class="p">(</code><code class="s">'i'</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">process_nbr</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">NBR_PROCESSES</code><code class="p">):</code>
        <code class="n">p</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">work</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">value</code><code class="p">,</code> <code class="n">MAX_COUNT_PER_PROCESS</code><code class="p">))</code>
        <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>
        <code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">p</code><code class="p">)</code>
<code class="o">...</code></pre></div>

<p class="author1">You can see the correctly synchronized count in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-console" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-43</a> using a <code class="calibre26">multiprocessing.Lock</code>.</p>
<div data-type="example" id="code-08-syncronization-valuelocking-lock-1-console" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-43. </span>Using a <code class="calibre26">Lock</code> to synchronize writes to a <code class="calibre26">Value</code></h5>
<pre data-type="programlisting" data-code-language="python" class="calibre59"><em class="calibre66"><code class="c1"># lock on the update, but this isn't atomic</code></em><code class="calibre26">
</code><code class="err">$</code><code class="calibre26"> </code><strong class="calibre83"><code class="n1">python</code><code class="calibre33"> </code><code class="n1">ex2_lock</code><code class="o1">.</code><code class="n1">py</code></strong><code class="calibre26">
</code><code class="n">Expecting</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="n">see</code><code class="calibre26"> </code><code class="n">a</code><code class="calibre26"> </code><code class="n">count</code><code class="calibre26"> </code><code class="n">of</code><code class="calibre26"> </code><code class="mi">4000</code><code class="calibre26">
</code><code class="n">We</code><code class="calibre26"> </code><code class="n">have</code><code class="calibre26"> </code><code class="n">counted</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="mi">4000</code><code class="calibre26">
</code><code class="err">$</code><code class="calibre26"> </code><strong class="calibre83"><code class="n1">python</code><code class="calibre33"> </code><code class="o1">-</code><code class="n1">m</code><code class="calibre33"> </code><code class="n1">timeit</code><code class="calibre33"> </code><code class="o1">-</code><code class="n1">s</code><code class="calibre33"> </code><code class="s1">"</code><code class="s1">import ex2_lock</code><code class="s1">"</code><code class="calibre33"> </code><code class="s1">"</code><code class="s1">ex2_lock.run_workers()</code><code class="s1">"</code></strong><code class="calibre26">
</code><code class="mi">20</code><code class="calibre26"> </code><code class="n">loops</code><code class="p">,</code><code class="calibre26"> </code><code class="n">best</code><code class="calibre26"> </code><code class="n">of</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">19.3</code><code class="calibre26"> </code><code class="n">msec</code><code class="calibre26"> </code><code class="n">per</code><code class="calibre26"> </code><code class="n">loop</code></pre>
</div>

<p class="author1">In <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-44</a>, we’ve used a context manager (<code class="calibre26">with Lock</code>) to acquire the lock.</p>
<div id="code-08-syncronization-valuelocking-lock-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-44. </span>Acquiring a <code class="calibre26">Lock</code> using a context manager</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">multiprocessing</code>


<code class="kn">def</code> <code class="nf">work</code><code class="p">(</code><code class="n">value</code><code class="p">,</code> <code class="n">max_count</code><code class="p">,</code> <code class="n">lock</code><code class="p">):</code>
    <code class="kn">for</code> <code class="n">n</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">max_count</code><code class="p">):</code>
        <code class="kn">with</code> <code class="n">lock</code><code class="p">:</code>
            <code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">+=</code> <code class="mi">1</code>


<code class="kn">def</code> <code class="nf">run_workers</code><code class="p">():</code>
<code class="o">...</code>
    <code class="n">processes</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">lock</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Lock</code><code class="p">()</code>
    <code class="n">value</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Value</code><code class="p">(</code><code class="s">'i'</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">process_nbr</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">NBR_PROCESSES</code><code class="p">):</code>
        <code class="n">p</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">work</code><code class="p">,</code>
                                    <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">value</code><code class="p">,</code> <code class="n">MAX_COUNT_PER_PROCESS</code><code class="p">,</code> <code class="n">lock</code><code class="p">))</code>
        <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>
        <code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">p</code><code class="p">)</code>
<code class="o">...</code></pre></div>

<p class="author1">If we avoid the context manager and directly wrap our increment with <code class="calibre26">acquire</code> and <code class="calibre26">release</code>, we can go a little faster, but the code is less readable compared to using the context manager. We suggest sticking to the context manager to improve readability. The snippet in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-1-inline-lock" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-45</a> shows how to <code class="calibre26">acquire</code> and <code class="calibre26">release</code> the <code class="calibre26">Lock</code> object.</p>
<div id="code-08-syncronization-valuelocking-lock-1-inline-lock" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-45. </span>Inline locking rather than using a context manager</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">lock</code><code class="o">.</code><code class="n">acquire</code><code class="p">()</code>
<code class="n">value</code><code class="o">.</code><code class="n">value</code> <code class="o">+=</code> <code class="mi">1</code>
<code class="n">lock</code><code class="o">.</code><code class="n">release</code><code class="p">()</code></pre></div>

<p class="author1">Since a <code class="calibre26">Lock</code> doesn’t give us the level of granularity that we’re after, the basic locking that it provides wastes a bit of time unnecessarily. We can replace the <code class="calibre26">Value</code> with a <a href="https://oreil.ly/MYjtB" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">RawValue</code></a>, as in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1-console" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-46</a>, and achieve an incremental speedup. If you’re interested in seeing the bytecode behind this change, read<a data-type="indexterm" data-primary="Bendersky, Eli" id="idm46122405271432" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="http://bit.ly/shared_counter" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Eli Bendersky’s blog post</a> on the subject.</p>
<div data-type="example" id="code-08-syncronization-valuelocking-lock-rawvalue-1-console" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-46. </span>Console output showing the faster <code class="calibre26">RawValue</code> and <code class="calibre26">Lock</code> approach</h5>
<pre data-type="programlisting" data-code-language="python" class="calibre59"><em class="calibre66"><code class="c1"># RawValue has no lock on it</code></em><code class="calibre26">
</code><code class="err">$</code><code class="calibre26"> </code><strong class="calibre83"><code class="n1">python</code><code class="calibre33"> </code><code class="n1">ex2_lock_rawvalue</code><code class="o1">.</code><code class="n1">py</code></strong><code class="calibre26">
</code><code class="n">Expecting</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="n">see</code><code class="calibre26"> </code><code class="n">a</code><code class="calibre26"> </code><code class="n">count</code><code class="calibre26"> </code><code class="n">of</code><code class="calibre26"> </code><code class="mi">4000</code><code class="calibre26">
</code><code class="n">We</code><code class="calibre26"> </code><code class="n">have</code><code class="calibre26"> </code><code class="n">counted</code><code class="calibre26"> </code><code class="n">to</code><code class="calibre26"> </code><code class="mi">4000</code><code class="calibre26">
</code><code class="err">$</code><code class="calibre26"> </code><strong class="calibre83"><code class="n1">python</code><code class="calibre33"> </code><code class="o1">-</code><code class="n1">m</code><code class="calibre33"> </code><code class="n1">timeit</code><code class="calibre33"> </code><code class="o1">-</code><code class="n1">s</code><code class="calibre33"> </code><code class="s1">"</code><code class="s1">import ex2_lock_rawvalue</code><code class="s1">"</code><code class="calibre33"> </code><code class="s1">"</code><code class="s1">ex2_lock_rawvalue.run_workers()</code><code class="s1">"</code></strong><code class="calibre26">
</code><code class="mi">50</code><code class="calibre26"> </code><code class="n">loops</code><code class="p">,</code><code class="calibre26"> </code><code class="n">best</code><code class="calibre26"> </code><code class="n">of</code><code class="calibre26"> </code><code class="mi">5</code><code class="p">:</code><code class="calibre26"> </code><code class="mi">9.49</code><code class="calibre26"> </code><code class="n">msec</code><code class="calibre26"> </code><code class="n">per</code><code class="calibre26"> </code><code class="n">loop</code></pre>
</div>

<p class="author1">To use a <code class="calibre26">RawValue</code>, just swap it for a <code class="calibre26">Value</code>, as shown in <a data-type="xref" href="ch09_split_001.xhtml#code-08-syncronization-valuelocking-lock-rawvalue-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 9-47</a>.</p>
<div id="code-08-syncronization-valuelocking-lock-rawvalue-1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 9-47. </span>Example of using a &lt;code&gt;RawValue&lt;/code&gt; integer</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="o">...</code>
<code class="kn">def</code> <code class="nf">run_workers</code><code class="p">():</code>
<code class="o">...</code>
    <code class="n">lock</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Lock</code><code class="p">()</code>
    <code class="n">value</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">RawValue</code><code class="p">(</code><code class="s">'i'</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">process_nbr</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">NBR_PROCESSES</code><code class="p">):</code>
        <code class="n">p</code> <code class="o">=</code> <code class="n">multiprocessing</code><code class="o">.</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">work</code><code class="p">,</code>
                                    <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">value</code><code class="p">,</code> <code class="n">MAX_COUNT_PER_PROCESS</code><code class="p">,</code> <code class="n">lock</code><code class="p">))</code>
        <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>
        <code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">p</code><code class="p">)</code></pre></div>

<p class="author1">We could also use a <code class="calibre26">RawArray</code> in place of a <code class="calibre26">multiprocessing.Array</code> if we were sharing an array of primitive objects.</p>

<p class="author1">We’ve looked at various ways of dividing up work on a single machine between multiple processes, along with sharing a flag and synchronizing data sharing between these <span class="publishername">processes</span>. Remember, though, that sharing data can lead to headaches—try to avoid it if possible. Making a machine deal with all the edge cases of state sharing is hard; the first time you have to debug the interactions of multiple processes, you’ll realize why the accepted wisdom is to avoid this situation if possible.</p>

<p class="author1">Do consider writing code that runs a bit slower but is more likely to be understood by your team. Using an external tool like Redis to share state leads to a system that can be inspected at runtime by people <em class="hyperlink">other</em> than the developers—this is a powerful way to enable your team to keep on top of what’s happening in your parallel systems.</p>

<p class="author1">Definitely bear in mind that tweaked performant Python code is less likely to be understood by more junior members of your team—they’ll either be scared of it or break it. Avoid this problem (and accept a sacrifice in speed) to keep team velocity high.<a data-type="indexterm" data-primary="" data-startref="mp_ch" id="idm46122405046536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="mp_syn" id="idm46122405045560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="syn_abt" id="idm46122405044616" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ds_abt" id="idm46122405043672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="lv_ab" id="idm46122405042728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Wrap-Up" class="calibre3"><div class="preface" id="idm46122405726888">
<h1 class="calibre25">Wrap-Up</h1>

<p class="author1">We’ve covered a lot in this chapter. First, we looked at two embarrassingly parallel problems, one with predictable complexity and the other with nonpredictable complexity. We’ll use these examples again on multiple machines when we discuss clustering in <a data-type="xref" href="ch10.xhtml#clustering" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 10</a>.</p>

<p class="author1">Next, we looked at <code class="calibre26">Queue</code> support in <code class="calibre26">multiprocessing</code> and its overheads. In general, we recommend using an external queue library so that the state of the queue is more transparent. Preferably, you should use an easy-to-read job format so that it is easy to debug, rather than pickled data.</p>

<p class="author1">The IPC discussion should have impressed upon you how difficult it is to use IPC efficiently, and that it can make sense just to use a naive parallel solution (without IPC). Buying a faster computer with more cores might be a far more pragmatic solution than trying to use IPC to exploit an existing machine.</p>

<p class="author1">Sharing <code class="calibre26">numpy</code> matrices in parallel without making copies is important for only a small set of problems, but when it counts, it’ll really count. It takes a few extra lines of code and requires some sanity checking to make sure that you’re really not copying the data between processes.</p>

<p class="author1">Finally, we looked at using file and memory locks to avoid corrupting data—this is a source of subtle and hard-to-track errors, and this section showed you some robust and lightweight solutions.</p>

<p class="author1">In the next chapter we’ll look at clustering using Python. With a cluster, we can move beyond single-machine parallelism and utilize the CPUs on a group of machines. This introduces a new world of debugging pain—not only can your code have errors, but the other machines can also have errors (either from bad configuration or from failing hardware). We’ll show how to parallelize the pi estimation demo using the Parallel Python module and how to run research code inside IPython using an 
<span class="publishername">IPython</span> cluster.</p>
</div></section>







<div data-type="footnotes" class="calibre52"><p data-type="footnote" id="idm46122410678856" class="calibre53"><sup class="calibre54"><a href="ch09_split_000.xhtml#idm46122410678856-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> See <a href="https://oreil.ly/DdIuv" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Brett Foster’s PowerPoint presentation</a> on using the Monte Carlo method to estimate pi.</p><p data-type="footnote" id="idm46122406714360" class="calibre53"><sup class="calibre54"><a href="ch09_split_001.xhtml#idm46122406714360-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> See the <a href="http://bit.ly/Python_multiprocessing" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Stack Overflow topic</a>.</p></div></div></section></div>



  </body></html>