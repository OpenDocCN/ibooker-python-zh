- en: Chapter 10\. Reading Documents
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 读取文档
- en: 'It is tempting to think of the internet primarily as a collection of text-based
    websites interspersed with newfangled web 2.0 multimedia content that can mostly
    be ignored for the purposes of web scraping. However, this ignores what the internet
    most fundamentally is: a content-agnostic vehicle for transmitting files.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在很容易把互联网主要看作是由基于文本的网站和新型Web 2.0多媒体内容构成的集合，而这些内容大部分可以忽略不计以便进行网络抓取。然而，这忽略了互联网最根本的本质：作为传输文件的内容不可知的载体。
- en: Although the internet has been around in some form or another since the late
    1960s, HTML didn’t debut until 1992\. Until then, the internet consisted mostly
    of email and file transmission; the concept of web pages as we know them today
    didn’t exist. In other words, the internet is not a collection of HTML files.
    It is a collection of many types of documents, with HTML files often being used
    as a frame to showcase them. Without being able to read a variety of document
    types, including text, PDF, images, video, email, and more, we are missing out
    on a huge part of the available data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管互联网在上世纪60年代末已经存在，但HTML直到1992年才首次亮相。在此之前，互联网主要由电子邮件和文件传输组成；我们今天所知的网页概念并不存在。换句话说，互联网不是HTML文件的集合。它是许多类型文档的集合，其中HTML文件通常用作展示它们的框架。如果不能阅读各种类型的文档，包括文本、PDF、图像、视频、电子邮件等，我们将错过大量可用数据的一部分。
- en: This chapter covers dealing with documents, whether you’re downloading them
    to a local folder or reading them and extracting data. You’ll also take a look
    at dealing with various types of text encoding, which can make it possible to
    read even foreign-language HTML pages.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了处理文档的内容，无论是将它们下载到本地文件夹还是阅读它们并提取数据。您还将了解处理各种文本编码，这使得即使是阅读外语HTML页面也变得可能。
- en: Document Encoding
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文档编码
- en: A document’s encoding tells applications—whether they are your computer’s operating
    system or your own Python code—how to read it. This encoding can usually be deduced
    from its file extension, although this file extension is not mandated by its encoding.
    I could, for example, save *myImage.jpg* as *myImage.txt* with no problems—at
    least until my text editor tried to open it. Fortunately, this situation is rare,
    and a document’s file extension is usually all you need to know to read it correctly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的编码告诉应用程序——无论是您计算机的操作系统还是您自己的Python代码——如何读取它。这种编码通常可以从其文件扩展名中推断出来，尽管文件扩展名并不一定反映其编码。例如，我可以将*myImage.jpg*保存为*myImage.txt*而不会出现问题——至少直到我的文本编辑器试图打开它。幸运的是，这种情况很少见，通常文件扩展名就足够了解它以正确地阅读。
- en: On a fundamental level, all documents are encoded in 0s and 1s. On top of that,
    encoding algorithms define things such as “how many bits per character” or “how
    many bits represent the color for each pixel” (in the case of image files). On
    top of that, you might have a layer of compression, or some space-reducing algorithm,
    as is the case with PNG files.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上讲，所有文档都是用0和1编码的。此外，编码算法定义了诸如“每个字符多少位”或“每个像素颜色用多少位表示”（对于图像文件）之类的内容。此外，您可能还有一层压缩或某种空间减少算法，如PNG文件的情况。
- en: 'Although dealing with non-HTML files might seem intimidating at first, rest
    assured that with the right library, Python will be properly equipped to deal
    with any format of information you want to throw at it. The only difference between
    a text file, a video file, and an image file is how their 0s and 1s are interpreted.
    This chapter covers several commonly encountered types of files: text, CSV, PDFs,
    and Word documents.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一开始处理非HTML文件可能看起来令人畏惧，但请放心，通过正确的库，Python将能够适应处理任何格式的信息。文本文件、视频文件和图像文件之间唯一的区别在于它们的0和1的解释方式。本章涵盖了几种常见的文件类型：文本、CSV、PDF和Word文档。
- en: Notice that these are all, fundamentally, files that store text. For information
    about working with images, I recommend that you read through this chapter to get
    used to working with and storing different types of files, and then head to [Chapter 16](ch16.html#c-16)
    for more information on image processing!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些从根本上讲都是存储文本的文件。关于处理图像的信息，请建议您阅读本章以熟悉处理和存储不同类型文件，然后转到[第16章](ch16.html#c-16)获取更多有关图像处理的信息！
- en: Text
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本
- en: It is somewhat unusual to have files stored as plain text online, but it is
    popular among bare-bones or old-school sites to have large repositories of text
    files. For example, the Internet Engineering Task Force (IETF) stores all of its
    published documents as HTML, PDF, and text files (see [*https://www.ietf.org/rfc/rfc1149.txt*](https://www.ietf.org/rfc/rfc1149.txt) as
    an example). Most browsers will display these text files just fine, and you should
    be able to scrape them with no problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在线存储纯文本文件有些不寻常，但它在极简或老式网站中很受欢迎，用于存储大量文本文件。例如，互联网工程任务组(IETF)将其所有已发布文档存储为HTML、PDF和文本文件（参见[*https://www.ietf.org/rfc/rfc1149.txt*](https://www.ietf.org/rfc/rfc1149.txt)
    作为示例）。大多数浏览器将正常显示这些文本文件，你应该能够毫无问题地进行抓取。
- en: 'For most basic text documents, such as the practice file located at [*http://www.pythonscraping.com/pages/warandpeace/chapter1.txt*](http://www.pythonscraping.com/pages/warandpeace/chapter1.txt), you
    can use the following method:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数基本文本文档，比如位于[*http://www.pythonscraping.com/pages/warandpeace/chapter1.txt*](http://www.pythonscraping.com/pages/warandpeace/chapter1.txt)
    的练习文件，你可以使用以下方法：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Normally, when you retrieve a page using `urlopen`, you turn it into a [`BeautifulSoup`](ch04.html#c-4) object
    in order to parse the HTML. In this case, you can read the page directly. Turning
    it into a BeautifulSoup object, while perfectly possible, would be counterproductive—there’s
    no HTML to parse, so the library would be useless. Once the text file is read
    in as a string, you merely have to analyze it as you would any other string read
    into Python. The disadvantage here, of course, is that you don’t have the ability
    to use HTML tags as context clues, pointing you in the direction of the text you
    actually need, versus the text you don’t want. This can present a challenge when
    you’re trying to extract certain information from text files.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你使用`urlopen`检索页面时，你会将其转换为[`BeautifulSoup`](ch04.html#c-4)对象以解析HTML。在这种情况下，你可以直接读取页面。将其转换为BeautifulSoup对象，虽然完全可行，但却是适得其反的——没有HTML可解析，因此该库将变得无用。一旦将文本文件读取为字符串，你只需像处理其他读入Python的字符串一样分析它即可。当然，这里的缺点是你无法使用HTML标签作为上下文线索，指导你找到实际需要的文本，而非你不想要的文本。当你尝试从文本文件中提取特定信息时，这可能会带来挑战。
- en: Text Encoding and the Global Internet
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本编码与全球互联网
- en: 'Most of the time, a file extension is all you need to know how to read a file
    correctly. Strangely enough though, this rule doesn’t apply to the most basic
    of all documents: the *.txt* file.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，文件扩展名就足以告诉你如何正确读取文件。然而，最基本的所有文档——*.txt* 文件，奇怪的是，这个规则不适用。
- en: Reading in text by using the previously described methods will work just fine
    9 times out of 10\. However, dealing with text on the internet can be a tricky
    business. Next, we’ll cover the basics of English and foreign-language encoding,
    from ASCII to Unicode to ISO, and how to deal with them.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述描述的方法读取文本通常会很好地运行，成功率达到10次中的9次。然而，在处理互联网文本时可能会遇到一些棘手的问题。接下来，我们将介绍从ASCII到Unicode到ISO的英语和外语编码基础，以及如何处理它们。
- en: A history of text encoding
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本编码的历史
- en: ASCII was first developed in the 1960s, when bits were expensive and there was
    no reason to encode anything besides the Latin alphabet and a few punctuation
    characters. For this reason, only 7 bits were used to encode a total of 128 capital
    letters, lowercase letters, and punctuation. Even with all that creativity, they
    were still left with 33 non-printing characters, some of which were used, replaced,
    and/or became obsolete as technologies changed over the years. Plenty of space
    for everyone, right?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII 最早在1960年代开发，当时比特昂贵，除了拉丁字母和少数标点符号外，没有理由编码其他内容。因此，只使用7位来编码128个大写字母、小写字母和标点符号。即使有了所有这些创意，他们仍然有33个非打印字符，随着技术的变化，其中一些被使用、替换或变为过时。对每个人来说，都有足够的空间，对吧？
- en: As any programmer knows, 7 is a strange number. It’s not a nice power of 2,
    but it’s temptingly close. Computer scientists in the 1960s fought over whether
    an extra bit should be added for the convenience of having a nice round number
    versus the practicality of files requiring less storage space. In the end, 7 bits
    won. However, in modern computing, each 7-bit sequence is padded with an extra
    0 at the beginning,^([1](ch10.html#id592)) leaving us with the worst of both worlds—14%
    larger files, and the lack of flexibility of only 128 characters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正如任何程序员所知道的那样，7是一个奇怪的数字。它不是一个好看的2的幂，但它非常接近。20世纪60年代的计算机科学家们争论是否应该添加一个额外的位，以便获得一个好看的圆整数，而不是为了减少文件占用的空间。最终，7位赢得了。然而，在现代计算中，每个7位序列在开头填充了一个额外的0^([1](ch10.html#id592))，留下了我们两全其美的结果——文件增大了14%，同时只有128个字符的灵活性。
- en: In the early 1990s, people realized that more languages than just English existed,
    and that it would be really nice if computers could display them. A nonprofit
    named The Unicode Consortium attempted to bring about a universal text encoder
    by establishing encodings for every character that needs to be used in any text
    document, in any language. The goal was to include everything from the Latin alphabet
    this book is written in, to Cyrillic (кириллица), Chinese pictograms (象形), math
    and logic symbols (⨊, ≥), and even emoticons and miscellaneous symbols, such as
    the biohazard sign (☣) and peace symbol (☮).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在1990年代初期，人们意识到不仅仅是英语存在更多的语言，如果计算机能够显示它们将是非常好的。一个名为Unicode联盟的非营利组织尝试通过为每个需要在任何文本文档中使用的字符建立编码来实现一种通用的文本编码器。目标是包括从本书所写的拉丁字母到西里尔字母（кириллица）、汉字象形文字、数学和逻辑符号（⨊、≥），甚至是表情符号和其他符号，如生化危险标志（☣）和和平符号（☮）的所有内容。
- en: The resulting encoder, as you might already know, was dubbed *UTF-8*, which
    stands for, confusingly, “Universal Character Set—Transformation Format 8 bit.”
    The *8 bit* here refers not to the size of every character but to the smallest
    size that a character requires to be displayed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最终产生的编码器，你可能已经知道，被称为*UTF-8*，这个名称令人困惑地指的是“通用字符集—转换格式8位”。这里的*8位*并不是每个字符的大小，而是一个字符需要显示的最小大小。
- en: The actual size of a UTF-8 character is flexible. It can range from 1 byte to
    4 bytes, depending on where it is placed in the list of possible characters (more
    popular characters are encoded with fewer bytes; more obscure ones require more
    bytes).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: UTF-8字符的实际大小是灵活的。它可以从1字节到4字节不等，这取决于它在可能字符列表中的位置（更常见的字符用较少的字节编码；更晦涩的字符需要更多字节）。
- en: 'How is this flexible encoding achieved? The use of 7 bits with an eventual
    useless leading 0 looked like a design flaw in ASCII at first but proved to be
    a huge advantage for UTF-8. Because ASCII was so popular, Unicode decided to take
    advantage of this leading 0 bit by declaring all bytes starting with a 0 to indicate
    that only one byte is used in the character, and making the two encoding schemes
    for ASCII and UTF-8 identical. Therefore, the following characters are valid in
    both UTF-8 and ASCII:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活的编码是如何实现的？起初，使用7位和最终无用的前导0在ASCII中看起来像是一个设计缺陷，但证明对UTF-8是一个巨大的优势。因为ASCII如此流行，Unicode决定利用这个前导0位，声明所有以0开头的字节表示该字符只使用一个字节，并使ASCII和UTF-8的两种编码方案相同。因此，以下字符在UTF-8和ASCII中都是有效的：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And the following characters are valid only in UTF-8 and will be rendered as
    nonprintable if the document is interpreted as an ASCII document:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下字符仅在UTF-8中有效，如果将文档解释为ASCII文档，则将呈现为不可打印字符。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In addition to UTF-8, other UTF standards exist, such as UTF-16, UTF-24, and
    UTF-32, although documents encoded in these formats are rarely encountered except
    in unusual circumstances, which are outside the scope of this book.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了UTF-8之外，还存在其他UTF标准，如UTF-16、UTF-24和UTF-32，尽管在正常情况下很少遇到使用这些格式编码的文档，这超出了本书的范围。
- en: ​While this original “design flaw” of ASCII had a major advantage for UTF-8,
    the disadvantage has not entirely gone away. The first 8 bits of information in
    each character can still encode only 128 characters, not a full 256\. In a UTF-8
    character requiring multiple bytes, additional leading bits are spent, not on
    character encoding but on check bits used to prevent corruption. Of the 32 (8
    x 4) bits in 4-byte characters, only 21 bits are used for character encoding,
    for a total of 2,097,152 possible characters, of which, 1,114,112 are currently
    allocated.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ASCII 的这一原始“设计缺陷”对 UTF-8 有重大优势，但劣势并未完全消失。每个字符中的前 8 位信息仍然只能编码 128 个字符，而不是完整的
    256 个。在需要多个字节的 UTF-8 字符中，额外的前导位被花费在校验位上，而不是字符编码上。在 4 字节字符的 32 位中，仅使用 21 位用于字符编码，共计
    2,097,152 个可能的字符，其中目前已分配 1,114,112 个。
- en: The problem with all universal language-encoding standards, of course, is that
    any document written in a single foreign language may be much larger than it has
    to be. Although your language might consist only of 100 or so characters, you
    will need 16 bits for each character rather than just 8 bits, as is the case for
    the English-specific ASCII. This makes foreign-language text documents in UTF-8
    about twice the size of English-language text documents, at least for foreign
    languages that don’t use the Latin character set.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，所有通用语言编码标准的问题在于，任何单一外语编写的文档可能比其实际需要的要大得多。尽管您的语言可能只包含大约 100 个字符，但每个字符需要 16
    位，而不像英语专用的 ASCII 那样只需 8 位。这使得 UTF-8 中的外语文本文档大约是英语文本文档的两倍大小，至少对于不使用拉丁字符集的外语而言。
- en: ISO solves this problem by creating specific encodings for each language. Like
    Unicode, it has the same encodings that ASCII does, but it uses the padding 0
    bit at the beginning of every character to allow it to create 128 special characters
    for all languages that require them. This works best for European languages that
    also rely heavily on the Latin alphabet (which remain in positions 0–127 in the
    encoding), but require additional special characters. This allows ISO-8859-1 (designed
    for the Latin alphabet) to have symbols such as fractions (e.g., ½) or the copyright
    sign (©).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ISO 通过为每种语言创建特定编码来解决这个问题。与 Unicode 类似，它使用与 ASCII 相同的编码，但在每个字符的开头使用填充 0 位，以便为所有需要的语言创建
    128 个特殊字符。这对于欧洲语言尤其有利，这些语言也严重依赖拉丁字母表（保留在编码的位置 0-127），但需要额外的特殊字符。这使得 ISO-8859-1（为拉丁字母表设计）可以拥有分数（如½）或版权符号（©）等符号。
- en: Other ISO character sets, such as ISO-8859-9 (Turkish), ISO-8859-2 (German,
    among other languages), and ISO-8859-15 (French, among other languages) can also
    be found on the internet with some regularity.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其他 ISO 字符集，比如 ISO-8859-9（土耳其语）、ISO-8859-2（德语等多种语言）和 ISO-8859-15（法语等多种语言），在互联网上也很常见。
- en: Although the popularity of ISO-encoded documents has been declining in recent
    years, about 9% of websites on the internet are still encoded with some flavor
    of ISO,^([2](ch10.html#id598)) making it essential to know about and check for
    encodings before scraping a site.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ISO 编码文档的流行度近年来有所下降，但约有 9% 的互联网网站仍使用某种 ISO 格式^([2](ch10.html#id598))，因此在抓取网站前了解和检查编码是至关重要的。
- en: Encodings in action
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码的实际应用
- en: In the previous section, you used the default settings for `urlopen` to read
    text documents you might encounter on the internet. This works great for most
    English text. However, the second you encounter Russian, Arabic, or even a word
    like “résumé,” you might run into problems.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，您使用了 `urlopen` 的默认设置来读取可能在互联网上遇到的文本文档。这对大多数英文文本效果很好。然而，一旦遇到俄语、阿拉伯语，或者甚至像“résumé”这样的单词，可能会遇到问题。
- en: 'Take the following code, for example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，看下面的代码：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This reads in the first chapter of the original *War and Peace* (written in
    Russian and French) and prints it to the screen. This screen text reads, in part:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这读取了原版《战争与和平》的第一章（用俄语和法语写成），并将其打印到屏幕上。屏幕文本部分内容如下：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In addition, visiting this page in most browsers results in gibberish (see [Figure 10-1](#text_encoded)).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用大多数浏览器访问该页面会导致乱码（见 [Figure 10-1](#text_encoded)）。
- en: '![Alt Text](assets/wsp3_1001.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![Alt Text](assets/wsp3_1001.png)'
- en: Figure 10-1\. French and Cyrillic text encoded in ISO-8859-1, the default text
    document encoding in many browsers
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-1\. 用 ISO-8859-1 编码的法语和西里尔文本，许多浏览器中的默认文本文档编码
- en: Even for native Russian speakers, that might be a bit difficult to make sense
    of. The problem is that Python is attempting to read the document as an ASCII
    document, whereas the browser is attempting to read it as an ISO-8859-1 encoded
    document. Neither one, of course, realizes it’s a UTF-8 document.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 即使对于母语为俄语的人来说，这可能会有些难以理解。问题在于 Python 试图将文档读取为 ASCII 文档，而浏览器试图将其读取为 ISO-8859-1
    编码的文档。当然，两者都没有意识到它实际上是一个 UTF-8 文档。
- en: 'You can explicitly define the string to be UTF-8, which correctly formats the
    output into Cyrillic characters:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以显式地定义字符串为 UTF-8，这样正确地将输出格式化为西里尔字符：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using this concept with BeautifulSoup looks like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 BeautifulSoup 实现这一概念如下：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Python encodes all characters into UTF-8 by default. You might be tempted to
    leave this alone and use UTF-8 encoding for every web scraper you write. After
    all, UTF-8 will also handle ASCII characters as well as foreign languages smoothly.
    However, it’s important to remember the 9% of websites out there that use some
    version of ISO encoding as well, so you can never avoid this problem entirely.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Python 默认将所有字符编码为 UTF-8。您可能会倾向于不作更改，并为编写的每个网络抓取器使用 UTF-8 编码。毕竟，UTF-8 也能顺利处理
    ASCII 字符以及外语字符。然而，重要的是要记住，有 9% 的网站使用某种 ISO 编码版本，因此您无法完全避免这个问题。
- en: "Unfortunately, in the case of text documents, it’s impossible to concretely\
    \ determine what encoding a document has. Some libraries can examine the document\
    \ and make a best guess (using a little logic to realize that “Ñ€Ð°Ñ\x81Ñ\x81\
    ÐºÐ°Ð·Ñ” is probably not a word), but many times they’re wrong."
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: "不幸的是，在处理文本文档时，无法确定文档具体使用的编码。一些库可以检查文档并做出最佳猜测（使用一些逻辑来认识到“Ñ€Ð°Ñ\x81Ñ\x81ÐºÐ°Ð·Ñ”可能不是一个单词），但很多时候它们会出错。"
- en: 'Fortunately, in the case of HTML pages, the encoding is usually contained in
    a tag found in the `<head>` section of the site. Most sites, particularly English-language
    sites, have this tag:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在 HTML 页面的情况下，编码通常包含在网站 `<head>` 部分的标签中。大多数网站，特别是英语网站，都有这样的标签：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Whereas the [ECMA International’s website](http://www.ecma-international.org)
    has this tag:^([3](ch10.html#id602))
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 而 [ECMA International 的网站](http://www.ecma-international.org) 就有这个标签:^([3](ch10.html#id602))
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you plan on doing a lot of web scraping, particularly of international sites,
    it might be wise to look for this meta tag and use the encoding it recommends
    when reading the contents of the page.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您计划大量进行网页抓取，特别是国际网站，最好查找这个元标签，并在读取页面内容时使用它推荐的编码方式。
- en: CSV
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CSV
- en: When web scraping, you are likely to encounter either a CSV file or a coworker
    who likes data formatted in this way. Fortunately, Python has a [fantastic library](https://docs.python.org/3.4/library/csv.html)
    for both reading and writing CSV files. Although this library is capable of handling
    many variations of CSV, this section focuses primarily on the standard format.
    If you have a special case you need to handle, consult the documentation!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行网页抓取时，您可能会遇到 CSV 文件或喜欢以这种方式格式化数据的同事。幸运的是，Python 有一个 [出色的库](https://docs.python.org/3.4/library/csv.html)
    既可以读取也可以写入 CSV 文件。虽然该库能处理多种 CSV 变体，但本节主要关注标准格式。如果您有特殊情况需要处理，请参考文档！
- en: Reading CSV Files
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取 CSV 文件
- en: 'Python’s *csv* library is geared primarily toward working with local files,
    on the assumption that the CSV data you need is stored on your machine. Unfortunately,
    this isn’t always the case, especially when you’re web scraping. There are several
    ways to work around this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的 *csv* 库主要用于处理本地文件，假设需要处理的 CSV 数据存储在您的计算机上。不幸的是，情况并非总是如此，特别是在进行网页抓取时。有几种方法可以解决这个问题：
- en: Download the file locally by hand and point Python at the local file location.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动下载文件并将 Python 指向本地文件位置。
- en: Write a Python script to download the file, read it, and (optionally) delete
    it after retrieval.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个 Python 脚本来下载文件，读取文件，并在检索后（可选）删除文件。
- en: Retrieve the file as a string from the web, and wrap the string in a `StringIO`
    object so that it behaves like a file.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从网页中检索文件字符串，并将字符串包装在 `StringIO` 对象中，以便其像文件一样运行。
- en: 'Although the first two options are workable, taking up hard drive space with
    files when you could easily keep them in memory is bad practice. It’s much better
    to read the file in as a string and wrap it in an object that allows Python to
    treat it as a file, without ever saving the file. The following script retrieves
    a CSV file from the internet (in this case, a list of Monty Python albums at [*http://pythonscraping.com/files/MontyPythonAlbums.csv*](http://pythonscraping.com/files/MontyPythonAlbums.csv))
    and prints it, row by row, to the terminal:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前两种选项可行，但将文件保存在硬盘上会占用空间，而你完全可以将它们保存在内存中，这是不良实践。最好的做法是将文件作为字符串读入，并将其包装在一个对象中，使Python能够将其视为文件，而无需保存文件。以下脚本从互联网获取CSV文件（在本例中，是[*http://pythonscraping.com/files/MontyPythonAlbums.csv*](http://pythonscraping.com/files/MontyPythonAlbums.csv)上的Monty
    Python专辑列表），并逐行将其打印到终端：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output looks like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来像这样：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As you can see from the code sample, the reader object returned by `csv.reader`
    is iterable and composed of Python list objects. Because of this, each row in
    the `csvReader` object is accessible in the following way:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从代码示例中看到的那样，`csv.reader`返回的读取器对象是可迭代的，并由Python列表对象组成。因此，`csvReader`对象中的每一行都可以通过以下方式访问：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is the output:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Notice the first line: `The album "Name" was released in Year`. Although this
    might be an easy-to-ignore result when writing example code, you don’t want this
    getting into your data in the real world. A lesser programmer might simply skip
    the first row in the `csvReader` object, or write in a special case to handle
    it. Fortunately, an alternative to the `csv.reader` function takes care of all
    of this for you automatically. Enter `DictReader`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意第一行：`The album "Name" was released in Year`。尽管这可能是编写示例代码时容易忽略的结果，但在现实世界中，你不希望这些内容出现在你的数据中。一个不那么熟练的程序员可能只是跳过`csvReader`对象中的第一行，或者编写一个特殊情况来处理它。幸运的是，`csv.reader`函数的替代方案会自动处理所有这些。进入`DictReader`：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`csv.DictReader` returns the values of each row in the CSV file as dictionary
    objects rather than list objects, with field names stored in the variable `dictReader.fieldnames`
    and as keys in each dictionary object:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`csv.DictReader`将CSV文件中每一行的值作为字典对象返回，而不是列表对象，字段名称存储在变量`dictReader.fieldnames`中，并作为每个字典对象的键：'
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The downside, of course, is that it takes slightly longer to create, process,
    and print these `DictReader` objects as opposed to `csvReader`, but the convenience
    and usability are often worth the additional overhead. Also keep in mind that,
    when it comes to web scraping, the overhead required for requesting and retrieving
    website data from an external server will almost always be the unavoidable limiting
    factor in any program you write, so worrying about which technique might shave
    microseconds off your total runtime is often a moot point!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，与`csvReader`相比，创建、处理和打印这些`DictReader`对象需要稍长时间，但其便利性和可用性往往超过了额外的开销。此外，请记住，在进行网页抓取时，从外部服务器请求和检索网站数据所需的开销几乎总是任何你编写的程序中不可避免的限制因素，因此担心哪种技术可以减少总运行时间的微秒级别问题通常是没有意义的！
- en: PDF
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PDF
- en: As a Linux user, I know the pain of being sent a *.docx* file that my non-Microsoft
    software mangles, and struggling trying to find the codecs to interpret some new
    Apple media format. In some ways, Adobe was revolutionary in creating its Portable
    Document Format in 1993\. PDFs allowed users on different platforms to view image
    and text documents in exactly the same way, regardless of the platform they were
    viewing it on.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Linux用户，我深知收到一个*.docx*文件，而我的非微软软件将其搞乱的痛苦，还有努力寻找解析某些新的Apple媒体格式的解码器。在某些方面，Adobe在1993年创建其便携式文档格式（PDF）方面具有革命性。PDF允许不同平台的用户以完全相同的方式查看图像和文本文档，而不受查看平台的影响。
- en: Although storing PDFs on the web is somewhat passé (why store content in a static,
    slow-loading format when you could write it up as HTML?), PDFs remain ubiquitous,
    particularly when dealing with official forms and filings.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管将PDF存储在网络上有点过时（为什么要将内容存储在静态、加载缓慢的格式中，而不是编写HTML呢？），但PDF仍然是无处不在的，特别是在处理官方表格和文件时。
- en: In 2009, a Briton named Nick Innes made the news when he requested public student
    test result information from the Buckinghamshire City Council, which was available
    under the United Kingdom’s version of the Freedom of Information Act. After some
    repeated requests and denials, he finally received the information he was looking
    for—in the form of 184 PDF documents.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 2009 年，英国人尼克·因斯（Nick Innes）因向巴克莱市议会根据英国版《信息自由法》请求公开学生测试结果信息而成为新闻人物。经过一些重复请求和拒绝后，他最终以
    184 份 PDF 文档的形式收到了他寻找的信息。
- en: Although Innes persisted and eventually received a more properly formatted database,
    had he been an expert web scraper, he likely could have saved himself a lot of
    time in the courts and used the PDF documents directly, with one of Python’s many
    PDF-parsing modules.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Innes 坚持不懈，并最终获得了一个更合适格式的数据库，但如果他是一个专业的网络爬虫，他很可能本可以节省很多时间，并直接使用 Python 的许多
    PDF 解析模块处理 PDF 文档。
- en: Unfortunately, because the PDF is a relatively simple and open source document
    format, the space is crowded when it comes to PDF-parsing libraries. These projects
    are commonly built, abandoned, revived, and built again as the years go by. The
    most popular, full-featured, and easy-to-use library is currently [pypdf](https://pypi.org/project/pypdf/).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于 PDF 是一个相对简单和开放源码的文档格式，在 PDF 解析库方面竞争激烈。这些项目通常会在多年间建立、弃用、重建。目前最受欢迎、功能齐全且易于使用的库是
    [pypdf](https://pypi.org/project/pypdf/)。
- en: Pypdf is a free, open source library that allows users to extract text and images
    from PDFs. It will also allow you to perform operations on PDF files and generate
    them directly from Python if you want to make them rather than just read them.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Pypdf 是一个免费的开源库，允许用户从 PDF 中提取文本和图像。它还允许您对 PDF 文件执行操作，并且如果您想生成 PDF 文件而不仅仅是阅读它们，也可以直接从
    Python 进行操作。
- en: 'You can install as usual using pip:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像往常一样使用 pip 进行安装：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The documentation is located at [*https://pypdf.readthedocs.io/en/latest/index.html*](https://pypdf.readthedocs.io/en/latest/index.html).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 文档位于 [*https://pypdf.readthedocs.io/en/latest/index.html*](https://pypdf.readthedocs.io/en/latest/index.html)。
- en: 'Here is a basic implementation that allows you to read arbitrary PDFs to a
    string, given a local file object:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个基本的实现，允许您从本地文件对象中读取任意 PDF 到字符串：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This gives the familiar plain-text output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了熟悉的纯文本输出：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that the PDF file argument must be an actual file object. You must download
    the file first locally before you can pass it to the `Pdfreader` class. However,
    if you’re processing large numbers of PDF files and don’t want to keep the original
    files around, you can always overwrite the previous file by sending the same filename
    to `urlretrieve` after you’ve extracted the text.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，PDF 文件参数必须是一个实际的文件对象。在将其传递给 `Pdfreader` 类之前，您必须先将文件下载到本地。然而，如果您处理大量的 PDF
    文件，并且不希望保留原始文件，您可以在从文本中提取后，通过再次将相同文件名传递给 `urlretrieve` 来覆盖先前的文件。
- en: The output from pypdf might not be perfect, especially for PDFs with images,
    oddly formatted text, or text arranged in tables or charts. However, for most
    text-only PDFs, the output should be no different than if the PDF were a text
    file.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Pypdf 的输出可能不完美，特别是对于带有图像、奇怪格式文本或以表格或图表形式排列的 PDF。然而，对于大多数仅包含文本的 PDF，输出应与将 PDF
    视为文本文件时的输出没有区别。
- en: Microsoft Word and .docx
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Microsoft Word 和 .docx
- en: 'At the risk of offending my friends at Microsoft: I do not like Microsoft Word.
    Not because it’s necessarily a bad piece of software, but because of the way its
    users misuse it. It has a particular talent for turning what should be simple
    text documents or PDFs into large, slow, difficult-to-open beasts that often lose
    all formatting from machine to machine, and are, for whatever reason, editable
    when the content is often meant to be static.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 冒犯微软朋友的风险在此：我不喜欢 Microsoft Word。并不是因为它本质上是个糟糕的软件，而是因为它的用户如何误用它。它有一种特殊的才能，可以将本应是简单文本文档或
    PDF 的内容转变为体积庞大、打开缓慢、易于在机器之间丢失所有格式的东西，并且由于某种原因，在内容通常意味着静态的情况下却是可编辑的。
- en: Word files are designed for content creation, not content sharing. Nevertheless,
    they are ubiquitous on certain sites, containing important documents, information,
    and even charts and multimedia; in short, everything that can and should be created
    with HTML.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Word 文件是为内容创建而设计，而不是为内容共享。尽管如此，在某些网站上它们无处不在，包含重要文件、信息，甚至图表和多媒体；总之，所有可以和应该使用
    HTML 创建的内容。
- en: Before about 2008, Microsoft Office products used the proprietary *.doc *file
    format. This binary-file format was difficult to read and poorly supported by
    other word processors. In an effort to get with the times and adopt a standard
    that was used by many other pieces of software, Microsoft decided to use the Open
    Office XML-based standard, which made the files compatible with open source and
    other software.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在约 2008 年之前，Microsoft Office 产品使用专有的 *.doc* 文件格式。这种二进制文件格式难以阅读，而且其他文字处理软件的支持很差。为了跟上时代并采用许多其他软件使用的标准，Microsoft
    决定使用基于 Open Office XML 的标准，使得这些文件与开源及其他软件兼容。
- en: Unfortunately, Python’s support for this file format, used by Google Docs, Open
    Office, and Microsoft Office, still isn’t great. There is the [python-docx library](http://python-docx.readthedocs.org/en/latest/),
    but this only gives users the ability to create documents and read only basic
    file data such as the size and title of the file, not the actual contents. To
    read the contents of a Microsoft Office file, you’ll need to roll your own solution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Python 对于由 Google Docs、Open Office 和 Microsoft Office 使用的此文件格式的支持仍然不够完善。有
    [python-docx 库](http://python-docx.readthedocs.org/en/latest/)，但它只能让用户创建文档并仅读取基本的文件数据，如文件的大小和标题，而不是实际的内容。要读取
    Microsoft Office 文件的内容，您需要自己解决方案。
- en: 'The first step is to read the XML from the file:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从文件中读取 XML：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This reads a remote Word document as a binary file object (`BytesIO` is analogous
    to `StringIO`, used earlier in this chapter), unzips it using Python’s core zipfile
    library (all *.docx* files are zipped to save space), and then reads the unzipped
    file, which is XML.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将一个远程 Word 文档作为二进制文件对象读取（`BytesIO` 类似于本章前面使用的 `StringIO`），使用 Python 的核心
    zipfile 库解压缩它（所有的 *.docx* 文件都被压缩以节省空间），然后读取解压后的 XML 文件。
- en: The Word document at [*http://pythonscraping.com/pages/AWordDocument.docx*](http://pythonscraping.com/pages/AWordDocument.docx) is
    shown in [Figure 10-2](#word_website).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[*http://pythonscraping.com/pages/AWordDocument.docx*](http://pythonscraping.com/pages/AWordDocument.docx)
    上展示了 [图 10-2](#word_website) 中的 Word 文档。'
- en: '![](assets/wsp3_1002.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_1002.png)'
- en: Figure 10-2\. This is a Word document that’s full of content you might want
    very much, but it’s difficult to access because I’m putting it on my website as
    a *.docx* file instead of publishing it as HTML. The word “unfortunatly” is misspelled.
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2。这是一个 Word 文档，里面可能包含您非常想要的内容，但由于我将其作为 *.docx* 文件放在网站上而不是发布为 HTML，所以访问起来很困难。单词“unfortunatly”拼写错误。
- en: 'The output of the Python script reading my simple Word document is the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Python 脚本读取我简单 Word 文档的输出如下所示：
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'There’s clearly a lot of metadata here, but the actual text content you want
    is buried. Fortunately, all of the text in the document, including the title at
    the top, is contained in `w:t` tags, which makes it easy to grab:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显然有大量的元数据，但实际上您想要的文本内容被埋藏起来了。幸运的是，文档中的所有文本，包括顶部的标题，都包含在 `w:t` 标签中，这使得抓取变得很容易：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note that instead of the *html.parser* parser that you normally use with `BeautifulSoup`,
    you’re passing it the *xml* parser. This is because colons are nonstandard in
    HTML tag names like `w:t`, and *html.parser* does not recognize them.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与通常在 `BeautifulSoup` 中使用的 *html.parser* 解析器不同，您需要将 *xml* 解析器传递给它。这是因为在像 `w:t`
    这样的 HTML 标签名中，冒号是非标准的，而 *html.parser* 无法识别它们。
- en: 'The output isn’t perfect but it’s getting there, and printing each `w:t` tag
    on a new line makes it easy to see how Word is splitting up the text:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出还不完美，但已经接近了，并且打印每个 `w:t` 标签到新行使得很容易看出 Word 如何分割文本：
- en: '[PRE21]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice that the word “unfortunatly” is split up across multiple lines. In the
    original XML, it is surrounded with the tag `<w:proofErr w:type="spellStart"/>`.
    This is how Word highlights the misspelling with a red squiggly underline.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，单词“unfortunatly”被分割成多行。在原始的 XML 中，它被标签 `<w:proofErr w:type="spellStart"/>`
    包围。这是 Word 用红色波浪线突出显示拼写错误的方式。
- en: 'The title of the document is preceded by the style descriptor tag `<w:pstyle
    w:val="Title">`. Although this doesn’t make it extremely easy for us to identify
    titles (or other styled text) as such, using BeautifulSoup’s navigation features
    can be useful:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 文档标题之前有样式描述符标签 `<w:pstyle w:val="Title">`。虽然这并没有使我们非常容易识别标题（或其他样式化的文本），但使用 BeautifulSoup
    的导航功能可能会有所帮助：
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This function easily can be expanded to print tags around a variety of text
    styles or label them in some other way.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以很容易扩展以在各种文本样式周围打印标签或以其他方式标记它们。
- en: ^([1](ch10.html#id592-marker)) This “padding” bit will come back to haunt us
    with the ISO standards a little later.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.html#id592-marker)) 这个“填充”位稍后会在 ISO 标准中困扰我们。
- en: ^([2](ch10.html#id598-marker)) According to [W3Techs](https://w3techs.com/technologies/history_overview/character_encoding),
    which uses web crawlers to gather these sorts of statistics.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.html#id598-marker)) 根据[W3Techs](https://w3techs.com/technologies/history_overview/character_encoding)提供的数据，该网站使用网络爬虫收集这些统计数据。
- en: ^([3](ch10.html#id602-marker)) ECMA was one of the original contributors to
    the ISO standard, so it’s no surprise its website is encoded with a flavor of
    ISO.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.html#id602-marker)) ECMA 是 ISO 标准的原始贡献者之一，所以其网站采用了一种 ISO 的编码方式并不令人意外。
