- en: Chapter 10\. Infrastructure as Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we had fancy DevOps titles and job descriptions, we were lowly system
    administrators, or sysadmins for short. Those were the dark, pre-cloud days when
    we had to load the trunks of our cars with bare-metal servers and drive to a colocation
    (colo) facility to rack the servers, wire them, attach a wheeled monitor/keyboard/mouse
    to them, and set them up one by one. Grig still shudders to think about the hours
    he spent in colos, in blinding light and freezing A/C. We had to be wizards at
    Bash scripting, then we graduated to Perl, and the more fortunate of us to Python.
    As the saying went, the internet circa 2004 was held together with duct tape and
    bubble gum.
  prefs: []
  type: TYPE_NORMAL
- en: Somewhere during the period of 2006 to 2007, we discovered the magical world
    of Amazon EC2 instances. We were able to provision servers through a simple point-and-click
    interface, or through command-line tools. No more driving to colocation facilities,
    no more stacking and wiring bare-metal servers. We could go wild and launch 10
    EC2 instances at a time. Or even 20! Or even 100! The sky was the limit. However,
    we quickly figured out that manually connecting to each EC2 instance using SSH
    and then setting up our applications on every instance separately was not going
    to scale. It was fairly easy to provision the instances themselves. What was difficult
    was to install the required packages for our applications, add the correct users,
    make sure the file permissions looked right, and finally install and configure
    our applications. To scratch this itch, the first generation of infrastructure
    automation software came into being, represented by “configuration management”
    tools. Puppet was the first well-known configuration management tool, released
    in 2005 and predated the release of Amazon EC2\. Other such tools that were launched
    on the heels of Puppet were Chef in 2008, followed by SaltStack in 2011, and Ansible
    in 2012.
  prefs: []
  type: TYPE_NORMAL
- en: 'By 2009, the world was ready to welcome the arrival of a new term: DevOps.
    To this day, there are competing definitions of DevOps. What is interesting is
    that it came into being in the tumultuous early days of infrastructure software
    automation. While there are important people and culture aspects to DevOps, one
    thing stands out in this chapter: the ability to automate the provisioning, configuration,
    and deployment of infrastructure and applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By 2011, it was getting hard to keep track of all the services comprising the
    Amazon Web Services (AWS) suite. The cloud was much more complicated than raw
    compute power (Amazon EC2) and object storage (Amazon S3). Applications started
    to rely on multiple services interacting with each other, and tools were needed
    to help automate the provisioning of these services. Amazon didn’t wait long to
    fill this need, and in 2011 it started offering just such a tool: AWS CloudFormation.
    This was one of the first moments when we could truly say that we were able to
    describe our infrastructure through code. CloudFormation opened the doors to a
    new generation of Infrastructure as Code (IaC) tools, which were operating at
    the layer of the cloud infrastructure itself, underneath the layer served by the
    first-generation configuration management tools.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By 2014, AWS had launched dozens of services. That was the year when another
    important tool in the world of IaC came into being: Terraform, by HashiCorp. To
    this day, the two most used IaC tools are CloudFormation and Terraform.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important development in the world of IaC and DevOps was taking place
    sometime between late 2013 and early 2014: the release of Docker, which came to
    be synonymous with container technologies. Although containers had been around
    for a number of years, the great benefit that Docker brought to the table was
    that it wrapped technologies such as Linux containers and cgroups into an easy-to-use
    API and command-line interface (CLI) toolset that significantly lowered the barrier
    of entry for people who wanted to package their applications into containers that
    could be deployed and run wherever Docker was running. Container technologies
    and container orchestration platforms are discussed in detail in Chapters [11](ch11.html#containers-docker)
    and [12](ch12.html#containers-kubernetes).'
  prefs: []
  type: TYPE_NORMAL
- en: The usage and mindshare of Docker exploded and damaged the popularity of the
    first-generation configuration management tools (Puppet, Chef, Ansible, SaltStack).
    The companies behind these tools are reeling at the moment and are all trying
    to stay afloat and current by reinventing themselves as cloud friendly. Before
    the advent of Docker, you would provision the infrastructure for your application
    with an IaC tool such as CloudFormation or Terraform, then deploy the application
    itself (code and configuration) with a configuration management tool such as Puppet,
    Chef, Ansible, or SaltStack. Docker suddenly made these configuration management
    tools obsolete, since it provided a means for you to package your application
    (code + configuration) in a Docker container that would then run inside the infrastructure
    provisioned by the IaC tools.
  prefs: []
  type: TYPE_NORMAL
- en: A Classification of Infrastructure Automation Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fast-forward to 2020 and it is easy to feel lost as a DevOps practitioner when
    faced with the multitude of infrastructure automation tools available.
  prefs: []
  type: TYPE_NORMAL
- en: One way to differentiate IaC tools is by looking at the layer at which they
    operate. Tools such as CloudFormation and Terraform operate at the cloud infrastructure
    layer. They allow you to provision cloud resources such as compute, storage, and
    networking, as well as various services such as databases, message queues, data
    analytics, and many others. Configuration management tools such as Puppet, Chef,
    Ansible, and SaltStack typically operate at the application layer, making sure
    that all the required packages are installed for your application, and that the
    application itself is configured correctly (although many of these tools also
    have modules that can provision cloud resources). Docker also operates at the
    application layer.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to compare IaC tools is by dividing them into declarative versus
    imperative categories. You can tell an automation tool what to do in a declarative
    manner where you describe the state of the system that you are trying to achieve.
    Puppet, CloudFormation, and Terraform operate in a declarative manner. Alternatively,
    you can use an automation tool in a procedural or imperative manner, where you
    specify the exact steps needed by the tool to achieve the desired system state.
    Chef and Ansible operate in an imperative manner. SaltStack can operate in both
    declarative and imperative manners.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the desired state of the system as a blueprint for the construction
    of a building, let’s say a stadium. You use procedural tools like Chef and Ansible
    to build the stadium, section by section and row by row inside each section. You
    need to keep track of the state of the stadium and the progress of the construction.
    Using declarative tools such as Puppet, CloudFormation, and Terraform, you first
    put together the blueprint for the stadium. The tool then makes sure that the
    construction achieves the state depicted in the blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: Given this chapter’s title, we will focus the remaining discussion on IaC tools,
    which can be further classified along several dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: One dimension is the way you specify the desired state of the system. In CloudFormation,
    you do it with JSON or YAML syntax, while in Terraform you do it with the proprietary
    HashiCorp Configuration Language (HCL) syntax. In contrast, Pulumi and the AWS
    Cloud Development Kit (CDK) allow you to use real programming languages, including
    Python, for specifying the desired state of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Another dimension is the cloud providers supported by each tool. Since CloudFormation
    is an Amazon service, it stands to reason that it focuses on AWS (although one
    can define non-AWS resources with CloudFormation when using the custom resources
    feature). The same is true for the AWS CDK. In contrast, Terraform supports many
    cloud providers, as does Pulumi.
  prefs: []
  type: TYPE_NORMAL
- en: Because this is a book about Python, we would like to mention a tool called
    [troposphere](https://oreil.ly/Zdid-), which allows you to specify CloudFormation
    stack templates using Python code, and then exports them to JSON or YAML. Troposphere
    stops at the generation of the stack templates, which means that you need to provision
    the stacks using CloudFormation. One other tool that also uses Python and is worth
    mentioning is [stacker](https://oreil.ly/gBF_N). It uses troposphere under the
    covers, but it also provisions the generated CloudFormation stack templates.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this chapter shows two of these automation tools, Terraform and
    Pulumi, in action, each working on a common scenario, which is the deployment
    of a static website in Amazon S3, which is fronted by the Amazon CloudFront CDN
    and secured by an SSL certificate provisioned via the AWS Certificate Manager
    (ACM) service.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Some of the commands used in the following examples produce large amounts of
    output. Except for cases where it is critical to the understanding of the command,
    we will omit the majority of the output lines to save trees and enable you to
    focus better on the text.
  prefs: []
  type: TYPE_NORMAL
- en: Manual Provisioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started by working through the scenario manually, using the AWS web-based
    console. Nothing like experiencing the pain of doing things manually so that you
    can better enjoy the results of automating tedious work!
  prefs: []
  type: TYPE_NORMAL
- en: We first followed the documentation from AWS [website for hosting in S3](https://oreil.ly/kdv8T).
  prefs: []
  type: TYPE_NORMAL
- en: 'We already had a domain name bought via Namecheap: devops4all.dev. We created
    a hosted zone in Amazon Route 53 for the domain, and pointed the name servers
    for this domain in Namecheap to AWS DNS servers handling the hosted domain.'
  prefs: []
  type: TYPE_NORMAL
- en: We provisioned two S3 buckets, one for the root URL of the site (devops4all.dev)
    and one for the www URL (www.devops4all.dev). The idea was to redirect requests
    to www to the root URL. We also went through the guide and configured the buckets
    for static site hosting, with the proper permissions. We uploaded an *index.html*
    file and a JPG image to the root S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: The next step was to provision an SSL certificate to handle both the root domain
    name (devops4all.dev) and any subdomain of that domain (*.devops4all.dev). For
    verification, we used DNS records that we added to the Route 53 hosted zone.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The ACM certificate needs to be provisioned in the us-east-1 AWS region so that
    it can be used in CloudFront.
  prefs: []
  type: TYPE_NORMAL
- en: We then created an AWS CloudFront CDN distribution pointing to the root S3 bucket
    and used the ACM certificate provisioned in the previous step. We specified that
    HTTP requests should be redirected to HTTPS. Once the distribution was deployed
    (which took approximately 15 minutes), we added Route 53 records for the root
    domain and the www domain as A records of type Alias pointing to the CloudFront
    distribution endpoint DNS name.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this exercise, we were able to go to *http://devops4all.dev*,
    be redirected automatically to *https://devops4all.dev*, and see the home page
    of the site showing the image we uploaded. We also tried going to *http://www.devops4all.dev*
    and were redirected to *https://devops4all.dev*.
  prefs: []
  type: TYPE_NORMAL
- en: The manual creation of all the AWS resources we mentioned took approximately
    30 minutes. We also spent 15 minutes waiting for the CloudFront distribution propagation,
    for a total of 45 minutes. Note that we had done all this before, so we knew exactly
    what to do, with only minimal reference to the AWS guide.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It is worth taking a moment to appreciate how easy it is these days to provision
    a free SSL certificate. Gone are the days when you had to wait hours or even days
    for the SSL certificate provider to approve your request, only after you submitted
    proof that your company existed. Between AWS ACM, and Let’s Encrypt, there is
    no excuse not to have SSL enabled on all pages of your site in 2020.
  prefs: []
  type: TYPE_NORMAL
- en: Automated Infrastructure Provisioning with Terraform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We decided to use Terraform as the first IaC tool for the automation of these
    tasks, even though Terraform is not directly related to Python. It has several
    advantages, such as maturity, strong ecosystem, and multicloud provisioners.
  prefs: []
  type: TYPE_NORMAL
- en: The recommended way of writing Terraform code is to use modules, which are reusable
    components of Terraform configuration code. There is a common [registry](https://registry.terraform.io)
    of Terraform modules hosted by HashiCorp where you can search for ready-made modules
    that you might use for provisioning the resources you need. In this example, we
    will write our own modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'The version of Terraform used here is 0.12.1, which is the latest version at
    the time of this writing. Install it on a Mac by using `brew`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Provisioning an S3 Bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create a *modules* directory and underneath it an *s3* directory containing
    three files: *main.tf*, *variables.tf*, and *outputs.tf*. The *main.tf* file in
    the *s3* directory tells Terraform to create an S3 bucket with a specific policy.
    It uses a variable called `domain_name` that is declared in *variables.tf* and
    whose value is passed to it by the caller of this module. It outputs the DNS endpoint
    of the S3 bucket, which will be used by other modules as an input variable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the three files in *modules/s3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `policy` attribute of the `aws_s3_bucket` resource above is an example of
    an S3 bucket policy that allows public access to the bucket. If you work with
    S3 buckets in an IaC context, it pays to familiarize yourself with the [official
    AWS documentation on bucket and user policies](https://oreil.ly/QtTYd).
  prefs: []
  type: TYPE_NORMAL
- en: 'The main Terraform script which ties together all the modules is a file called
    *main.tf* in the current directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It refers to variables that are defined in a separate file called *variables.tf*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the current directory tree at this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first step in running Terraform is to invoke the `terraform init` command,
    which will read the contents of any module referenced by the main file.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to run the `terraform plan` command, which creates the blueprint
    mentioned in the earlier discussion.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the resources specified in the plan, run `terraform apply`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: At this point, check that the S3 bucket was created using the AWS web console
    UI.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning an SSL Certificate with AWS ACM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next module is created for the provisioning of an SSL certificate using
    the AWS Certificate Manager service. Create a directory called *modules/acm* with
    three files: *main.tf*, *variables.tf*, and *outputs.tf*. The *main.tf* file in
    the *acm* directory tells Terraform to create an ACM SSL certificate using DNS
    as the validation method. It uses a variable called `domain_name` which is declared
    in *variables.tf* and whose value is passed to it by the caller of this module.
    It outputs the ARN identifier of the certificate, which will be used by other
    modules as an input variable.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a reference to the new `acm` module in the main Terraform file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The next three steps are the same as in the S3 bucket creation sequence: `terraform
    init`, `terraform plan`, and `terraform apply`.'
  prefs: []
  type: TYPE_NORMAL
- en: Use the AWS console to add the necessary Route 53 records for the validation
    process. The certificate is normally validated and issued in a few minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning an Amazon CloudFront Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next module is created for the provisioning of an Amazon CloudFront distribution.
    Create a directory called *modules/cloudfront* with three files: *main.tf*, *variables.tf*,
    and *outputs.tf*. The *main.tf* file in the *cloudfront* directory tells Terraform
    to create a CloudFront distribution resource. It uses several variables that are
    declared in *variables.tf* and whose values are passed to it by the caller of
    this module. It outputs the DNS domain name for the CloudFront endpoint and the
    hosted Route 53 zone ID for the CloudFront distribution, which will be used by
    other modules as input variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Add a reference to the `cloudfront` module in the main Terraform file. Pass
    `s3_www_website_endpoint` and `acm_certificate_arn` as input variables to the
    `cloudfront` module. Their values are retrieved from the outputs of the other
    modules, `s3` and `acm`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: ARN stands for Amazon Resource Name. It is a string that uniquely identifies
    a given AWS resource. You will see many ARN values generated and passed around
    as variables when you use IaC tools that operate within AWS.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The next three steps are the usual ones for the provisioning of resources with
    Terraform: `terraform init`, `terraform plan`, and `terraform` `apply`.'
  prefs: []
  type: TYPE_NORMAL
- en: The `terraform apply` step took almost 23 minutes in this case. Provisioning
    an Amazon CloudFront distribution is one of the lengthiest operations in AWS,
    because the distribution is being deployed globally by Amazon behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning a Route 53 DNS Record
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next module was for the creation of a Route 53 DNS record for the main
    domain of the site www.devops4all.dev. Create a directory called *modules/route53*
    with two files: *main.tf* and *variables.tf*. The *main.tf* file in the *route53*
    directory tells Terraform to create a Route 53 DNS record of type `A` as an alias
    to the DNS name of the CloudFront endpoint. It uses several variables that are
    declared in *variables.tf* and whose values are passed to it by the caller of
    this module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a reference to the `route53` module in the *main.tf* Terraform file. Pass
    `zone_id`, `cloudfront_domain_name`, and `cloudfront_zone_id` as input variables
    to the `route53` module. The value of `zone_id` is declared in *variables.tf*
    in the current directory, while the other values are retrieved from the outputs
    of the `cloudfront` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The next three steps, which should be very familiar to you by now, are for
    the provisioning of resources with Terraform: `terraform init`, `terraform plan`,
    and `terraform apply`.'
  prefs: []
  type: TYPE_NORMAL
- en: Copying Static Files to S3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To test the provisioning of the static website from end to end, create a simple
    file called *index.html* that includes a JPEG image, and copy both files to the
    S3 bucket previously provisioned with Terraform. Make sure that the `AWS_PROFILE`
    environment variable is set to a correct value already present in the *~/.aws/credentials*
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Visit [*https://www.devops4all.dev/*](https://www.devops4all.dev/) and verify
    that you can see the JPG image that was uploaded.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting All AWS Resources Provisioned with Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whenever you provision cloud resources, you need to be mindful of the cost associated
    with them. It is very easy to forget about them, and you may be surprised by the
    AWS bill you receive at the end of the month. Make sure to delete all the resources
    provisioned above. Remove these resources by running the `terraform destroy` command.
    One more thing to note is that the contents of the S3 bucket need to be removed
    before running `terraform destroy` because Terraform will not delete a nonempty
    bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Before running the `terraform destroy` command, make sure you will not delete
    resources that might still be used in production!
  prefs: []
  type: TYPE_NORMAL
- en: Automated Infrastructure Provisioning with Pulumi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pulumi is one of the new kids on the block when it comes to IaC tools. The keyword
    here is *new*, which means it is still somewhat rough around the edges, especially
    in regards to Python support.
  prefs: []
  type: TYPE_NORMAL
- en: Pulumi allows you to specify the desired state of your infrastructure by telling
    it which resources to provision using real programming languages. TypeScript was
    the first language supported by Pulumi, but nowadays Go and Python are also supported.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand the difference between writing infrastructure
    automation code in Python using Pulumi and an AWS automation library such as Boto.
  prefs: []
  type: TYPE_NORMAL
- en: With Pulumi, your Python code describes the resources that you want to be provisioned.
    You are, in effect, creating the blueprint or the state discussed at the beginning
    of the chapter. This makes Pulumi similar to Terraform, but the big difference
    is that Pulumi gives you the full power of a programming language such as Python
    in terms of writing functions, loops, using variables, etc. You are not hampered
    by the use of a markup language such as Terraform’s HCL. Pulumi combines the power
    of a declarative approach, where you describe the desired end state, with the
    power of a real programming language.
  prefs: []
  type: TYPE_NORMAL
- en: With an AWS automation library such as Boto, you both describe and provision
    individual AWS resources through the code you write. There is no overall blueprint
    or state. You need to keep track of the provisioned resources yourself, and to
    orchestrate their creation and removal. This is the imperative or procedural approach
    for automation tools. You still get the advantage of writing Python code.
  prefs: []
  type: TYPE_NORMAL
- en: To start using Pulumi, create a free account on their website pulumi.io. Then
    you can install the `pulumi` command-line tool on your local machine. On a Macintosh,
    use Homebrew to install `pulumi`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first command to run locally is `pulumi login`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Creating a New Pulumi Python Project for AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Create a directory called *proj1*, run `pulumi new` in that directory, and
    chose the `aws-python` template. As part of the project creation, `pulumi` asks
    for the name of a stack. Call it `staging`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It is important to understand the difference between a Pulumi project and a
    Pulumi stack. A project is the code you write for specifying the desired state
    of the system, the resources you want Pulumi to provision. A stack is a specific
    deployment of the project. For example, a stack can correspond to an environment
    such as development, staging, or production. In the examples that follow, we will
    create two Pulumi stacks, one called `staging` that corresponds to a staging environment,
    and further down the line, another stack called `prod` that corresponds to a production
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the files automatically generated by the `pulumi new` command as part
    of the `aws-python` template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Follow the instructions in the output of `pulumi new` and install `virtualenv`,
    then create a new `virtualenv` environment and install the libraries specified
    in *requirements.txt*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Before provisioning any AWS resources with `pulumi up`, make sure you are using
    the AWS account that you are expecting to target. One way to specify the desired
    AWS account is to set the `AWS_PROFILE` environment variable in your current shell.
    In our case, an AWS profile called `gheorghiu-net` was already set up in the local
    *~/.aws/credentials* file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The *__main__.py* file generated by Pulumi as part of the `aws-python` template
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Clone the [Pulumi examples GitHub repository](https://oreil.ly/SIT-v) locally,
    then copy *__main__.py* and the *www* directory from *pulumi-examples/aws-py-s3-folder*
    into the current directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the new *__main__.py* file in the current directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note the use of Python variables for `content_dir` and `bucket_name`, the use
    of a `for` loop, and also the use of a regular Python function `public_read_policy_for_bucket`.
    It is refreshing to be able to use regular Python constructs in IaC programs!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s time to run `pulumi up` to provision the resources specified in *__main__.py*.
    This command will show all the resources that will be created. Moving the current
    choice to `yes` will kick off the provisioning process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the existing Pulumi stacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Inspect the outputs of the current stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Visit the URL specified in the `website_url` output ([*http://s3-website-bucket-8e08f8f.s3-website-us-east-1.amazonaws.com*](http://s3-website-bucket-8e08f8f.s3-website-us-east-1.amazonaws.com))
    and make sure you can see the static site.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the sections that follow, the Pulumi project will be enhanced by specifying
    more AWS resources to be provisioned. The goal is to have parity with the resources
    that were provisioned with Terraform: an ACM SSL certificate, a CloudFront distribution,
    and a Route 53 DNS record for the site URL.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating Configuration Values for the Staging Stack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The current stack is `staging`. Rename the existing *www* directory to *www-staging*,
    then use the `pulumi config set` command to specify two configuration values for
    the current `staging` stack: `domain_name` and `local_webdir`.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For more details on how Pulumi manages configuration values and secrets, see
    [the Pulumi reference documentation](https://oreil.ly/D_Cy5).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To inspect the existing configuration values for the current stack, run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the configuration values are set, use them in the Pulumi code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Now that the configuration values are in place; next we will provision an SSL
    certificate with the AWS Certificate Manager service.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning an ACM SSL Certificate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Around this point, Pulumi starts to show its rough edges when it comes to its
    Python SDK. Just reading the Pulumi Python SDK reference for the [`acm`](https://oreil.ly/Niwaj)
    module is not sufficient to make sense of what you need to do in your Pulumi program.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there are many Pulumi examples in TypeScript that you can take
    inspiration from. One such example that illustrated our use case is [`aws-ts-static-website`](https://oreil.ly/7F39c).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the TypeScript code for creating a new ACM certificate (from [`index.ts`](https://oreil.ly/mlSr1)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the equivalent Python code that we wrote:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A rule of thumb in porting Pulumi code from TypeScript to Python is that parameter
    names that are camelCased in TypeScript become snake_cased in Python. As you can
    see in the earlier example, `domainName` becomes `domain_name` and `validationMethod`
    becomes `validation_method`.
  prefs: []
  type: TYPE_NORMAL
- en: Our next step was to provision a Route 53 zone and in that zone a DNS validation
    record for the ACM SSL certificate.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning a Route 53 Zone and DNS Records
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Provisioning a new Route 53 zone with Pulumi is easy if you follow the [Pulumi
    SDK reference for route53](https://oreil.ly/cU9Yj).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The preceding snippet shows how to use a regular Python function to split the
    configuration value read into the `domain_name` variable into two parts. If `domain_name`
    is `staging.devops4all.dev`, the function will split it into `subdomain` (`staging`)
    and `parent_domain` (`devops4all.dev`).
  prefs: []
  type: TYPE_NORMAL
- en: The `parent_domain` variable is then used as a parameter to the constructor
    of the `zone` object, which tells Pulumi to provision a `route53.Zone` resource.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once the Route 53 zone was created, we had to point the Namecheap name servers
    at the name servers specified in the DNS record for the new zone so that the zone
    can be publicly accessible.
  prefs: []
  type: TYPE_NORMAL
- en: All was well and good so far. The next step was to create both the ACM certificate
    and a DNS record to validate the certificate.
  prefs: []
  type: TYPE_NORMAL
- en: We first tried to port the example TypeScript code by applying the rule of thumb
    of turning camelCase parameter names into snake_case.
  prefs: []
  type: TYPE_NORMAL
- en: 'TypeScript:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The first attempt at porting to Python by switching camelCase to snake_case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'No luck. `pulumi up` shows this error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we were stumped, because the Python SDK documentation doesn’t
    include this level of detail. We did not know what attributes we needed to specify
    for the `domain_validation_options` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'We were only able to get past this by adding the `domain_validation_options`
    object to the list of Pulumi exports, which are printed out by Pulumi at the end
    of the `pulumi up` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from `pulumi up` was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Bingo! It turns out that the attributes of the `domain_validation_options` object
    are still camelCased.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the second attempt at porting to Python, which was successful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, specify a new type of resource to be provisioned: a certificate validation
    completion resource. This causes the `pulumi up` operation to wait until ACM validates
    the certificate by checking the Route 53 validation record created earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you have a fully automated way of provisioning an ACM SSL certificate
    and of validating it via DNS.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to provision the CloudFront distribution in front of the S3
    bucket hosting the static files for the site.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning a CloudFront Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the SDK reference for the Pulumi [`cloudfront` module](https://oreil.ly/4n98-)
    to figure out which constructor parameters to pass to `cloudfront.Distribution`.
    Inspect the TypeScript code to know what the proper values are for those parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Run `pulumi up` to provision the CloudFront distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning a Route 53 DNS Record for the Site URL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last step in the end-to-end provisioning of the resources for the `staging`
    stack was the relatively simple task of specifying a DNS record of type `A` as
    an alias to the domain of the CloudFront endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Run `pulumi up` as usual.
  prefs: []
  type: TYPE_NORMAL
- en: Visit [*https://staging.devops4all.dev*](https://staging.devops4all.dev) and
    see the files uploaded to S3\. Go to the logging bucket in the AWS console and
    make sure the CloudFront logs are there.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how to deploy the same Pulumi project to a new environment, represented
    by a new Pulumi stack.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and Deploying a New Stack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We decided to modify the Pulumi program so that it does not provision a new
    Route 53 zone, but instead uses the value of the zone ID for an existing zone
    as a configuration value.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the `prod` stack, use the command `pulumi stack init` and specify
    `prod` for its name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing the stacks now shows the two stacks, `staging` and `prod`, with an
    asterisk next to `prod` signifying that `prod` is the current stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it’s time to set the proper configuration values for the `prod` stack.
    Use a new `dns_zone_id` configuration value, set to the ID of the zone that was
    already created by Pulumi when it provisioned the `staging` stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Change the code to read `zone_id` from the configuration and to not create the
    Route 53 zone object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `pulumi up` to provision the AWS resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Success! The `prod` stack was fully deployed.
  prefs: []
  type: TYPE_NORMAL
- en: However, the contents of the *www-prod* directory containing the static files
    for the site are identical at this point to the contents of the *www-staging*
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify *www-prod/index.html* to change “Hello, S3!” to “Hello, S3 production!”,
    then run `pulumi up` again to detect the changes and upload the modified file
    to S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Invalidate the cache of the CloudFront distribution to see the change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Visit [*https://www.devops4all.dev*](https://www.devops4all.dev) and see the
    message: `Hello, S3 production!`'
  prefs: []
  type: TYPE_NORMAL
- en: 'One caveat about IaC tools that keep track of the state of the system: there
    are situations when the state as seen by the tool will be different from the actual
    state. In that case, it is important to synchronize the two states; otherwise,
    they will drift apart more and more and you will be in the situation where you
    don’t dare make any more changes for fear that you will break production. It’s
    not for nothing that the word *Code* is prominent in *Infrastructure as Code*.
    Once you commit to using an IaC tool, best practices say that you should provision
    all resources via code, and no longer spin up any resource manually. It is hard
    to maintain this discipline, but it pays dividends in the long run.'
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Provision the same set of AWS resources by using the [AWS Cloud Development
    Kit](https://aws.amazon.com/cdk).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Terraform or Pulumi to provision cloud resources from other cloud providers,
    such as Google Cloud Platform or Microsoft Azure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
