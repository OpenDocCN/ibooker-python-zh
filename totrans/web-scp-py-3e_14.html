<html><head></head><body><section data-pdf-bookmark="Chapter 12. Reading and Writing Natural Languages" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-12">&#13;
<h1><span class="label">Chapter 12. </span>Reading and Writing Natural Languages</h1>&#13;
&#13;
<p>So far, the data you have worked with in this book has been in the form of numbers or countable values. In most cases, you’ve simply stored the data without conducting any analysis after the fact. This chapter attempts to tackle the tricky subject of the English language.<sup><a data-type="noteref" href="ch12.html#id650" id="id650-marker">1</a></sup></p>&#13;
&#13;
<p>How does Google know what you’re looking for when you type “cute kitten” into its image search? Because of the text that surrounds the cute kitten images. How does YouTube know to bring up a certain Monty Python sketch when you type “dead parrot” into its search bar? Because of the title and description text that accompanies each uploaded video.</p>&#13;
&#13;
<p>In fact, even typing in terms such as “deceased bird monty python” immediately brings up the same “Dead Parrot” sketch, even though the page itself contains no mention of the words “deceased” or “bird.” Google knows that a “hot dog” is a food and that a “boiling puppy” is an entirely different thing. How? It’s all statistics!</p>&#13;
&#13;
<p>Although you might not think that text analysis has anything to do with your project, understanding the concepts behind it can be extremely useful for all sorts of machine learning, as well as the more general ability to model real-world problems in probabilistic and algorithmic terms.</p>&#13;
&#13;
<p>For instance, the Shazam music service can identify audio as containing a certain song recording, even if that audio contains ambient noise or distortion. Google is working on automatically captioning images based on nothing but the image itself.<sup><a data-type="noteref" href="ch12.html#id651" id="id651-marker">2</a></sup> By comparing known images of, say, hot dogs to other images of hot dogs, the search engine can gradually learn what a hot dog looks like and observe these patterns in additional images it is shown.</p>&#13;
&#13;
<section data-pdf-bookmark="Summarizing Data" data-type="sect1"><div class="sect1" id="id73">&#13;
<h1>Summarizing Data</h1>&#13;
&#13;
<p>In <a data-type="xref" href="ch11.html#c-11">Chapter 11</a>, you looked <a contenteditable="false" data-primary="summarizing data" data-type="indexterm" id="smzdt"/><a contenteditable="false" data-primary="data summaries" data-type="indexterm" id="dtsmmr"/>at breaking up text content into n-grams, or sets of phrases that are <em>n</em> words in length. At a basic level, this can be used to determine which sets of words and phrases tend to be most commonly used in a section of text. In addition, it can be used to create natural-sounding data summaries by going back to the original text and extracting sentences around some of these most popular phrases.</p>&#13;
&#13;
<p>One piece of sample text you’ll be using to do this is the inauguration speech of the ninth president of the United States, William Henry Harrison. Harrison’s presidency set two records in the history of the office: one for the longest inauguration speech, and another for the shortest time in office, 32 days.</p>&#13;
&#13;
<p>You’ll use the full text of this <a href="http://pythonscraping.com/files/inaugurationSpeech.txt">speech</a> as the source for many of the code samples in this chapter.</p>&#13;
&#13;
<p>A slightly modified set of functions from the cleaning code in <a data-type="xref" href="ch11.html#c-11">Chapter 11</a> can be used to transform this text into a list of sentences ready for splitting into n-grams:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">re</code>&#13;
<code class="kn">import</code> <code class="nn">string</code> &#13;
&#13;
<code class="k">def</code> <code class="nf">replace_newlines</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="k">return</code> <code class="n">text</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="s1">' '</code><code class="p">)</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">make_lowercase</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="k">return</code> <code class="n">text</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">split_sentences</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">s</code><code class="o">.</code><code class="n">strip</code><code class="p">()</code> <code class="k">for</code> <code class="n">s</code> <code class="ow">in</code> <code class="n">text</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">'. '</code><code class="p">)]</code>&#13;
&#13;
<code class="n">puncts</code> <code class="o">=</code> <code class="p">[</code><code class="n">re</code><code class="o">.</code><code class="n">escape</code><code class="p">(</code><code class="n">c</code><code class="p">)</code> <code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="n">string</code><code class="o">.</code><code class="n">punctuation</code><code class="p">]</code>&#13;
<code class="n">PUNCTUATION_REGEX</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'|'</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">puncts</code><code class="p">))</code>&#13;
<code class="k">def</code> <code class="nf">remove_punctuation</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="k">return</code> <code class="n">re</code><code class="o">.</code><code class="n">sub</code><code class="p">(</code><code class="n">PUNCTUATION_REGEX</code><code class="p">,</code> <code class="s1">''</code><code class="p">,</code> <code class="n">text</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">Then we fetch the text and call these functions in a particular order:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">content</code> <code class="o">=</code> <code class="nb">str</code><code class="p">(</code>&#13;
    <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/files/inaugurationSpeech.txt'</code><code class="p">)</code><code class="o">.</code><code class="n">read</code><code class="p">(),</code>&#13;
    <code class="s1">'utf-8'</code>&#13;
<code class="p">)</code>&#13;
&#13;
<code class="n">text_operations</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">replace_newlines</code><code class="p">,</code>&#13;
    <code class="n">split_sentences</code><code class="p">,</code>&#13;
    <code class="n">make_lowercase</code><code class="p">,</code>&#13;
    <code class="n">remove_punctuation</code>&#13;
<code class="p">]</code>&#13;
&#13;
<code class="n">cleaned</code> <code class="o">=</code> <code class="n">content</code>&#13;
<code class="k">for</code> <code class="n">op</code> <code class="ow">in</code> <code class="n">text_operations</code><code class="p">:</code>&#13;
    <code class="k">if</code> <code class="nb">type</code><code class="p">(</code><code class="n">cleaned</code><code class="p">)</code> <code class="o">==</code> <code class="nb">list</code><code class="p">:</code>&#13;
        <code class="n">cleaned</code> <code class="o">=</code> <code class="p">[</code><code class="n">op</code><code class="p">(</code><code class="n">c</code><code class="p">)</code> <code class="k">for</code> <code class="n">c</code> <code class="ow">in</code> <code class="n">cleaned</code><code class="p">]</code>&#13;
    <code class="k">else</code><code class="p">:</code>&#13;
        <code class="n">cleaned</code> <code class="o">=</code> <code class="n">op</code><code class="p">(</code><code class="n">cleaned</code><code class="p">)</code>&#13;
        &#13;
<code class="nb">print</code><code class="p">(</code><code class="n">cleaned</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Next we use the cleaned text to get a <code>Counter</code> object of all 2-grams and find the most popular ones:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="k">def</code> <code class="nf">getNgrams</code><code class="p">(</code><code class="n">text</code><code class="p">,</code> <code class="n">n</code><code class="p">):</code>&#13;
    <code class="n">text</code> <code class="o">=</code> <code class="n">text</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">' '</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="s1">' '</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">text</code><code class="p">[</code><code class="n">i</code><code class="p">:</code><code class="n">i</code><code class="o">+</code><code class="n">n</code><code class="p">])</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">text</code><code class="p">)</code><code class="o">-</code><code class="n">n</code><code class="o">+</code><code class="mi">1</code><code class="p">)]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">countNGramsFromSentences</code><code class="p">(</code><code class="n">sentences</code><code class="p">,</code> <code class="n">n</code><code class="p">):</code>&#13;
    <code class="n">counts</code> <code class="o">=</code> <code class="n">Counter</code><code class="p">()</code>&#13;
    <code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">sentences</code><code class="p">:</code>&#13;
        <code class="n">counts</code><code class="o">.</code><code class="n">update</code><code class="p">(</code><code class="n">getNgrams</code><code class="p">(</code><code class="n">sentence</code><code class="p">,</code> <code class="n">n</code><code class="p">))</code>&#13;
    <code class="k">return</code> <code class="n">counts</code>&#13;
&#13;
<code class="n">counts</code> <code class="o">=</code> <code class="n">countNGramsFromSentences</code><code class="p">(</code><code class="n">cleaned</code><code class="p">,</code> <code class="mi">2</code><code class="p">)</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">counts</code><code class="o">.</code><code class="n">most_common</code><code class="p">())</code>&#13;
</pre>&#13;
&#13;
<p>This example illustrates the convenience and power of the Python standard library collections. No, it wouldn’t be particularly difficult to write a function that creates a dictionary counter, sorts it by values, and returns the most popular keys for those top values. However, knowing about the built-in collections and being able to pick the right one for the task at hand can save you many lines of code!</p>&#13;
&#13;
<p>The output produces, in part:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
[('of the', 213), ('in the', 65), ('to the', 61), ('by the', 41),&#13;
('the constitution', 34), ('of our', 29), ('to be', 26),&#13;
('the people', 24), ('from the', 24), ('that the', 23)...</pre>&#13;
&#13;
<p>Of these 2-grams, “the constitution” seems like a reasonably popular subject in the speech, but “of the,” “in the,” and “to the” don’t seem especially noteworthy. How can you automatically and accurately get rid of unwanted words?</p>&#13;
&#13;
<p>Fortunately, there are people out there who carefully study the differences between “interesting” words and “uninteresting” words, and their work can help us do just that. Mark Davies, a linguistics professor at Brigham Young University, maintains <a contenteditable="false" data-primary="Corpus of Contemporary American English" data-type="indexterm" id="id652"/>the <a href="http://corpus.byu.edu/coca/">Corpus of Contemporary American English</a>, a collection of over 450 million words from the last decade or so of popular American publications.</p>&#13;
&#13;
<p>The list of 5,000 most frequently found words is available for free, and fortunately, this is more than enough to act as a basic filter to weed out the most common <span class="keep-together">2-grams.</span> Just the first one hundred words vastly improves the results, with the addition of <code>isCommon</code> and <code>filterCommon</code> functions:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">COMMON_WORDS</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'the'</code><code class="p">,</code> <code class="s1">'be'</code><code class="p">,</code> <code class="s1">'and'</code><code class="p">,</code> <code class="s1">'of'</code><code class="p">,</code> <code class="s1">'a'</code><code class="p">,</code> <code class="s1">'in'</code><code class="p">,</code> <code class="s1">'to'</code><code class="p">,</code> <code class="s1">'have'</code><code class="p">,</code>&#13;
<code class="s1">'it'</code><code class="p">,</code> <code class="s1">'i'</code><code class="p">,</code> <code class="s1">'that'</code><code class="p">,</code> <code class="s1">'for'</code><code class="p">,</code> <code class="s1">'you'</code><code class="p">,</code> <code class="s1">'he'</code><code class="p">,</code> <code class="s1">'with'</code><code class="p">,</code> <code class="s1">'on'</code><code class="p">,</code> <code class="s1">'do'</code><code class="p">,</code> <code class="s1">'say'</code><code class="p">,</code>&#13;
<code class="s1">'this'</code><code class="p">,</code> <code class="s1">'they'</code><code class="p">,</code> <code class="s1">'is'</code><code class="p">,</code> <code class="s1">'an'</code><code class="p">,</code> <code class="s1">'at'</code><code class="p">,</code> <code class="s1">'but'</code><code class="p">,</code> <code class="s1">'we'</code><code class="p">,</code> <code class="s1">'his'</code><code class="p">,</code> <code class="s1">'from'</code><code class="p">,</code> <code class="s1">'that'</code><code class="p">,</code>&#13;
<code class="s1">'not'</code><code class="p">,</code> <code class="s1">'by'</code><code class="p">,</code> <code class="s1">'she'</code><code class="p">,</code> <code class="s1">'or'</code><code class="p">,</code> <code class="s1">'as'</code><code class="p">,</code> <code class="s1">'what'</code><code class="p">,</code> <code class="s1">'go'</code><code class="p">,</code> <code class="s1">'their'</code><code class="p">,</code> <code class="s1">'can'</code><code class="p">,</code>&#13;
<code class="s1">'who'</code><code class="p">,</code> <code class="s1">'get'</code><code class="p">,</code> <code class="s1">'if'</code><code class="p">,</code> <code class="s1">'would'</code><code class="p">,</code> <code class="s1">'her'</code><code class="p">,</code> <code class="s1">'all'</code><code class="p">,</code> <code class="s1">'my'</code><code class="p">,</code> <code class="s1">'make'</code><code class="p">,</code> <code class="s1">'about'</code><code class="p">,</code>&#13;
<code class="s1">'know'</code><code class="p">,</code> <code class="s1">'will'</code><code class="p">,</code> <code class="s1">'as'</code><code class="p">,</code> <code class="s1">'up'</code><code class="p">,</code> <code class="s1">'one'</code><code class="p">,</code> <code class="s1">'time'</code><code class="p">,</code> <code class="s1">'has'</code><code class="p">,</code> <code class="s1">'been'</code><code class="p">,</code> <code class="s1">'there'</code><code class="p">,</code>&#13;
<code class="s1">'year'</code><code class="p">,</code> <code class="s1">'so'</code><code class="p">,</code> <code class="s1">'think'</code><code class="p">,</code> <code class="s1">'when'</code><code class="p">,</code> <code class="s1">'which'</code><code class="p">,</code> <code class="s1">'them'</code><code class="p">,</code> <code class="s1">'some'</code><code class="p">,</code> <code class="s1">'me'</code><code class="p">,</code>&#13;
<code class="s1">'people'</code><code class="p">,</code> <code class="s1">'take'</code><code class="p">,</code> <code class="s1">'out'</code><code class="p">,</code> <code class="s1">'into'</code><code class="p">,</code> <code class="s1">'just'</code><code class="p">,</code> <code class="s1">'see'</code><code class="p">,</code> <code class="s1">'him'</code><code class="p">,</code> <code class="s1">'your'</code><code class="p">,</code>&#13;
<code class="s1">'come'</code><code class="p">,</code> <code class="s1">'could'</code><code class="p">,</code> <code class="s1">'now'</code><code class="p">,</code> <code class="s1">'than'</code><code class="p">,</code> <code class="s1">'like'</code><code class="p">,</code> <code class="s1">'other'</code><code class="p">,</code> <code class="s1">'how'</code><code class="p">,</code> <code class="s1">'then'</code><code class="p">,</code>&#13;
<code class="s1">'its'</code><code class="p">,</code> <code class="s1">'our'</code><code class="p">,</code> <code class="s1">'two'</code><code class="p">,</code> <code class="s1">'more'</code><code class="p">,</code> <code class="s1">'these'</code><code class="p">,</code> <code class="s1">'want'</code><code class="p">,</code> <code class="s1">'way'</code><code class="p">,</code> <code class="s1">'look'</code><code class="p">,</code> <code class="s1">'first'</code><code class="p">,</code>&#13;
<code class="s1">'also'</code><code class="p">,</code> <code class="s1">'new'</code><code class="p">,</code> <code class="s1">'because'</code><code class="p">,</code> <code class="s1">'day'</code><code class="p">,</code> <code class="s1">'more'</code><code class="p">,</code> <code class="s1">'use'</code><code class="p">,</code> <code class="s1">'no'</code><code class="p">,</code> <code class="s1">'man'</code><code class="p">,</code> <code class="s1">'find'</code><code class="p">,</code>&#13;
<code class="s1">'here'</code><code class="p">,</code> <code class="s1">'thing'</code><code class="p">,</code> <code class="s1">'give'</code><code class="p">,</code> <code class="s1">'many'</code><code class="p">,</code> <code class="s1">'well'</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">isCommon</code><code class="p">(</code><code class="n">ngram</code><code class="p">):</code>&#13;
  <code class="k">return</code> <code class="nb">any</code><code class="p">([</code><code class="n">w</code> <code class="ow">in</code> <code class="n">COMMON_WORDS</code> <code class="k">for</code> <code class="n">w</code> <code class="ow">in</code> <code class="n">ngram</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">' '</code><code class="p">)])</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">filterCommon</code><code class="p">(</code><code class="n">counts</code><code class="p">):</code>&#13;
  <code class="k">return</code> <code class="n">Counter</code><code class="p">({</code><code class="n">key</code><code class="p">:</code> <code class="n">val</code> <code class="k">for</code> <code class="n">key</code><code class="p">,</code> <code class="n">val</code> <code class="ow">in</code> <code class="n">counts</code><code class="o">.</code><code class="n">items</code><code class="p">()</code> <code class="k">if</code> <code class="ow">not</code> <code class="n">isCommon</code><code class="p">(</code><code class="n">key</code><code class="p">)})</code>&#13;
&#13;
<code class="n">filterCommon</code><code class="p">(</code><code class="n">counts</code><code class="p">)</code><code class="o">.</code><code class="n">most_common</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>This produces the following 2-grams that were found more than twice in the text body:</p>&#13;
&#13;
<pre data-code-language="text" data-executable="true" data-type="programlisting">&#13;
('united states', 10),&#13;
('executive department', 4),&#13;
('general government', 4),&#13;
('called upon', 3),&#13;
('chief magistrate', 3),&#13;
('legislative body', 3),&#13;
('same causes', 3),&#13;
('government should', 3),&#13;
('whole country', 3)</pre>&#13;
&#13;
<p class="pagebreak-before">Appropriately enough, the first two items in the list are “United States” and “executive department,” which you would expect for a presidential inauguration speech.</p>&#13;
&#13;
<p>It’s important to note that you are using a list of common words from relatively modern times to filter the results, which might not be appropriate given that the text was written in 1841. However, because you’re using only the first one hundred or so words on the list—which you can assume are more stable over time than, say, the last one hundred words—and you appear to be getting satisfactory results, you can likely save yourself the effort of tracking down or creating a list of the most common words from 1841 (although such an effort might be interesting).</p>&#13;
&#13;
<p>Now that some key topics have been extracted from the text, how does this help you write text summaries? One way is to search for the first sentence that contains each “popular” n-gram, the theory being that the first instance will yield a satisfactory overview of the body of the content. The first five most popular 2-grams yield these bullet points:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>“The Constitution of the United States is the instrument containing this grant of power to the several departments composing the Government.”</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>“Such a one was afforded by the executive department constituted by the Constitution.”</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>“The General Government has seized upon none of the reserved rights of the States.”</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>“Called from a retirement which I had supposed was to continue for the residue of my life to fill the chief executive office of this great and free nation, I appear before you, fellow-citizens, to take the oaths which the constitution prescribes as a necessary qualification for the performance of its duties; and in obedience to a custom coeval with our government and what I believe to be your expectations I proceed to present to you a summary of the principles which will govern me in the discharge of the duties which I shall be called upon to perform.”</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>“The presses in the necessary employment of the Government should never be used to ‘clear the guilty or to varnish crime.’”</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Sure, it might not be published in CliffsNotes anytime soon, but considering that the original document was 217 sentences in length, and the fourth sentence (“Called from a retirement...”) condenses the main subject down fairly well, it’s not too bad for a first pass.</p>&#13;
&#13;
<p>With longer blocks of text, or more varied text, it may be worth looking at 3-grams or even 4-grams when retrieving the “most important” sentences of a passage. In this case, only one 3-gram is used multiple times and that is “exclusive metallic currency”—referring to the proposal of a gold standard for US currency, which was an important issue of the day. With longer passages, using 3-grams may be appropriate.</p>&#13;
&#13;
<p>Another approach is to look for sentences that contain the most popular n-grams. These will, of course, tend to be longer sentences, so if that becomes a problem, you can look for sentences with the highest percentage of words that are popular n-grams or create a scoring <a contenteditable="false" data-primary="summarizing data" data-startref="smzdt" data-type="indexterm" id="id653"/><a contenteditable="false" data-primary="data summaries" data-startref="dtsmmr" data-type="indexterm" id="id654"/>metric of your own, combining several techniques.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Markov Models" data-type="sect1"><div class="sect1" id="id74">&#13;
<h1>Markov Models</h1>&#13;
&#13;
<p>You might have heard of Markov text <a contenteditable="false" data-primary="Markov models" data-type="indexterm" id="mkvmd"/><a contenteditable="false" data-primary="text" data-secondary="Markov models" data-type="indexterm" id="txkvdl"/>generators. They’ve become popular for entertainment purposes, as in the <a href="http://yes.thatcan.be/my/next/tweet/">“That can be my next tweet!”</a> app, as well as their use for generating real-sounding spam emails to fool detection systems.</p>&#13;
&#13;
<p>All of these text generators <a contenteditable="false" data-primary="text generators, Markov models and" data-type="indexterm" id="id655"/>are based on the Markov model, which is often used to analyze large sets of random events, where one discrete event is followed by another discrete event with a certain probability.</p>&#13;
&#13;
<p>For example, you might build a Markov model of a weather system, as illustrated in <a data-type="xref" href="#Markov_model">Figure 12-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="Markov_model"><img alt="Alt Text" class="iimagesweathermarkovpng" src="assets/wsp3_1201.png"/>&#13;
<h6><span class="label">Figure 12-1. </span>Markov model describing a theoretical weather system</h6>&#13;
</div></figure>&#13;
&#13;
<p>In this model, each sunny day has a 70% chance of the following day also being sunny, with a 20% chance of the following day being cloudy with a mere 10% chance of rain. If the day is rainy, there is a 50% chance of rain the following day, a 25% chance of sun, and a 25% chance of clouds.</p>&#13;
&#13;
<p>You might note several properties in this Markov model:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>All percentages leading away from any one node must add up to exactly 100%. No matter how complicated the system, there must always be a 100% chance that it can lead somewhere else in the next step.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Although there are only three possibilities for the weather at any given time, you can use this model to generate an infinite list of weather states.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Only the state of the current node you are on influences where you will go to next. If you’re on the Sunny node, it doesn’t matter if the preceding 100 days were sunny or rainy—the chances of sun the next day are exactly the same: 70%.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>It might be more difficult to reach some nodes than others. The math behind this is reasonably complicated, but it should be fairly easy to see that Rainy (with less than “100%” worth of arrows pointing toward it) is a much less likely state to reach in this system, at any given point in time, than Sunny or Cloudy.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Obviously, this is a simple system, and Markov models can grow arbitrarily large. Google’s page-rank algorithm is based partly on a Markov model, with websites represented as nodes, and inbound/outbound links represented as connections between nodes. The “likelihood” of landing on a particular node represents the relative popularity of the site. That is, if our weather system represented an extremely small internet, “rainy” would have a low page rank, while “cloudy” would have a high page rank.</p>&#13;
&#13;
<p>With all of this in mind, let’s bring it back down to a more concrete example: analyzing and generating text.</p>&#13;
&#13;
<p>Again using the inauguration speech of William Henry Harrison analyzed in the previous example, you can write the following code that generates arbitrarily long Markov chains (with the chain length set to 100) based on the structure of its text:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">random</code> <code class="kn">import</code> <code class="n">randint</code>&#13;
<code class="kn">from</code> <code class="nn">collections</code> <code class="kn">import</code> <code class="n">defaultdict</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">retrieveRandomWord</code><code class="p">(</code><code class="n">wordList</code><code class="p">):</code>&#13;
    <code class="n">randIndex</code> <code class="o">=</code> <code class="n">randint</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="nb">sum</code><code class="p">(</code><code class="n">wordList</code><code class="o">.</code><code class="n">values</code><code class="p">()))</code>&#13;
    <code class="k">for</code> <code class="n">word</code><code class="p">,</code> <code class="n">value</code> <code class="ow">in</code> <code class="n">wordList</code><code class="o">.</code><code class="n">items</code><code class="p">():</code>&#13;
        <code class="n">randIndex</code> <code class="o">-=</code> <code class="n">value</code>&#13;
        <code class="k">if</code> <code class="n">randIndex</code> <code class="o">&lt;=</code> <code class="mi">0</code><code class="p">:</code>&#13;
            <code class="k">return</code> <code class="n">word</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">cleanAndSplitText</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="c1"># Remove newlines and quotes</code>&#13;
    <code class="n">text</code> <code class="o">=</code> <code class="n">text</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="s1">' '</code><code class="p">)</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'"'</code><code class="p">,</code> <code class="s1">''</code><code class="p">);</code>&#13;
&#13;
    <code class="c1"># Make sure punctuation marks are treated as their own "words,"</code>&#13;
    <code class="c1"># so that they will be included in the Markov chain</code>&#13;
    <code class="n">punctuation</code> <code class="o">=</code> <code class="p">[</code><code class="s1">','</code><code class="p">,</code><code class="s1">'.'</code><code class="p">,</code><code class="s1">';'</code><code class="p">,</code><code class="s1">':'</code><code class="p">]</code>&#13;
    <code class="k">for</code> <code class="n">symbol</code> <code class="ow">in</code> <code class="n">punctuation</code><code class="p">:</code>&#13;
        <code class="n">text</code> <code class="o">=</code> <code class="n">text</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="n">symbol</code><code class="p">,</code> <code class="sa">f</code><code class="s1">' </code><code class="si">{</code><code class="n">symbol</code><code class="si">}</code><code class="s1"> '</code><code class="p">);</code>&#13;
    <code class="c1"># Filter out empty words</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">word</code> <code class="k">for</code> <code class="n">word</code> <code class="ow">in</code> <code class="n">text</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">' '</code><code class="p">)</code> <code class="k">if</code> <code class="n">word</code> <code class="o">!=</code> <code class="s1">''</code><code class="p">]</code>&#13;
     &#13;
<code class="k">def</code> <code class="nf">buildWordDict</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>&#13;
    <code class="n">words</code> <code class="o">=</code> <code class="n">cleanAndSplitText</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>&#13;
    <code class="n">wordDict</code> <code class="o">=</code> <code class="n">defaultdict</code><code class="p">(</code><code class="nb">dict</code><code class="p">)</code>&#13;
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">words</code><code class="p">)):</code>&#13;
        <code class="n">wordDict</code><code class="p">[</code><code class="n">words</code><code class="p">[</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">]][</code><code class="n">words</code><code class="p">[</code><code class="n">i</code><code class="p">]]</code> <code class="o">=</code> \&#13;
        <code class="n">wordDict</code><code class="p">[</code><code class="n">words</code><code class="p">[</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">]]</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">words</code><code class="p">[</code><code class="n">i</code><code class="p">],</code> <code class="mi">0</code><code class="p">)</code> <code class="o">+</code> <code class="mi">1</code>&#13;
    <code class="k">return</code> <code class="n">wordDict</code>&#13;
&#13;
<code class="n">text</code> <code class="o">=</code> <code class="nb">str</code><code class="p">(</code><code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://pythonscraping.com/files/inaugurationSpeech.txt'</code><code class="p">)</code>&#13;
          <code class="o">.</code><code class="n">read</code><code class="p">(),</code> <code class="s1">'utf-8'</code><code class="p">)</code>&#13;
<code class="n">wordDict</code> <code class="o">=</code> <code class="n">buildWordDict</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#Generate a Markov chain of length 100</code>&#13;
<code class="n">length</code> <code class="o">=</code> <code class="mi">100</code>&#13;
<code class="n">chain</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'I'</code><code class="p">]</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">length</code><code class="p">):</code>&#13;
    <code class="n">newWord</code> <code class="o">=</code> <code class="n">retrieveRandomWord</code><code class="p">(</code><code class="n">wordDict</code><code class="p">[</code><code class="n">chain</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]])</code>&#13;
    <code class="n">chain</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">newWord</code><code class="p">)</code>&#13;
&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">' '</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">chain</code><code class="p">))</code>&#13;
&#13;
</pre>&#13;
&#13;
<p>The output of this code changes every time it is run, but here’s an example of the uncannily nonsensical text it will generate:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
I sincerely believe in Chief Magistrate to make all necessary sacrifices and&#13;
oppression of the remedies which we may have occurred to me in the arrangement &#13;
and disbursement of the democratic claims them , consolatory to have been best &#13;
political power in fervently commending every other addition of legislation , by&#13;
the interests which violate that the Government would compare our aboriginal &#13;
neighbors the people to its accomplishment . The latter also susceptible of the &#13;
Constitution not much mischief , disputes have left to betray . The maxim which &#13;
may sometimes be an impartial and to prevent the adoption or </pre>&#13;
&#13;
<p>So what’s going on in the code?</p>&#13;
&#13;
<p>The function <code>buildWordDict</code> takes in the string of text, which was retrieved from the internet. It then does some cleaning and formatting, removing quotes and putting spaces around other punctuation so it is effectively treated as a separate word. After this, it builds a two-dimensional dictionary—a dictionary of dictionaries—that has the following form:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="p">{</code><code class="n">word_a</code> <code class="p">:</code> <code class="p">{</code><code class="n">word_b</code> <code class="p">:</code> <code class="mi">2</code><code class="p">,</code> <code class="n">word_c</code> <code class="p">:</code> <code class="mi">1</code><code class="p">,</code> <code class="n">word_d</code> <code class="p">:</code> <code class="mi">1</code><code class="p">},</code>&#13;
 <code class="n">word_e</code> <code class="p">:</code> <code class="p">{</code><code class="n">word_b</code> <code class="p">:</code> <code class="mi">5</code><code class="p">,</code> <code class="n">word_d</code> <code class="p">:</code> <code class="mi">2</code><code class="p">},</code><code class="o">...</code><code class="p">}</code></pre>&#13;
&#13;
<p>In this example dictionary, <code>word_a</code> was found four times, two instances of which were followed by “word_b,” one instance followed by <code>word_c</code>, and one instance followed by <code>word_d.</code> Then “word_e” was followed seven times: five times by <code>word_b</code> and twice by <code>word_d</code>.</p>&#13;
&#13;
<p>If we were to draw a node model of this result, the node representing <code>word_a</code> would have a 50% arrow pointing toward <code>word_b</code> (which followed it two out of four times), a 25% arrow pointing toward <code>word_c</code>, and a 25% arrow pointing toward <code>word_d.</code></p>&#13;
&#13;
<p>After this dictionary is built up, it can be used as a lookup table to see where to go next, no matter which word in the text you happen to be on.<sup><a data-type="noteref" href="ch12.html#id656" id="id656-marker">3</a></sup> Using the sample dictionary of dictionaries, you might currently be on <code>word_e</code>, which means that you’ll pass the dictionary <code>{word_b : 5, word_d: 2}</code> to the <code>retrieveRandomWord</code> function. This function in turn retrieves a random word from the dictionary, weighted by the number of times it occurs.</p>&#13;
&#13;
<p>By starting with a random starting word (in this case, the ubiquitous “I”), you can traverse through the Markov chain easily, generating as many words as you like.</p>&#13;
&#13;
<p>These Markov chains tend to improve in their “realism” as more text is collected, especially from sources with similar writing styles. Although this example used <span class="keep-together">2-grams</span> to create the chain (where the previous word predicts the next word), 3-grams or higher-order n-grams can be used, where two or more words predict the next word.</p>&#13;
&#13;
<p>Although entertaining, and a great use for megabytes of text that you might have accumulated during web scraping, applications like these can make it difficult to see the practical side of Markov chains. As mentioned earlier in this section, Markov chains model how websites link from one page to the next. Large collections of these links as pointers can form weblike graphs that are useful to store, track, and analyze. In this way, Markov chains form the foundation for both how to <a contenteditable="false" data-primary="Markov models" data-startref="mkvmd" data-type="indexterm" id="id657"/><a contenteditable="false" data-primary="text" data-secondary="Markov models" data-startref="txkvdl" data-type="indexterm" id="id658"/>think about web crawling and how your web crawlers can think.</p>&#13;
&#13;
<section data-pdf-bookmark="Six Degrees of Wikipedia: Conclusion" data-type="sect2"><div class="sect2" id="six-degrees-conclusion">&#13;
<h2>Six Degrees of Wikipedia: Conclusion</h2>&#13;
&#13;
<p>In <a data-type="xref" href="ch06.html#c-6">Chapter 6</a>, you created a <a contenteditable="false" data-primary="Markov models" data-secondary="Six Degrees of Wikipedia" data-type="indexterm" id="mkvxkp"/><a contenteditable="false" data-primary="text" data-secondary="Markov models" data-tertiary="Six Degrees of Wikipedia" data-type="indexterm" id="xkvdxkp"/>scraper that collects links from one Wikipedia article to the next, starting with the article on Kevin Bacon, and in <a data-type="xref" href="ch09.html#c-9">Chapter 9</a>, stored those links in a database. Why am I bringing it up again? Because it turns out the problem of choosing a path of links that starts on one page and ends up on the target page (i.e., finding a string of pages between <a href="https://en.wikipedia.org/wiki/Kevin_Bacon"><em>https://en.wikipedia.org/wiki/Kevin_Bacon</em></a> and <em><a href="https://en.wikipedia.org/wiki/Eric_Idle"><em class="hyperlink">https://en.wikipedia.org/wiki/Eric_Idle</em></a></em>) is the same as finding a Markov chain where both the first word and last word are defined.</p>&#13;
&#13;
<p>These sorts of problems <a contenteditable="false" data-primary="directed graphs" data-type="indexterm" id="id659"/>are <em>directed graph</em> problems, where A → B does not necessarily mean that B → A. The word “football” might often be followed by the word “player,” but you’ll find that the word “player” is much less often followed by the word “football.” Although Kevin Bacon’s Wikipedia article links to the article on his home city, Philadelphia, the article on Philadelphia does not reciprocate by linking back to him.</p>&#13;
&#13;
<p>In contrast, the original <a contenteditable="false" data-primary="undirected graphs" data-type="indexterm" id="id660"/>Six Degrees of Kevin Bacon game is an <em>undirected graph</em> problem. If Kevin Bacon starred in <em>Flatliners</em> with Julia Roberts, then Julia Roberts necessarily starred in <em>Flatliners</em> with Kevin Bacon, so the relationship goes both ways (it has no “direction”). Undirected graph problems tend to be less common in computer science than directed graph problems, and both are computationally difficult to solve.</p>&#13;
&#13;
<p>Although much work has been done on these sorts of problems and multitudes of variations on them, one of the best and most common ways to find shortest paths in a directed graph—and thus find paths between the Wikipedia article on Kevin Bacon and all other Wikipedia articles—is through a breadth-first search.</p>&#13;
&#13;
<p>A <em>breadth-first search</em> is performed by first <a contenteditable="false" data-primary="breadth-first searches" data-type="indexterm" id="id661"/><a contenteditable="false" data-primary="searches" data-secondary="breadth-first" data-type="indexterm" id="id662"/>searching all links that link directly to the starting page. If those links do not contain the target page (the page you are searching for), then a second level of links—pages that are linked by a page that is linked by the starting page—is searched. This process continues until either the depth limit (6 in this case) is reached or the target page is found.</p>&#13;
&#13;
<p>A complete solution to the breadth-first search, using a table of links as described in <a data-type="xref" href="ch09.html#c-9">Chapter 9</a>, is as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">pymysql</code>&#13;
&#13;
<code class="n">conn</code> <code class="o">=</code> <code class="n">pymysql</code><code class="o">.</code><code class="n">connect</code><code class="p">(</code><code class="n">host</code><code class="o">=</code><code class="s1">'127.0.0.1'</code><code class="p">,</code> <code class="n">unix_socket</code><code class="o">=</code><code class="s1">'/tmp/mysql.sock'</code><code class="p">,</code>&#13;
    <code class="n">user</code><code class="o">=</code><code class="s1">''</code><code class="p">,</code> <code class="n">passwd</code><code class="o">=</code><code class="s1">''</code><code class="p">,</code> <code class="n">db</code><code class="o">=</code><code class="s1">'mysql'</code><code class="p">,</code> <code class="n">charset</code><code class="o">=</code><code class="s1">'utf8'</code><code class="p">)</code>&#13;
<code class="n">cur</code> <code class="o">=</code> <code class="n">conn</code><code class="o">.</code><code class="n">cursor</code><code class="p">()</code>&#13;
<code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'USE wikipedia'</code><code class="p">)</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">getUrl</code><code class="p">(</code><code class="n">pageId</code><code class="p">):</code>&#13;
    <code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'SELECT url FROM pages WHERE id = </code><code class="si">%s</code><code class="s1">'</code><code class="p">,</code> <code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">pageId</code><code class="p">)))</code>&#13;
    <code class="k">return</code> <code class="n">cur</code><code class="o">.</code><code class="n">fetchone</code><code class="p">()[</code><code class="mi">0</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">getLinks</code><code class="p">(</code><code class="n">fromPageId</code><code class="p">):</code>&#13;
    <code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'SELECT toPageId FROM links WHERE fromPageId = </code><code class="si">%s</code><code class="s1">'</code><code class="p">,</code>&#13;
        <code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">fromPageId</code><code class="p">)))</code>&#13;
    <code class="k">if</code> <code class="n">cur</code><code class="o">.</code><code class="n">rowcount</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>&#13;
        <code class="k">return</code> <code class="p">[]</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">x</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="k">for</code> <code class="n">x</code> <code class="ow">in</code> <code class="n">cur</code><code class="o">.</code><code class="n">fetchall</code><code class="p">()]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">searchBreadth</code><code class="p">(</code><code class="n">targetPageId</code><code class="p">,</code> <code class="n">paths</code><code class="o">=</code><code class="p">[[</code><code class="mi">1</code><code class="p">]]):</code>&#13;
    <code class="n">newPaths</code> <code class="o">=</code> <code class="p">[]</code>&#13;
    <code class="k">for</code> <code class="n">path</code> <code class="ow">in</code> <code class="n">paths</code><code class="p">:</code>&#13;
        <code class="n">links</code> <code class="o">=</code> <code class="n">getLinks</code><code class="p">(</code><code class="n">path</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">])</code>&#13;
        <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code><code class="p">:</code>&#13;
            <code class="k">if</code> <code class="n">link</code> <code class="o">==</code> <code class="n">targetPageId</code><code class="p">:</code>&#13;
                <code class="k">return</code> <code class="n">path</code> <code class="o">+</code> <code class="p">[</code><code class="n">link</code><code class="p">]</code>&#13;
            <code class="k">else</code><code class="p">:</code>&#13;
                <code class="n">newPaths</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">path</code><code class="o">+</code><code class="p">[</code><code class="n">link</code><code class="p">])</code>&#13;
    <code class="k">return</code> <code class="n">searchBreadth</code><code class="p">(</code><code class="n">targetPageId</code><code class="p">,</code> <code class="n">newPaths</code><code class="p">)</code>&#13;
                &#13;
<code class="n">nodes</code> <code class="o">=</code> <code class="n">getLinks</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">targetPageId</code> <code class="o">=</code> <code class="mi">28624</code>&#13;
<code class="n">pageIds</code> <code class="o">=</code> <code class="n">searchBreadth</code><code class="p">(</code><code class="n">targetPageId</code><code class="p">)</code>&#13;
<code class="k">for</code> <code class="n">pageId</code> <code class="ow">in</code> <code class="n">pageIds</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">getUrl</code><code class="p">(</code><code class="n">pageId</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p><code>getUrl</code> is a helper function that retrieves URLs from the database given a page ID. Similarly, <code>getLinks</code> takes a <code>fromPageId</code> representing the integer ID for the current page and fetches a list of all integer IDs for pages it links to.</p>&#13;
&#13;
<p>The main function, <code>searchBreadth</code>, works recursively to construct a list of all possible paths from the search page and stops when it finds a path that has reached the target page:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>It starts with a single path, <code>[1]</code>, representing a path in which the user stays on the target page with the ID 1 (Kevin Bacon) and follows no links.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>For each path in the list of paths (in the first pass, there is only one path, so this step is brief), it gets all of the links that link out from the page represented by the last page in the path.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>For each of these outbound links, it checks whether they match the <code>targetPageId</code>. If there’s a match, that path is returned.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>If there’s no match, a new path is added to a new list of (now longer) paths, consisting of the old path plus the new outbound page link.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>If the <code>targetPageId</code> is not found at this level at all, a recursion occurs and <code>searchBreadth</code> is called with the same <code>targetPageId</code> and a new, longer, list of paths.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>After the list of page IDs containing a path between the two pages is found, each ID is resolved to its actual URL and printed.</p>&#13;
&#13;
<p>The output for searching for a link between the page on Kevin Bacon (page ID 1 in this database) and the page on Eric Idle (page ID 28624 in this database) is:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
/wiki/Kevin_Bacon&#13;
/wiki/Primetime_Emmy_Award_for_Outstanding_Lead_Actor_in_a_&#13;
Miniseries_or_a_Movie&#13;
/wiki/Gary_Gilmore&#13;
/wiki/Eric_Idle&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">This translates into the relationship of links: Kevin Bacon → Primetime Emmy Award → Gary Gilmore → Eric Idle.</p>&#13;
&#13;
<p>In addition to solving Six Degrees problems and modeling which words tend to follow which other words in sentences, directed and undirected graphs can be used to model a variety of situations encountered in web scraping. Which websites link to which other websites? Which research papers cite which other research papers? Which products tend to be shown with which other products on a retail site? What is the strength of this link? Is the link reciprocal?</p>&#13;
&#13;
<p>Recognizing these fundamental types of relationships can be extremely helpful for making models, visualizations, <a contenteditable="false" data-primary="Markov models" data-secondary="Six Degrees of Wikipedia" data-startref="mkvxkp" data-type="indexterm" id="id663"/><a contenteditable="false" data-primary="text" data-secondary="Markov models" data-startref="xkvdxkp" data-tertiary="Six Degrees of Wikipedia" data-type="indexterm" id="id664"/>and predictions based on scraped data.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Natural Language Toolkit" data-type="sect1"><div class="sect1" id="id76">&#13;
<h1>Natural Language Toolkit</h1>&#13;
&#13;
<p>So far, this chapter has focused primarily <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-type="indexterm" id="id665"/><a contenteditable="false" data-primary="Natural Language Toolkit for Python (NLTK)" data-see="NLTK (Natural Language Toolkit for Python)" data-type="indexterm" id="id666"/>on the statistical analysis of words in bodies of text. Which words are most popular? Which words are unusual? Which words are likely to come after which other words? How are they grouped together? What you are missing is understanding, to the extent that you can, what the words represent.</p>&#13;
&#13;
<p>The <em>Natural Language Toolkit</em> (NLTK) is a suite of Python libraries designed to identify and tag parts of speech found in natural English text. Its development began in 2000, and over the past 20-plus years, dozens of developers around the world have contributed to the project. Although the functionality it provides is tremendous (entire books are devoted to NLTK), this section focuses on just a few of its uses.</p>&#13;
&#13;
<section data-pdf-bookmark="Installation and Setup" data-type="sect2"><div class="sect2" id="id153">&#13;
<h2>Installation and Setup</h2>&#13;
&#13;
<p>The <code>nltk</code> module can be installed <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="installation and setup" data-type="indexterm" id="ntkyll"/>in the same way as other Python modules, either by downloading the package through the NLTK website directly or by using any number of third-party installers with the keyword “nltk.” For complete installation instructions and help with troubleshooting, see the <a href="http://www.nltk.org/install.html">NLTK website</a>.</p>&#13;
&#13;
<p>After installing the module, you can browse the extensive collection of text corpora available for download and use:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">import</code> <code class="nn">nltk</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">nltk</code><code class="o">.</code><code class="n">download</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>This opens the NLTK Downloader. You can navigate <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="NLTK Downloader" data-type="indexterm" id="id667"/>it in the terminal using the commands provided its menu:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">NLTK</code> <code class="n">Downloader</code>&#13;
<code class="o">---------------------------------------------------------------------------</code>&#13;
    <code class="n">d</code><code class="p">)</code> <code class="n">Download</code>   <code class="n">l</code><code class="p">)</code> <code class="n">List</code>    <code class="n">u</code><code class="p">)</code> <code class="n">Update</code>   <code class="n">c</code><code class="p">)</code> <code class="n">Config</code>   <code class="n">h</code><code class="p">)</code> <code class="n">Help</code>   <code class="n">q</code><code class="p">)</code> <code class="n">Quit</code>&#13;
<code class="o">---------------------------------------------------------------------------</code>&#13;
&#13;
<code class="n">Downloader</code><code class="o">&gt;</code> <code class="n">l</code>&#13;
&#13;
<code class="n">Packages</code><code class="p">:</code>&#13;
&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">abc</code><code class="o">.................</code> <code class="n">Australian</code> <code class="n">Broadcasting</code> <code class="n">Commission</code> <code class="mi">2006</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">alpino</code><code class="o">..............</code> <code class="n">Alpino</code> <code class="n">Dutch</code> <code class="n">Treebank</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">averaged_perceptron_tagger</code> <code class="n">Averaged</code> <code class="n">Perceptron</code> <code class="n">Tagger</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">averaged_perceptron_tagger_ru</code> <code class="n">Averaged</code> <code class="n">Perceptron</code> <code class="n">Tagger</code> <code class="p">(</code><code class="n">Russian</code><code class="p">)</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">basque_grammars</code><code class="o">.....</code> <code class="n">Grammars</code> <code class="k">for</code> <code class="n">Basque</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">bcp47</code><code class="o">...............</code> <code class="n">BCP</code><code class="o">-</code><code class="mi">47</code> <code class="n">Language</code> <code class="n">Tags</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">biocreative_ppi</code><code class="o">.....</code> <code class="n">BioCreAtIvE</code> <code class="p">(</code><code class="n">Critical</code> <code class="n">Assessment</code> <code class="n">of</code> <code class="n">Information</code>&#13;
                           <code class="n">Extraction</code> <code class="n">Systems</code> <code class="ow">in</code> <code class="n">Biology</code><code class="p">)</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">bllip_wsj_no_aux</code><code class="o">....</code> <code class="n">BLLIP</code> <code class="n">Parser</code><code class="p">:</code> <code class="n">WSJ</code> <code class="n">Model</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">book_grammars</code><code class="o">.......</code> <code class="n">Grammars</code> <code class="kn">from</code> <code class="nn">NLTK</code> <code class="n">Book</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">brown</code><code class="o">...............</code> <code class="n">Brown</code> <code class="n">Corpus</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">brown_tei</code><code class="o">...........</code> <code class="n">Brown</code> <code class="n">Corpus</code> <code class="p">(</code><code class="n">TEI</code> <code class="n">XML</code> <code class="n">Version</code><code class="p">)</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">cess_cat</code><code class="o">............</code> <code class="n">CESS</code><code class="o">-</code><code class="n">CAT</code> <code class="n">Treebank</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">cess_esp</code><code class="o">............</code> <code class="n">CESS</code><code class="o">-</code><code class="n">ESP</code> <code class="n">Treebank</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">chat80</code><code class="o">..............</code> <code class="n">Chat</code><code class="o">-</code><code class="mi">80</code> <code class="n">Data</code> <code class="n">Files</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">city_database</code><code class="o">.......</code> <code class="n">City</code> <code class="n">Database</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">cmudict</code><code class="o">.............</code> <code class="n">The</code> <code class="n">Carnegie</code> <code class="n">Mellon</code> <code class="n">Pronouncing</code> <code class="n">Dictionary</code> <code class="p">(</code><code class="mf">0.6</code><code class="p">)</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">comparative_sentences</code> <code class="n">Comparative</code> <code class="n">Sentence</code> <code class="n">Dataset</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">comtrans</code><code class="o">............</code> <code class="n">ComTrans</code> <code class="n">Corpus</code> <code class="n">Sample</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">conll2000</code><code class="o">...........</code> <code class="n">CONLL</code> <code class="mi">2000</code> <code class="n">Chunking</code> <code class="n">Corpus</code>&#13;
&#13;
<code class="n">Hit</code> <code class="n">Enter</code> <code class="n">to</code> <code class="k">continue</code><code class="p">:</code></pre>&#13;
&#13;
<p>The last page of the corpora list contains its collections:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">Collections</code><code class="p">:</code>&#13;
  <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="nb">all</code><code class="o">-</code><code class="n">corpora</code><code class="o">.........</code> <code class="n">All</code> <code class="n">the</code> <code class="n">corpora</code>&#13;
  <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="nb">all</code><code class="o">-</code><code class="n">nltk</code><code class="o">............</code> <code class="n">All</code> <code class="n">packages</code> <code class="n">available</code> <code class="n">on</code> <code class="n">nltk_data</code> <code class="n">gh</code><code class="o">-</code><code class="n">pages</code>&#13;
                           <code class="n">branch</code>&#13;
  <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="nb">all</code><code class="o">.................</code> <code class="n">All</code> <code class="n">packages</code>&#13;
  <code class="p">[</code><code class="o">*</code><code class="p">]</code> <code class="n">book</code><code class="o">................</code> <code class="n">Everything</code> <code class="n">used</code> <code class="ow">in</code> <code class="n">the</code> <code class="n">NLTK</code> <code class="n">Book</code>&#13;
  <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="n">popular</code><code class="o">.............</code> <code class="n">Popular</code> <code class="n">packages</code>&#13;
  <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="n">tests</code><code class="o">...............</code> <code class="n">Packages</code> <code class="k">for</code> <code class="n">running</code> <code class="n">tests</code>&#13;
  <code class="p">[</code> <code class="p">]</code> <code class="n">third</code><code class="o">-</code><code class="n">party</code><code class="o">.........</code> <code class="n">Third</code><code class="o">-</code><code class="n">party</code> <code class="n">data</code> <code class="n">packages</code>&#13;
&#13;
<code class="p">([</code><code class="o">*</code><code class="p">]</code> <code class="n">marks</code> <code class="n">installed</code> <code class="n">packages</code><code class="p">;</code> <code class="p">[</code><code class="n">P</code><code class="p">]</code> <code class="n">marks</code> <code class="n">partially</code> <code class="n">installed</code> <code class="n">collections</code><code class="p">)</code>&#13;
&#13;
</pre>&#13;
&#13;
<p>For the exercises here, we will be using the book collection. You can download it through the downloader <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="installation and setup" data-startref="ntkyll" data-type="indexterm" id="id668"/>interface, or in Python:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">nltk</code><code class="o">.</code><code class="n">download</code><code class="p">(</code><code class="s1">'book'</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Statistical Analysis with NLTK" data-type="sect2"><div class="sect2" id="id77">&#13;
<h2>Statistical Analysis with NLTK</h2>&#13;
&#13;
<p>NLTK is great for generating statistical <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="statistical analysis with" data-type="indexterm" id="ntkkys"/><a contenteditable="false" data-primary="text" data-secondary="statistical analysis, NLTK" data-type="indexterm" id="stttyk"/>information about word counts, word frequency, and word diversity in sections of text. If all you need is a relatively straightforward calculation (e.g., the number of unique words used in a section of text), importing <code>nltk</code> might be overkill—it’s a large module. However, if you need to do relatively extensive analysis of a text, you have functions at your fingertips that will give you just about any metric you want.</p>&#13;
&#13;
<p>Analysis with NLTK always starts with the <code>Text</code> object. <code>Text</code> objects can be created from simple Python strings in the following way:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">word_tokenize</code>&#13;
<code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">Text</code>&#13;
&#13;
<code class="n">tokens</code> <code class="o">=</code> <code class="n">word_tokenize</code><code class="p">(</code><code class="s1">'Here is some not very interesting text'</code><code class="p">)</code>&#13;
<code class="n">text</code> <code class="o">=</code> <code class="n">Text</code><code class="p">(</code><code class="n">tokens</code><code class="p">)</code></pre>&#13;
&#13;
<p>The input for the <code>word_tokenize</code> function can be any Python text string. Any text can be passed in, but the NLTK corpora are handy for playing around with the features and for research. You can use the NLTK collection downloaded in the previous section by importing everything from the book module:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">nltk.book</code> <code class="kn">import</code> <code class="o">*</code></pre>&#13;
&#13;
<p>This loads the nine books:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
*** Introductory Examples for the NLTK Book ***&#13;
Loading text1, ..., text9 and sent1, ..., sent9&#13;
Type the name of the text or sentence to view it.&#13;
Type: 'texts()' or 'sents()' to list the materials.&#13;
text1: Moby Dick by Herman Melville 1851&#13;
text2: Sense and Sensibility by Jane Austen 1811&#13;
text3: The Book of Genesis&#13;
text4: Inaugural Address Corpus&#13;
text5: Chat Corpus&#13;
text6: Monty Python and the Holy Grail&#13;
text7: Wall Street Journal&#13;
text8: Personals Corpus&#13;
text9: The Man Who Was Thursday by G . K . Chesterton 1908</pre>&#13;
&#13;
<p>You will be working with <code>text6</code>, “Monty Python and the Holy Grail” (the screenplay for the 1975 movie), in all of the following examples.</p>&#13;
&#13;
<p>Text objects can be manipulated much like normal Python arrays, as if they were an array containing words of the text. Using this property, you can count the number of unique words in a text and compare it against the total number of words (remember that a Python <code>set</code> holds only unique values):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="nb">len</code><code class="p">(</code><code class="n">text6</code><code class="p">)</code><code class="o">/</code><code class="nb">len</code><code class="p">(</code><code class="nb">set</code><code class="p">(</code><code class="n">text6</code><code class="p">))</code>&#13;
<code class="mf">7.833333333333333</code></pre>&#13;
&#13;
<p>The preceding shows that each word in the script was used about eight times on average. You can also put the text into a frequency distribution object to determine some of the most common words and the frequencies for various words:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">FreqDist</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fdist</code> <code class="o">=</code> <code class="n">FreqDist</code><code class="p">(</code><code class="n">text6</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fdist</code><code class="o">.</code><code class="n">most_common</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>&#13;
<code class="p">[(</code><code class="s1">':'</code><code class="p">,</code> <code class="mi">1197</code><code class="p">),</code> <code class="p">(</code><code class="s1">'.'</code><code class="p">,</code> <code class="mi">816</code><code class="p">),</code> <code class="p">(</code><code class="s1">'!'</code><code class="p">,</code> <code class="mi">801</code><code class="p">),</code> <code class="p">(</code><code class="s1">','</code><code class="p">,</code> <code class="mi">731</code><code class="p">),</code> <code class="p">(</code><code class="s2">"'"</code><code class="p">,</code> <code class="mi">421</code><code class="p">),</code> <code class="p">(</code><code class="s1">'['</code><code class="p">,</code> <code class="mi">3</code>&#13;
<code class="mi">19</code><code class="p">),</code> <code class="p">(</code><code class="s1">']'</code><code class="p">,</code> <code class="mi">312</code><code class="p">),</code> <code class="p">(</code><code class="s1">'the'</code><code class="p">,</code> <code class="mi">299</code><code class="p">),</code> <code class="p">(</code><code class="s1">'I'</code><code class="p">,</code> <code class="mi">255</code><code class="p">),</code> <code class="p">(</code><code class="s1">'ARTHUR'</code><code class="p">,</code> <code class="mi">225</code><code class="p">)]</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fdist</code><code class="p">[</code><code class="s2">"Grail"</code><code class="p">]</code>&#13;
<code class="mi">34</code></pre>&#13;
&#13;
<p>Because this is a screenplay, some artifacts of how it is written can pop up. For instance, “ARTHUR” in all caps crops up frequently because it appears before each of King Arthur’s lines in the script. In addition, a colon (:) appears before every single line, acting as a separator between the name of the character and the character’s line. Using this fact, we can see that there are 1,197 lines in the movie!</p>&#13;
&#13;
<p>What we have called 2-grams in previous chapters, NLTK refers to as <em>bigrams</em> (from time to time, you might also hear 3-grams referred to as <em>trigrams</em>, but I prefer 2-gram and 3-gram rather than bigram or trigram). You can create, search, and list 2-grams extremely easily:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">bigrams</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">bigrams</code> <code class="o">=</code> <code class="n">bigrams</code><code class="p">(</code><code class="n">text6</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">bigramsDist</code> <code class="o">=</code> <code class="n">FreqDist</code><code class="p">(</code><code class="n">bigrams</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">bigramsDist</code><code class="p">[(</code><code class="s1">'Sir'</code><code class="p">,</code> <code class="s1">'Robin'</code><code class="p">)]</code>&#13;
<code class="mi">18</code></pre>&#13;
&#13;
<p>To search for the 2-grams “Sir Robin,” you need to break it into the tuple (“Sir”, “Robin”), to match the way the 2-grams are represented in the frequency distribution. There is also a <code>trigrams</code> module that works in the same way. For the general case, you can also import the <code>ngrams</code> module:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">ngrams</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fourgrams</code> <code class="o">=</code> <code class="n">ngrams</code><code class="p">(</code><code class="n">text6</code><code class="p">,</code> <code class="mi">4</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fourgramsDist</code> <code class="o">=</code> <code class="n">FreqDist</code><code class="p">(</code><code class="n">fourgrams</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">fourgramsDist</code><code class="p">[(</code><code class="s1">'father'</code><code class="p">,</code> <code class="s1">'smelt'</code><code class="p">,</code> <code class="s1">'of'</code><code class="p">,</code> <code class="s1">'elderberries'</code><code class="p">)]</code>&#13;
<code class="mi">1</code></pre>&#13;
&#13;
<p>Here, the <code>ngrams</code> function is called to break a text object into n-grams of any size, governed by the second parameter. In this case, you’re breaking the text into 4-grams. Then, you can demonstrate that the phrase “father smelt of elderberries” occurs in the screenplay exactly once.</p>&#13;
&#13;
<p>Frequency distributions, text objects, and n-grams <a contenteditable="false" data-primary="frequency distribution" data-type="indexterm" id="id669"/><a contenteditable="false" data-primary="text objects" data-type="indexterm" id="id670"/><a contenteditable="false" data-primary="n-grams" data-type="indexterm" id="id671"/>also can be iterated through and operated on in a loop. The following prints out all 4-grams that begin with the word “coconut,” for instance:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">nltk.book</code> <code class="kn">import</code> <code class="o">*</code>&#13;
<code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">ngrams</code>&#13;
&#13;
<code class="n">fourgrams</code> <code class="o">=</code> <code class="n">ngrams</code><code class="p">(</code><code class="n">text6</code><code class="p">,</code> <code class="mi">4</code><code class="p">)</code>&#13;
&#13;
<code class="p">[</code><code class="n">f</code> <code class="k">for</code> <code class="n">f</code> <code class="ow">in</code> <code class="n">fourgrams</code> <code class="k">if</code> <code class="n">f</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">==</code> <code class="s1">'coconut'</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>The NLTK library has a vast array of tools and objects designed to organize, count, sort, and measure large swaths of text. Although we’ve barely scratched the surface of their uses, most of these <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="statistical analysis with" data-startref="ntkkys" data-type="indexterm" id="id672"/><a contenteditable="false" data-primary="text" data-secondary="statistical analysis, NLTK" data-startref="stttyk" data-type="indexterm" id="id673"/>tools are well designed and operate rather intuitively for someone familiar with Python.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Lexicographical Analysis with NLTK" data-type="sect2"><div class="sect2" id="id78">&#13;
<h2>Lexicographical Analysis with NLTK</h2>&#13;
&#13;
<p>So far, you’ve compared and categorized all <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="lexicographical analysis with" data-type="indexterm" id="id674"/><a contenteditable="false" data-primary="lexicographical analysis, NLTK" data-type="indexterm" id="id675"/><a contenteditable="false" data-primary="text" data-secondary="lexicographical analysis, NLTK" data-type="indexterm" id="id676"/>the words you’ve encountered based only on the value they represent by themselves. There is no differentiation between homonyms or the context in which the words are used.</p>&#13;
&#13;
<p>Although some people might be tempted to dismiss homonyms as rarely problematic, you might be surprised at how frequently they crop up. Most native English speakers probably don’t often register that a word is a homonym, much less consider that it might be confused for another word in a different context.</p>&#13;
&#13;
<p>“He was objective in achieving his objective of writing an objective philosophy, primarily using verbs in the objective case” is easy for humans to parse but might make a web scraper think the same word is being used four times and cause it to simply discard all the information about the meaning behind each word.</p>&#13;
&#13;
<p>In addition to sussing out parts of speech, being able to distinguish between a word used in one way versus another might be useful. For example, you might want to look for company names made up of common English words, or analyze someone’s opinions about a company. “ACME Products is good” and “ACME Products is not bad” can have the same basic meaning, even if one sentence uses “good” and the other uses “bad.”</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id677">&#13;
<h1>Penn Treebank’s Tags</h1>&#13;
&#13;
<p>NLTK uses a popular system of tagging parts of <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="Penn Treebank project and" data-type="indexterm" id="nkkpt"/><a contenteditable="false" data-primary="Penn Treebank project" data-type="indexterm" id="ptkjc"/>speech developed by the University of Pennsylvania’s <a href="https://catalog.ldc.upenn.edu/docs/LDC95T7/cl93.html ">Penn Treebank Project</a>. Although some of the tags make sense (e.g., CC is a coordinating conjunction), others can be confusing (e.g., RP is a particle). Use the following as a reference for the tags referred to in this section:</p>&#13;
&#13;
<table>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>CC</td>&#13;
			<td>Coordinating conjunction</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>CD</td>&#13;
			<td>Cardinal number</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>DT</td>&#13;
			<td>Determiner</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>EX</td>&#13;
			<td>Existential “there”</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>FW</td>&#13;
			<td>Foreign word</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>IN</td>&#13;
			<td>Preposition, subordinating conjunction</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>JJ</td>&#13;
			<td>Adjective</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>JJR</td>&#13;
			<td>Adjective, comparative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>JJS</td>&#13;
			<td>Adjective, superlative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>LS</td>&#13;
			<td>List item marker</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>MD</td>&#13;
			<td>Modal</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>NN</td>&#13;
			<td>Noun, singular or mass</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>NNS</td>&#13;
			<td>Noun, plural</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>NNP</td>&#13;
			<td>Proper noun, singular</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>NNPS</td>&#13;
			<td>Proper noun, plural</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>PDT</td>&#13;
			<td>Predeterminer</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>POS</td>&#13;
			<td>Possessive ending</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>PRP</td>&#13;
			<td>Personal pronoun</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>PRP$</td>&#13;
			<td>Possessive pronoun</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>RB</td>&#13;
			<td>Adverb</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>RBR</td>&#13;
			<td>Adverb, comparative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>RBS</td>&#13;
			<td>Adverb, superlative</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>RP</td>&#13;
			<td>Particle</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>SYM</td>&#13;
			<td>Symbol</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>TO</td>&#13;
			<td>“to”</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>UH</td>&#13;
			<td>Interjection</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VB</td>&#13;
			<td>Verb, base form</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VBD</td>&#13;
			<td>Verb, past tense</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VBG</td>&#13;
			<td>Verb, gerund or present participle</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VBN</td>&#13;
			<td>Verb, past participle</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VBP</td>&#13;
			<td>Verb, non-third-person singular present</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>VBZ</td>&#13;
			<td>Verb, third person singular present</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>WDT</td>&#13;
			<td>wh-determiner</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>WP</td>&#13;
			<td>Wh-pronoun</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>WP$</td>&#13;
			<td>Possessive wh-pronoun</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>WRB</td>&#13;
			<td>Wh-adverb</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div></aside>&#13;
&#13;
<p>In addition to measuring language, NLTK can assist <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="parts of speech" data-type="indexterm" id="id678"/>in finding meaning in the words based on context and its own sizable dictionaries. At a basic level, NLTK can identify parts of speech:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk.book</code> <code class="kn">import</code> <code class="o">*</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">word_tokenize</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">text</code> <code class="o">=</code> <code class="n">word_tokenize</code><code class="p">(</code><code class="s1">'Strange women lying in ponds distributing swords'</code>\&#13;
<code class="s1">'is no basis for a system of government.'</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">pos_tag</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">pos_tag</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>&#13;
<code class="p">[(</code><code class="s1">'Strange'</code><code class="p">,</code> <code class="s1">'NNP'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'women'</code><code class="p">,</code> <code class="s1">'NNS'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'lying'</code><code class="p">,</code> <code class="s1">'VBG'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'in'</code><code class="p">,</code> <code class="s1">'IN'</code><code class="p">)</code>&#13;
<code class="p">,</code> <code class="p">(</code><code class="s1">'ponds'</code><code class="p">,</code> <code class="s1">'NNS'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'distributing'</code><code class="p">,</code> <code class="s1">'VBG'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'swords'</code><code class="p">,</code> <code class="s1">'NNS'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'is'</code>&#13;
<code class="p">,</code> <code class="s1">'VBZ'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'no'</code><code class="p">,</code> <code class="s1">'DT'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'basis'</code><code class="p">,</code> <code class="s1">'NN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'for'</code><code class="p">,</code> <code class="s1">'IN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'a'</code><code class="p">,</code> <code class="s1">'DT'</code><code class="p">),</code> &#13;
<code class="p">(</code><code class="s1">'system'</code><code class="p">,</code> <code class="s1">'NN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'of'</code><code class="p">,</code> <code class="s1">'IN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'government'</code><code class="p">,</code> <code class="s1">'NN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'.'</code><code class="p">,</code> <code class="s1">'.'</code><code class="p">)]</code></pre>&#13;
&#13;
<p>Each word is separated into a <em>tuple</em> containing the word and a tag identifying the part of speech (see the preceding sidebar for more information about these tags). Although this might seem like a straightforward lookup, the complexity needed to perform the task correctly becomes apparent with the following example:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">text</code> <code class="o">=</code> <code class="n">word_tokenize</code><code class="p">(</code><code class="s1">'The dust was thick so he had to dust'</code><code class="p">)</code>&#13;
<code class="o">&gt;&gt;&gt;</code> <code class="n">pos_tag</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>&#13;
<code class="p">[(</code><code class="s1">'The'</code><code class="p">,</code> <code class="s1">'DT'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'dust'</code><code class="p">,</code> <code class="s1">'NN'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'was'</code><code class="p">,</code> <code class="s1">'VBD'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'thick'</code><code class="p">,</code> <code class="s1">'JJ'</code><code class="p">),</code> &#13;
<code class="p">(</code><code class="s1">'so'</code><code class="p">,</code> <code class="s1">'RB'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'he'</code><code class="p">,</code> <code class="s1">'PRP'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'had'</code><code class="p">,</code> <code class="s1">'VBD'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'to'</code><code class="p">,</code> <code class="s1">'TO'</code><code class="p">),</code> <code class="p">(</code><code class="s1">'dust'</code><code class="p">,</code> <code class="s1">'VB'</code><code class="p">)]</code></pre>&#13;
&#13;
<p>Notice that the word “dust” is used twice in the sentence: once as a noun, and again as a verb. NLTK identifies both usages correctly, based on their context in the sentence. NLTK identifies parts of speech by using a context-free grammar defined by the English language. <em>Context-free grammars</em> are sets of rules that define which things are allowed to follow other things in ordered lists. In this case, they define which parts of speech are allowed to follow other parts of speech. Whenever an ambiguous word such as “dust” is encountered, the rules of the context-free grammar are consulted, and an appropriate part of speech that follows the <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="Penn Treebank project and" data-startref="nkkpt" data-type="indexterm" id="id679"/><a contenteditable="false" data-primary="Penn Treebank project" data-startref="ptkjc" data-type="indexterm" id="id680"/>rules is selected.</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id681">&#13;
<h1>Machine Learning and Machine Training</h1>&#13;
&#13;
<p>You can have NLTK generate brand-new context-free grammars when training it, for example, on a foreign language. If <a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="ML (machine learning) and" data-type="indexterm" id="id682"/><a contenteditable="false" data-primary="ML (machine learning), NLTK and" data-type="indexterm" id="id683"/><a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-secondary="machine training and" data-type="indexterm" id="id684"/><a contenteditable="false" data-primary="machine training, NLTK and" data-type="indexterm" id="id685"/>you tag large sections of text by hand in the language by using the appropriate Penn Treebank tags, you can feed them back into NLTK and train it to properly tag other text it might encounter. This type of training is a necessary component of any machine-learning activity that you will revisit in <a data-type="xref" href="ch16.html#c-16">Chapter 16</a>, when training scrapers to recognize CAPTCHA characters.</p>&#13;
</div></aside>&#13;
&#13;
<p>What’s the point of knowing whether a word is a verb or a noun in a given context? It might be neat in a computer science research lab, but how does it help with web scraping?</p>&#13;
&#13;
<p>A common problem in web scraping deals with search. You might be scraping text off a site and want to search it for instances of the word “google,” but only when it’s being used as a verb, not a proper noun. Or you might be looking only for instances of the company Google and don’t want to rely on people’s correct use of capitalization in order to find those instances. Here, the <code>pos_tag</code> function can be extremely useful:</p>&#13;
&#13;
<pre class="fse fs" data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">nltk</code> <code class="kn">import</code> <code class="n">word_tokenize</code><code class="p">,</code> <code class="n">sent_tokenize</code><code class="p">,</code> <code class="n">pos_tag</code>&#13;
<code class="n">sentences</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="s1">'Google is one of the best companies in the world.'</code><code class="p">,</code>&#13;
    <code class="s1">' I constantly google myself to see what I</code><code class="se">\'</code><code class="s1">m up to.'</code>&#13;
<code class="p">]</code>&#13;
<code class="n">nouns</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'NN'</code><code class="p">,</code> <code class="s1">'NNS'</code><code class="p">,</code> <code class="s1">'NNP'</code><code class="p">,</code> <code class="s1">'NNPS'</code><code class="p">]</code>&#13;
&#13;
<code class="k">for</code> <code class="n">sentence</code> <code class="ow">in</code> <code class="n">sentences</code><code class="p">:</code>&#13;
    <code class="k">for</code> <code class="n">word</code><code class="p">,</code> <code class="n">tag</code> <code class="ow">in</code> <code class="n">pos_tag</code><code class="p">(</code><code class="n">word_tokenize</code><code class="p">(</code><code class="n">sentence</code><code class="p">)):</code>&#13;
        <code class="k">if</code> <code class="n">word</code><code class="o">.</code><code class="n">lower</code><code class="p">()</code> <code class="o">==</code> <code class="s1">'google'</code> <code class="ow">and</code> <code class="n">tag</code> <code class="ow">in</code> <code class="n">nouns</code><code class="p">:</code>&#13;
            <code class="nb">print</code><code class="p">(</code><code class="n">sentence</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>This prints only sentences that contain the word “google” (or “Google”) as some sort of a noun, not a verb. Of course, you could be more specific and demand that only instances of Google tagged with “NNP” (a proper noun) are printed, but even NLTK makes mistakes at times, and it can be good to leave yourself a little wiggle room, depending on the application.</p>&#13;
&#13;
<p>Much of the ambiguity of natural language can be resolved using NLTK’s <code>pos_tag</code> function. By searching text for instances of your target word or phrase <em>plus</em> its tag, you can greatly increase the accuracy and effectiveness of your scraper’s searches.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Additional Resources" data-type="sect1"><div class="sect1" id="id247">&#13;
<h1>Additional Resources</h1>&#13;
&#13;
<p>Processing, analyzing, and understanding natural language by machine is one of the most difficult tasks in computer science, and countless volumes and research papers have been written on the subject. I hope that the coverage here will inspire you to think beyond conventional web scraping, or at least give you some initial direction about where to begin when undertaking a project that requires natural language <span class="keep-together">analysis.</span></p>&#13;
&#13;
<p>Many excellent resources are available on introductory language processing and Python’s Natural Language Toolkit. In particular, Steven Bird, Ewan Klein, and Edward Loper’s book <a class="orm:hideurl" href="http://oreil.ly/1HYt3vV"><em>Natural Language Processing with Python</em></a> (O’Reilly) presents both a comprehensive and introductory approach to the topic.</p>&#13;
&#13;
<p>In addition, James Pustejovsky and Amber Stubbs’ <a class="orm:hideurl" href="http://oreil.ly/S3BudT"><em>Natural Language Annotations for Machine Learning</em></a> (O’Reilly) provides a slightly more advanced theoretical guide. You’ll need knowledge of Python to implement the lessons; the topics covered work perfectly with Python’s Natural Language Toolkit.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id650"><sup><a href="ch12.html#id650-marker">1</a></sup> Although many of the techniques described in this chapter can be applied to all or most languages, it’s OK for now to <a contenteditable="false" data-primary="NLP (natural language processing)" data-type="indexterm" id="id686"/><a contenteditable="false" data-primary="NLTK (Natural Language Toolkit for Python)" data-type="indexterm" id="id687"/>focus on natural language processing in English only. Tools such as Python’s Natural Language Toolkit, for example, focus on English. Some 53% of the internet is still in English (with Spanish following at a mere 5.4%, according to <a href="http://w3techs.com/technologies/overview/content_language/all">W3Techs</a>). But who knows? The hold English has on the majority of the internet will almost certainly change in the future, and further updates may be necessary in the next few years.</p><p data-type="footnote" id="id651"><sup><a href="ch12.html#id651-marker">2</a></sup> Oriol Vinyals et al, <a href="http://bit.ly/1HEJ8kX">“A Picture Is Worth a Thousand (Coherent) Words: Building a Natural Description of Images”</a>, <em>Google Research blog</em>, November 17, 2014.</p><p data-type="footnote" id="id656"><sup><a href="ch12.html#id656-marker">3</a></sup> The exception is the last word in the text, because nothing follows the last word. In our example text, the last word is a period (.), which is convenient because it has 215 other occurrences in the text and so does not represent a dead end. However, in real-world implementations of the Markov generator, the last word of the text might be something you need to account for.</p></div></div></section></body></html>