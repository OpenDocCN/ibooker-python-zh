- en: 12 Future directions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using prompt patterns to write and explain code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current limitations and future directions of generative AI tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this final chapter, we want to give you a glimpse of the creative ways people
    are currently using generative AI tools such as GitHub Copilot and ChatGPT. For
    example, it’s possible to make Copilot Chat ask you the questions, rather than
    the other way around. And it’s possible to make Copilot take on a different persona
    to be even more helpful to your current programming task. We’re going to keep
    this brief, and it’s not clear how much of this will become standard practice,
    but we want to take this opportunity to demonstrate the power of being creative
    with these new tools. We’ll also talk about some of the current limitations of
    generative AI tools (you’ve seen some of them already in this book!) and offer
    our thoughts on what may be next.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1 Prompt patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout the book, we’ve conveyed why programming directly in Python is a
    very different experience compared to programming using Copilot. Rather than writing
    code, our focus shifts to writing prompts and interacting with the generated code
    to determine whether or not it’s correct, and then fixing it if needed. But along
    with those differences, there are surprising similarities between coding without
    Copilot and coding with Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: 'When programmers write code, they don’t start from scratch each time they write
    a new program. Researchers and programmers have created catalogs of design *patterns*,
    that is, general-purpose ways of organizing programs to make them easier to write,
    debug, and extend. The most famous such catalog is a book called *Design Patterns:
    Elements of Reusable Object-Oriented Software* [1], also known as the “Gang of
    Four book” because it was written by four authors. It requires familiarity with
    object-oriented programming, which we haven’t taught in this book, so we don’t
    recommend picking up that book quite yet. Just know that thousands of programmers
    have saved thousands of hours using the patterns in this book and not reinventing
    the wheel.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As just one example of a design pattern, suppose that you’re writing a computer
    game where a human player plays against the computer. You want to implement several
    AI opponents of varying difficulties (e.g., beginner, intermediate, advanced,
    and expert) to provide different skill levels of opponents for the human. Each
    AI opponent will have its own code for determining its behavior. It would be possible
    to use `if` conditions to determine what the AI opponent should do:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The downside to doing it that way, though, is organizational. We’d have all
    the AI code for the various AI opponents in the same place. We know from what
    we’ve learned in this book that huge functions like that aren’t easy to design
    and test.
  prefs: []
  type: TYPE_NORMAL
- en: The clean way to organize this kind of program is using a pattern called the
    *strategy pattern*. We’re not going to go into details of that pattern here, but
    the important thing is that people have documented this pattern [1] for others
    to use. The pattern documentation tells you its intent (purpose), motivation for
    why we would use it, the structure of the code needed to implement it, and example
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Researchers are beginning to catalog patterns that can be used with generative
    AI tools like GitHub Copilot and ChatGPT [2]. They’re called *prompt patterns*,
    and similar to design patterns, they tell you how to construct a prompt to achieve
    a desired goal. The documentation for each of these patterns is similar to the
    documentation for design patterns, but rather than example code, we get example
    prompts that we can use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this book, we’ve spent most of our time on two types of AI responses: generating
    code (by pressing Tab in VS Code) and explaining code (by using Copilot Chat).
    The new prompt patterns that are emerging can help generative AI tools go beyond
    these to help with other code-related tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To give you a flavor of the state of the art in prompt patterns, we’ll sample
    a couple of them here. For many more, we encourage you to check the catalog of
    prompt patterns that we’ve used [2]. Be warned, though: we’re referring you to
    an academic paper, rather than a beginner’s guide because we’re not aware of any
    beginner’s guides at this time (this is still new stuff).'
  prefs: []
  type: TYPE_NORMAL
- en: Copilot Chat may not engage in these prompt patterns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: At the time of writing, Copilot Chat refuses to engage in some of the cataloged
    prompt patterns, claiming that they are unrelated to programming assistance. While
    some may be less specifically related to programming, they are all designed to
    help programmers. Unlike ChatGPT, Copilot has been designed to try to always stay
    squarely on the topic of programming. If you decide to explore the variety of
    patterns further, you may wish to do so using ChatGPT when your interaction with
    Copilot isn’t productive.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.1 Flipped interaction pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To this point, we’ve been the one requesting code and asking questions, and
    Copilot has been the one answering. But it’s possible to flip the script so that
    Copilot does the asking and we do the answering. This is called the *flipped interaction
    pattern*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The intent of this pattern is to help us interact with the AI when we don’t
    know what information it needs to perform a task. The motivation is that the AI
    may know what to ask us to get to its goal faster than if we provided incomplete
    or unhelpful information. The structure of our prompt will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: I would like you to ask me questions to achieve X. You should ask questions
    until we achieve this goal, where X is the goal we’d like to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: This structure isn’t meant to precisely dictate the prompt that we should use.
    Rather, it cues us to the key ideas that we need to convey in the prompt. Here,
    for example, the key ideas are that we want Copilot to ask the questions and that
    we don’t want it to stop until our goal has been achieved.
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 3, we wrote a function to keep asking the user for a password until
    they typed a strong password. Suppose we weren’t sure how to design this function.
    We could ask Copilot to design it for us by providing a code prompt, but then
    it might make decisions that we don’t agree with. Instead, we can have Copilot
    ask us the questions. Let’s use Copilot Chat to do this.
  prefs: []
  type: TYPE_NORMAL
- en: LPHumanI would like a Python function that keeps asking the user for a password
    until they provide a strong password. Ask me questions one at a time until you
    can write that Python function.
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Sure, I’d be happy to help
    you write a Python function that keeps asking the user for a strong password!
    Here are some questions to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: What do you consider to be a strong password?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should the function have any input parameters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What should the function return?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should the function have any side effects, such as printing messages to the
    console?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Should the function have any error handling, such as handling invalid input
    from the user?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copilot failed to follow our instruction to “Ask me questions one at a time.”
    Let’s remind it.
  prefs: []
  type: TYPE_NORMAL
- en: LPHumanAsk me the questions one at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Sure, let’s start with the
    first question:'
  prefs: []
  type: TYPE_NORMAL
- en: What do you consider to be a strong password?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we can start answering the questions. Copilot will use the answers to these
    questions to write the code for us.
  prefs: []
  type: TYPE_NORMAL
- en: LPHumanThe password must have at least one uppercase character, at least one
    number, and at least one punctuation mark.
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Great, thanks for letting me
    know! Here’s the next question:'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Should the function have any input parameters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LPHumanI don’t know. What would they be used for?
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Input parameters are used to
    pass data into a function so that the function can perform some operation on that
    data. For example, if we want to write a function that adds two numbers together,
    we would need to pass those two numbers into the function as input parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of our password function, we might want to pass in some parameters
    that define the requirements for a strong password. For example, we might want
    to pass in the minimum length of the password, the required number of uppercase
    characters, the required number of numbers, and the required number of punctuation
    characters.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, we could hard-code these requirements into the function itself,
    but using input parameters would make the function more flexible and reusable.
  prefs: []
  type: TYPE_NORMAL
- en: LPHumanPlease hard-code them.
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Sure, we can hard-code the
    password requirements into the function itself. Here’s the next question:'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. What should the function return?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LPHumanIt should return the user’s strong password.
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Great, thanks for letting me
    know! Here’s the next question:'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Should the function have any side effects, such as printing messages to
    the console?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’ll stop here as we don’t think it’s interesting to read our full interaction.
    We continued our conversation with Copilot and answered questions 4 and 5, and
    Copilot had the information it needed to write the code we wanted. The code we
    ultimately received, after answering all five questions, is shown in the following
    listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 12.1 Function designed via the flipped interaction pattern
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 There’s no way to make this True condition False!'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 If there’s no uppercase character in the password'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 If there’s no digit character in the password'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 If there’s no punctuation character in the password'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 This is how we get out of the “while True” loop.'
  prefs: []
  type: TYPE_NORMAL
- en: In our `while` loops to this point, we’ve always used a loop condition that
    we hope eventually becomes `False` (otherwise, we’d have an infinite loop). For
    example, we could imagine having a loop that says, in effect, “while the password
    is not valid.” But here, the code is using `while True`, and `True` is a condition
    that can never become `False`. There must be some other way out of the loop—and
    there is! We get out of the loop through a `return` statement when the password
    is valid. That is, instead of “while the password is not valid,” the logic here
    is “loop forever; if the password is valid, stop looping.” The `while True` form
    of `while` loops is a common alternative structure to the style that we’ve seen
    throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: This code does a good job of implementing our task. It starts with some `print`
    calls to tell the user the rules for strong passwords. It also tells the user
    what’s wrong with their password if, in fact, it isn’t strong. It keeps looping
    until the user enters a strong password. And, when we eventually have a strong
    password from the user, we return it.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we already knew how to write this function because of our work in chapter
    3\. And your Python knowledge by this point is sufficiently strong that you can
    cut to the chase and write the function signature for Copilot to write the code
    as we’ve been doing throughout the book. But for tasks with which you’re less
    familiar and may not know where to start, this flipped interaction pattern may
    help.
  prefs: []
  type: TYPE_NORMAL
- en: 12.1.2 Persona pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The intent of this pattern is to have the AI take on a particular persona or
    point of view. Why would we ever be motivated to do this? Well, here’s an example:
    say you’re a student in an introductory Python programming course. Your instructor
    is using Copilot as part of the course, but they are disallowing some Python features
    that they feel detract from learning introductory Python. You could ask Copilot
    to take on the persona of that instructor and then help you check your code to
    find and, if necessary, remove any disallowed Python features. The structure of
    our prompt will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: From now on, act as persona X. Provide outputs that persona X would create.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll fill in X with a particular persona. Let’s try this with our introductory
    programming instructor persona. We’ll ask Copilot to play the part, disallowing
    a list of more advanced Python concepts. (Don’t worry if you’ve never heard of
    these!)
  prefs: []
  type: TYPE_NORMAL
- en: 'LPHumanFrom now on, act as an introductory Python programming instructor. In
    the course that you’re teaching, the following Python features aren’t allowed:
    list comprehensions, generators, “lambda”, and the “any” function. I will provide
    code, and you’ll review the code for any Python features that aren’t allowed and
    suggest how to rewrite the code to not use those features.'
  prefs: []
  type: TYPE_NORMAL
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot Sure, I can do that! Please
    provide the code you would like me to review.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s feed it the `get_strong_password` function from the previous section.
    It uses the `any` function, and by our persona rules, that function isn’t allowed.
    Here’s our original code and what Copilot does in response.
  prefs: []
  type: TYPE_NORMAL
- en: '**LPHuman**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![chatGpt](../Images/chatGpt.png)GitHub Copilot The `get_strong_password` function
    uses the `any` function, which is not allowed in your course. Here’s a modified
    version of the function that does not use the `any` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The loop that replaces “any”'
  prefs: []
  type: TYPE_NORMAL
- en: This version of the function uses a `for` loop to iterate over each character
    in the password and check if it meets the requirements. This approach is more
    verbose than using the `any` function, but it does not use the disallowed Python
    features.
  prefs: []
  type: TYPE_NORMAL
- en: As Copilot Chat indicated, this program doesn’t use the `any` function. Copilot
    has rewritten the program to avoid that function, thereby following the rules
    set by our Python programming persona.
  prefs: []
  type: TYPE_NORMAL
- en: The `any` function returns `True` if one or more values in its argument are
    true, and `False` if all values in its argument are false. Behind the scenes,
    `any` must be looking at each value to check whether it’s true or false. Sounds
    like a loop, right? Indeed, a loop is exactly what Copilot has used here to replace
    the `any` function calls.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2 Limitations and future directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our experience working with Copilot (and students) and reading the research
    literature published while we were writing this book, we’ve observed some limitations
    and future possibilities of generative AI models that we wanted to share.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2.1 Where Copilot (currently) struggles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We found that Copilot struggles in three different types of scenarios: contrived
    problems, ill-defined problems, and large tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Contrived problems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Shortly after ChatGPT and GitHub Copilot took the world by storm, programming
    instructors feverishly worked to find types of tasks that these tools couldn’t
    do well. One early proposal was to use contrived tasks: tasks made obscure and
    convoluted in an attempt to misdirect tools like Copilot to have them generate
    incorrect code. To us, such tasks seem wholly uninteresting and unfair to students,
    and their use seems to be a last-ditch attempt to retain the previous style of
    programming courses without acknowledging the disruption wrought by tools like
    Copilot. Our sense is that these contrived tasks will eventually be solved by
    Copilot as the models continue to improve, but even if they aren’t, these types
    of problems aren’t generally important to solve anyway.'
  prefs: []
  type: TYPE_NORMAL
- en: Ill-defined problems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An ill-defined problem is a problem that hasn’t been precisely specified, meaning
    we don’t exactly know or haven’t decided what we should do in all cases. For example,
    asking Copilot for a function to determine whether a password is strong is ill-defined
    until we define what we mean by “strong password.” Your first thought may be that
    Copilot can’t possibly get better at solving these kinds of problems. After all,
    if we struggle to precisely specify the behavior we want, how are we going to
    communicate the required behavior to Copilot? Ill-defined problems are certainly
    challenging for Copilot, but they aren’t impossible. Remember the flipped interaction
    prompt pattern that we discussed earlier in the chapter? Perhaps, one day soon,
    Copilot will automatically switch into that mode when it doesn’t have enough precision
    from you to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Large tasks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ve spent a lot of time throughout the book teaching you how to design small
    functions and how to organize those functions using top-down design to solve large
    problems. We did this because Copilot struggles when given a monolithic task to
    solve. Is this an inherent limitation of tools like Copilot, or can AI get past
    it? We don’t know. Right now, Copilot struggles with problem decomposition, and
    even if it could get that right, probabilities aren’t in its favor. Specifically,
    it has a higher probability of getting something wrong the more code it writes.
    For example, if it needs to write 20 functions to solve a task with each function
    averaging 10 lines, it’s almost certainly going to make a mistake somewhere. But
    it’s also foolish to bet against these systems. With advancements in how Copilot
    learns, perhaps this isn’t that far off after all.
  prefs: []
  type: TYPE_NORMAL
- en: 12.2.2 Is Copilot a new programming language?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we write computer code in a language like Python, there’s a compiler behind
    the scenes converting the Python to an assembly code or machine code that the
    computer can understand. There was a time when programmers wrote code in an old
    computer language like Fortran or C, ran the compiler to produce code in assembly
    language, and then checked the assembly code to make sure it was correct. We weren’t
    around then, and it probably didn’t happen that much, but we can understand why
    programmers didn’t trust compilers back then. Compilers were a new technology,
    and it took time to work out the bugs. In addition, the code output from compilers
    was probably fairly inefficient compared to handwritten assembly. But after decades
    of improvements both to correctness and efficiency (compiler optimizations are
    a really exciting and interesting topic for anyone curious!), very few programmers
    ever look at the output of compilers. Could there be a point when humans simply
    use large language models (LLMs) as the primary interface to computers and don’t
    spend much time examining the code they produce? Let’s think about both possible
    answers to this question.
  prefs: []
  type: TYPE_NORMAL
- en: Why LLMs may not replace programming languages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are reasons to think LLMs won’t become the primary interface for humans
    to program computers. The principle one is that LLMs aren’t a stringent programming
    language. We trust compilers because there’s a programming language specification
    for each programming language and there’s a specified, exact behavior expected
    from each line of code. LLMs don’t have this. It’s just someone writing English
    or another natural language to an LLM. The LLM isn’t bound to interpret the natural
    language in a particular way. It doesn’t have to output the answer based on any
    rigorous specification. And, randomness and nondeterminism make it so the answer
    it gives us could vary or be wrong! Compilers are deterministic and by now are
    a mature, trusted technology. They don’t face these problems.
  prefs: []
  type: TYPE_NORMAL
- en: Why LLMs may replace programming languages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are also reasons to believe that, like compilers, LLMs will get better
    and become our primary programming interface. In fact, for data science, this
    is already starting to happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we’ve learned throughout the book, a key challenge to working with Copilot
    is determining whether the generated code is correct. In a sense, it isn’t fair
    to nonprogrammers: we give Copilot natural language (our preference), and it gives
    us back code that’s not in a natural language (the computer’s preference). It
    would be nice if we could “skip the code” and use natural language not only to
    communicate with Copilot but to receive our answer.'
  prefs: []
  type: TYPE_NORMAL
- en: Researchers are beginning to explore this possibility in restricted domains
    of interest to millions of computer users. As one example, let’s think about data
    science. Data scientists make sense of data by exploring the data, visualizing
    the data, and using data to make predictions. Much of what they do involves manipulating
    data in constrained, well-understood ways, such as merging spreadsheets, cleaning
    particular columns of data, or conducting analyses such as clustering the data
    into meaningful categories or simplifying data to focus only on its core underlying
    structure. Data scientists who use Python use many libraries to work with their
    data, but one extremely popular library is called pandas.
  prefs: []
  type: TYPE_NORMAL
- en: 'Researchers have successfully “skipped the code” in this context of doing data
    science with pandas [3]. Here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: The user expresses their intent in a natural language such as English.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The AI generates Python code and runs it to get the result (e.g., a table of
    results for an analysis or a new spreadsheet) for the user. Importantly, the user
    doesn’t see this Python code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The AI converts the code back to natural language and presents that (not the
    Python code!) back to the user. The natural language that the user gets back is
    in a consistent format that can be reliably interpreted by the AI. The researchers
    describe the purpose of the response from the AI like this: “This is how you should
    ask the system to do what the system thinks you just asked it to do.” The response
    helps the user understand the capabilities of the AI and the types of queries
    that are effective.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The user can edit the natural language from step 3 if it’s not correct. If the
    user makes an edit, they can submit the new prompt, which repeats the cycle.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An example provided by the researchers clarifies this process [3]. Suppose
    we have a spreadsheet with one astronaut per row. Each row has three relevant
    columns: the astronaut’s name, their total time in space, and a comma-separated
    list of missions that they participated in. We want to calculate the average mission
    length for each astronaut.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In step 1, the user writes a prompt like “calculate average mission length.”
    In step 2, the AI generates code corresponding to that prompt. It runs the code
    and adds a new column to the user’s spreadsheet containing the average mission
    length. In step 3, the AI converts the code to a list of tasks in natural language,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create column “Mission Length.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Column “Space Flight(hr)” divided by (count “,” from column “Missions” + 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In step 4, the user can edit the natural language from step 3 and resubmit the
    updated tasks to the AI. Might we be able to “skip the code” in the far broader
    area of “Python programming” rather than the more restricted setting of “data
    science with pandas”? It’s too early to tell. Data manipulation has the benefit
    of working in a visual medium, with spreadsheets and graphs that can be directly
    presented to the user, who may be able to discern whether the analysis looks correct
    or if further prompt engineering is needed. Such visual representations aren’t
    readily apparent for general-purpose programming.
  prefs: []
  type: TYPE_NORMAL
- en: Still, we can imagine a new era where humans continue to perform important tasks
    like problem decomposition, specifying program behavior, writing tests, designing
    algorithms, and so on but where the programming of functions is entirely done
    using LLMs. The human tells the AI tool what the program is required to do and
    provides the test cases, and the AI generates the code. The human can then check
    that the program works properly without ever needing to see the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'For another take on whether LLMs will replace programming languages, we recommend
    the blog post written by Chris Lattner [4], a programming and compiler expert.
    Lattner argues that, at least in the short term and possibly longer, programming
    languages won’t go away because the code from LLMs can be subtly wrong. So, if
    programming languages are sticking around for a while, the question is: Which
    programming languages should we be using? Lattner says, “The best language for
    an LLM is one that is highly usable and easy to read for humans, but whose implementation
    can scale to many different use cases and applications” [4]. Do existing languages
    meet this goal? Can we do better by designing a programming language that’s easier
    to read than, say, Python? Stay tuned!'
  prefs: []
  type: TYPE_NORMAL
- en: OK, so maybe programming languages go away, or maybe they don’t; maybe they
    change. Regardless, do we need to worry about programmer jobs? We think not. Anyone
    who has worked at a software company will tell you that writing code isn’t the
    only or even main thing that programmers do with their time. Programmers also
    meet with clients to determine what they need. They specify what programs do and
    how they fit together. They check systems for performance and security concerns.
    They work with other teams to coordinate the design of huge pieces of software.
    If the writing code step gets easier, maybe we just get more useful software.
    That’s what happened when we got high-level languages. No one is going to code
    the next killer app in assembly! Compilers improve how we make software. Used
    thoughtfully, we think LLMs can do this too.
  prefs: []
  type: TYPE_NORMAL
- en: An exciting future
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although we’re partially unsure of what’s to come, it’s clear LLMs are going
    to dramatically change the future of programming. Perhaps, for now, they are just
    aids to help software engineers write better code. Perhaps five years from now,
    however, the majority of software will be written by LLMs and only a small subset
    of software engineers will be writing code from scratch. Whichever outcome proves
    true, changes are coming fast, and they’ll likely lead to more people being able
    to write software to meet their needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As of writing, we already have some insights into how these tools are being
    used. In one survey, 92% of software developers reported using these tools on
    a regular basis [5]. Recent studies have found evidence that developers who use
    these tools are more productive than without the tools [6]. In one particularly
    interesting research study conducted at UC San Diego, researchers found that professional
    developers use these tools in two ways: acceleration and exploration [7]. In the
    acceleration phase, developers use these tools to help generate code faster than
    if they wrote it themselves. In the exploration phase, developers use these tools
    to help them find libraries that may be helpful or to understand the existing
    codebase. These findings align with what we’ve been learning in this book, and
    we look forward to the research to come.'
  prefs: []
  type: TYPE_NORMAL
- en: More than anything else, we hope that you’re now able to make your own, informed
    decision on how you’ll use LLMs to program and what LLMs may mean for the future
    of programming. At times like these, with some fervently proclaiming, “Programming
    is over!” and others equally fervently proclaiming, “Programming won’t change
    much at all!” [8], it’s important for us to be able to weigh the arguments ourselves
    and the ways that this change may affect us and everyone else. Can these tools
    help us? We think so. We should therefore use them, but use them responsibly.
    Are there concerns? Again, we think so, as we’ve discussed throughout the book.
    We should take steps, such as testing and debugging, to mitigate those concerns.
  prefs: []
  type: TYPE_NORMAL
- en: The approach to teaching programming that we’ve taken in this book is new. Teachers
    and professors like us have just begun incorporating tools like Copilot into programming
    courses [9], though we’re still working on the balance between when we want learners
    to use Copilot and when we don’t. No matter the balance that programmers choose
    to learn programming, we want to stress to you that you’ve learned absolutely
    essential skills that everyone needs to create good software, whether you’re writing
    code occasionally at work to automate tedious tasks or you’re planning to become
    a professional software engineer. You have a strong foundation going forward,
    wherever your path may take you.
  prefs: []
  type: TYPE_NORMAL
- en: 12.3 Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Explain how the persona pattern can be used to enforce coding standards in a
    company. For example, a company may ask its employees to always use camel case
    (e.g., xVal, ZValOut). Provide an example of a prompt you could use to have GitHub
    Copilot act as a manager enforcing specific coding standards.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You want to create a Python function that generates a username based on a user’s
    preferred username and full name. The function should follow these rules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the preferred username is available (i.e., not already taken), use it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If the preferred username is taken, generate a new username by appending a single
    digit (e.g., 1, 2, 3, … . ) to the preferred username.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If the generated usernames are also taken, use the user’s full name to generate
    a username by combining parts of their first and last name.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The function should keep asking for a new preferred username if the generated
    usernames are also taken.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which interaction pattern (flipped interaction pattern or persona pattern) would
    you use to design this function with the help of GitHub Copilot? Justify your
    choice, and outline how you would start the interaction.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A prompt pattern is a template to help us construct a prompt to meet a given
    goal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The flipped interaction pattern flips the script: rather than posing questions
    to the LLM, the LLM poses questions to us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The flipped interaction pattern is useful when we don’t know how to effectively
    prompt the LLM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The persona pattern is used to have the AI take on a particular persona, such
    as “introductory programming instructor,” or a specific point of view.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The persona pattern is useful when we want the LLM to respond from a given perspective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copilot currently struggles with tasks that are contrived, not well defined,
    or large.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some believe that LLMs will replace programming languages; others believe that
    programming languages are here to stay.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are helping people perform data science tasks without those people ever
    seeing the underlying programming language code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may be that programming languages themselves aren’t replaced, but that the
    leading languages will be developed to be more readable than today’s languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
