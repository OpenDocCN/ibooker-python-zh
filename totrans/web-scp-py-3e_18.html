<html><head></head><body><section data-pdf-bookmark="Chapter 16. Image Processing and Text Recognition" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-16">&#13;
<h1><span class="label">Chapter 16. </span>Image Processing and Text Recognition</h1>&#13;
&#13;
<p>From Google’s self-driving cars to vending machines that recognize counterfeit currency, machine vision is a huge field with far-reaching goals and implications. This chapter focuses on one small aspect of the field: text recognition—specifically, how to recognize and use text-based images found online by using a variety of Python <span class="keep-together">libraries.</span></p>&#13;
&#13;
<p>Using an image in lieu of text is a common technique when you don’t want text to be found and read by bots. This is often seen on contact forms when an email address is partially or completely rendered as an image. Depending on how skillfully it is done, it might not even be noticeable to human viewers, but bots have a difficult time reading these images, and the technique is enough to stop most spammers from acquiring your email address.</p>&#13;
&#13;
<p>CAPTCHAs, of course, take advantage of <a contenteditable="false" data-primary="CAPTCHAs" data-type="indexterm" id="id792"/><a contenteditable="false" data-primary="images" data-secondary="CAPTCHAs" data-type="indexterm" id="id793"/>the fact that users can read security images but most bots can’t. Some CAPTCHAs are more difficult than others, an issue we’ll tackle later in this book.</p>&#13;
&#13;
<p>But CAPTCHAs aren’t the only place on the web where scrapers need image-to-text translation assistance. Even to, many documents are scanned from hard copies and put on the web, making these documents inaccessible as far as much of the internet is concerned, although they are “hiding in plain sight.” Without image-to-text capabilities, the only way to make these documents accessible is for a human to type them up by hand—and nobody has time for that.</p>&#13;
&#13;
<p>Translating images into text <a contenteditable="false" data-primary="images" data-secondary="OCR (optical character recognition)" data-type="indexterm" id="id794"/><a contenteditable="false" data-primary="OCR (optical character recognition)" data-type="indexterm" id="id795"/>is called <em>optical character recognition</em>, or <em>OCR</em>. A few major libraries can perform OCR, and many other libraries support them or are built on top of them. This system of libraries can get fairly complicated, so I recommend you read the next section before attempting any of the exercises in this chapter.</p>&#13;
&#13;
<p>All example images used throughout this chapter can be found in the GitHub repository folder <em>Chapter16_ImageProcessingFiles</em>. For the sake of brevity, all in-text code samples will refer to this directory simply as <em>files</em>.</p>&#13;
&#13;
<section data-pdf-bookmark="Overview of Libraries" data-type="sect1"><div class="sect1" id="id250">&#13;
<h1>Overview of Libraries</h1>&#13;
&#13;
<p>Python is a fantastic language for image processing and reading, image-based machine-learning, and even image creation. Although many libraries can be used for image processing, I’ll focus on two: Pillow and Tesseract.</p>&#13;
&#13;
<p>These two libraries make for a powerful complementary duo when it comes to processing and doing OCR on images from around the web. <em>Pillow</em> performs the first pass, cleaning and filtering images, and <em>Tesseract</em> attempts to match the shapes found in those images to its library of known text.</p>&#13;
&#13;
<p>This chapter covers their installation and basic usage, along with several examples of this library duo working together. I’ll also cover some advanced Tesseract training, so that you can train Tesseract to OCR additional fonts and languages (or even CAPTCHAs) that you might encounter on the web.</p>&#13;
&#13;
<section data-pdf-bookmark="Pillow" data-type="sect2"><div class="sect2" id="id99">&#13;
<h2>Pillow</h2>&#13;
&#13;
<p>Although Pillow might not be the <a contenteditable="false" data-primary="images" data-secondary="libraries" data-tertiary="Pillow" data-type="indexterm" id="id796"/><a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="Pillow" data-type="indexterm" id="id797"/><a contenteditable="false" data-primary="Pillow" data-type="indexterm" id="id798"/><a contenteditable="false" data-primary="libraries" data-secondary="Pillow" data-type="indexterm" id="id799"/>most fully featured image-processing library, it has all the features you are likely to need and then some—unless you plan to rewrite Photoshop in Python, in which case you’re reading the wrong book! Pillow also has the advantage of being one of the better-documented third-party libraries and is extremely easy to use out of the box.</p>&#13;
&#13;
<p>Forked off the Python Imaging Library (PIL) for Python 2.x, Pillow adds support for Python 3.x. Like its <a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="PIL (Python Imaging Library)" data-type="indexterm" id="id800"/><a contenteditable="false" data-primary="libraries" data-secondary="Python" data-tertiary="PIL (Python Imaging Library)" data-type="indexterm" id="id801"/><a contenteditable="false" data-primary="PIL (Python Imaging Library)" data-type="indexterm" id="id802"/><a contenteditable="false" data-primary="Python Imaging Library (PIL)" data-type="indexterm" id="id803"/>predecessor, Pillow allows you to easily import and manipulate images with a variety of filters, masks, and even pixel-specific transformations:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code><code class="p">,</code> <code class="n">ImageFilter</code>&#13;
&#13;
<code class="n">kitten</code> <code class="o">=</code> <code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'kitten.jpg'</code><code class="p">)</code>&#13;
<code class="n">blurryKitten</code> <code class="o">=</code> <code class="n">kitten</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="n">ImageFilter</code><code class="o">.</code><code class="n">GaussianBlur</code><code class="p">)</code>&#13;
<code class="n">blurryKitten</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="s1">'kitten_blurred.jpg'</code><code class="p">)</code>&#13;
<code class="n">blurryKitten</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<p>In the preceding example, the image <em>kitten.jpg</em> will open in your default image viewer with a blur added to it and will also be saved in its blurrier state as <em>kitten_blurred.jpg</em> in the same directory.</p>&#13;
&#13;
<p>You will use Pillow to perform preprocessing on images to make them more machine readable, but as mentioned before, you can do many other things with the library aside from these simple filter applications. For more information, check out the <a href="http://pillow.readthedocs.org">Pillow documentation</a>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Tesseract" data-type="sect2"><div class="sect2" id="id100">&#13;
<h2>Tesseract</h2>&#13;
&#13;
<p>Tesseract is an OCR library. Sponsored <a contenteditable="false" data-primary="images" data-secondary="libraries" data-tertiary="Tesseract" data-type="indexterm" id="igbssc"/><a contenteditable="false" data-primary="Python" data-secondary="libraries" data-tertiary="Tesseract" data-type="indexterm" id="id804"/><a contenteditable="false" data-primary="Tesseract" data-type="indexterm" id="id805"/><a contenteditable="false" data-primary="libraries" data-secondary="Tesseract" data-type="indexterm" id="id806"/><a contenteditable="false" data-primary="OCR (optical character recognition)" data-secondary="Tesseract" data-type="indexterm" id="ocrtsrtc"/><a contenteditable="false" data-primary="Tesseract" data-secondary="OCR and" data-type="indexterm" id="tsccrd"/>by Google (a company obviously well-known for its OCR and machine-learning technologies), Tesseract is widely regarded to be the best, most accurate, open source OCR system available.</p>&#13;
&#13;
<p>In addition to being accurate, it is also extremely flexible. It can be trained to recognize any number of fonts (as long as those fonts are relatively consistent within themselves, as you will see soon). It also can be expanded to recognize any Unicode character.</p>&#13;
&#13;
<p>This chapter uses both the command-line program <em>Tesseract</em> along with its third-party Python wrapper <em>pytesseract</em>. Both will be explicitly named as one of these two, so know that when you see Tesseract, I’m referring to the command-line software, and when you see pytesseract, I’m specifically referring to its third-party Python wrapper.</p>&#13;
&#13;
<section data-pdf-bookmark="Installing Tesseract" data-type="sect3"><div class="sect3" id="id101">&#13;
<h3>Installing Tesseract</h3>&#13;
&#13;
<p>For Windows users, there is a <a contenteditable="false" data-primary="Tesseract" data-secondary="installing" data-type="indexterm" id="tscstl"/><a contenteditable="false" data-primary="libraries" data-secondary="Tesseract" data-tertiary="installing" data-type="indexterm" id="brtssst"/>convenient <a href="https://code.google.com/p/tesseract-ocr/downloads/list">executable installer</a>. As of this writing, the current version is 3.02, although newer versions should be fine as well.</p>&#13;
&#13;
<p>Linux users can install Tesseract with <code>apt-get</code>:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>sudo<code class="w"> </code>apt-get<code class="w"> </code>tesseract-ocr<code class="w"/></pre>&#13;
&#13;
<p>Installing Tesseract on a Mac is slightly more complicated, although it can be done easily with many third-party installers, such as <a href="http://brew.sh">Homebrew</a>, which was used in <a data-type="xref" href="ch09.html#c-9">Chapter 9</a> to install MySQL. For example, you can install Homebrew and use it to install Tesseract in two lines:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>/bin/bash<code class="w"> </code>-c<code class="w"> </code><code class="s2">"</code><code class="k">$(</code>curl<code class="w"> </code>-fsSL<code class="w"> </code>https://raw.githubusercontent.com/Homebrew/install/<code class="se">\</code>&#13;
HEAD/install.sh<code class="k">)</code><code class="s2">"</code><code class="w"/>&#13;
$<code class="w"> </code>brew<code class="w"> </code>install<code class="w"> </code>tesseract<code class="w"/></pre>&#13;
&#13;
<p>Tesseract also can be installed from the source, on the <a href="https://code.google.com/p/tesseract-ocr/downloads/list">project’s download page</a>.</p>&#13;
&#13;
<p>To convert images to text, Tesseract uses machine learning models that have been trained on large datasets in various languages (or sets of characters). To view the available models that come with your installation, use the command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>tesseract<code class="w"> </code>--list-langs<code class="w"/>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">This will print the directory where the models are stored (<em>/usr/local/share</em> on Linux, and <em>/opt/homebrew/share/tessdata/</em> on a Mac installed with HomeBrew) and the models that are available.</p>&#13;
&#13;
<p>After Tesseract is installed, you’re ready to install the Python wrapper library, pytesseract, which uses your <a contenteditable="false" data-primary="pytesseract" data-type="indexterm" id="pytssc"/><a contenteditable="false" data-primary="Tesseract" data-seealso="pytesseract" data-type="indexterm" id="id807"/>existing Tesseract installation to read image files and output strings and objects that can be used in Python scripts.</p>&#13;
&#13;
<p>As usual, you can install pytesseract via pip:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>pip<code class="w"> </code>install<code class="w"> </code>pytesseract<code class="w"/>&#13;
</pre>&#13;
Pytesseract can be used in conjunction with PIL to read text from images:&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code>&#13;
<code class="kn">import</code> <code class="nn">pytesseract</code>&#13;
&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_string</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'files/test.png'</code><code class="p">)))</code>&#13;
</pre>&#13;
&#13;
<p>If pytesseract does not recognize that you have Tesseract installed, you can get the location of your Tesseract installation using the command:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="err">$</code> <code class="n">which</code> <code class="n">tesseract</code></pre>&#13;
&#13;
<p>and, in Python, point pytesseract to the location by including this line:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">pytesseract</code><code class="o">.</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">tesseract_cmd</code> <code class="o">=</code> <code class="s1">'/path/to/tesseract'</code>&#13;
</pre>&#13;
&#13;
<p>Pytesseract has several useful features in addition to returning the OCR results of an image as in the code sample above. It can estimate box files (pixel locations for the boundaries of each character):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_boxes</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'files/test.png'</code><code class="p">)))</code>&#13;
</pre>&#13;
&#13;
<p>It can also return a complete output of all data, such as confidence scores, page and line numbers, box data, as well as other information:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_data</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'files/test.png'</code><code class="p">)))</code>&#13;
</pre>&#13;
&#13;
<p>The default output for these last two files is as space- or tab-delimited string files, but you can also get output as dictionaries or (if decoding in UTF-8 isn’t sufficient) byte strings:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code>&#13;
<code class="kn">import</code> <code class="nn">pytesseract</code>&#13;
<code class="kn">from</code> <code class="nn">pytesseract</code> <code class="kn">import</code> <code class="n">Output</code>&#13;
&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_data</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'files/test.png'</code><code class="p">),</code>&#13;
    <code class="n">output_type</code><code class="o">=</code><code class="n">Output</code><code class="o">.</code><code class="n">DICT</code><code class="p">))</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_string</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'files/test.png'</code><code class="p">),</code>&#13;
    <code class="n">output_type</code><code class="o">=</code><code class="n">Output</code><code class="o">.</code><code class="n">BYTES</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">This chapter uses a combination of the pytesseract library, as well as command-line Tesseract and triggering Tesseract from Python via the <code>subprocess</code> library. Although the pytesseract library is useful and convenient, there <a contenteditable="false" data-primary="Tesseract" data-secondary="installing" data-startref="tscstl" data-type="indexterm" id="id808"/><a contenteditable="false" data-primary="libraries" data-secondary="Tesseract" data-startref="brtssst" data-tertiary="installing" data-type="indexterm" id="id809"/><a contenteditable="false" data-primary="OCR (optical character recognition)" data-secondary="Tesseract" data-startref="ocrtsrtc" data-type="indexterm" id="id810"/><a contenteditable="false" data-primary="pytesseract" data-startref="pytssc" data-type="indexterm" id="id811"/><a contenteditable="false" data-primary="images" data-secondary="libraries" data-startref="igbssc" data-tertiary="Tesseract" data-type="indexterm" id="id812"/><a contenteditable="false" data-primary="Tesseract" data-secondary="OCR and" data-startref="tsccrd" data-type="indexterm" id="id813"/>are some Tesseract functions it cannot do, so it’s good to be familiar with all methods.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="NumPy" data-type="sect2"><div class="sect2" id="id102">&#13;
<h2>NumPy</h2>&#13;
&#13;
<p>While NumPy is not required for <a contenteditable="false" data-primary="NumPy" data-type="indexterm" id="id814"/><a contenteditable="false" data-primary="libraries" data-secondary="NumPy" data-type="indexterm" id="id815"/><a contenteditable="false" data-primary="images" data-secondary="libraries" data-tertiary="NumPy" data-type="indexterm" id="id816"/>straightforward OCR, you will need it if you want to train Tesseract to recognize additional character sets or fonts introduced later in this chapter. You will also be using it for simple math tasks (such as weighted averages) in some of the code samples later in this chapter.</p>&#13;
&#13;
<p>NumPy is a powerful library used for linear algebra and other large-scale math applications. NumPy works well with Tesseract because of its ability to mathematically represent and manipulate images as large arrays of pixels.</p>&#13;
&#13;
<p>NumPy can be installed using any third-party Python installer such as pip, or by <a href="https://pypi.python.org/pypi/numpy">downloading the package</a> and installing with <span class="keep-together"><code>$ python setup.py install</code></span>.</p>&#13;
&#13;
<p>Even if you don’t plan on running any of the code samples that use it, I highly recommend installing it or adding it to your Python arsenal. It serves to round out Python’s built-in math library and has many useful features, particularly for operations with lists of numbers.</p>&#13;
&#13;
<p>By convention, NumPy is imported as <code>np</code> and can be used as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
&#13;
<code class="n">numbers</code> <code class="o">=</code> <code class="p">[</code><code class="mi">100</code><code class="p">,</code> <code class="mi">102</code><code class="p">,</code> <code class="mi">98</code><code class="p">,</code> <code class="mi">97</code><code class="p">,</code> <code class="mi">103</code><code class="p">]</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="n">numbers</code><code class="p">))</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">numbers</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p>This example prints the standard deviation and mean of the set of numbers provided to it.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Processing Well-Formatted Text" data-type="sect1"><div class="sect1" id="id165">&#13;
<h1>Processing Well-Formatted Text</h1>&#13;
&#13;
<p>With any luck, most of the text <a contenteditable="false" data-primary="text" data-secondary="well-formatted" data-type="indexterm" id="id817"/>that you’ll need to process will be relatively clean and well formatted. Well-formatted text generally meets several requirements, although the line between what is “messy” and what is “well formatted” can be subjective.</p>&#13;
&#13;
<p class="pagebreak-before">In general, well-formatted text:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Is written in one standard font (excluding handwriting fonts, cursive fonts, or excessively decorative fonts)</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>If copied or photographed, has extremely crisp lines, with no copying artifacts or dark spots</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Is well aligned, without slanted letters</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Does not run off the image, nor is there cut-off text or margins on the edges of the image</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Some of these things can be fixed in preprocessing. For instance, images can be converted to grayscale, brightness and contrast can be adjusted, and the image can be cropped and rotated as needed. However, some fundamental limitations might require more extensive training. See <a data-type="xref" href="#reading_caps_train_tesser">“Reading CAPTCHAs and Training Tesseract”</a>.</p>&#13;
&#13;
<p><a data-type="xref" href="#tesseract_tiff">Figure 16-1</a> is an ideal example of well-formatted text.</p>&#13;
&#13;
<figure><div class="figure" id="tesseract_tiff"><img alt="Alt Text" class="iimageschapter13text_1png" src="assets/wsp3_1601.png"/>&#13;
<h6><span class="label">Figure 16-1. </span>Sample text saved as a .tiff file, to be read by Tesseract</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the <em>files</em> directory, you can run <a contenteditable="false" data-primary="Tesseract" data-secondary="well-formatted text" data-type="indexterm" id="tsscwfttx"/>Tesseract from the command line to read this file and write the results to a text file:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>tesseract<code class="w"> </code>text.png<code class="w"> </code>textoutput<code class="w"/>&#13;
$<code class="w"> </code>cat<code class="w"> </code>textoutput.txt<code class="w"/></pre>&#13;
&#13;
<p>The output contains the contents of the newly created <em>textoutput.txt</em> file:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
This is some text, written in Arial, that will be read by&#13;
Tesseract. Here are some symbols: !|@#$%&amp;*()&#13;
</pre>&#13;
&#13;
<p>You can see that the results are mostly accurate, although it added an extra pipe character between the <code>!</code> and the <code>@</code>. On the whole, though, this lets you read the text fairly comfortably.</p>&#13;
&#13;
<p>After blurring the image text, creating some JPG compression artifacts, and adding a slight background gradient, the Tesseract’s results get much worse (see <a data-type="xref" href="#bad_jpg">Figure 16-2</a>).</p>&#13;
&#13;
<figure class="pagebreak-before"><div class="figure" id="bad_jpg"><img alt="Alt Text" class="iimageschapter13text_2png" src="assets/wsp3_1602.png"/>&#13;
<h6><span class="label">Figure 16-2. </span>Unfortunately, many of the documents you will encounter on the internet will look more like this than the previous example</h6>&#13;
</div></figure>&#13;
&#13;
<p>Rather than write the results to a file, you can also pass a dash character (<code>-</code>) where the filename would normally be, and Tesseract will echo the results to the terminal:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>tesseract<code class="w"> </code>text_bad.png<code class="w"> </code>-<code class="w"/></pre>&#13;
&#13;
<p>Tesseract is not able to deal with this image nearly as well mainly because of the background gradient and produces the following output:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
This is some text, written In Arlal, that"&#13;
Tesseract. Here are some symbols: _</pre>&#13;
&#13;
<p>Notice that the text is cut off as soon as the background gradient makes the text more difficult to distinguish, and that the last character from each line is wrong, as Tesseract tries futilely to make sense of it. In addition, the JPG artifacts and blurring make it difficult for Tesseract to distinguish between a lowercase <em>i</em> and an uppercase <em>I</em> and the number <em>1</em>.</p>&#13;
&#13;
<p>This is where using a Python script to clean your images first comes in handy. Using the Pillow library, you can create a threshold filter to get rid of the gray in the background, bring out the text, and make the image clearer for Tesseract to read.</p>&#13;
&#13;
<p>In addition, instead of using <a contenteditable="false" data-primary="pytesseract" data-secondary="library" data-type="indexterm" id="id818"/><a contenteditable="false" data-primary="libraries" data-secondary="pytesseract, well-formatted text and" data-type="indexterm" id="id819"/>Tesseract from the command line, you can use the pytesseract library to run the Tesseract commands and read the resulting file:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code>&#13;
<code class="kn">import</code> <code class="nn">pytesseract</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">cleanFile</code><code class="p">(</code><code class="n">filePath</code><code class="p">,</code> <code class="n">newFilePath</code><code class="p">):</code>&#13;
    <code class="n">image</code> <code class="o">=</code> <code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="n">filePath</code><code class="p">)</code>&#13;
&#13;
    <code class="c1">#Set a threshold value for the image, and save</code>&#13;
    <code class="n">image</code> <code class="o">=</code> <code class="n">image</code><code class="o">.</code><code class="n">point</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="mi">0</code> <code class="k">if</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="mi">143</code> <code class="k">else</code> <code class="mi">255</code><code class="p">)</code>&#13;
    <code class="n">image</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">newFilePath</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="n">image</code>&#13;
&#13;
<code class="n">image</code> <code class="o">=</code> <code class="n">cleanFile</code><code class="p">(</code><code class="s1">'files/textBad.png'</code><code class="p">,</code> <code class="s1">'files/textCleaned.png'</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#call tesseract to do OCR on the newly created image</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_string</code><code class="p">(</code><code class="n">image</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p>The resulting image, automatically created as <em>text_cleaned.png</em>, is shown in <a data-type="xref" href="#better_image">Figure 16-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="better_image"><img alt="Alt Text" class="iimageschapter13text_2_cleanpng" src="assets/wsp3_1603.png"/>&#13;
<h6><span class="label">Figure 16-3. </span>This image was created by passing the previous “messy” version of the image through a threshold filter</h6>&#13;
</div></figure>&#13;
&#13;
<p>Apart from some barely legible or missing punctuation, the text is readable, at least to us. Tesseract gives it its best shot:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
This is some text, written In Anal, that will be read by &#13;
Tesseract Here are some symbols: !@#$%"&amp;'()</pre>&#13;
&#13;
<p>The periods and commas, being extremely small, are the first victims of this image wrangling and nearly disappear, both from our view and Tesseract’s. There’s also the unfortunate misinterpretation of “Arial” as “Anal,” the result of Tesseract interpreting the <em>r</em> and the <em>i</em> as the single character <em>n</em>.</p>&#13;
&#13;
<p>Still, it’s an improvement over the previous version, in which nearly half of the text was cut off.</p>&#13;
&#13;
<p>Tesseract’s greatest weakness seems to be backgrounds with varying brightness. Tesseract’s algorithms attempt to adjust the contrast of the image automatically before reading the text, but you can probably get better results doing this yourself with a tool like the Pillow library.</p>&#13;
&#13;
<p>Images you should definitely fix before submitting to Tesseract are those that are tilted, have large areas of nontext, or have other problems.</p>&#13;
&#13;
<section data-pdf-bookmark="Adjusting Images Automatically" data-type="sect2"><div class="sect2" id="id166">&#13;
<h2>Adjusting Images Automatically</h2>&#13;
&#13;
<p>In the previous example, the value 143 was chosen <a contenteditable="false" data-primary="Tesseract" data-secondary="image adjustment" data-type="indexterm" id="trcmgdj"/><a contenteditable="false" data-primary="images" data-secondary="libraries" data-tertiary="Tesseract" data-type="indexterm" id="mgtdj"/>experimentally as the “ideal” threshold to adjust all image pixels to black or white, in order for Tesseract to read the image. But what if you have many images, all with slightly different grayscale problems, and aren’t reasonably able to go and adjust all of them by hand?</p>&#13;
&#13;
<p>One way to find the best solution (or at least, a pretty good one) is to run Tesseract against a range of images adjusted to different values and algorithmically choose the one with the best result, as measured by some combination of the number of characters and/or strings Tesseract is able to read, and the “confidence” with which it reads those characters.</p>&#13;
&#13;
<p>Which algorithm you use, exactly, may vary slightly from application to application, but this is one example of iterating through image-processing thresholds to find the “best” setting:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">pytesseract</code>&#13;
<code class="kn">from</code> <code class="nn">pytesseract</code> <code class="kn">import</code> <code class="n">Output</code>&#13;
<code class="kn">from</code> <code class="nn">PIL</code> <code class="kn">import</code> <code class="n">Image</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">cleanFile</code><code class="p">(</code><code class="n">filePath</code><code class="p">,</code> <code class="n">threshold</code><code class="p">):</code>&#13;
    <code class="n">image</code> <code class="o">=</code> <code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="n">filePath</code><code class="p">)</code>&#13;
    <code class="c1">#Set a threshold value for the image, and save</code>&#13;
    <code class="n">image</code> <code class="o">=</code> <code class="n">image</code><code class="o">.</code><code class="n">point</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="mi">0</code> <code class="k">if</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="n">threshold</code> <code class="k">else</code> <code class="mi">255</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="n">image</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">getConfidence</code><code class="p">(</code><code class="n">image</code><code class="p">):</code>&#13;
    <code class="n">data</code> <code class="o">=</code> <code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_data</code><code class="p">(</code><code class="n">image</code><code class="p">,</code> <code class="n">output_type</code><code class="o">=</code><code class="n">Output</code><code class="o">.</code><code class="n">DICT</code><code class="p">)</code>&#13;
    <code class="n">text</code> <code class="o">=</code> <code class="n">data</code><code class="p">[</code><code class="s1">'text'</code><code class="p">]</code>&#13;
    <code class="n">confidences</code> <code class="o">=</code> <code class="p">[]</code>&#13;
    <code class="n">numChars</code> <code class="o">=</code> <code class="p">[]</code>&#13;
    &#13;
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">text</code><code class="p">)):</code>&#13;
        <code class="k">if</code> <code class="n">data</code><code class="p">[</code><code class="s1">'conf'</code><code class="p">][</code><code class="n">i</code><code class="p">]</code> <code class="o">&gt;</code> <code class="o">-</code><code class="mi">1</code><code class="p">:</code>&#13;
            <code class="n">confidences</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s1">'conf'</code><code class="p">][</code><code class="n">i</code><code class="p">])</code>&#13;
            <code class="n">numChars</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">text</code><code class="p">[</code><code class="n">i</code><code class="p">]))</code>&#13;
            &#13;
    <code class="k">return</code> <code class="n">np</code><code class="o">.</code><code class="n">average</code><code class="p">(</code><code class="n">confidences</code><code class="p">,</code> <code class="n">weights</code><code class="o">=</code><code class="n">numChars</code><code class="p">),</code> <code class="nb">sum</code><code class="p">(</code><code class="n">numChars</code><code class="p">)</code>&#13;
    &#13;
<code class="n">filePath</code> <code class="o">=</code> <code class="s1">'files/textBad.png'</code>&#13;
&#13;
<code class="n">start</code> <code class="o">=</code> <code class="mi">80</code>&#13;
<code class="n">step</code> <code class="o">=</code> <code class="mi">5</code>&#13;
<code class="n">end</code> <code class="o">=</code> <code class="mi">200</code>&#13;
&#13;
<code class="k">for</code> <code class="n">threshold</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">start</code><code class="p">,</code> <code class="n">end</code><code class="p">,</code> <code class="n">step</code><code class="p">):</code>&#13;
    <code class="n">image</code> <code class="o">=</code> <code class="n">cleanFile</code><code class="p">(</code><code class="n">filePath</code><code class="p">,</code> <code class="n">threshold</code><code class="p">)</code>&#13;
    <code class="n">scores</code> <code class="o">=</code> <code class="n">getConfidence</code><code class="p">(</code><code class="n">image</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s2">"threshold: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">threshold</code><code class="p">)</code> <code class="o">+</code> <code class="s2">", confidence: "</code>&#13;
        <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">scores</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code> <code class="o">+</code> <code class="s2">" numChars "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">scores</code><code class="p">[</code><code class="mi">1</code><code class="p">]))</code>&#13;
</pre>&#13;
&#13;
<p>This script has two functions:</p>&#13;
&#13;
<dl>&#13;
	<dt><code>cleanFile</code></dt>&#13;
	<dd>Takes in an original “bad” file and a threshold variable to run the PIL threshold tool with. It processes the file and returns the PIL image object.</dd>&#13;
	<dt><code>getConfidence</code></dt>&#13;
	<dd>Takes in the cleaned PIL image object and runs it through Tesseract. It calculates the average confidence of each recognized string (weighted by the number of characters in that string), as well as the number of recognized characters.</dd>&#13;
</dl>&#13;
&#13;
<p>By varying the threshold value and getting the confidence and number of recognized characters at each value, you get the output:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
threshold: 80, confidence: 61.8333333333 numChars 18&#13;
threshold: 85, confidence: 64.9130434783 numChars 23&#13;
threshold: 90, confidence: 62.2564102564 numChars 39&#13;
threshold: 95, confidence: 64.5135135135 numChars 37&#13;
threshold: 100, confidence: 60.7878787879 numChars 66&#13;
threshold: 105, confidence: 61.9078947368 numChars 76&#13;
threshold: 110, confidence: 64.6329113924 numChars 79&#13;
threshold: 115, confidence: 69.7397260274 numChars 73&#13;
threshold: 120, confidence: 72.9078947368 numChars 76&#13;
threshold: 125, confidence: 73.582278481 numChars 79&#13;
threshold: 130, confidence: 75.6708860759 numChars 79&#13;
threshold: 135, confidence: 76.8292682927 numChars 82&#13;
threshold: 140, confidence: 72.1686746988 numChars 83&#13;
threshold: 145, confidence: 75.5662650602 numChars 83&#13;
threshold: 150, confidence: 77.5443037975 numChars 79&#13;
threshold: 155, confidence: 79.1066666667 numChars 75&#13;
threshold: 160, confidence: 78.4666666667 numChars 75&#13;
threshold: 165, confidence: 80.1428571429 numChars 70&#13;
threshold: 170, confidence: 78.4285714286 numChars 70&#13;
threshold: 175, confidence: 76.3731343284 numChars 67&#13;
threshold: 180, confidence: 76.7575757576 numChars 66&#13;
threshold: 185, confidence: 79.4920634921 numChars 63&#13;
threshold: 190, confidence: 76.0793650794 numChars 63&#13;
threshold: 195, confidence: 70.6153846154 numChars 65&#13;
</pre>&#13;
&#13;
<p>There is a clear trend among both the average confidence in the result, as well as the number of characters recognized. Both tend to peak around a threshold of 145, which is close to the manually found “ideal” result of 143.</p>&#13;
&#13;
<p>Thresholds of both 140 and 145 give the maximum number of recognized characters (83), but a threshold of 145 gives the highest confidence for those found characters, so you may want to go with that result and return the text that was recognized at that threshold as the “best guess” for what text the image contains.</p>&#13;
&#13;
<p>Of course, simply finding the “most” characters does not necessarily mean that all of those characters are real. At some thresholds, Tesseract could split single characters into multiple ones, or interpret random noise in the image as a text character that doesn’t actually exist. In this case, you may want to rely more heavily on the average confidence of each score.</p>&#13;
&#13;
<p>For example, if you find results that read (in part):</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
threshold: 145, confidence: 75.5662650602 numChars 83&#13;
threshold: 150, confidence: 97.1234567890 numChars 82&#13;
</pre>&#13;
&#13;
<p>it would probably be a no-brainer to go with the result that gives you over a 20% increase in confidence, with only a one-character loss, and assume that the result with a threshold of 145 was simply incorrect, or perhaps split a character or found something that wasn’t there.</p>&#13;
&#13;
<p>This is the part where some up-front experimentation to perfect your threshold selection algorithm may come in handy. For instance, you may want to select the score for which the <em>product</em> of the confidence and the number of characters is maximized (in this case, 145 still wins with a product of 6272, and in our imaginary example, the threshold 150 would win with a product of 7964) or some other metric.</p>&#13;
&#13;
<p>Note that this type of selection algorithm also works with arbitrary PIL tool values besides just <code>threshold</code>. You also can use it to select two or more values by varying the values of each and similarly selecting the best resulting score.</p>&#13;
&#13;
<p>Obviously, this type of selection algorithm is computationally intensive. You’re running both PIL and Tesseract many times on every single image, whereas if you know the “ideal” threshold values ahead of time, you have to run them only once.</p>&#13;
&#13;
<p>Keep in mind that, as you start to work with the images you’re processing, you may start to notice patterns in the “ideal” values found. Instead of trying every threshold from 80 to 200, you may realistically need to try only thresholds from 130 to 180.</p>&#13;
&#13;
<p>You may even take another approach and choose thresholds that are, say, 20 apart on the first pass, and then use a greedy algorithm to hone in on the best result by decreasing your step size for thresholds between the “best” solutions found in the previous iteration. This may also <a contenteditable="false" data-primary="Tesseract" data-secondary="image adjustment" data-startref="trcmgdj" data-type="indexterm" id="id820"/>work best when you’re dealing with multiple <span class="keep-together">variables.</span></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Scraping Text from Images on Websites" data-type="sect2"><div class="sect2" id="id103">&#13;
<h2>Scraping Text from Images on Websites</h2>&#13;
&#13;
<p>Using Tesseract to read text from an image on <a contenteditable="false" data-primary="Tesseract" data-secondary="with web scrapers" data-type="indexterm" id="id821"/><a contenteditable="false" data-primary="images" data-secondary="libraries " data-startref="mgtdj" data-tertiary="Tesseract" data-type="indexterm" id="id822"/>your hard drive might not seem all that exciting, but it can be a powerful tool when used with a web scraper. Images can inadvertently obfuscate text on websites (as with the JPG copy of a menu on a local restaurant site), but they can also purposefully hide the text, as I’ll show in the next example.</p>&#13;
&#13;
<p>Although Amazon’s <em>robots.txt</em> file allows scraping of the site’s product pages, book previews typically don’t get picked up by passing bots. That’s because the book previews are loaded via user-triggered Ajax scripts, and the images are carefully hidden in layers of divs and an iframe. Of course, even if you could get to the images, there’s the not-so-small matter of reading them as text.</p>&#13;
&#13;
<p>The following script accomplishes just this feat: it navigates to the large-print edition of Tolstoy’s <em>The Death of Ivan Ilyich</em>, opens the reader, collects image URLs, and then systematically <a contenteditable="false" data-primary="Tesseract" data-secondary="well-formatted text" data-startref="tsscwfttx" data-type="indexterm" id="id823"/>downloads, reads, and prints the text from each one.</p>&#13;
&#13;
<div data-type="note" epub:type="note">&#13;
<h1>Picking a Test Subject</h1>&#13;
&#13;
<p>When it comes to processing fonts it hasn’t <a contenteditable="false" data-primary="Tesseract" data-secondary="fonts" data-type="indexterm" id="tsrcft"/><a contenteditable="false" data-primary="text" data-secondary="fonts, Tessereact" data-type="indexterm" id="xfsrc"/><a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-type="indexterm" id="tssrtrng"/><a contenteditable="false" data-primary="training, Tesseract" data-type="indexterm" id="trngtsct"/>been trained on, Tesseract fares much better with large-format editions of books, especially if the images are small. The next section covers how to train Tesseract on different fonts, which can help it read much smaller font sizes, including previews for non-large-print book editions!</p>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before">Note that this code depends on a live Amazon listing as well as several architectural features of the Amazon website to run correctly. If this listing goes down or is replaced, please fill free to substitute the URL of another book with a Preview feature (I find that large print, sans serif fonts work well).</p>&#13;
&#13;
<p>Because this is relatively complex code that draws on multiple concepts from previous chapters, I’ve added comments throughout to make it a little easier to understand what’s going on:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Retrieve and image URL and read the image as text</code>&#13;
<code class="k">def</code> <code class="nf">image_to_text</code><code class="p">(</code><code class="n">image</code><code class="p">):</code>&#13;
    <code class="n">urlretrieve</code><code class="p">(</code><code class="n">image</code><code class="p">,</code> <code class="s1">'page.jpg'</code><code class="p">)</code>&#13;
    <code class="n">imageList</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">image</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">pytesseract</code><code class="o">.</code><code class="n">image_to_string</code><code class="p">(</code><code class="n">Image</code><code class="o">.</code><code class="n">open</code><code class="p">(</code><code class="s1">'page.jpg'</code><code class="p">)))</code>&#13;
&#13;
<code class="c1"># Create new Selenium driver</code>&#13;
<code class="n">driver</code> <code class="o">=</code> <code class="n">webdriver</code><code class="o">.</code><code class="n">Chrome</code><code class="p">(</code><code class="n">service</code><code class="o">=</code><code class="n">Service</code><code class="p">(</code><code class="n">CHROMEDRIVER_PATH</code><code class="p">))</code>&#13;
&#13;
<code class="n">driver</code><code class="o">.</code><code class="n">get</code><code class="p">(</code>&#13;
    <code class="s1">'https://www.amazon.com/Death-Ivan-Ilyich-Nikolayevich-Tolstoy/</code><code class="se">\</code>&#13;
<code class="s1">dp/1427027277'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Click on the book preview button</code>&#13;
<code class="n">driver</code><code class="o">.</code><code class="n">find_element</code><code class="p">(</code><code class="n">By</code><code class="o">.</code><code class="n">ID</code><code class="p">,</code> <code class="s1">'litb-canvas-click-wrapper'</code><code class="p">)</code><code class="o">.</code><code class="n">click</code><code class="p">()</code>&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="c1"># Wait for iframe to load</code>&#13;
    <code class="n">WebDriverWait</code><code class="p">(</code><code class="n">driver</code><code class="p">,</code> <code class="mi">600</code><code class="p">)</code><code class="o">.</code><code class="n">until</code><code class="p">(</code>&#13;
        <code class="n">EC</code><code class="o">.</code><code class="n">presence_of_element_located</code><code class="p">((</code><code class="n">By</code><code class="o">.</code><code class="n">ID</code><code class="p">,</code> <code class="s1">'litb-read-frame'</code><code class="p">))</code>&#13;
    <code class="p">)</code>&#13;
<code class="k">except</code> <code class="n">TimeoutException</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Did not find the iframe'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Switch to iframe</code>&#13;
<code class="n">frame</code> <code class="o">=</code> <code class="n">driver</code><code class="o">.</code><code class="n">find_element</code><code class="p">(</code><code class="n">By</code><code class="o">.</code><code class="n">ID</code><code class="p">,</code> <code class="s1">'litb-read-frame'</code><code class="p">)</code>&#13;
<code class="n">driver</code><code class="o">.</code><code class="n">switch_to</code><code class="o">.</code><code class="n">frame</code><code class="p">(</code><code class="n">frame</code><code class="p">)</code>&#13;
&#13;
<code class="k">try</code><code class="p">:</code>&#13;
    <code class="n">Wait</code> <code class="k">for</code> <code class="n">preview</code> <code class="n">reader</code> <code class="n">to</code> <code class="n">load</code>&#13;
    <code class="n">WebDriverWait</code><code class="p">(</code><code class="n">driver</code><code class="p">,</code> <code class="mi">600</code><code class="p">)</code><code class="o">.</code><code class="n">until</code><code class="p">(</code>&#13;
        <code class="n">EC</code><code class="o">.</code><code class="n">presence_of_element_located</code><code class="p">((</code><code class="n">By</code><code class="o">.</code><code class="n">ID</code><code class="p">,</code> <code class="s1">'kr-renderer'</code><code class="p">))</code>&#13;
    <code class="p">)</code>&#13;
<code class="k">except</code> <code class="n">TimeoutException</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Did not find the images'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Collect all images inside divs with the "data-page" attribute</code>&#13;
<code class="n">images</code> <code class="o">=</code> <code class="n">driver</code><code class="o">.</code><code class="n">find_elements</code><code class="p">(</code><code class="n">By</code><code class="o">.</code><code class="n">XPATH</code><code class="p">,</code> <code class="s1">'//div[@data-page]/img'</code><code class="p">)</code>&#13;
<code class="k">for</code> <code class="n">image</code> <code class="ow">in</code> <code class="n">images</code><code class="p">:</code>&#13;
    <code class="n">image_url</code> <code class="o">=</code> <code class="n">image</code><code class="o">.</code><code class="n">get_attribute</code><code class="p">(</code><code class="s1">'src'</code><code class="p">)</code>&#13;
    <code class="n">image_to_text</code><code class="p">(</code><code class="n">image_url</code><code class="p">)</code>&#13;
&#13;
<code class="n">driver</code><code class="o">.</code><code class="n">quit</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>Although this script can, in theory, be run with any type of Selenium webdriver, I’ve found that it currently works most reliably with Chrome.</p>&#13;
&#13;
<p>As you have experienced with the Tesseract reader before, this prints many long passages of the book mostly legibly, as seen in the preview of the first chapter:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
Chapter I&#13;
&#13;
During an interval in the Melvinski trial in the large&#13;
building of the Law Courts the members and public&#13;
prosecutor met in Ivan Egorovich Shebek's private&#13;
room, where the conversation turned on the celebrated&#13;
Krasovski case. Fedor Vasilievich warmly maintained&#13;
that it was not subject to their jurisdiction, Ivan&#13;
Egorovich maintained the contrary, while Peter&#13;
Ivanovich, not having entered into the discussion at&#13;
the start, took no part in it but looked through the&#13;
Gazette which had just been handed in.&#13;
&#13;
“Gentlemen,” he said, “Ivan Ilych has died!”&#13;
</pre>&#13;
&#13;
<p>The large print and sans serif font makes for a flawless transcription of the images. In cases where errors in the transcription might occur, they can be fixed by making guesses based on a dictionary word list (perhaps with additions based on relevant proper nouns like “Melvinski”).</p>&#13;
&#13;
<p>Occasionally, an error may span an entire word, such as on page three of the text:</p>&#13;
&#13;
<pre data-code-language="text">&#13;
it is he who is dead and not 1.&#13;
</pre>&#13;
&#13;
<p>In this case the word “I” is replaced by the character “1.” A Markov chain analysis might be useful here, in addition to a word dictionary. If any part of the text contains an extremely uncommon phrase (“and not 1”), it might be assumed that the text was actually the more common phrase (“and not I”).</p>&#13;
&#13;
<p>Of course, it helps that these character substitutions follow predictable patterns: “vi” becomes “w,” and “I” becomes “1.” If these substitutions occur frequently in your text, you might create a list of them that can be used to “try” new words and phrases, selecting the solution that makes the most sense. An approach might be to substitute frequently confused characters, and use a solution that matches a word in a dictionary, or is a recognized (or most common) n-gram.</p>&#13;
&#13;
<p>If you do take this approach, be sure to read <a data-type="xref" href="ch12.html#c-12">Chapter 12</a> for more information about working with text and natural language processing.</p>&#13;
&#13;
<p>Although the text in this example is a common sans serif font and Tesseract should be able to recognize it with relative ease, sometimes a little retraining helps improve the accuracy as well. The next section discusses another approach to solving the problem of mangled text with a little up-front time investment.</p>&#13;
&#13;
<p>By providing Tesseract with a large collection of text images with known values, Tesseract can be “taught” to recognize the same font in the future with far greater precision and accuracy, even despite <a contenteditable="false" data-primary="Tesseract" data-secondary="fonts" data-startref="tsrcft" data-type="indexterm" id="id824"/><a contenteditable="false" data-primary="text" data-secondary="fonts, Tessereact" data-startref="xfsrc" data-type="indexterm" id="id825"/><a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-startref="tssrtrng" data-type="indexterm" id="id826"/>occasional background and positioning problems in the text.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Reading CAPTCHAs and Training Tesseract" data-type="sect1"><div class="sect1" id="reading_caps_train_tesser">&#13;
<h1>Reading CAPTCHAs and Training Tesseract</h1>&#13;
&#13;
<p>Although the word <em>CAPTCHA</em> is familiar <a contenteditable="false" data-primary="Tesseract" data-secondary="CAPTCHAs" data-type="indexterm" id="tsctcpt"/><a contenteditable="false" data-primary="CAPTCHAs" data-secondary="reading" data-type="indexterm" id="cpthtsr"/><a contenteditable="false" data-primary="Completely Automated Public Turing Test to Tell Computers and Human Apart" data-see="CAPTCHAs" data-type="indexterm" id="id827"/>to most, far fewer people know what it stands for: <em>Completely Automated Public Turing Test to Tell Computers and Humans Apart</em>. Its unwieldy acronym hints at its rather unwieldy role in obstructing otherwise perfectly usable web interfaces, as both humans and nonhuman robots often struggle to solve CAPTCHA tests.</p>&#13;
&#13;
<p>The Turing test was first <a contenteditable="false" data-primary="Turing test" data-type="indexterm" id="id828"/><a contenteditable="false" data-primary="Turing, Alan" data-type="indexterm" id="id829"/><a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="Turing test" data-type="indexterm" id="id830"/>described by Alan Turing in his 1950 paper, “Computing Machinery and Intelligence.” In the paper, he described a theoretical scenario in which a human being could communicate with both humans and artificial intelligence programs through a computer terminal. If the human was unable to distinguish the humans from the AI programs during a casual conversation, the AI programs would be considered to have passed the Turing test. The artificial intelligence, Turing reasoned, would be genuinely “thinking” for all intents and purposes.</p>&#13;
&#13;
<p>Seventy years after the theoretical inception of Turing tests, today CAPTCHAs are primarily used to infuriate humans rather than machines. In 2017, Google shut down its iconic  reCAPTCHA due in large part to its tendency to block legitimate website users.<sup><a data-type="noteref" href="ch16.html#id831" id="id831-marker">1</a></sup> &#13;
&#13;
(See <a data-type="xref" href="#fig-16-4">Figure 16-4</a> for an example.) Many other companies followed suit, replacing the traditional text-based CAPTCHAs with alternative bot blockers.</p>&#13;
&#13;
<figure><div class="figure" id="fig-16-4"><img alt="" class="iimageswswp3_16_01jpeg" src="assets/wsp3_1604.png"/>&#13;
<h6><span class="label">Figure 16-4. </span>Text from Google reCAPTCHA, prior to 2017</h6>&#13;
</div></figure>&#13;
&#13;
<p>Although CAPTCHAs have declined somewhat in popularity, they are still commonly used, especially on smaller sites. They are also useful as a source of sample “difficult” text for a computer to read. Perhaps your goal is not solving CAPTCHAs but reading badly scanned PDFs or handwritten notes. The principles are the same.</p>&#13;
&#13;
<p>With that in mind, I’ve created a form that robots are “blocked” from submitting because it requires solving a CAPTCHA: <a href="https://pythonscraping.com/humans-only/"><em class="hyperlink">https://pythonscraping.com/humans-only/</em></a>. In this section, you will train the Tesseract library on its specific font and text variations in order to solve this CAPTCHA with high reliability.</p>&#13;
&#13;
<p>In case you are a robot and have trouble reading this image, “U8DG” is the solution to the CAPTCHA in <a data-type="xref" href="#fig-16-5">Figure 16-5</a>. Tesseract, being a robot, certainly has trouble solving it.</p>&#13;
&#13;
<figure><div class="figure" id="fig-16-5"><img alt="" class="iimageswswp_1602png" src="assets/wsp3_1605.png"/>&#13;
<h6><span class="label">Figure 16-5. </span>The bot-proof captcha at <a href="https://pythonscraping.com/humans-only/"><em class="hyperlink">https://pythonscraping.com/humans-only/</em></a></h6>&#13;
</div></figure>&#13;
&#13;
<pre data-type="programlisting">&#13;
$ tesseract U8DG.png -&#13;
&#13;
u&amp; DS&#13;
</pre>&#13;
&#13;
<p>In this case, Tesseract returns five characters (including a space) and gets only one of the characters, the uppercase D, correctly.</p>&#13;
&#13;
<p>The issue isn’t that Tesseract is bad at reading text, or that this CAPTCHA is too difficult for a computer to comprehend—it’s that this particular handwriting font is dissimilar to the regular English-language fonts that Tesseract has been trained on “out of the box.” Fortunately, it is possible to train it to recognize additional fonts, characters, and languages.</p>&#13;
&#13;
<section data-pdf-bookmark="Training Tesseract" data-type="sect2"><div class="sect2" id="id105">&#13;
<h2>Training Tesseract</h2>&#13;
&#13;
<p>Whether you’re training for CAPTCHAs or <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-type="indexterm" id="id832"/><a contenteditable="false" data-primary="training, Tesseract" data-startref="trngtsct" data-type="indexterm" id="id833"/>any other text, there are a few factors to consider that greatly impact Tesseract’s performance and the approach you might take for training it:</p>&#13;
&#13;
<ul>&#13;
	<li>Do characters overlap in the image, or can you draw a neat rectangle around each character without parts of any other character infringing on this rectangle?</li>&#13;
	<li>Are there multiple variations of the font or style of writing or is only a single font used?</li>&#13;
	<li>Are there any background images, lines, or other distracting garbage in the image?</li>&#13;
	<li>Is there high contrast with clear boundaries between the characters and the background?</li>&#13;
	<li>Is the font a fairly standard serif or sans serif font, or is it an unusual font with random elements and perhaps a “handwriting” style? </li>&#13;
</ul>&#13;
&#13;
<p>If there is some overlap of the characters in some of the text samples, you might consider using only text samples where no overlap occurs. If overlap occurs in every text sample, consider preprocessing to separate characters before training.</p>&#13;
&#13;
<section data-pdf-bookmark="Scraping and preparing images" data-type="sect3"><div class="sect3" id="id167">&#13;
<h3>Scraping and preparing images</h3>&#13;
&#13;
<p>Preprocessing helps remove any <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-tertiary="image scraping" data-type="indexterm" id="trtrgs"/><a contenteditable="false" data-primary="training, Tesseract" data-secondary="image scraping" data-type="indexterm" id="trssgr"/><a contenteditable="false" data-primary="images" data-secondary="Tesseract" data-type="indexterm" id="mgtrtc"/>background junk and improves the color, contrast, and separation of characters in images.</p>&#13;
&#13;
<div data-type="note" epub:type="note">&#13;
<h1>How Many Images Do You Need?</h1>&#13;
&#13;
<p>How many images should you obtain? I recommend about 10 examples per character, or more if there is high variation or randomness in your text. Tesseract does occasionally discard files as being unreadable, for having overlapping boxes, or for other arcane reasons, so you may want some buffer room on top of that. If you find that your OCR results aren’t quite as good as you’d like, or Tesseract is stumbling over certain characters, it’s a good debugging step to create additional training data and try again.</p>&#13;
&#13;
<p>In addition, if there are multiple variations of fonts in the same text sample or if there are other variations involved (randomly tilted or obfuscated text), you may need more training data.</p>&#13;
&#13;
<p>If the font is fairly standard and there are no other severe complicating factors, make sure you’ve tried Tesseract without additional training first! The performance without training may be acceptable for your needs, and training can be a very time-consuming process.</p>&#13;
</div>&#13;
&#13;
<p>Training requires giving Tesseract at least a few examples of each character you want it to be able to recognize. The following downloads 100 sample CAPTCHA images, each containing four characters, for a total of 400 character samples:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
from bs4 import BeautifulSoup&#13;
from urllib.request import urlopen, urlretrieve&#13;
import os &#13;
&#13;
if not os.path.exists('captchas'):&#13;
    os.mkdir('captchas')&#13;
&#13;
for i in range(0, 100):&#13;
    bs = BeautifulSoup(urlopen('https://pythonscraping.com/humans-only/'))&#13;
    imgUrl = bs.find('img', {'class': 'wpcf7-captchac'})['src']&#13;
    urlretrieve(imgUrl, f'captchas/{imgUrl.split("/")[-1]}')    &#13;
</pre>&#13;
&#13;
<p>After reviewing the downloaded training images, it’s time to decide what sort of preprocessing, if any, needs to be done. The images in this CAPTCHA have gray text on a black background. You can write a <code>cleanImage</code> function that transforms this into black text on a white background and adds a white border to make sure each character has separation <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-startref="trtrgs" data-tertiary="image scraping" data-type="indexterm" id="id834"/><a contenteditable="false" data-primary="training, Tesseract" data-secondary="image scraping" data-startref="trssgr" data-type="indexterm" id="id835"/><a contenteditable="false" data-primary="images" data-secondary="Tesseract" data-startref="mgtrtc" data-type="indexterm" id="id836"/>from the edge of the image:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
def cleanImage(imagePath):&#13;
    image = Image.open(imagePath)&#13;
    image = image.point(lambda x: 255 if x&lt;143 else 0)&#13;
    image = ImageOps.expand(image,border=20,fill='white')&#13;
    image.save(imagePath)&#13;
    &#13;
for filename in os.listdir('captchas'):&#13;
    if '.png' in filename:&#13;
        cleanImage(f'captchas/{filename}')</pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Creating box files with the Tesseract trainer project" data-type="sect3"><div class="sect3" id="id106">&#13;
<h3>Creating box files with the Tesseract trainer project</h3>&#13;
&#13;
<p>Next, you need to use these cleaned <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-tertiary="box files" data-type="indexterm" id="tstgxf"/><a contenteditable="false" data-primary="training, Tesseract" data-secondary="box files" data-type="indexterm" id="tgtcxfl"/><a contenteditable="false" data-primary="box files" data-type="indexterm" id="bxfls"/>images to create <em>box files</em>. A box file contains each character in the image on its own line, followed by the bounding box coordinates for that character. For example, a CAPTCHA image with the characters “AK6F” might have the corresponding box file:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
A 32 34 54 58&#13;
K 66 32 91 56&#13;
6 101 34 117 57&#13;
F 135 32 156 57&#13;
</pre>&#13;
&#13;
<p>I’ve created a project at <a href="https://github.com/REMitchell/tesseract-trainer"><em class="hyperlink">https://github.com/REMitchell/tesseract-trainer</em></a> that contains, among other things, a web app that assists in creating these box files. To create box files using this project, follow these steps:</p>&#13;
&#13;
<ol>&#13;
	<li>Rename each CAPTCHA image to its solution. For example, the image containing “AK6F” would be renamed to “AK6F.png.”</li>&#13;
	<li>In the Tesseract trainer project, open the file <em>createBoxes.html</em> in the web browser of your choice. </li>&#13;
	<li>Click the “Add a new file” link and select the multiple image files that you renamed in step 1. </li>&#13;
	<li>The web app will automatically generate boxes based on the image’s name. Drag these boxes around their corresponding character, as shown in &#13;
	<a data-type="xref" href="#1606">Figure 16-6</a>.</li>&#13;
	<li>When you are happy with the placement of the boxes, click “Download .box” to download the box file, and the next image should appear. </li>&#13;
</ol>&#13;
&#13;
<figure><div class="figure" id="1606"><img class="iimageswswp_1604png" src="assets/wsp3_1606.png"/>&#13;
<h6><span class="label">Figure 16-6. </span>Creating box files using the Tesseract trainer tool</h6>&#13;
</div></figure>&#13;
&#13;
<p>As an optional step, I recommend putting on a good podcast or TV show, because it’s going to be a couple of hours of boring work. Exactly how long depends on how many boxes you need to draw.</p>&#13;
&#13;
<p>The next step after creating your box files is to show off all your hard work to Tesseract and let it get training. The end goal of this process is to create a <span class="keep-together"><em>traineddata</em></span> file that you can add to your Tesseract language directory.</p>&#13;
&#13;
<p>In the Tesseract trainer project at <a href="https://github.com/REMitchell/tesseract-trainer"><em class="hyperlink">https://github.com/REMitchell/tesseract-trainer</em></a>, I’ve included a file called trainer.py. This script expects a <em>data</em> directory in the project root with the directories <em>cleaned</em> and <em>box</em> under it:</p>&#13;
&#13;
<ul class="pagebreak-before">&#13;
	<li><em>data</em>&#13;
	<ul>&#13;
		<li><em>cleaned</em>&#13;
		<ul>&#13;
			<li>CAPTCHA images with any preprocessing and cleaning done, with the filenames matching the box files</li>&#13;
		</ul>&#13;
		</li>&#13;
		<li><em>box</em>&#13;
		<ul>&#13;
			<li>Box files, as downloaded from the web app</li>&#13;
		</ul>&#13;
		</li>&#13;
	</ul>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>After creating your folders of <em>.box</em> files and image files, copy this data into a backup folder before doing any further manipulation on it. Although running training scripts over the data is unlikely to delete anything, it’s better safe than sorry when hours worth of work put into <em>.box</em> file creation are involved.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Training Tesseract from box files" data-type="sect3"><div class="sect3" id="id107">&#13;
<h3>Training Tesseract from box files</h3>&#13;
&#13;
<p>Performing the data analysis and creating the training files required for Tesseract involves many steps involves many steps. The <em>trainer.py</em> file does all of them for you.</p>&#13;
&#13;
<p>The initial settings and steps that this program takes can be seen in the <code>__init__</code> and <code>runAll</code> methods of the class:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">CLEANED_DIR</code> <code class="o">=</code> <code class="s1">'cleaned'</code>&#13;
<code class="n">BOX_DIR</code> <code class="o">=</code> <code class="s1">'box'</code>&#13;
<code class="n">EXP_DIR</code> <code class="o">=</code> <code class="s1">'exp'</code>&#13;
<code class="k">class</code> <code class="nc">TesseractTrainer</code><code class="p">():</code>&#13;
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">languageName</code><code class="p">,</code> <code class="n">fontName</code><code class="p">,</code> <code class="n">directory</code><code class="o">=</code><code class="s1">'data'</code><code class="p">):</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">languageName</code> <code class="o">=</code> <code class="n">languageName</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">fontName</code> <code class="o">=</code> <code class="n">fontName</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">directory</code> <code class="o">=</code> <code class="n">directory</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf">runAll</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>&#13;
        <code class="n">os</code><code class="o">.</code><code class="n">chdir</code><code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">directory</code><code class="p">)</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">createDirectories</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">createFontProperties</code><code class="p">()</code>&#13;
        <code class="n">prefixes</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">renameFiles</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">createTrainingFiles</code><code class="p">(</code><code class="n">prefixes</code><code class="p">)</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">extractUnicode</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">runShapeClustering</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">runMfTraining</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">runCnTraining</code><code class="p">()</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">createTessData</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>At the bottom of <em>trainer.py</em> a new <code>TesseractTrainer</code> instance is created and the runAll method is called:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">trainer</code> <code class="o">=</code> <code class="n">TesseractTrainer</code><code class="p">(</code><code class="s1">'captcha'</code><code class="p">,</code> <code class="s1">'captchaFont'</code><code class="p">)</code>&#13;
<code class="n">trainer</code><code class="o">.</code><code class="n">runAll</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">The three attributes passed into the <code>TesseractTrainer</code> object are:</p>&#13;
&#13;
<dl>&#13;
	<dt><code>languageName</code></dt>&#13;
	<dd>The three-letter language code that Tesseract uses to keep track of languages. For specific training scenarios, I prefer to create a new language rather than combine it or use it to replace Tesseract’s pre-trained English data. </dd>&#13;
	<dt><code>fontName</code></dt>&#13;
	<dd>The name for your chosen font. This can be anything, but it must be a single word without spaces. In practice, this is just for internal purposes during training, and you’re unlikely to see it or need to reference it.</dd>&#13;
	<dt><code>directory</code></dt>&#13;
	<dd>The directory name containing the directories of your cleaned images and box files. By default, this is data. If you have multiple projects, you can pass in a unique data directory name for each project to keep everything organized.</dd>&#13;
</dl>&#13;
&#13;
<p>Let’s look at some of the individual methods used.</p>&#13;
&#13;
<p><code>createDirectories</code> does some initial housekeeping and creates subdirectories such as the <em>exp</em> directory, which will later store the trained files.</p>&#13;
&#13;
<p><code>createFontProperties</code> creates a required file, <em>font_properties</em>, that lets Tesseract know about the new font you are creating:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
captchaFont 0 0 0 0 0</pre>&#13;
&#13;
<p>This file consists of the name of the font, followed by 1s and 0s indicating whether italic, bold, or other versions of the font should be considered. Training fonts with these properties is an interesting exercise but unfortunately outside the scope of this book.</p>&#13;
&#13;
<p><code>renameFiles</code> renames all your <em>.box</em> files and their corresponding image files with the names required by Tesseract (the file numbers here are sequential digits to keep multiple files separate):</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p><em>&lt;languageName&gt;.&lt;fontName&gt;.exp&lt;fileNumber&gt;.box</em></p>&#13;
	</li>&#13;
	<li>&#13;
	<p><em>&lt;languageName&gt;.&lt;fontName&gt;.exp&lt;fileNumber&gt;.tiff</em></p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p><code>extractUnicode</code> looks at all of the created <em>.box</em> files and determines the total set of characters available to be trained. The resulting Unicode file will tell you how many different characters you’ve found and could be a good way to quickly see if you’re missing anything.</p>&#13;
&#13;
<p class="pagebreak-before">The next three functions, <code>runShapeClustering</code>, <code class="keep-together">runMfTraining</code>, and <code>runCtTraining</code>, create the files <code>shapetable</code>, <code>pfftable</code>, and <code>normproto</code>, respectively. These all provide information about the geometry and shape of each character, as well as provide statistical information that Tesseract uses to calculate the probability that a given character is one type or another.</p>&#13;
&#13;
<p>Finally, Tesseract renames each of the compiled data folders to be prepended by the required language name (e.g., <em>shapetable</em> is renamed to <em>cap.shapetable</em>) and compiles all of those <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-startref="tstgxf" data-tertiary="box files" data-type="indexterm" id="id837"/><a contenteditable="false" data-primary="training, Tesseract" data-secondary="box files" data-startref="tgtcxfl" data-type="indexterm" id="id838"/><a contenteditable="false" data-primary="box files" data-startref="bxfls" data-type="indexterm" id="id839"/>files into the final training data file <em>cap.traineddata</em>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Using traineddata files with Tesseract" data-type="sect3"><div class="sect3" id="id108">&#13;
<h3>Using traineddata files with Tesseract</h3>&#13;
&#13;
<p>The <em>traineddata</em> file is the main <a contenteditable="false" data-primary="Tesseract" data-secondary="training" data-tertiary="traineddata files" data-type="indexterm" id="id840"/><a contenteditable="false" data-primary="training, Tesseract" data-secondary="traineddata files" data-type="indexterm" id="id841"/><a contenteditable="false" data-primary="traineddata files, Tesseract" data-type="indexterm" id="id842"/>output of this entire process. This file tells Tesseract how to identify characters in the training dataset you’ve given it. To use the file, you need to move it to your <em>tessdata</em> root folder.</p>&#13;
&#13;
<p>You can find this folder using the following command:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>tesseract<code class="w"> </code>--list-langs<code class="w"/></pre>&#13;
&#13;
<p>This will provide some output like:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
List<code class="w"> </code>of<code class="w"> </code>available<code class="w"> </code>languages<code class="w"> </code><code class="k">in</code><code class="w"> </code><code class="s2">"/opt/homebrew/share/tessdata/"</code><code class="w"> </code><code class="o">(</code><code class="m">3</code><code class="o">)</code>:<code class="w"/>&#13;
eng<code class="w"/>&#13;
osd<code class="w"/>&#13;
snum<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>Then set the <code>TESSDATA_PREFIX</code> environment variable to this directory:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code><code class="nb">export</code><code class="w"> </code><code class="nv">TESSDATA_PREFIX</code><code class="o">=</code>/opt/homebrew/share/tessdata/<code class="w"/></pre>&#13;
&#13;
<p>Finally, move your new <em>traineddata</em> file to the <em>languages</em> directory:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>cp<code class="w"> </code>data/exp/cap.traineddata<code class="w"> </code><code class="nv">$TESSDATA_PREFIX</code>/cap.traineddata<code class="w"/>&#13;
</pre>&#13;
&#13;
<p>After the new <em>traineddata</em> file is in place, Tesseract should recognize it automatically as a new language and be able to solve new CAPTCHAs it’s presented with:</p>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>tesseract<code class="w"> </code>-l<code class="w"> </code>captcha<code class="w"> </code>U8DG.png<code class="w"> </code>-<code class="w"/>&#13;
&#13;
U8DG<code class="w"/></pre>&#13;
&#13;
<p>Success! A significant improvement over the previous interpretation of the image as <code>u&amp; DS</code>.</p>&#13;
&#13;
<p>This is just a quick overview of the full power of Tesseract’s font training and recognition capabilities. If you are interested in extensively training Tesseract, perhaps starting your own library of CAPTCHA training files, or sharing new font recognition capabilities with the world, I recommend checking out the <a href="https://github.com/tesseract-ocr/tesseract">documentation</a>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Retrieving CAPTCHAs and Submitting Solutions" data-type="sect1"><div class="sect1" id="id168">&#13;
<h1>Retrieving CAPTCHAs and Submitting Solutions</h1>&#13;
&#13;
<p>Many popular content management <a contenteditable="false" data-primary="CAPTCHAs" data-secondary="retrieving" data-type="indexterm" id="cpchrv"/>systems are frequently spammed with registrations by bots that are preprogrammed with the well-known location of these user registration pages. On <a href="http://pythonscraping.com"><em>http://pythonscraping.com</em></a>, for instance, even a CAPTCHA (admittedly, weak) does little to put a damper on the influx of registrations.</p>&#13;
&#13;
<p>So how do these bots do it? You’ve successfully solved CAPTCHAs in images sitting around on your hard drive, but how do you make a fully functioning bot? This section ties together many techniques covered in previous chapters. If you haven’t already, you should at least skim <a data-type="xref" href="ch13.html#c-13">Chapter 13</a>.</p>&#13;
&#13;
<p>Most image-based CAPTCHAs have several properties:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>They are dynamically generated images, created by a server-side program. They might have image sources that do not look like traditional images, such as <code>&lt;img src="WebForm.aspx?id=8AP85CQKE9TJ"&gt;</code>, but can be downloaded and manipulated like any other image.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The solution to the image is stored in a server-side database.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Many CAPTCHAs time out if you take too long to solve them. This usually isn’t a problem for bots, but queuing CAPTCHA solutions for later use, or other practices that may delay the time between when the CAPTCHA was requested and when the solution is submitted, may not be successful.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>The general approach to this is to download the CAPTCHA image file to your hard drive, clean it, use Tesseract to parse the image, and return the solution under the appropriate form parameter.</p>&#13;
&#13;
<p>I’ve created a page at <a href="http://pythonscraping.com/humans-only"><em>http://pythonscraping.com/humans-only</em></a> with a CAPTCHA-protected comment form for the purpose of writing a bot to defeat. This bot uses the command-line Tesseract library, rather than the pytesseract wrapper, although either could be used.</p>&#13;
&#13;
<p>To start, load the page and find the location of a hidden token that needs to be POSTed with the rest of the form data:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'https://www.pythonscraping.com/humans-only'</code><code class="p">)</code>&#13;
<code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
<code class="c1">#Gather prepopulated form values</code>&#13;
<code class="n">hiddenToken</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code>&#13;
    <code class="s1">'input'</code><code class="p">,</code>&#13;
    <code class="p">{</code><code class="s1">'name'</code><code class="p">:</code><code class="s1">'_wpcf7_captcha_challenge_captcha-170'</code><code class="p">}</code>&#13;
<code class="p">)[</code><code class="s1">'value'</code><code class="p">]</code></pre>&#13;
&#13;
<p>This hidden token also happens to be the filename of the CAPTCHA image presented on the page, which makes writing the <code>getCaptchaSolution</code> function relatively straightforward:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="k">def</code> <code class="nf">getCaptchaSolution</code><code class="p">(</code><code class="n">hiddenToken</code><code class="p">):</code>&#13;
    <code class="n">imageLocation</code> <code class="o">=</code> <code class="sa">f</code><code class="s1">'https://pythonscraping.com/wp-content/</code><code class="se">\</code>&#13;
<code class="s1">uploads/wpcf7_captcha/</code><code class="si">{</code><code class="n">hiddenToken</code><code class="si">}</code><code class="s1">.png'</code>&#13;
    <code class="n">urlretrieve</code><code class="p">(</code><code class="n">imageLocation</code><code class="p">,</code> <code class="s1">'captcha.png'</code><code class="p">)</code>&#13;
    <code class="n">cleanImage</code><code class="p">(</code><code class="s1">'captcha.png'</code><code class="p">)</code>&#13;
    <code class="n">p</code> <code class="o">=</code> <code class="n">subprocess</code><code class="o">.</code><code class="n">Popen</code><code class="p">(</code>&#13;
        <code class="p">[</code><code class="s1">'tesseract'</code><code class="p">,</code><code class="s1">'-l'</code><code class="p">,</code> <code class="s1">'captcha'</code><code class="p">,</code> <code class="s1">'captcha.png'</code><code class="p">,</code> <code class="s1">'output'</code><code class="p">],</code>&#13;
        <code class="n">stdout</code><code class="o">=</code><code class="n">subprocess</code><code class="o">.</code><code class="n">PIPE</code><code class="p">,</code><code class="n">stderr</code><code class="o">=</code><code class="n">subprocess</code><code class="o">.</code><code class="n">PIPE</code>&#13;
    <code class="p">)</code>&#13;
    <code class="n">p</code><code class="o">.</code><code class="n">wait</code><code class="p">()</code>&#13;
    <code class="n">f</code> <code class="o">=</code> <code class="nb">open</code><code class="p">(</code><code class="s1">'output.txt'</code><code class="p">,</code> <code class="s1">'r'</code><code class="p">)</code>&#13;
&#13;
    <code class="c1">#Clean any whitespace characters</code>&#13;
    <code class="n">captchaResponse</code> <code class="o">=</code> <code class="n">f</code><code class="o">.</code><code class="n">read</code><code class="p">()</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">' '</code><code class="p">,</code> <code class="s1">''</code><code class="p">)</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="s1">''</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Captcha solution attempt: '</code><code class="o">+</code><code class="n">captchaResponse</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="n">captchaResponse</code>&#13;
</pre>&#13;
&#13;
<p>Note that this script will fail under two conditions: if Tesseract did not extract exactly four characters from the image (because we know that all valid solutions to this CAPTCHA must have four characters), or if it submits the form but the CAPTCHA was solved incorrectly.</p>&#13;
&#13;
<p>In the first case, you can reload the page and try again, likely with no penalty from the web server. In the second case, the server might take note that you’re solving CAPTCHAs incorrectly and penalize you. Many servers, on multiple failed CAPTCHA attempts, will block the user or subject them to more rigorous screening.</p>&#13;
&#13;
<p>Of course, as the owner of this particular server I can attest to the fact that it’s extremely forgiving and unlikely to block you!</p>&#13;
&#13;
<p>The form data itself is relatively lengthy and can be viewed in full in the GitHub repository or in your browser’s network inspector tools when submitting the form yourself. Checking the length of the CAPTCHA solution and submitting it using the Requests library is fairly straightforward, however:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">captcha_solution</code><code class="p">)</code> <code class="o">==</code> <code class="mi">4</code><code class="p">:</code>&#13;
    <code class="n">formSubmissionUrl</code> <code class="o">=</code> <code class="s1">'https://pythonscraping.com/wp-json/contact-form-7/v1/</code><code class="se">\</code>&#13;
<code class="s1">contact-forms/93/feedback'</code>&#13;
    <code class="n">headers</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'Content-Type'</code><code class="p">:</code> <code class="s1">'multipart/form-data;boundary=----WebKitFormBou</code><code class="se">\</code>&#13;
<code class="s1">ndaryBFvsPGsghJe0Esco'</code><code class="p">}</code>&#13;
    <code class="n">r</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="n">formSubmissionUrl</code><code class="p">,</code> <code class="n">data</code><code class="o">=</code><code class="n">form_data</code><code class="p">,</code> <code class="n">headers</code><code class="o">=</code><code class="n">headers</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="n">r</code><code class="o">.</code><code class="n">text</code><code class="p">)</code>&#13;
<code class="k">else</code><code class="p">:</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'There was a problem reading the CAPTCHA correctly!'</code><code class="p">)</code></pre>&#13;
&#13;
<p class="pagebreak-before">If the CAPTCHA solution was correct (and it usually is), you should expect to see something like the following printed out:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">Captcha</code> <code class="n">solution</code> <code class="n">attempt</code><code class="p">:</code> <code class="n">X9SU</code>&#13;
<code class="p">{</code><code class="s2">"contact_form_id"</code><code class="p">:</code><code class="mi">93</code><code class="p">,</code><code class="s2">"status"</code><code class="p">:</code><code class="s2">"mail_sent"</code><code class="p">,</code><code class="s2">"message"</code><code class="p">:</code>&#13;
<code class="s2">"Thank you for your message. It has been sent."</code><code class="p">,</code>&#13;
<code class="s2">"posted_data_hash"</code><code class="p">:</code><code class="s2">"2bc8d1e0345bbfc281eac0410fc7b80d"</code><code class="p">,</code>&#13;
<code class="s2">"into"</code><code class="p">:</code><code class="s2">"#wpcf7-f93-o1"</code><code class="p">,</code><code class="s2">"invalid_fields"</code><code class="p">:[],</code><code class="s2">"captcha"</code><code class="p">:</code>&#13;
<code class="p">{</code><code class="s2">"captcha-170"</code><code class="p">:</code>&#13;
<code class="s2">"https:\/\/pythonscraping.com\/wp-content\/uploads</code><code class="w"/>&#13;
\<code class="o">/</code><code class="n">wpcf7_captcha</code>\<code class="o">/</code><code class="mf">3551342528.</code><code class="n">png</code><code class="s2">"}}</code><code class="w"/></pre>&#13;
&#13;
<p>While CAPTCHAs are not as common as they were 10 or 20 years ago, they are still used by many sites, and knowing how to handle <a contenteditable="false" data-primary="CAPTCHAs" data-secondary="retrieving" data-startref="cpchrv" data-type="indexterm" id="id843"/>them is important. In addition, the skills gained by working with CAPTCHA solving easily translate to other image-to-text scenarios you may encounter.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id831"><sup><a href="ch16.html#id831-marker">1</a></sup> See Rhett Jones, “Google Has Finally Killed the CAPTCHA,” Gizmodo, March 11, 2017, <a href="https://gizmodo.com/google-has-finally-killed-the-captcha-1793190374"><em>https://gizmodo.com/google-has-finally-killed-the-captcha-1793190374</em></a>.</p></div></div></section></body></html>