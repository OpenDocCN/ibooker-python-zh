["```py\nimport socks\nimport socket\nfrom urllib.request import urlopen\n\nsocks.set_default_proxy(socks.PROXY_TYPE_SOCKS5, \"localhost\", 9150)\nsocket.socket = socks.socksocket\nprint(urlopen('http://icanhazip.com').read())\n\n```", "```py\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import Options\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nCHROMEDRIVER_PATH = ChromeDriverManager().install()\ndriver = webdriver.Chrome(service=Service(CHROMEDRIVER_PATH))\nchrome_options = Options()\nchrome_options.add_argument('--headless')\nchrome_options.add_argument('--proxy-server=socks5://127.0.0.1:9150')\ndriver = webdriver.Chrome(\n    service=Service(CHROMEDRIVER_PATH),\n    options=chrome_options\n)\n\ndriver.get('http://icanhazip.com')\nprint(driver.page_source)\ndriver.close()\n\n```", "```py\nHandler: cgi-script\nExtension(s): .py\n```", "```py\nimport requests\nimport time \n\nstart = time.time()\nparams = {\n    'api_key': SCRAPING_BEE_KEY,\n    'url': 'https://www.target.com/p/-/A-83650487',\n}\nresponse = requests.get('https://app.scrapingbee.com/api/v1/', params=params)\n\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.content}')\n\n```", "```py\n$ pip install scrapingbee\n```", "```py\nfrom scrapingbee import ScrapingBeeClient\n\nstart = time.time()\nclient = ScrapingBeeClient(api_key=SCRAPING_BEE_KEY)\nresponse = client.get('https://www.target.com/p/-/A-83650487')\n\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.content}')\n\n```", "```py\nclient = ScrapingBeeClient(api_key=SCRAPING_BEE_KEY)\nparams = {'render_js': 'false'}\nresponse = client.get('https://www.target.com/p/-/A-83650487', params=params)\n```", "```py\nimport requests\nimport time \n\nstart = time.time()\nparams = {\n    'api_key': SCRAPER_API_KEY,\n    'url': 'https://www.target.com/p/-/A-83650487'\n}\nresponse = requests.get('http://api.scraperapi.com', params=params)\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.content}')\n\n```", "```py\n$ pip install scraperapi-sdk\n```", "```py\nfrom scraper_api import ScraperAPIClient\n\nclient = ScraperAPIClient(SCRAPER_API_KEY)\nstart = time.time()\nresult = client.get('https://www.target.com/p/-/A-83650487')\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.content}')\n\n```", "```py\nclass RyansAPIClient:\n    def __init__(self, key):\n        self.key = key\n        self.api_root = 'http://api.pythonscraping.com/ryansApiPath'\n\n    def get(url):\n        params = {'key': self.key, 'url': url}\n        return requests.get(self.api_root, params=params)\n\n```", "```py\nfrom scraper_api import ScraperAPIClient\n\nclient = ScraperAPIClient(SCRAPER_API_KEY)\nstart = time.time()\nresult = client.get('https://www.amazon.com/Web-Scraping-Python-Collecting\\\n-Modern/dp/1491985577')\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.text}')\n\n```", "```py\nTime: 4.672130823135376\nHTTP status: 200\nResponse body: {\"name\":\"Web Scraping with Python: Collecting More \nData from the Modern Web\",\"product_information\":{\"publisher\":\n\"‎O'Reilly Media; 2nd edition (May 8, 2018)\",\"language\":\"‎English\",\n\"paperback\":\"‎306 pages\",\"isbn_10\":\"‎1491985577\",\"isbn_13\":\n\"‎978-1491985571\",\"item_weight\":\"‎1.21 pounds\" ...\n```", "```py\nstart = time.time()\nparams = {\n    'apiKey': SCRAPER_API_KEY,\n    'url': 'https://www.target.com/p/-/A-83650487'\n}\nresponse = requests.post('https://async.scraperapi.com/jobs', json=params)\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response.status_code}')\nprint(f'Response body: {response.content}')\n```", "```py\nTime: 0.09664416313171387\nHTTP status: 200\nResponse body: b'{\"id\":\"728a365b-3a2a-4ed0-9209-cc4e7d88de96\",\n\"attempts\":0,\"status\":\"running\",\"statusUrl\":\"https://async.\nscraperapi.com/jobs/728a365b-3a2a-4ed0-9209-cc4e7d88de96\",\n\"url\":\"https://www.target.com/p/-/A-83650487\"}'\n```", "```py\nresponse = requests.get('https://async.scraperapi.com/jobs/\\\n 728a365b-3a2a-4ed0-9209-cc4e7d88de96')\nprint(f'Response body: {response.content}')\n\n```", "```py\nimport requests\nimport time\n\nstart = time.time()\ndata = {\n    'url': 'https://www.target.com/p/-/A-83650487',\n    'source': 'universal',\n}\n\nresponse = requests.post(\n    'https://realtime.oxylabs.io/v1/queries',\n    auth=(OXYLABS_USERNAME, OXYLABS_PASSWORD),\n    json=data\n)\n\nresponse = response.json()['results'][0]\n\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response[\"status_code\"]}')\nprint(f'Response body: {response[\"content\"]}')\n\n```", "```py\ndata = {\n    'url': 'https://www.amazon.com/Web-Scraping-Python-Collecting-Modern\\\n-dp-1491985577/dp/1491985577',\n    'source': 'universal',\n}\n\nresponse = requests.post(\n    'https://realtime.oxylabs.io/v1/queries',\n    auth=(OXYLABS_USERNAME, OXYLABS_PASSWORD),\n)\nprint(response.json())\n\n```", "```py\n{'message': 'provided url is not supported'}\n```", "```py\ndata = {\n    'url': 'https://www.amazon.com/Web-Scraping-Python-Collecting-Modern\\\n-dp-1491985577/dp/1491985577',\n    'source': 'amazon',\n}\n\nresponse = requests.post(\n    'https://realtime.oxylabs.io/v1/queries',\n    auth=(OXYLABS_USERNAME_ECOMMERCE, OXYLABS_PASSWORD),\n    json=data\n)\n\n```", "```py\ndata = {\n    'url': 'https://www.amazon.com/Web-Scraping-Python-Collecting-Modern\\\n-dp-1491985577/dp/1491985577',\n    'source': 'amazon',\n    'parse': True\n}\n```", "```py\n...\n'page': 1,\n'price': 32.59,\n'stock': 'Only 7 left in stock - order soon',\n'title': 'Web Scraping with Python: Collecting More Data from the Modern Web',\n'buybox': [{'name': 'buy_new', 'price': 32.59, 'condition': 'new'},\n...\n\n```", "```py\ndata = {\n    'url': 'https://www.target.com/p/-/A-83650487',\n    'source': 'universal',\n    'parse': True\n}\n\nresponse = requests.post(\n    'https://realtime.oxylabs.io/v1/queries',\n    auth=(OXYLABS_USERNAME, OXYLABS_PASSWORD),\n    json=data\n)\n\n```", "```py\n'url': 'https://www.target.com/p/-/A-83650487',\n'price': 44.99,\n'title': 'Web Scraping with Python - 2nd Edition by  Ryan Mitchell (Paperback)',\n'category': 'Target/Movies, Music & Books/Books/All Book Genres/Computers & Techn\nology Books',\n'currency': 'USD',\n'description': 'Error while parsing `description`: `(<class \\'AttributeError\\'>, \nAttributeError(\"\\'NoneType\\' object has no attribute \\'xpath\\'\"))`.', 'rating_sco\nre': 0, 'parse_status_code': 12004\n```", "```py\ndata = {\n    'query': 'foo',\n    'source': 'bing_search',\n}\n```", "```py\ndata = {\n    'url': 'https://bing.com?q=foo',\n    'source': 'bing',\n}\n```", "```py\nimport time\nfrom base64 import b64decode\nimport requests\n\njson_data = {\n    'url': 'https://www.target.com/p/-/A-83650487',\n    'httpResponseBody': True,\n}\nstart = time.time()\nresponse = requests.post('https://api.zyte.com/v1/extract',\n    auth=(ZYTE_KEY, ''), json=json_data)\n\nresponse = response.json()\nprint(f'Time: {time.time() - start}')\nprint(f'HTTP status: {response[\"statusCode\"]}')\nbody = b64decode(response[\"httpResponseBody\"])\nprint(f'Response body: {body}')\n\n```", "```py\njson_data = [{\n    'url': 'https://www.target.com/p/-/A-83650487',\n    'pageType': 'product',\n}]\n\nresponse = requests.post(\n    'https://autoextract.zyte.com/v1/extract',\n    auth=(ZYTE_KEY, ''),\n    json=json_data\n)\n\nprint(response.json())\n\n```", "```py\nresponse = requests.get(\n    'https://www.target.com/p/-/A-83650487',\n    proxies={\n        'http': f'http://{ZYTE_KEY}:@proxy.crawlera.com:8011/',\n        'https': f'http://{ZYTE_KEY}:@proxy.crawlera.com:8011/',\n    },\n    verify='/path/to/zyte-proxy-ca.crt' \n)\nprint(response.text)\n```", "```py\nresponse = requests.get(\n    ...\n    verify=False\n)\n```"]