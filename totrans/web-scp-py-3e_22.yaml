- en: Chapter 20\. Web Scraping Proxies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第20章 网络抓取代理
- en: 'That this is the last chapter in the book is somewhat appropriate. Until now
    you have been running all the Python applications from the command line, within
    the confines of your home computer. As the saying goes: “If you love something,
    set it free.”'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的最后一章也算是相当合适的。到目前为止，您一直在命令行中运行所有 Python 应用程序，限制在您的家用计算机的范围内。正如谚语所说：“如果你爱某物，请释放它。”
- en: Although you might be tempted to put off this step as something you don’t *need*
    right now, you might be surprised at how much easier your life becomes when you
    stop trying to run Python scrapers from your laptop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您可能会因为目前不“需要”此步骤而推迟此步骤，但当您停止尝试从笔记本电脑上运行 Python 网络爬虫时，您可能会惊讶于生活变得多么容易。
- en: What’s more, since the first edition of this book was published in 2015, a whole
    industry of web scraping proxy companies has emerged and flourished. Paying someone
    to run a web scraper for you used to be a matter of paying for the cloud server
    instance and running your scraper on it like you would any other software. Now,
    you can make an API request to, essentially, say “fetch this website,” and a remote
    program will take care of the details, handle any security issues, and return
    the data to you (for a fee, of course!).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，自2015年第一版本书出版以来，一个专门的网络抓取代理公司行业已经兴起并蓬勃发展。支付某人为您运行网络爬虫曾经是支付云服务器实例和在其上运行爬虫的事情。现在，您可以通过
    API 请求基本上说“获取此网站”，一个远程程序将处理详细信息，处理任何安全问题，并将数据返回给您（当然要收费！）。
- en: In this chapter, we’ll look at some methods that will allow you to route your
    requests through remote IP addresses, host and run your software elsewhere, and
    even offload the work to a web scraping proxy entirely.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一些方法，可以通过远程 IP 地址路由您的请求，将软件托管和运行在其他地方，甚至完全将工作转移到网页抓取代理。
- en: Why Use Remote Servers?
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用远程服务器？
- en: 'Although using a remote server might seem like an obvious step when launching
    a web application intended for use by a wide audience, often the tools programmers
    build for their own purposes are left running locally. In the absence of a motivation
    for moving the program elsewhere, why do anything? A reason to move it usually
    falls into one of two camps: the need for an alternate IP address (either because
    yours is blocked, or to prevent it from getting blocked), and the need for greater
    power and flexibility.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在推出面向广大用户使用的网络应用程序时，使用远程服务器似乎是一个显而易见的步骤，但程序员为自己目的构建的工具通常仍然在本地运行。在没有将程序移至其他地方的动机的情况下，为什么要做任何事情？通常将其移到其他地方的原因可以分为两大类：需要替代
    IP 地址（要么是因为您的 IP 被阻止了，要么是为了防止被阻止），以及需要更强大和灵活性。
- en: Avoiding IP Address Blocking
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免 IP 地址阻塞
- en: 'When building web scrapers, the rule of thumb is: almost everything can be
    faked. You can send emails from addresses you don’t own, automate mouse-movement
    data from a command line, or even horrify web administrators by sending their
    website traffic from Internet Explorer 9.0.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建网络爬虫时，一个经验法则是：几乎一切都可以伪造。您可以从您不拥有的地址发送电子邮件，从命令行自动化鼠标移动数据，甚至通过发送来自 Internet
    Explorer 9.0 的网站流量来惊吓网站管理员。
- en: 'The one thing that cannot be faked is your IP address. In the real world, anyone
    can send you a letter with the return address: “The President, 1600 Pennsylvania
    Avenue Northwest, Washington, DC 20500.” However, if the letter is postmarked
    from Albuquerque, NM, you can be fairly certain you’re not corresponding with
    the President of the United States.^([1](ch20.html#id921))'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一无法伪造的是您的 IP 地址。在现实世界中，任何人都可以寄给您一封信，署名是：“总统，华盛顿特区1600号宾夕法尼亚大道，20500号。”然而，如果这封信的邮戳是从新墨西哥州的阿尔伯克基寄出的，您几乎可以确定您并没有在与美国总统通信。^([1](ch20.html#id921))
- en: 'Most efforts to stop scrapers from accessing websites focus on detecting the
    difference between humans and bots. Going so far as to block IP addresses is a
    little like a farmer giving up spraying pesticides in favor of just torching the
    field. It’s a last-ditch but effective method of discarding packets sent from
    troublesome IP addresses. However, there are problems with this solution:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数阻止网络爬虫访问网站的方法集中在检测人类和机器人之间的差异。将 IP 地址封锁起来有点像农民放弃喷洒杀虫剂，而选择火烧田地。这是一种最后的但有效的丢弃来自问题
    IP 地址发送的数据包的方法。但是，这种解决方案存在问题：
- en: IP address access lists are painful to maintain. Although large websites most
    often have their own programs automating some of the routine management of these
    lists (bots blocking bots!), someone has to occasionally check them or at least
    monitor their growth for problems.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址访问列表的维护非常痛苦。尽管大型网站通常有自己的程序自动化管理这些列表的一些常规工作（机器人阻止机器人！），但仍然需要有人偶尔检查它们，或者至少监控它们的增长以便及时发现问题。
- en: Each address adds a tiny amount of processing time to receive packets, as the
    server must check received packets against the list to decide whether to approve
    them. Many addresses multiplied by many packets can add up quickly. To save on
    processing time and complexity, admins often group these IP addresses into blocks
    and make rules such as “all 256 addresses in this range are blocked” if there
    are a few tightly clustered offenders. Which leads us to the third point.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个地址在接收数据包时都会增加一小段处理时间，因为服务器必须根据列表检查接收到的数据包以决定是否批准它们。许多地址乘以许多数据包可能会迅速累加。为了节省处理时间和复杂性，管理员通常将这些
    IP 地址分组成块，并制定诸如“这个范围内的所有 256 个地址都被阻止”的规则，如果有几个严密聚集的违规者的话。这导致我们到达第三点。
- en: IP address blocking can lead to blocking the “good guys” as well. For example,
    while I was an undergrad at Olin College of Engineering, one student wrote some
    software that attempted to rig votes for content on the then-popular [*http://digg.com*](http://digg.com/).
    This software was blocked, and that single blocked IP address led to an entire
    dormitory being unable to access the site. The student simply moved his software
    to another server; in the meantime, Digg lost page visits from many regular users
    in its prime target demographic.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址阻止可能会导致“好人”也被阻止访问。例如，我曾在 Olin College of Engineering 读本科时，有一名学生编写了一些软件，试图操纵当时流行的[*http://digg.com*](http://digg.com/)网站上的内容投票。这个软件被阻止了，而那个被阻止的单个
    IP 地址导致整个宿舍无法访问该网站。学生简单地将他的软件移动到了另一台服务器；与此同时，Digg 失去了许多主要目标受众的常规用户页面访问量。
- en: Despite its drawbacks, IP address blocking remains an extremely common method
    for server administrators to stop suspected web scrapers from accessing servers.
    If an IP address is blocked, the only real solution is to scrape from a different
    IP address. This can be accomplished by moving the scraper to a new server or
    routing your traffic through a different server using a service such as Tor.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它有缺点，但 IP 地址阻止仍然是服务器管理员阻止怀疑的网络爬虫访问服务器的极为常见的方法。如果一个 IP 地址被阻止，唯一的真正解决办法就是从不同的
    IP 地址进行爬取。这可以通过将爬虫移动到新的服务器或者通过像 Tor 这样的服务将流量路由到不同的服务器来实现。
- en: Portability and Extensibility
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可移植性和可扩展性
- en: Some tasks are too large for a home computer and internet connection. Although
    you don’t want to put a large load on any single website, you might be collecting
    data across a wide range of sites and thus require a lot more bandwidth and storage
    than your current setup can provide.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一些任务对家用计算机和互联网连接来说太大了。虽然你不想给任何单个网站带来大负载，但你可能正在跨越广泛的网站收集数据，因此需要比你当前设置提供的带宽和存储空间多得多。
- en: Moreover, by offloading computationally intensive processing, you can free up
    your home machine’s cycles for more important tasks (*World of Warcraft*, anyone?).
    You don’t have to worry about maintaining power and an internet connection. You
    can launch your app at a Starbucks, pack up your laptop, and leave knowing that
    everything’s still running safely. Similarly, later on you can access your collected
    data anywhere there’s an internet connection.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过将计算密集型处理转移，你可以释放出家用机器的周期来完成更重要的任务（*魔兽世界*，有人？）。你不必担心维持电力和互联网连接。你可以在星巴克启动你的应用程序，收拾好笔记本电脑，离开时仍然知道一切都在安全运行。同样，在以后只要有互联网连接的地方，你都可以访问你收集的数据。
- en: If you have an application that requires so much computing power that a single
    Amazon extra-large computing instance won’t satisfy you, you can also look into
    *distributed computing*. This allows multiple machines to work in parallel to
    accomplish your goals. As a simple example, you might have one machine crawl one
    set of sites and another crawl a second set of sites, and have both of them store
    collected data in the same database.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个需要大量计算能力的应用程序，单个亚马逊超大型计算实例无法满足你的需求，你也可以考虑*分布式计算*。这允许多台机器并行工作以完成你的目标。举个简单的例子，你可以让一台机器爬取一组网站，另一台爬取另一组网站，并让它们都将收集到的数据存储在同一个数据库中。
- en: Of course, as noted in previous chapters, many can replicate what Google search
    does, but few can replicate the scale at which Google search does it. Distributed
    computing is a large field of computer science that is outside the scope of this
    book. However, learning how to launch your application onto a remote server is
    a necessary first step, and you might be surprised at what computers are capable
    of these days.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，正如前几章所指出的，许多人可以复制Google搜索的功能，但很少有人能够复制Google搜索的规模。分布式计算是计算机科学的一个广阔领域，超出了本书的范围。然而，学习如何将你的应用程序部署到远程服务器是必要的第一步，你可能会对现在计算机的功能感到惊讶。
- en: Tor
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tor
- en: The Onion Router network, better known by the acronym *Tor*, is a network of
    volunteer servers set up to route and reroute traffic through many layers (hence
    the onion reference) of different servers in order to obscure its origin. Data
    is encrypted before it enters the network so that if any particular server is
    eavesdropped on, the nature of the communication cannot be revealed. In addition,
    although the inbound and outbound communications of any particular server can
    be compromised, one would need to know the details of inbound and outbound communication
    for *all* the servers along the path of communication in order to decipher the
    true start and endpoints of a communication—a near-impossible feat.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 洋葱路由器网络，更为人熟知的是缩写为*Tor*的网络，是一组志愿者服务器，设置为通过许多层次（因此有洋葱参考）的不同服务器来路由和重新路由流量，以模糊其起源。数据在进入网络之前被加密，以便如果任何特定服务器被监听，通信的性质就无法被揭示。此外，尽管任何特定服务器的入站和出站通信可能会被破坏，但为了解密通信的真实起点和终点，你需要知道沿通信路径的*所有*服务器的入站和出站通信的详细信息——这几乎是不可能的壮举。
- en: Tor is commonly used by human rights workers and political whistleblowers to
    communicate with journalists, and it receives much of its funding from the US
    government. Of course, it is also commonly used for illegal activities, and so
    remains a constant target for government surveillance—although it’s unclear how
    useful this surveillance is.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Tor通常被人权工作者和政治告密者用于与记者交流，并且它的大部分资金来自美国政府。当然，它也经常被用于非法活动，因此仍然是政府监视的持续目标——尽管目前尚不清楚这种监视的有用性。
- en: Limits of Tor Anonymity
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tor匿名性的限制
- en: Although the reason you are using Tor in this book is to change your IP address,
    not achieve complete anonymity per se, it is worth taking a moment to address
    some of the strengths and limitations of Tor’s ability to anonymize traffic.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你在本书中使用Tor的原因是为了更改你的IP地址，而不是实现完全的匿名性，但值得花一点时间来讨论Tor匿名流量的一些优点和限制。
- en: Although you can assume when using Tor that the IP address you are coming from,
    according to a web server, is not an IP address that can be traced back to you,
    any information you share with that web server might expose you. For instance,
    if you log in to your own Gmail account and then make incriminating Google searches,
    those searches can now be tied back to your identity.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在使用Tor时你可以假设你的IP地址对于网站服务器来说是不可追踪的，但你与该网站分享的任何信息都可能暴露你的身份。例如，如果你登录自己的Gmail账户然后进行具有指控性的Google搜索，这些搜索现在就可以与你的身份联系起来。
- en: Beyond the obvious, however, even the act of logging in to Tor might be hazardous
    to your anonymity. In December 2013, a Harvard undergraduate student, in an attempt
    to get out of final exams, emailed a bomb threat to the school through the Tor
    network, using an anonymous email account. When the Harvard IT team looked at
    their logs, they found traffic going out to the Tor network from only a single
    machine, registered to a known student, during the time that the bomb threat was
    sent. Although they could not identify the eventual destination of this traffic
    (only that it was sent across Tor), the fact that the times matched up and only
    a single machine was logged in at the time was damning enough to prosecute the
    student.^([2](ch20.html#id930))
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了显而易见的之外，甚至登录Tor的行为本身可能对你的匿名性构成危险。2013年12月，一名哈佛大学本科生试图逃避期末考试，通过Tor网络向学校发送了一封炸弹威胁邮件，使用了匿名邮件账户。当哈佛的IT团队查看他们的日志时，他们发现在发送炸弹威胁时，只有一台机器注册了一个已知学生的Tor网络流量。尽管他们无法确定这些流量的最终目的地（只知道它是通过Tor发送的），但时间上的匹配以及在该时间段内只有一台机器登录的事实已足以起诉这名学生。^([2](ch20.html#id930))
- en: Logging in to Tor is not an automatic invisibility cloak, nor does it give you
    free rein to do as you please on the internet. Although it is a useful tool, be
    sure to use it with caution, intelligence, and, of course, morality.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 登录Tor并不是一个自动的隐形斗篷，也不会让您在互联网上随意行事。虽然它是一个有用的工具，但请确保谨慎使用，智慧使用，当然还有道德。
- en: Having Tor installed and running is a requirement for using Python with Tor,
    as you will see in the next section. Fortunately, the Tor service is extremely
    easy to install and start running with. Just go to the [Tor downloads page](https://www.torproject.org/download)
    and download, install, open, and connect. Keep in mind that your internet speed
    might appear to be slower while using Tor. Be patient—it might be going around
    the world several times!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 安装和运行Tor是使用Python与Tor的必备条件，正如你将在下一节看到的那样。幸运的是，Tor服务安装和启动非常简单。只需访问[Tor下载页面](https://www.torproject.org/download)，下载、安装、打开并连接即可。请注意，使用Tor时你的互联网速度可能会变慢。耐心一点——可能它要绕地球几次！
- en: PySocks
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PySocks
- en: PySocks is a remarkably simple Python module that is capable of routing traffic
    through proxy servers and works fantastically in conjunction with Tor. You can
    download it from [its website](https://pypi.python.org/pypi/PySocks/1.5.0) or
    use any number of third-party module managers to install it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: PySocks是一个非常简单的Python模块，能够通过代理服务器路由流量，并且与Tor一起工作效果非常好。您可以从[其网站](https://pypi.python.org/pypi/PySocks/1.5.0)下载它，或者使用任何第三方模块管理器来安装它。
- en: 'Although not much in the way of documentation exists for this module, using
    it is extremely straightforward. The Tor service must be running on port 9150
    (the default port) while running this code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对于此模块并不存在太多的文档，但使用它非常简单。运行此代码时，Tor服务必须在端口9150上运行（默认端口）：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The website [*http://icanhazip.com*](http://icanhazip.com) displays only the
    IP address for the client connecting to the server and can be useful for testing
    purposes. When this script is run, it should display an IP address that is not
    your own.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 网站[*http://icanhazip.com*](http://icanhazip.com)仅显示连接到服务器的客户端的IP地址，对于测试目的可能很有用。运行此脚本时，应显示一个不是您自己的IP地址。
- en: 'If you want to use Selenium and ChromeDriver with Tor, you don’t need PySocks
    at all—just make sure that Tor is currently running and add the optional `proxy-server`
    Chrome option, specifying that Selenium should connect on the socks5 protocol
    on port 9150:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要使用Selenium和ChromeDriver与Tor，您完全不需要PySocks——只需确保Tor当前正在运行，并添加可选的`proxy-server`
    Chrome选项，指定Selenium应该连接到端口9150上的socks5协议：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Again, this should print out an IP address that is not your own but the one
    that your running Tor client is currently using.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这应该打印出一个不是您自己的IP地址，而是您当前正在使用的Tor客户端的IP地址。
- en: Remote Hosting
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 远程托管
- en: Although complete anonymity is lost after you pull out your credit card, hosting
    your web scrapers remotely may dramatically improve their speed. This is because
    you’re able to purchase time on much larger machines than you likely own, but
    also because the connection no longer has to bounce through layers of a Tor network
    to reach its destination.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在您使用信用卡时完全匿名性会丢失，但远程托管您的网络爬虫可能会显著提高其速度。这是因为你可以购买比你拥有的大得多的机器时间，但也因为连接不再需要通过多层Tor网络到达目的地。
- en: Running from a Website-Hosting Account
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从网站托管账户运行
- en: If you have a personal or business website, you might already likely have the
    means to run your web scrapers from an external server. Even with relatively locked-down
    web servers, where you have no access to the command line, it is possible to trigger
    scripts to start and stop through a web interface.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有个人或商业网站，你可能已经拥有从外部服务器运行网络爬虫的手段了。即使在相对封闭的Web服务器上，你无法访问命令行，也可以通过Web界面触发脚本的启动和停止。
- en: If your website is hosted on a Linux server, the server likely already runs
    Python. If you’re hosting on a Windows server, you might be out of luck; you’ll
    need to check specifically to see if Python is installed, or if the server administrator
    is willing to install it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的网站托管在Linux服务器上，服务器很可能已经运行Python。如果您在Windows服务器上托管，您可能没有运气；您需要具体检查Python是否已安装，或者服务器管理员是否愿意安装它。
- en: 'Most small web-hosting providers come with software called *cPanel*, used to
    provide basic administration services and information about your website and related
    services. If you have access to cPanel, you can make sure that Python is set up
    to run on your server by going to Apache Handlers and adding a new handler (if
    it is not already present):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数小型Web托管提供商配备了称为*cPanel*的软件，用于提供基本管理服务以及有关您的网站和相关服务的信息。如果您可以访问cPanel，您可以通过转到Apache
    Handlers并添加新处理程序（如果尚不存在）来确保Python已设置为在服务器上运行：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This tells your server that all Python scripts should be executed as a *CGI-script*.
    CGI, which stands for *Common Gateway Interface*, is any program that can be run
    on a server and dynamically generate content that is displayed on a website. By
    explicitly defining Python scripts as CGI scripts, you’re giving the server permission
    to execute them, rather than just display them in a browser or send the user a
    download.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉您的服务器，所有Python脚本都应作为*CGI脚本*执行。CGI代表*通用网关接口*，是可以在服务器上运行并动态生成显示在网站上的内容的任何程序。通过明确将Python脚本定义为CGI脚本，您正在授权服务器执行它们，而不仅仅是在浏览器中显示或向用户发送下载。
- en: 'Write your Python script, upload it to the server, and set the file permissions
    to 755 to allow it to be executed. To execute the script, navigate to the place
    you uploaded it to through your browser (or even better, write a scraper to do
    it for you). If you’re worried about the general public accessing and executing
    the script, you have two options:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 编写您的Python脚本，将其上传到服务器，并将文件权限设置为755以允许执行。要执行脚本，请通过浏览器导航到您上传的位置（或者更好地编写一个爬虫来代劳）。如果您担心一般公众能够访问和执行脚本，您有两个选择：
- en: Store the script at an obscure or hidden URL and make sure to never link to
    the script from any other accessible URL to avoid search engines indexing it.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将脚本存储在不常见或隐藏的URL，并确保从任何其他可访问URL中不链接到脚本，以避免搜索引擎索引它。
- en: Protect the script with a password, or require that a password or secret token
    be sent to it before it can execute.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用密码保护脚本，或要求在执行之前发送密码或秘密令牌。
- en: Of course, running a Python script from a service that is specifically designed
    to display websites is a bit of a hack. For instance, you’ll probably notice that
    your web scraper-cum-website is a little slow to load. In fact, the page doesn’t
    actually load (complete with the output of all `print` statements you might have
    written in) until the entire scrape is complete. This might take minutes, hours,
    or never complete at all, depending on how it is written. Although it certainly
    gets the job done, you might want more real-time output. For that, you’ll need
    a server that’s designed for more than just the web.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，从专门设计用于显示网站的服务运行Python脚本有些取巧。例如，您可能会注意到您的网络爬虫兼网站加载速度有点慢。事实上，页面实际上并没有加载（包括您可能编写的所有`print`语句的输出），直到整个抓取完成为止。这可能需要几分钟、几小时或根本不会完成，这取决于编写的方式。虽然它确实完成了工作，但您可能希望获得更多实时输出。为此，您需要一个不仅仅是为Web设计的服务器。
- en: Running from the Cloud
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从云端运行
- en: Back in the olden days of computing, programmers paid for or reserved time on
    computers in order to execute their code. With the advent of personal computers,
    this became unnecessary—you simply write and execute code on your own computer.
    Now programmers are once again moving to pay-per-hour computing instances.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 回到计算机的旧时代，程序员为了执行其代码而支付或预留了计算机上的时间。随着个人计算机的出现，这变得不再必要——您只需在自己的计算机上编写和执行代码。现在，程序员们再次转向按小时支付的计算实例。
- en: This time around, however, users aren’t paying for time on a single, physical
    machine but on its equivalent computing power, often spread among many machines.
    The nebulous structure of this system allows computing power to be priced according
    to times of peak demand. For instance, Amazon allows for bidding on “spot instances”
    when low costs are more important than immediacy.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一次，用户不是为单一物理机器的时间付费，而是为其等效计算能力付费，通常分布在多台机器之间。这种系统的模糊结构允许计算能力根据高峰需求时段定价。例如，亚马逊允许在低成本更重要的情况下对“竞价实例”进行竞标。
- en: Compute instances are also more specialized and can be selected based on the
    needs of your application, with options like “high memory,” “fast computing,”
    and “large storage.” Although web scrapers don’t typically use much in the way
    of memory, you may want to consider large storage or fast computing in lieu of
    a more general-purpose instance for your scraping application. If you’re doing
    large amounts of natural language processing, OCR work, or path finding (such
    as with the Six Degrees of Wikipedia problem), a fast computing instance might
    work well. If you’re scraping large amounts of data, storing files, or doing large-scale
    analytics, you might want to go for an instance with storage optimization.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 计算实例还更专业化，可以根据应用程序的需求进行选择，例如“高内存”、“快速计算”和“大容量存储”。虽然Web爬虫通常不使用太多内存，但对于您的爬取应用程序，您可能希望考虑大容量存储或快速计算，而不是选择更通用的实例。如果您进行大量的自然语言处理、OCR工作或路径搜索（例如维基百科的六度分隔问题），快速计算实例可能非常适合。如果您正在爬取大量数据、存储文件或进行大规模分析，您可能需要选择一个具有存储优化的实例。
- en: Although the sky is the limit as far as spending goes, at the time of this writing,
    instances start at just 0.9 cents (less than a penny) an hour for the cheapest
    Google instance, the f1-micro, and 0.8 cents an hour for a comparable Amazon EC2
    micro instance. Thanks to the economies of scale, buying a small compute instance
    with a large company is almost always cheaper than buying your own physical, dedicated
    machine. Because now you don’t need to hire an IT guy to keep it running.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然支出可以无限制地增加，但截至目前，最便宜的Google实例f1-micro每小时仅需0.9美分（不到一分钱），相当于Amazon EC2微型实例的每小时0.8美分。由于规模经济效应，购买大公司的小型计算实例几乎总是比购买自己的物理专用机器便宜。因为现在您不需要雇佣IT人员来保持其运行。
- en: Of course, step-by-step instructions for setting up and running cloud computing
    instances are somewhat outside the scope of this book, but you will likely find
    that step-by-step instructions are not needed. With both Amazon and Google (not
    to mention the countless smaller companies in the industry) vying for cloud computing
    dollars, they’ve made setting up new instances as easy as following a simple prompt,
    thinking of an app name, and providing a credit card number. As of this writing,
    both Amazon and Google also offer hundreds of dollars’ worth of free computing
    hours to further tempt new clients.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，本书不涵盖逐步设置和运行云计算实例的详细说明，但您可能会发现并不需要逐步说明。Amazon和Google（更不用说行业中无数的小公司了）为争夺云计算市场份额，已经使得设置新实例就像按照简单的提示操作、考虑一个应用程序名称并提供信用卡号码那样简单。截至目前，Amazon和Google还提供价值数百美元的免费计算小时，以进一步吸引新客户。
- en: If you’re new to cloud computing, DigitalOcean is also a great provider of compute
    instances (which they call droplets), starting at 0.6 cents an hour. They have
    an incredibly easy user interface and simply email you the IP address and credentials
    for any new droplet they create so that you can log in and start running. Although
    they specialize more in web app hosting, DNS management, and load balancing, you
    can run anything you want from your instance!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是云计算的新手，DigitalOcean也是一个提供计算实例（他们称之为droplets）的优秀供应商，起价每小时仅为0.6美分。他们拥有非常简单的用户界面，并通过电子邮件向您发送任何新创建的droplet的IP地址和凭据，以便您登录并开始运行。虽然他们更专注于Web应用程序托管、DNS管理和负载均衡，但您可以从您的实例运行任何您想要的东西！
- en: Once you have an instance set up, you should be the proud new owner of an IP
    address, username, and public/private keys that can be used to connect to your
    instance through SSH. From there, everything should be the same as working with
    a server that you physically own—except, of course, you no longer have to worry
    about hardware maintenance or running your own plethora of advanced monitoring
    tools.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您设置好实例，您将成为一个有IP地址、用户名和公私钥的自豪新机主，这些可以用于通过SSH连接到您的实例。从那里开始，一切都应该和操作您自己的服务器一样——当然，您不再需要担心硬件维护或运行自己的各种高级监控工具。
- en: For quick and dirty jobs, especially if you don’t have a lot of experience dealing
    with SSH and key pairs, I’ve found that Google’s Cloud Platform instances can
    be easier to get up and running right away. They have a simple launcher and even
    have a button available after launch to view an SSH terminal right in the browser,
    as shown in [Figure 20-1](#browser-based-terminal).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于快速且简单的任务，特别是如果你没有处理 SSH 和密钥对的经验，我发现 Google 的 Cloud 平台实例可以更容易地立即启动和运行。它们有一个简单的启动器，甚至在启动后还提供一个按钮，可以在浏览器中查看
    SSH 终端，如[图 20-1](#browser-based-terminal)所示。
- en: '![](assets/wsp3_2001.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_2001.png)'
- en: Figure 20-1\. Browser-based terminal from a running Google Cloud Platform VM
    instance
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-1\. 来自正在运行的 Google Cloud 平台 VM 实例的基于浏览器的终端
- en: Moving Forward
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 展望未来
- en: The web is constantly changing. The technologies that bring us images, video,
    text, and other data files are constantly being updated and reinvented. To keep
    pace, the collection of technologies used to scrape data from the internet must
    also change.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网在不断变化。为我们带来图像、视频、文本和其他数据文件的技术正在不断更新和重新发明。为了跟上步伐，从互联网抓取数据所使用的技术集合也必须发生变化。
- en: Who knows? Future versions of this text may omit JavaScript entirely as an obsolete
    and rarely used technology and instead focus on HTML8 hologram parsing. However,
    what won’t change is the mindset and general approach needed to successfully scrape
    any website (or whatever we use for “websites” in the future).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 谁知道呢？未来版本的本文可能完全省略 JavaScript，因为它是过时且很少使用的技术，而转而专注于 HTML8 全息解析。然而，不会改变的是成功地抓取任何网站（或者未来用于“网站”的东西）所需的思维方式和一般方法。
- en: 'When encountering any web scraping project, you should always ask yourself:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何网页抓取项目中，你应该始终问自己：
- en: What is the question I want answered or the problem I want solved?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我想要回答的问题是什么，或者我想要解决的问题是什么？
- en: What data will help me achieve this and where is it?
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么数据可以帮助我实现这一目标？它在哪里？
- en: How is the website displaying this data? Can I identify exactly which part of
    the website’s code contains this information?
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站如何显示这些数据？我能否准确地识别出网站代码的哪一部分包含这些信息？
- en: How can I isolate the data and retrieve it?
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何隔离数据并获取它？
- en: What processing or analysis needs to be done to make it more useful?
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了使其更有用，需要进行哪些处理或分析？
- en: How can I make this process better, faster, and more robust?
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使这个过程更好、更快、更强大？
- en: In addition, you need to understand not just how to use the tools presented
    in this book in isolation but how they can work together to solve a larger problem.
    Sometimes the data is easily available and well formatted, allowing a simple scraper
    to do the trick. Other times you have to put some thought into it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你不仅需要理解如何独立使用本书中介绍的工具，还要理解它们如何共同解决更大的问题。有时数据很容易获取且格式良好，可以使用简单的抓取器来完成。其他时候，你需要多加思考。
- en: In [Chapter 16](ch16.html#c-16), for example, you combined the Selenium library
    to identify Ajax-loaded images on Amazon and Tesseract to use OCR to read them.
    In the Six Degrees of Wikipedia problem, you used regular expressions to write
    a crawler that stored link information in a database, and then used a graph-solving
    algorithm to answer the question, “What is the shortest path of links between
    Kevin Bacon and Eric Idle?”
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 16 章](ch16.html#c-16)中，例如，你结合了 Selenium 库来识别亚马逊上加载的 Ajax 图像，并使用 Tesseract
    进行 OCR 读取。在“维基百科六度分离问题”中，你使用正则表达式编写了一个爬虫，将链接信息存储在数据库中，然后使用图解算法回答了“凯文·贝肯与埃里克·爱德尔之间的最短链接路径是什么”的问题。
- en: 'There is rarely an unsolvable problem when it comes to automated data collection
    on the internet. Just remember: the internet is one giant API with a somewhat
    poor user interface.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化数据收集方面，几乎没有无法解决的问题。只要记住：互联网就是一个巨大的 API，其用户界面相对较差。
- en: Web Scraping Proxies
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络抓取代理
- en: This book discusses many products and technologies, with a focus on free and
    open-source software. In cases where paid products are discussed, it’s generally
    because a free alternative doesn’t exist, isn’t practical, and/or the paid products
    are so ubiquitous I’d feel remiss not to mention them.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本书讨论了许多产品和技术，重点放在自由和开源软件上。在讨论付费产品的情况下，通常是因为不存在免费替代品，不切实际，和/或者付费产品非常普及，如果不提及会感到有所遗漏。
- en: The web scraping proxy and API service industry is an odd one, as far as industries
    go. It’s new, relatively niche, but still extremely crowded with a low barrier
    to entry. Because of this, there aren’t any big “household names” yet that all
    programmers would agree *require* discussion. Yes, some names are bigger than
    others, and some services are better than others, but it’s still quite the jungle
    out there.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 网页抓取代理和API服务行业是一个有点奇怪的行业。它是新兴的、相对小众的，但仍然极度拥挤，入门门槛较低。正因为如此，目前还没有任何大家都会同意需要讨论的大型“家喻户晓的名字”。是的，有些名字比其他的大，有些服务比其他的更好，但这个行业确实相当混乱。
- en: Also, because web scraping proxying requires vast amounts of equipment and electricity
    to run, a viable free alternative does not exist and is unlikely to exist in the
    future.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，因为网页抓取代理需要大量设备和电力运行，目前不存在可行的免费替代方案，未来也不太可能存在。
- en: This puts me in the precarious position of writing about an assortment of companies
    that you may not have heard of but that want your money. Rest assured, while I
    have opinions about these companies, I have not been paid for those opinions.
    I have used their services, spoken with their representatives, and in several
    cases been given free account credits for research purposes, but I do not have
    any incentive to promote them. I am not invested, either financially or emotionally,
    in any of these companies.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我处于一个棘手的位置，需要写一些你可能没有听说过但却想要你的钱的公司。请放心，虽然我对这些公司有自己的看法，但我没有因此被付费。我曾使用过它们的服务，与它们的代表交谈过，并且在几种情况下因研究目的而获得了免费的账户积分，但我没有任何推广它们的动机。我对这些公司没有任何财务或情感投资。
- en: When you read this section, I suggest that you think more generally about the
    attributes of web scraping proxies and API services, their specialties, your budget,
    and your project requirements. These profiles are designed to be read as case
    studies and examples of “what’s out there” rather than specific endorsements.
    And if you do feel like giving any of these particular companies money, that’s
    between you and them!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当您阅读本节时，我建议您更广泛地考虑网页抓取代理和API服务的属性、它们的特长、您的预算以及项目需求。这些档案被设计为案例研究和“市场上有什么”的示例，而不是特定的认可。如果您确实想要向其中某些公司付款，那就是您和它们之间的事情！
- en: ScrapingBee
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ScrapingBee
- en: ScrapingBee is the smallest of the companies in this list. It has a strong focus
    on JavaScript automation, headless browsers, and innocuous-looking IP addresses.
    Its API is well documented but, if you prefer not to do any reading, ScrapingBee
    also has an API request generation tool on its website that reduces the problem
    to button clicking and copy/pasting.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ScrapingBee是这份清单中最小的公司。它专注于JavaScript自动化、无头浏览器和外观不起眼的IP地址。其API文档完善，但如果您不喜欢阅读，ScrapingBee网站还提供了API请求生成工具，可以通过按钮点击和复制/粘贴来解决问题。
- en: An important feature to consider when evaluating proxy services is the amount
    of time it takes to return request data to you. Not only does the request have
    to be routed from your computer to their server to the target’s server and back
    again, but the proxy service may actually be buffering these requests on its end
    and not sending them out immediately. It’s not unusual for a request to take a
    minute or longer to return. During a formal evaluation, it’s important to time
    these requests throughout the day and time multiple types of requests for any
    features you might want to use.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估代理服务时需要考虑的一个重要特性是返回请求数据所需的时间。请求不仅需要从您的计算机路由到它们的服务器再到目标服务器，然后再返回，而且代理服务可能会在其端口缓冲这些请求，不会立即发送出去。请求返回需要一分钟甚至更长时间并不罕见。在正式评估过程中，重要的是在一天中的不同时间测量这些请求，并对可能要使用的任何功能进行多次请求。
- en: 'Using ScrapingBee’s API directly, we can scrape a product page and print both
    the results and the time it took to fetch them:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 直接使用ScrapingBee的API，我们可以抓取产品页面并打印结果及其获取所需时间：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'ScrapingBee also has a [Python package](https://pypi.org/project/scrapingbee/)
    that can be installed with pip:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ScrapingBee还有一个可以通过pip安装的[Python包](https://pypi.org/project/scrapingbee/)：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This is a Software Development Kit (SDK) that let you use various features
    of the API in a slightly more convenient way. For example, the request above can
    be written as:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个软件开发工具包（SDK），它让您以稍微更方便的方式使用API的各种功能。例如，上述请求可以编写为：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Notice that the response is a Python requests response, and it can be used in
    the same way as in the previous example.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，响应是 Python requests 响应，可以像前面的示例一样使用。
- en: Scraping API services usually deal in units of “credits,” where one basic API
    request costs one credit. Features such as JavaScript rendering with a headless
    browser or a residential IP address may cost anywhere from 5 credits to 75 credits. Each
    paid account level gives you a certain number of credits per month.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 抓取 API 服务通常以“积分”为单位，其中一个基本 API 请求花费一个积分。使用无头浏览器进行 JavaScript 渲染或居住 IP 地址等功能可能需要从
    5 个积分到 75 个积分不等。每个付费账户级别每月提供一定数量的积分。
- en: While there is a free trial with 1,000 credits, ScrapingBee’s paid subscriptions
    start at $50/month for 150,000 credits, or 3,000 credits per dollar. Like with
    most of these services, there are large volume discounts—credits can be 13,000
    per dollar or less with greater monthly spend.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有 1,000 个免费试用积分，ScrapingBee 的付费订阅从每月 $50 起，可获得 150,000 个积分，即每美元 3,000 个积分。与大多数这类服务一样，有大量的量级折扣
    —— 每月支出增加，积分可以降低到每美元 13,000 个或更少。
- en: If you want to maximize your requests, keep in mind that ScrapingBee charges
    5 credits for JavaScript rendering and turns it on by default. This means that
    the requests above will cost 5 credits each, not 1.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想最大化请求，请注意，ScrapingBee 对 JavaScript 渲染收取 5 个积分，并默认打开。这意味着上述请求每个都将花费 5 个积分，而不是
    1 个。
- en: 'This makes it convenient for customers who may not have read [Chapter 14](ch14.html#c-14)
    of this book and do not understand why the data appearing in their web browser
    does not appear in the scraping results coming back from ScrapingBee. If those
    customers read [Chapter 15](ch15.html#c-15), they would also understand how to
    get the data they want without JavaScript rendering at all. If you have read both
    of these chapters, you can turn off JavaScript rendering and reduce request costs
    by 80% using:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于可能没有阅读本书 [第 14 章](ch14.html#c-14) 的客户来说非常方便，他们不理解为什么在他们的网页浏览器中看到的数据在从 ScrapingBee
    返回的抓取结果中没有出现。如果这些客户阅读了 [第 15 章](ch15.html#c-15)，他们还会了解如何在完全不使用 JavaScript 渲染的情况下获取他们想要的数据。如果您已经阅读了这两章，可以关闭
    JavaScript 渲染并将请求成本降低 80% 使用：
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Like many of these services, ScrapingBee offers the option of using “premium”
    IP addresses, which may prevent your scrapers from getting blocked by websites
    wary of IP addresses frequently used by bots. These IP addresses are reported
    as residential addresses owned by smaller telecommunication companies. If that’s
    not enough, ScrapingBee also offers a “stealth” IP address for 75 credits per
    request. The stealth IP addresses I was given were listed as datacenters and VPN
    servers, so it’s unclear what, exactly, the stealth IP addresses are and what
    real advantages they offer over the premium addresses.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多这类服务一样，ScrapingBee 提供使用“高级” IP 地址的选项，这可能会防止您的爬虫被警惕频繁使用的 IP 地址的网站屏蔽。这些 IP
    地址被报告为由较小的电信公司拥有的住宅地址。如果这还不够，ScrapingBee 还提供每次请求 75 个积分的“隐身”IP地址。我得到的隐身 IP 地址被列为数据中心和
    VPN 服务器，所以目前尚不清楚隐身 IP 地址具体是什么，以及相对于高级地址提供了什么真正的优势。
- en: ScraperAPI
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ScraperAPI
- en: ScraperAPI, true to its name, has a mostly clean and REST-ful API with tons
    of features. It supports asynchronous requests, which allow you to make the scraping
    request and fetch the results later in a separate API call. Alternatively, you
    can provide a webhook endpoint that the results are sent to after the request
    is complete.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名，ScraperAPI 拥有大多数清洁和符合 REST 原则的 API，具有大量功能。它支持异步请求，允许您发出抓取请求，并在稍后的 API 调用中获取结果。或者，您可以提供一个
    Webhook 端点，在请求完成后将结果发送到该端点。
- en: 'A simple one-credit call with ScraperAPI looks like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ScraperAPI 的简单一积分调用如下所示：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'ScraperAPI also has an SDK that can be installed with pip:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ScraperAPI 还有一个可以用 pip 安装的 SDK：
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Like with most of these SDKs, it is a very thin wrapper around the Python requests
    library. As with the ScrapingBee API, a Python Requests response is returned:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数这类 SDK 一样，它只是 Python requests 库的一个非常薄的包装。与 ScrapingBee API 一样，返回一个 Python
    Requests 响应：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When evaluating web scraping services, it may be tempting to prefer those that
    have Python SDKs built around their APIs. However, you should carefully consider
    how much programming effort it will reduce or convenience it will provide. Technically,
    a Python “SDK” can be written around any scraping API with very little effort,
    including your own. This example SDK is written around an imaginary API in just
    a few lines of code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估网络爬取服务时，可能会倾向于偏爱围绕其 API 构建 Python SDK 的服务。然而，您应该仔细考虑它将减少多少编程工作量或提供多少便利。技术上，可以轻松地围绕任何爬取
    API 编写 Python “SDK”，包括您自己的。此示例 SDK 仅围绕想象中的 API 编写了几行代码：
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'But one unique feature of ScraperAPI is its auto-parsing tools for Amazon products
    and Google search results. A request for an Amazon product page or an Amazon or
    Google search results page has a cost of 5 credits, rather the 1 credit for most
    requests. Although the documentation does mention an explicit call to the Amazon
    Product Endpoint at [*https://api.scraperapi.com/structured/amazon/product*](https://api.scraperapi.com/structured/amazon/product),
    this service appears to be turned on by default:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但 ScraperAPI 的一个独特功能是其自动解析工具，适用于亚马逊产品和谷歌搜索结果。请求亚马逊产品页面或亚马逊或谷歌搜索结果页面的成本为 5 个积分，而大多数请求只需
    1 个积分。尽管文档确实提到了对亚马逊产品端点的显式调用 [*https://api.scraperapi.com/structured/amazon/product*](https://api.scraperapi.com/structured/amazon/product)，但此服务似乎默认已打开：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With the response:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有了响应：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: While writing an Amazon product parsing tool is hardly an insurmountable challenge,
    offloading the responsibility of testing and maintaining that parsing tool over
    the years may be well worth the costs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然编写亚马逊产品解析工具并不是一项难以克服的挑战，但在多年的测试和维护解析工具责任上进行卸载可能是非常值得的成本。
- en: 'As mentioned before, ScraperAPI also allows you to make asynchronous requests
    to its API and fetch the results at a later time. This request takes less than
    100 ms to return:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，ScraperAPI 还允许您对其 API 发出异步请求，并在稍后的时间获取结果。此请求在返回时少于`100 ms`：
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that this is a `POST` request rather than a `GET` request, as shown in
    previous examples. We are, in a sense, posting data for the creation of a stored
    entity on Scraper​A⁠PI’s server. Also, the attribute used to send the key changes
    from `api_key` to `apiKey`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个 `POST` 请求，而不是前面示例中的 `GET` 请求。在某种意义上，我们正在向 ScraperAPI 的服务器发布用于创建存储实体的数据。此外，用于发送密钥的属性从
    `api_key` 变更为 `apiKey`。
- en: 'The response body contains only a URL where the job can be fetched:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 响应主体仅包含可以获取作业的 URL：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Calling it does not require an API key—the UUID is sufficient security here—and,
    assuming the request has been completed on their end, it returns the target’s
    body:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 调用它不需要 API 密钥——UUID 在这里足够作为安全措施——并且假设他们端已完成请求，则返回目标的主体：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The results of these async requests are stored for up to four hours, or until
    you retrieve the data. While you could accomplish a similar result at home with
    a multi-threaded scraper and a little code, you could not easily do it while rotating
    residential and mobile IP addresses, changing countries of origin, managing session
    data, rendering all the JavaScript (which will quickly bog down a machine), and
    tracking all successes and failures in a dashboard.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些异步请求的结果将存储最多四个小时，或直到您检索数据。虽然您可以在家里通过多线程爬虫和少量代码实现类似的结果，但在旋转住宅和移动 IP 地址、更改原始国家、管理会话数据、呈现所有
    JavaScript（这会快速使机器变慢）并在仪表板中跟踪所有成功和失败时，您不能轻松地做到这一点。
- en: Asynchronous requests and webhooks (where the proxy service returns the results
    to the URL you provide) are excellent features in an API service, especially for
    larger and longer-running scraping projects. ScraperAPI provides this at no extra
    cost per request, which is especially nice.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 异步请求和 Webhooks（代理服务将结果返回到您提供的 URL）是 API 服务中的出色功能，特别适用于较大和长时间运行的爬取项目。ScraperAPI
    提供此功能，每次请求均不需额外费用，这尤为方便。
- en: Oxylabs
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Oxylabs
- en: Oxylabs is a large Lithuanian-based company with a focus on search engine results
    page (SERP) and product page scraping. Its product ecosystem and API have a bit
    of a learning curve. After creating an account, you must activate (either with
    a one-week trial or paid subscription) every “product” that you want to use and
    create separate username/password credentials specific to each product. These
    username/password credentials work a bit like an API key.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Oxylabs 是一家总部位于立陶宛的大型公司，专注于搜索引擎结果页面（SERP）和产品页面的抓取。其产品生态系统和 API 有一定的学习曲线。创建账户后，您必须激活（使用一周试用或付费订阅）您想要使用的每个“产品”，并创建与每个产品特定的用户名/密码凭据。这些用户名/密码凭据有点类似于
    API 密钥。
- en: 'The Web Scraper API product allows you to make calls that look like this, with
    a Web Scraper API username and password:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Web Scraper API 产品允许您进行如下调用，使用 Web Scraper API 用户名和密码：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'However, the user may be in for a surprise if the target URL is switched to
    one from the amazon.com domain:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果目标 URL 切换为 amazon.com 域，则用户可能会感到惊讶：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This code prints an error message:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码打印出错误消息：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Like ScraperAPI, Oxylabs has parsing tools predesigned for sites like Amazon
    and Google. However, to scrape those domains—with or without the special parsing
    tools—you must subscribe specifically to the SERP Scraper API product (to scrape
    Google, Bing, Baidu, or Yandex) or the E-Commerce Scraper API product (to scrape
    Amazon, Aliexpress, eBay, and many others).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 ScraperAPI，Oxylabs 还有专门设计用于网站如 Amazon 和 Google 的解析工具。然而，要解析这些域名，无论是否使用特殊的解析工具，您都必须专门订阅
    SERP Scraper API 产品（用于抓取 Google、Bing、百度或 Yandex）或 E-Commerce Scraper API 产品（用于抓取
    Amazon、Aliexpress、eBay 等）。
- en: 'If subscribed to the E-Commerce Scraper API product, the Amazon domain can
    be successfully scraped by changing the `source` attribute to `amazon` and passing
    in the E-Commerce-specific credentials:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果订阅了 E-Commerce Scraper API 产品，则可以通过将 `source` 属性更改为 `amazon` 并传递特定于电子商务的凭据成功抓取
    Amazon 域：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This does not do anything special; it simply returns the content of the page
    as usual. To use the product information formatting templates, we must also set
    the attribute `parse` to `True`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 它并没有做任何特殊处理；它只是像往常一样返回页面内容。要使用产品信息格式化模板，我们还必须将属性 `parse` 设置为 `True`：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This parses the website and returns formatted JSON data:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这会解析网站并返回格式化的 JSON 数据：
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It’s important to keep in mind that parsing tools themselves are not specific
    to the E-Commerce Scraper API product. We can also parse the target.com domain
    using the regular Web Scraper API product, setting the source back to universal
    and using the Web Scraper API credentials:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，解析工具本身并不专门针对 E-Commerce Scraper API 产品。我们也可以使用常规的 Web Scraper API 产品解析
    target.com 域，将源设置回 universal 并使用 Web Scraper API 凭据：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Which returns JSON-formatted product data:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回 JSON 格式的产品数据：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Because it was attempting to parse pages at the domain target.com automatically,
    it is liable to run into errors here and there, like it did with the description.
    Fortunately, users can also write custom parsers, which are compatible with any
    API product type (Web Scraper API, SERP Scraper API, E-Commerce Scraper API, etc.).
    These custom parsers take the form of JSON files with a format specified by Oxylabs,
    which defines the various fields and the XPath selectors that collect data for
    them.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它尝试自动解析目标域名为 target.com 的页面，所以可能会偶尔遇到错误，就像在描述中所做的那样。幸运的是，用户还可以编写自定义解析器，这些解析器与任何
    API 产品类型兼容（Web Scraper API、SERP Scraper API、E-Commerce Scraper API 等）。这些自定义解析器采用由
    Oxylabs 指定的 JSON 文件格式，定义了各种字段和收集数据的 XPath 选择器。
- en: These custom parsers are essentially the “business logic” of the web scraper
    itself. It may be worth considering that, if you move to another web scraping
    API or proxy platform, these templates would be essentially useless and would
    need to be heavily modified, rewritten, or your new code base would need to be
    written specifically to work with them. Writing web scraping templates in the
    Oxylabs-specific language may be somewhat limiting if you choose to go elsewhere.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这些自定义解析器本质上就是网页抓取器的“业务逻辑”。值得考虑的是，如果您转移到另一个网页抓取 API 或代理平台，这些模板基本上将变得无用，并且需要进行大幅修改、重写，或者您的新代码库需要专门编写以使其与其它平台兼容。在
    Oxylabs 特定语言中编写网页抓取模板可能会在选择其他平台时有所限制。
- en: It’s also important to stress that these different API “products” (which, in
    fact, use the same API endpoint and call structure) are defined, based not on
    their particular features but on the domains they’re allowed to send requests
    to, which could change at any time.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 还需强调一点，这些不同的API“产品”（实际上使用相同的API端点和调用结构）的定义，并非基于它们的特定功能，而是基于它们被允许发送请求的领域，这些领域随时可能发生变化。
- en: 'The domains under the purview of a specific product may not necessarily be
    well-supported by that product either. Oxylab’s SERP Scraping API advertises support
    for sites such as Baidu and Bing, but it does not have parsing templates developed
    for them. This “support” may be as simple as the ability to specify a search like:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 特定产品管辖的领域可能并不一定得到该产品的良好支持。例如，Oxylab的SERP Scraping API宣传支持百度和必应等网站，但并未为它们开发解析模板。这种“支持”可能仅仅是能够指定类似于以下搜索的能力：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'instead of writing out the full URL:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是完整写出URL：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note that, while I am critical of some aspects of Oxylab’s API products, this
    criticism is not directed at the company per se and should not be interpreted
    as a comprehensive review or recommendation. I intend it only as a case study,
    or as an example for consideration, for those who might be evaluating similar
    products in the future.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然我对Oxylab的某些API产品持批评态度，但这些批评并不针对公司本身，也不应被视为全面审查或推荐。我只是将其作为一个案例研究或供将来评估类似产品的人参考的例子。
- en: When evaluating APIs and web scraping services, it’s always important to consider
    what is being advertised, what is being provided, and who the target audience
    is. The structure of an API call may reveal important information about the actual
    construction of a product, and even the documentation can be misleading.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估API和网络爬取服务时，始终要考虑广告宣传内容、实际提供内容以及目标受众是谁。API调用的结构可能揭示关于产品实际构建的重要信息，甚至文档也可能具有误导性。
- en: Oxylabs has many excellent qualities as well. It is one of the best providers
    of proxy IP addresses. Oxylabs continuously sources a wide variety and large number
    of IP addresses, listed publicly as being residential, mobile, and data centers.
    Like other proxy services, these IP addresses are available at a higher cost,
    depending on the type. However, Oxylabs charges by the gigabyte for these proxy
    services, rather than the request. Currently, costs range from $22/GB (low-volume
    mobile IP addresses) to $8/GB (high-volume residential IP addresses).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Oxylabs也有许多优点。它是最佳代理IP地址提供商之一。Oxylabs持续获取各种类型和大量IP地址，公开列出的类型包括住宅、移动和数据中心。与其他代理服务一样，这些IP地址的成本较高，具体费用根据类型而定。但是，Oxylabs按GB计费这些代理服务，而不是按请求计费。目前，成本从每GB的低容量移动IP地址22美元到每GB的高容量住宅IP地址8美元不等。
- en: Zyte
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Zyte
- en: Zyte, formerly Scrapinghub, is another large web scraping proxy and API service
    company. It’s also one of the oldest, founded in 2010. While I have no particular
    attachment to any of these companies, I would be lying if I said that, as the
    maintainers of Scrapy, Zyte doesn’t stand out from the crowd somewhat. And, beginning
    in 2019,  it also hosts the [Web Data Extraction Summit](https://www.extractsummit.io).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Zyte，之前名为Scrapinghub，是另一家大型网络爬虫代理和API服务公司。成立于2010年，也是最早之一。虽然我对这些公司没有特别的偏好，但如果说作为Scrapy的维护者，Zyte在某种程度上确实脱颖而出。自2019年起，它还主办[Web数据抽取峰会](https://www.extractsummit.io)。
- en: As a large company, Zyte has most of the features of the previous companies
    mentioned, and more. Unlike most others, it also sells data outright. If you need,
    for example, job postings, real estate data, or product information, it can provide
    those datasets or provide consultants who can build custom datasets.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一家大公司，Zyte拥有前述公司的大多数功能，甚至更多。与大多数其他公司不同的是，它还直接销售数据。例如，如果你需要职位发布信息、房地产数据或产品信息，它可以提供这些数据集，或提供能够构建定制数据集的顾问。
- en: Zyte maintains Scrapy and has incorporated it into its product lineup in the
    form of Scrapy Cloud. This tool allows you to deploy and run Scrapy projects in
    the cloud from either a GitHub repository or from your local machine using the
    [Scrapinghub command-line client](https://pypi.org/project/shub/). This allows
    you to keep your web scrapers platform agnostic and portable but still interface
    tightly with the Zyte ecosystem.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Zyte维护着Scrapy，并将其以Scrapy Cloud的形式纳入其产品线。这个工具允许你从GitHub仓库或本地机器使用[Scrapinghub命令行客户端](https://pypi.org/project/shub/)在云中部署和运行Scrapy项目。这使得你的网络爬虫可以跨平台且可移植，同时与Zyte生态系统紧密集成。
- en: Once a Scrapy project is deployed, Zyte finds all of the spider classes in the
    project and automatically loads them into your dashboard. You can use Zyte’s dashboard
    UI to launch and monitor these spiders as they run in the cloud, then view or
    download the resulting data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了一个Scrapy项目，Zyte会找到项目中的所有蜘蛛类，并自动加载到您的仪表板中。您可以使用Zyte的仪表板UI启动和监视这些蜘蛛在云中运行，然后查看或下载生成的数据。
- en: 'Of course, Zyte also has an API. It is somewhat similar to the other APIs in
    that it heavily relies on the Python requests package. It is also similar to Oxylab’s
    API in that it uses the POST method entirely along with HTTP Basic Authentication.
    However, unlike Oxylab, only a Zyte key is sent over Basic Auth, rather than the
    username and password:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Zyte还有一个API。它在某种程度上类似于其他API，因为它大量依赖于Python的requests包。它也类似于Oxylab的API，因为它完全使用POST方法以及HTTP基本身份验证。然而，与Oxylab不同的是，只有一个Zyte密钥通过基本身份验证发送，而不是用户名和密码：
- en: '[PRE26]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The other major difference is that all response bodies are returned as base64
    encoded strings, rather than HTML or JSON text. This is trivial to handle with
    Python’s `base64` package. It also allows you to retrieve binary data, images,
    and other files just like any other request response by simply decoding the response
    as that file type.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 所有响应主体都以base64编码字符串返回，而不是HTML或JSON文本。使用Python的`base64`包处理这一点非常简单。它还允许您像处理任何其他请求响应一样通过简单解码响应来检索二进制数据、图像和其他文件。
- en: 'If you don’t feel like using Scrapy and have a fairly straightforward project,
    Zyte’s Automatic Extraction API uses AI to detect various fields on a page and
    return them as JSON-formatted data. Currently, it works with both articles and
    product types. Obviously, it does not need to use base64 encoding because all
    the pages it parses must be text:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想使用Scrapy并且有一个相当简单的项目，Zyte的自动提取API使用AI检测页面上的各种字段，并将它们作为JSON格式数据返回。目前，它适用于文章和产品类型。显然，它不需要使用base64编码，因为它解析的所有页面必须是文本：
- en: '[PRE27]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The documentation for Zyte’s Automatic Extraction API provides the URL *https://autoextract.scrapinghub.com/v1/extract*,
    as an artifact of their previous name, ScrapingHub. If you see this, know that
    you can usually replace `zyte.com` with `scrapinghub.com` and give your code some
    backwards compatibility if Zyte decides to shut down the old domain.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Zyte的自动提取API文档提供了URL *https://autoextract.scrapinghub.com/v1/extract*，作为其之前名称ScrapingHub的一个遗物。如果您看到这一点，请知道您通常可以用`zyte.com`替换`scrapinghub.com`，如果Zyte决定关闭旧域名，则可以为您的代码提供一些向后兼容性。
- en: Zyte’s products are heavily geared toward developers working in an enterprise
    environment who want full transparency and control over their scrapers. However,
    Zyte prefers to take IP address management out of the hands of users with its
    Zyte Smart Proxy Manager. Zyte controls which IP addresses the traffic is proxied
    through. IP addresses are maintained between sessions, but IP addresses are switched
    if one is being blocked. Zyte attempts to use IP address switching to create an
    organic-looking flow of traffic to a site that avoids suspicion.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Zyte的产品主要面向在企业环境中工作的开发人员，他们希望完全透明和控制他们的爬虫。然而，Zyte更倾向于通过其Zyte智能代理管理器将IP地址管理权从用户手中拿走。Zyte控制通过哪些IP地址进行代理流量。IP地址在会话之间保持不变，但如果一个IP地址被阻止，则会切换IP地址。Zyte尝试使用IP地址切换来创建一个看起来有机的流量流向站点，避免引起怀疑。
- en: 'Using the Smart Proxy Manager is straightforward, although installing certificates
    on your machine may add complexity:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用智能代理管理器很简单，尽管在您的计算机上安装证书可能会增加复杂性：
- en: '[PRE28]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If you don’t want to use a certificate (although this is not recommended) you
    can turn off verification in the requests module:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想使用证书（尽管这不推荐），您可以在请求模块中关闭验证：
- en: '[PRE29]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Of course, Zyte also has instructions for integrating its [proxy services with
    Scrapy](https://scrapy-zyte-smartproxy.readthedocs.io/en/latest/), which can then
    be run in its Scrapy Cloud.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Zyte还有关于如何将其[代理服务与Scrapy集成](https://scrapy-zyte-smartproxy.readthedocs.io/en/latest/)的说明，然后可以在其Scrapy
    Cloud中运行。
- en: Proxy requests are around 1,600 per dollar (or less with more expensive monthly
    plans), API requests start around 12,000 per dollar. The Scrapy Cloud plans are
    relatively inexpensive, with a generous free tier and a $9/month “Professional”
    tier. This is likely to encourage the use of Scrapy and promote integration with
    the Zyte platform.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 代理请求大约每美元1600个（或者更昂贵的月度计划更少），API请求从每美元开始约12000个。Scrapy Cloud计划相对廉价，有一个慷慨的免费层和一个每月9美元的“专业”层。这很可能鼓励使用Scrapy并促进与Zyte平台的集成。
- en: Additional Resources
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: Many years ago, running “in the cloud” was mostly the domain of those who felt
    like slogging through the documentation and already had some server administration
    experience. Today, the tools have improved dramatically due to increased popularity
    and competition among cloud computing providers.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 许多年前，“云计算”主要是那些愿意费时阅读文档并且已经具备一定服务器管理经验的人的领域。如今，由于云计算服务的普及和竞争加剧，工具得到了显著改进。
- en: Still, for building large-scale or more-complex scrapers and crawlers, you might
    want a little more guidance on creating a platform for collecting and storing
    data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果要构建大规模或更复杂的网页抓取器和网络爬虫，你可能需要更多关于创建数据收集和存储平台的指导。
- en: '[*Google Compute Engine*](http://oreil.ly/1FVOw6y) by Marc Cohen, Kathryn Hurley,
    and Paul Newson (O’Reilly) is a straightforward resource on using Google Cloud
    Computing with both Python and JavaScript. It covers not only Google’s user interface
    but also the command-line and scripting tools that you can use to give your application
    greater flexibility.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Google Compute Engine*](http://oreil.ly/1FVOw6y) 由马克·科恩、凯瑟琳·赫利和保罗·纽森（O''Reilly）撰写，是一本关于使用Google云计算的简明资源，涵盖了Python和JavaScript。它不仅涵盖了Google的用户界面，还包括了命令行和脚本工具，可以让你的应用程序拥有更大的灵活性。'
- en: If you prefer to work with Amazon, Mitch Garnaat’s [*Python and AWS Cookbook*](http://oreil.ly/VSctQP)
    (O’Reilly) is a brief but extremely useful guide that will get you started with
    Amazon Web Services and show you how to get a scalable application up and running.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更喜欢使用亚马逊，米奇·加纳特的[*Python and AWS Cookbook*](http://oreil.ly/VSctQP)（O'Reilly）是一本简短但非常实用的指南，可以帮助你开始使用Amazon
    Web Services，并展示如何运行可扩展的应用程序。
- en: ^([1](ch20.html#id921-marker)) Technically, IP addresses can be spoofed in outgoing
    packets, which is a technique used in distributed denial-of-service attacks, where
    the attackers don’t care about receiving return packets (which, if sent, will
    be sent to the wrong address). But web scraping is, by definition, an activity
    in which a response from the web server is required, so we think of IP addresses
    as one thing that can’t be faked.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch20.html#id921-marker)) 从技术上讲，IP地址可以伪造出站的数据包，这是分布式拒绝服务攻击中使用的技术，攻击者并不关心是否接收返回的数据包（如果发送的话，会发送到错误的地址）。但网页抓取定义上是一种需要从网络服务器获取响应的活动，因此我们认为IP地址是无法伪造的一个因素。
- en: ^([2](ch20.html#id930-marker)) See Nicholas P. Fandos, “Harvard Sophomore Charged
    in Bomb Threat,” *The Harvard Crimson*, December 17, 2023, [*https://www.thecrimson.com/article/2013/12/17/student-charged-bomb-threat*](https://www.thecrimson.com/article/2013/12/17/student-charged-bomb-threat).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch20.html#id930-marker)) 参见尼古拉斯·P·范多斯，“哈佛大学二年级学生被指控炸弹威胁”，*哈佛深红报*，2023年12月17日，[*https://www.thecrimson.com/article/2013/12/17/student-charged-bomb-threat*](https://www.thecrimson.com/article/2013/12/17/student-charged-bomb-threat)。
