["```py\nmany_chunks = dd.read_csv(url, blocksize=\"1kb\")\nmany_chunks.index\n```", "```py\ndf = dd.read_csv(\n    \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\")\n```", "```py\ndf = dd.read_csv(\n    \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\",\n    dtype={'CompanyNumber': 'str', 'DiffMeanHourlyPercent': 'float64'})\n```", "```py\nfrom sqlite3 import connect\nfrom sqlalchemy import sql\nimport dask.dataframe as dd\n\n#sqlite connection\ndb_conn = \"sqlite://fake_school.sql\"\ndb = connect(db_conn)\n\ncol_student_num = sql.column(\"student_number\")\ncol_grade = sql.column(\"grade\")\ntbl_transcript = sql.table(\"transcripts\")\n\nselect_statement = sql.select([col_student_num,\n                              col_grade]\n                              ).select_from(tbl_transcript)\n\n#read from sql db\nddf = dd.read_sql_query(select_stmt,\n                        npartitions=4,\n                        index_col=col_student_num,\n                        con=db_conn)\n\n#alternatively, read whole table\nddf = dd.read_sql_table(\"transcripts\",\n                        db_conn,\n                        index_col=\"student_number\",\n                        npartitions=4\n                        )\n\n#do_some_ETL...\n\n#save to db\nddf.to_sql(\"transcript_analytics\",\n           uri=db_conn,\n           if_exists='replace',\n           schema=None,\n           index=False\n           )\n```", "```py\nfrom fsspec.registry import known_implementations\nknown_implementations\n```", "```py\nminio_storage_options = {\n    \"key\": \"YOURACCESSKEY\",\n    \"secret\": \"YOURSECRETKEY\",\n    \"client_kwargs\": {\n        \"endpoint_url\": \"http://minio-1602984784.minio.svc.cluster.local:9000\",\n        \"region_name\": 'us-east-1'\n    },\n    \"config_kwargs\": {\"s3\": {\"signature_version\": 's3v4'}},\n}\n```", "```py\nmini_sf_covid_df = (sf_covid_df\n                    [sf_covid_df['vaccination_status'] == 'All']\n                    [['specimen_collection_date', 'new_cases']])\n```", "```py\ndef process_overlap_window(df):\n    return df.rolling('5D').mean()\n\nrolling_avg = partitioned_df.map_overlap(\n    process_overlap_window,\n    pd.Timedelta('5D'),\n    0)\n```", "```py\ndask.compute(\n    raw_grouped[[\"new_cases\"]].max(),\n    raw_grouped[[\"new_cases\"]].mean())\n```", "```py\n# Write a custom weighted mean, we get either a DataFrameGroupBy\n# with multiple columns or SeriesGroupBy for each chunk\ndef process_chunk(chunk):\n    def weighted_func(df):\n        return (df[\"EmployerSize\"] * df[\"DiffMeanHourlyPercent\"]).sum()\n    return (chunk.apply(weighted_func), chunk.sum()[\"EmployerSize\"])\n\ndef agg(total, weights):\n    return (total.sum(), weights.sum())\n\ndef finalize(total, weights):\n    return total / weights\n\nweighted_mean = dd.Aggregation(\n    name='weighted_mean',\n    chunk=process_chunk,\n    agg=agg,\n    finalize=finalize)\n\naggregated = (df_diff_with_emp_size.groupby(\"PostCode\")\n              [\"EmployerSize\", \"DiffMeanHourlyPercent\"].agg(weighted_mean))\n```", "```py\nraw_grouped = sf_covid_df.groupby(lambda x: 0)\n```", "```py\n# Wrap Dask's hyperloglog in dd.Aggregation\n\nfrom dask.dataframe import hyperloglog\n\napprox_unique = dd.Aggregation(\n    name='approx_unique',\n    chunk=hyperloglog.compute_hll_array,\n    agg=hyperloglog.reduce_state,\n    finalize=hyperloglog.estimate_count)\n\naggregated = (df_diff_with_emp_size.groupby(\"PostCode\")\n              [\"EmployerSize\", \"DiffMeanHourlyPercent\"].agg(weighted_mean))\n```", "```py\ndivisions = pd.date_range(\n    start=\"2021-01-01\",\n    end=datetime.today(),\n    freq='7D').tolist()\npartitioned_df_as_part_of_set_index = mini_sf_covid_df.set_index(\n    'specimen_collection_date', divisions=divisions)\n```", "```py\nreparted = indexed.repartition(partition_size=\"20kb\")\n```", "```py\ndef fillna(df):\n    return df.fillna(value={\"PostCode\": \"UNKNOWN\"}).fillna(value=0)\n\nnew_df = df.map_partitions(fillna)\n# Since there could be an NA in the index clear the partition / division\n# information\nnew_df.clear_divisions()\n```", "```py\nfilename = './nyc_taxi/*.parquet'\ndf_x = dd.read_parquet(\n    filename,\n    split_row_groups=2\n)\n```", "```py\nimport pandas as pd\n\npd.set_option('display.float_format', lambda x: '%.5f' % x)\ndf.describe(percentiles=[.25, .5, .75]).compute()\n```", "```py\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport numpy as np\n\nget_ipython().run_line_magic('matplotlib', 'inline')\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\nf, axes = plt.subplots(1, 1, figsize=(11, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(\n    np.log(\n        df['trip_distance'].values +\n        1),\n    axlabel='Log(trip_distance)',\n    label='log(trip_distance)',\n    bins=50,\n    color=\"r\")\nplt.setp(axes, yticks=[])\nplt.tight_layout()\nplt.show()\n```"]