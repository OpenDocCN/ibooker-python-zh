["```py\nimport pandas as pd\n```", "```py\ndf = pd.read_csv(\n  \"https://raw.githubusercontent.com/noahgift/\\\n regression-concepts/master/\\\n height-weight-25k.csv\")\ndf.head()\n```", "```py\nimport seaborn as sns\nimport numpy as np\n```", "```py\nsns.lmplot(\"Height-Inches\", \"Weight-Pounds\", data=df)\n```", "```py\ndf.describe()\n```", "```py\nsns.jointplot(\"Height-Inches\", \"Weight-Pounds\", data=df, kind=\"kde\")\n```", "```py\nfrom sklearn.model_selection import train_test_split\n```", "```py\ny = df['Weight-Pounds'].values #Target\ny = y.reshape(-1, 1)\nX = df['Height-Inches'].values #Feature(s)\nX = X.reshape(-1, 1)\n```", "```py\ny.shape\n```", "```py\n(25000, 1)\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n```", "```py\n(20000, 1) (20000, 1)\n(5000, 1) (5000, 1)\n```", "```py\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nmodel = lm.fit(X_train, y_train)\ny_predicted = lm.predict(X_test)\n```", "```py\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n#RMSE Root Mean Squared Error\nrms = sqrt(mean_squared_error(y_predicted, y_test))\nrms\n```", "```py\n10.282608230082417\n```", "```py\nimport matplotlib.pyplot as plt\n_, ax = plt.subplots()\n\nax.scatter(x = range(0, y_test.size), y=y_test, c = 'blue', label = 'Actual',\n  alpha = 0.5)\nax.scatter(x = range(0, y_predicted.size), y=y_predicted, c = 'red',\n  label = 'Predicted', alpha = 0.5)\n\nplt.title('Actual Height vs Predicted Height')\nplt.xlabel('Weight')\nplt.ylabel('Height')\nplt.legend()\nplt.show()\n```", "```py\n# Training Data\nx_train = np.array(X_train, dtype=np.float32)\nx_train = x_train.reshape(-1, 1)\ny_train = np.array(y_train, dtype=np.float32)\ny_train = y_train.reshape(-1, 1)\n\n# Test Data\nx_test = np.array(X_test, dtype=np.float32)\nx_test = x_test.reshape(-1, 1)\ny_test = np.array(y_test, dtype=np.float32)\ny_test = y_test.reshape(-1, 1)\n```", "```py\nimport torch\nfrom torch.autograd import Variable\n\nclass linearRegression(torch.nn.Module):\n    def __init__(self, inputSize, outputSize):\n        super(linearRegression, self).__init__()\n        self.linear = torch.nn.Linear(inputSize, outputSize)\n\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n```", "```py\ninputDim = 1        # takes variable 'x'\noutputDim = 1       # takes variable 'y'\nlearningRate = 0.0001\nepochs = 1000\n\nmodel = linearRegression(inputDim, outputDim)\nmodel.cuda()\n```", "```py\nlinearRegression(\n  (linear): Linear(in_features=1, out_features=1, bias=True)\n)\n```", "```py\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n```", "```py\nfor epoch in range(epochs):\n    inputs = Variable(torch.from_numpy(x_train).cuda())\n    labels = Variable(torch.from_numpy(y_train).cuda())\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    print(loss)\n    # get gradients w.r.t to parameters\n    loss.backward()\n    # update parameters\n    optimizer.step()\n    print('epoch {}, loss {}'.format(epoch, loss.item()))\n```", "```py\ntensor(29221.6543, device='cuda:0', grad_fn=<MseLossBackward>)\nepoch 0, loss 29221.654296875\ntensor(266.7252, device='cuda:0', grad_fn=<MseLossBackward>)\nepoch 1, loss 266.72515869140625\ntensor(106.6842, device='cuda:0', grad_fn=<MseLossBackward>)\nepoch 2, loss 106.6842269897461\n....output suppressed....\nepoch 998, loss 105.7930908203125\ntensor(105.7931, device='cuda:0', grad_fn=<MseLossBackward>)\nepoch 999, loss 105.7930908203125\n```", "```py\nwith torch.no_grad():\n    predicted = model(Variable(torch.from_numpy(x_test).cuda())).cpu().\\\n      data.numpy()\n    print(predicted)\n\nplt.clf()\nplt.plot(x_test, y_test, 'go', label='Actual Height', alpha=0.5)\nplt.plot(x_test, predicted, '--', label='Predicted Height', alpha=0.5)\nplt.legend(loc='best')\nplt.show()\n```", "```py\n#RMSE Root Mean Squared Error\nrms = sqrt(mean_squared_error(x_test, predicted))\nrms\n```", "```py\n59.19054613663507\n```", "```py\nFROM python:3.7.3-stretch\n\n# Working Directory\nWORKDIR /app\n\n# Copy source code to working directory\nCOPY . app.py /app/\n\n# Install packages from requirements.txt\n# hadolint ignore=DL3013\nRUN pip install --upgrade pip &&\\\n    pip install --trusted-host pypi.python.org -r requirements.txt\n\n# Expose port 80\nEXPOSE 80\n\n# Run app.py at container launch\nCMD [\"python\", \"app.py\"]\n```", "```py\nsetup:\n  python3 -m venv ~/.python-devops\n\ninstall:\n  pip install --upgrade pip &&\\\n    pip install -r requirements.txt\n\ntest:\n  #python -m pytest -vv --cov=myrepolib tests/*.py\n  #python -m pytest --nbval notebook.ipynb\n\nlint:\n  hadolint Dockerfile\n  pylint --disable=R,C,W1203 app.py\n\nall: install lint test\n```", "```py\nFlask==1.0.2\npandas==0.24.2\nscikit-learn==0.20.3\n```", "```py\nfrom flask import Flask, request, jsonify\nfrom flask.logging import create_logger\nimport logging\n\nimport pandas as pd\nfrom sklearn.externals import joblib\nfrom sklearn.preprocessing import StandardScaler\n\napp = Flask(__name__)\nLOG = create_logger(app)\nLOG.setLevel(logging.INFO)\n\ndef scale(payload):\n    \"\"\"Scales Payload\"\"\"\n\n    LOG.info(f\"Scaling Payload: {payload}\")\n    scaler = StandardScaler().fit(payload)\n    scaled_adhoc_predict = scaler.transform(payload)\n    return scaled_adhoc_predict\n\n@app.route(\"/\")\ndef home():\n    html = \"<h3>Sklearn Prediction Home</h3>\"\n    return html.format(format)\n\n# TO DO:  Log out the prediction value\n@app.route(\"/predict\", methods=['POST'])\ndef predict():\n    \"\"\"Performs an sklearn prediction\n\n input looks like:\n {\n \"CHAS\":{\n \"0\":0\n },\n \"RM\":{\n \"0\":6.575\n },\n \"TAX\":{\n \"0\":296.0\n },\n \"PTRATIO\":{\n \"0\":15.3\n },\n \"B\":{\n \"0\":396.9\n },\n \"LSTAT\":{\n \"0\":4.98\n }\n\n result looks like:\n { \"prediction\": [ 20.35373177134412 ] }\n\n \"\"\"\n\n    json_payload = request.json\n    LOG.info(f\"JSON payload: {json_payload}\")\n    inference_payload = pd.DataFrame(json_payload)\n    LOG.info(f\"inference payload DataFrame: {inference_payload}\")\n    scaled_payload = scale(inference_payload)\n    prediction = list(clf.predict(scaled_payload))\n    return jsonify({'prediction': prediction})\n\nif __name__ == \"__main__\":\n    clf = joblib.load(\"boston_housing_prediction.joblib\")\n    app.run(host='0.0.0.0', port=80, debug=True)\n```", "```py\n#!/usr/bin/env bash\n\n# Build image\ndocker build --tag=flasksklearn .\n\n# List docker images\ndocker image ls\n\n# Run flask app\ndocker run -p 8000:80 flasksklearn\n```", "```py\n#!/usr/bin/env bash\n\ndockerpath=\"noahgift/flasksklearn\"\n\n# Run in Docker Hub container with kubernetes\nkubectl run flaskskearlndemo\\\n    --generator=run-pod/v1\\\n    --image=$dockerpath\\\n    --port=80 --labels app=flaskskearlndemo\n\n# List kubernetes pods\nkubectl get pods\n\n# Forward the container port to host\nkubectl port-forward flaskskearlndemo 8000:80\n```", "```py\n#!/usr/bin/env bash\n# This tags and uploads an image to Docker Hub\n\n#Assumes this is built\n#docker build --tag=flasksklearn .\n\ndockerpath=\"noahgift/flasksklearn\"\n\n# Authenticate & Tag\necho \"Docker ID and Image: $dockerpath\"\ndocker login &&\\\n    docker image tag flasksklearn $dockerpath\n\n# Push Image\ndocker image push $dockerpath\n```", "```py\nimport numpy\nfrom numpy import arange\nfrom matplotlib import pyplot\nimport seaborn as sns\nimport pandas as pd\nfrom pandas import read_csv\nfrom pandas import set_option\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n```", "```py\nboston_housing = \"https://raw.githubusercontent.com/\\\nnoahgift/boston_housing_pickle/master/housing.csv\"\nnames = ['CRIM', 'ZN', 'INDUS', 'CHAS',\n'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndf = read_csv(boston_housing,\n  delim_whitespace=True, names=names)\n```", "```py\ndf.head()\n```", "```py\nprices = df['MEDV']\ndf = df.drop(['CRIM','ZN','INDUS','NOX','AGE','DIS','RAD'], axis = 1)\nfeatures = df.drop('MEDV', axis = 1)\ndf.head()\n```", "```py\n# Split-out validation dataset\narray = df.values\nX = array[:,0:6]\nY = array[:,6]\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y,\n  test_size=validation_size, random_state=seed)\n```", "```py\nfor sample in list(X_validation)[0:2]:\n    print(f\"X_validation {sample}\")\n```", "```py\nX_validation [  1.      6.395 666.     20.2   391.34   13.27 ]\nX_validation [  0.      5.895 224.     20.2   394.81   10.56 ]\n```", "```py\n# Test options and evaluation metric using Root Mean Square error method\nnum_folds = 10\nseed = 7\nRMS = 'neg_mean_squared_error'\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nparam_grid = dict(n_estimators=numpy.array([50,100,150,200,250,300,350,400]))\nmodel = GradientBoostingRegressor(random_state=seed)\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=RMS, cv=kfold)\ngrid_result = grid.fit(rescaledX, Y_train)\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n```", "```py\nBest: -11.830068 using {'n_estimators': 200}\n-12.479635 (6.348297) with: {'n_estimators': 50}\n-12.102737 (6.441597) with: {'n_estimators': 100}\n-11.843649 (6.631569) with: {'n_estimators': 150}\n-11.830068 (6.559724) with: {'n_estimators': 200}\n-11.879805 (6.512414) with: {'n_estimators': 250}\n-11.895362 (6.487726) with: {'n_estimators': 300}\n-12.008611 (6.468623) with: {'n_estimators': 350}\n-12.053759 (6.453899) with: {'n_estimators': 400}\n\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841:\nDeprecationWarning:\nDeprecationWarning)\n```", "```py\n# prepare the model\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nmodel = GradientBoostingRegressor(random_state=seed, n_estimators=400)\nmodel.fit(rescaledX, Y_train)\n# transform the validation dataset\nrescaledValidationX = scaler.transform(X_validation)\npredictions = model.predict(rescaledValidationX)\nprint(\"Mean Squared Error: \\n\")\nprint(mean_squared_error(Y_validation, predictions))\n```", "```py\nMean Squared Error:\n\n26.326748591395717\n```", "```py\npredictions=predictions.astype(int)\nevaluate = pd.DataFrame({\n        \"Org House Price\": Y_validation,\n        \"Pred House Price\": predictions\n    })\nevaluate[\"difference\"] = evaluate[\"Org House Price\"]-evaluate[\"Pred House Price\"]\nevaluate.head()\n```", "```py\nevaluate.describe()\n```", "```py\nactual_sample = df.head(1)\nactual_sample\n```", "```py\nadhoc_predict = actual_sample[[\"CHAS\", \"RM\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]]\nadhoc_predict.head()\n```", "```py\njson_payload = adhoc_predict.to_json()\njson_payload\n```", "```py\n{\"CHAS\":{\"0\":0},\"RM\":\n{\"0\":6.575},\"TAX\":\n{\"0\":296.0},\"PTRATIO\":\n{\"0\":15.3},\"B\":{\"0\":396.9},\"LSTAT\":\n{\"0\":4.98}}\n```", "```py\nscaler = StandardScaler().fit(adhoc_predict)\nscaled_adhoc_predict = scaler.transform(adhoc_predict)\nscaled_adhoc_predict\n```", "```py\narray([[0., 0., 0., 0., 0., 0.]])\n```", "```py\nlist(model.predict(scaled_adhoc_predict))\n```", "```py\n[20.35373177134412]\n```", "```py\nfrom sklearn.externals import joblib\n```", "```py\njoblib.dump(model, 'boston_housing_prediction.joblib')\n```", "```py\n['boston_housing_prediction.joblib']\n```", "```py\n!ls -l\n```", "```py\ntotal 672\n-rw-r--r-- 1 root root 681425 May  5 00:35 boston_housing_prediction.joblib\ndrwxr-xr-x 1 root root   4096 Apr 29 16:32 sample_data\n```", "```py\nclf = joblib.load('boston_housing_prediction.joblib')\n```", "```py\nactual_sample2 = df.head(5)\nactual_sample2\n```", "```py\nadhoc_predict2 = actual_sample[[\"CHAS\", \"RM\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]]\nadhoc_predict2.head()\n```", "```py\nscaler = StandardScaler().fit(adhoc_predict2)\nscaled_adhoc_predict2 = scaler.transform(adhoc_predict2)\nscaled_adhoc_predict2\n```", "```py\narray([[0., 0., 0., 0., 0., 0.]])\n```", "```py\n# Use pickle loaded model\nlist(clf.predict(scaled_adhoc_predict2))\n```", "```py\n[20.35373177134412]\n```"]