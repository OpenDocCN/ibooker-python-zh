<html><head></head><body><section data-pdf-bookmark="Chapter 19. Web Scraping in Parallel" data-type="chapter" epub:type="chapter"><div class="chapter" id="c-19">&#13;
<h1><span class="label">Chapter 19. </span>Web Scraping in Parallel</h1>&#13;
&#13;
<p>Web crawling is fast. At least, it’s usually much faster than hiring a dozen interns to copy data from the internet by hand! Of course, the progression of technology and the hedonic treadmill demand that at a certain point even this will not be “fast enough.” That’s the point at which people generally start to look toward distributed computing.</p>&#13;
&#13;
<p>Unlike most other technology fields, web crawling cannot often be improved simply by “throwing more cycles at the problem.” Running one process is fast; running two processes is not necessarily twice as fast. Running three processes might get you banned from the remote server you’re hammering on with all your requests!</p>&#13;
&#13;
<p>However, in some situations parallel web crawling, or running parallel threads or processes, can still be of benefit:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Collecting data from multiple sources (multiple remote servers) instead of just a single source</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Performing long or complex operations on the collected data (such as doing image analysis or OCR) that could be done in parallel with fetching the data</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Collecting data from a large web service where you are paying for each query, or where creating multiple connections to the service is within the bounds of your usage agreement</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<section data-pdf-bookmark="Processes Versus Threads" data-type="sect1"><div class="sect1" id="id118">&#13;
<h1>Processes Versus Threads</h1>&#13;
&#13;
<p>Threads and processes are not a Python-specific <a contenteditable="false" data-primary="parallel web crawling, processes versus threads" data-type="indexterm" id="pwwpvth"/>concept. While the exact implementation details differ between (and are dependent on) operating systems, the general consensus in computer science is that processes are larger and have their own <span class="keep-together">memory, while</span> threads are smaller and share memory within the process that contains them.</p>&#13;
&#13;
<p>Generally, when you run a simple Python program, you are running it within its own process which contains a single thread. But Python supports both multiprocessing and multithreading. Both multiprocessing and multithreading achieve the same ultimate goal: performing two programming tasks in parallel instead of running one function after another in a more traditional linear way.</p>&#13;
&#13;
<p>However, you must consider the pros and cons of each carefully. For example, each process has its own memory allocated separately by the operating system. This means that memory is not shared between processes. While multiple threads can happily write to the same shared Python queues, lists, and other objects, processes cannot and must communicate this information more explicitly.</p>&#13;
&#13;
<p>Using multithreaded programming to execute tasks in separate threads with shared memory is often considered easier than multiprocess programming. But this convenience comes at a cost.</p>&#13;
&#13;
<p>Python’s global interpreter lock (or GIL) acts <a contenteditable="false" data-primary="GIL (global interpreter lock)" data-type="indexterm" id="id897"/>to prevent threads from executing the same line of code at once. The GIL ensures that the common memory shared by all processes does not become corrupted (for instance, bytes in memory being half written with one value and half written with another value). This locking makes it possible to write a multithreaded program and know what you’re getting, within the same line, but it also <a contenteditable="false" data-primary="parallel web crawling, processes versus threads" data-startref="pwwpvth" data-type="indexterm" id="id898"/>has the potential to create bottlenecks.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Multithreaded Crawling" data-type="sect1"><div class="sect1" id="id119">&#13;
<h1>Multithreaded Crawling</h1>&#13;
&#13;
<p>The following example illustrates using <a contenteditable="false" data-primary="multithreaded web crawling" data-type="indexterm" id="mttww"/>multiple threads to perform a task:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">threading</code>&#13;
<code class="kn">import</code> <code class="nn">time</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">print_time</code><code class="p">(</code><code class="n">threadName</code><code class="p">,</code> <code class="n">delay</code><code class="p">,</code> <code class="n">iterations</code><code class="p">):</code>&#13;
    <code class="n">start</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">())</code>&#13;
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="n">iterations</code><code class="p">):</code>&#13;
        <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="n">delay</code><code class="p">)</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'</code><code class="si">{</code><code class="nb">int</code><code class="p">(</code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code> <code class="o">-</code> <code class="n">start</code><code class="p">)</code><code class="si">}</code><code class="s1"> - </code><code class="si">{</code><code class="n">threadName</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
&#13;
<code class="n">threads</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Fizz'</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">33</code><code class="p">)),</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Buzz'</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">20</code><code class="p">)),</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Counter'</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">100</code><code class="p">))</code>&#13;
<code class="p">]</code>&#13;
&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>This is a reference to the classic <a href="http://wiki.c2.com/?FizzBuzzTest">FizzBuzz programming test</a>, with a <a contenteditable="false" data-primary="FizzBuzz programming test" data-type="indexterm" id="id899"/>somewhat more verbose output:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
1 Counter&#13;
2 Counter&#13;
3 Fizz&#13;
3 Counter&#13;
4 Counter&#13;
5 Buzz&#13;
5 Counter&#13;
6 Fizz&#13;
6 Counter&#13;
</pre>&#13;
&#13;
<p>The script starts three threads, one that prints “Fizz” every three seconds, another that prints “Buzz” every five seconds, and a third that prints “Counter" every second.</p>&#13;
&#13;
<p>Rather than printing fizzes and buzzes, you can perform a useful task in the threads, such as crawling a website:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
<code class="kn">import</code> <code class="nn">re</code>&#13;
<code class="kn">import</code> <code class="nn">random</code>&#13;
<code class="kn">import</code> <code class="nn">threading</code>&#13;
<code class="kn">import</code> <code class="nn">time</code>&#13;
&#13;
<code class="c1"># Recursively find links on a Wikipedia page, </code>&#13;
<code class="c1"># then follow a random link, with artificial 5 sec delay</code>&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">path</code><code class="p">):</code>&#13;
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'</code><code class="si">{</code><code class="n">thread_name</code><code class="si">}</code><code class="s1">: Scraping </code><code class="si">{</code><code class="n">path</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
    <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://en.wikipedia.org</code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
    <code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
    <code class="n">title</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'h1'</code><code class="p">)</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'bodyContent'</code><code class="p">})</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'a'</code><code class="p">,</code>&#13;
        <code class="n">href</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'^(/wiki/)((?!:).)*$'</code><code class="p">))</code>&#13;
    <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">:</code>&#13;
        <code class="n">newArticle</code> <code class="o">=</code> <code class="n">links</code><code class="p">[</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code><code class="o">-</code><code class="mi">1</code><code class="p">)]</code><code class="o">.</code><code class="n">attrs</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code>&#13;
        <code class="n">scrape_article</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">newArticle</code><code class="p">)</code>&#13;
&#13;
           &#13;
<code class="n">threads</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code>&#13;
        <code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code>&#13;
        <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Thread 1'</code><code class="p">,</code> <code class="s1">'/wiki/Kevin_Bacon'</code><code class="p">,)</code>&#13;
    <code class="p">),</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code>&#13;
        <code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code>&#13;
        <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Thread 2'</code><code class="p">,</code> <code class="s1">'/wiki/Monty_Python'</code><code class="p">,)</code>&#13;
    <code class="p">),</code>&#13;
<code class="p">]</code>&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>Note the inclusion of this line:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Because you are crawling Wikipedia almost twice as fast as you would with just a single thread, the inclusion of this line prevents the script from putting too much of a load on Wikipedia’s servers. In practice, when running against a server where the number of requests is not an issue, this line should be removed.</p>&#13;
&#13;
<p>What if you want to rewrite this slightly to keep track of the articles the threads have collectively seen so far, so that no article is visited twice? You can use a list in a multithreaded environment in the same way that you use it in a single-threaded <span class="keep-together">environment:</span></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">visited</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="k">def</code> <code class="nf">get_links</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">bs</code><code class="p">):</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Getting links in </code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">thread_name</code><code class="p">))</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'bodyContent'</code><code class="p">})</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'a'</code><code class="p">,</code>&#13;
        <code class="n">href</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'^(/wiki/)((?!:).)*$'</code><code class="p">)</code>&#13;
    <code class="p">)</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">link</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code> <code class="k">if</code> <code class="n">link</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">visited</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">path</code><code class="p">):</code>&#13;
    <code class="n">visited</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">path</code><code class="p">)</code>&#13;
    <code class="o">...</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">get_links</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">bs</code><code class="p">)</code>&#13;
    <code class="o">...</code>&#13;
</pre>&#13;
&#13;
<p>Note that you are appending the path to <a contenteditable="false" data-primary="threading module" data-secondary="paths, appending" data-type="indexterm" id="id900"/>the list of visited paths as the first action that <code>scrape_article</code> takes. This reduces, but does not entirely eliminate, the chances that it will be scraped twice.</p>&#13;
&#13;
<p>If you are unlucky, both threads might still stumble across the same path at the same instant, both will see that it is not in the visited list, and both will subsequently add it to the list and scrape at the same time. However, in practice this is unlikely to happen because of the speed of execution and the number of pages that Wikipedia contains.</p>&#13;
&#13;
<p>This is an example of a <em>race condition</em>. Race conditions can be tricky to debug, even for experienced programmers, so it is important to evaluate your code for these potential situations, estimate their likelihood, and anticipate the seriousness of their impact.</p>&#13;
&#13;
<p>In the case of this particular race condition, where the scraper goes over the same page twice, it may not be worth writing around.</p>&#13;
&#13;
<section data-pdf-bookmark="Race Conditions and Queues" data-type="sect2"><div class="sect2" id="id120">&#13;
<h2>Race Conditions and Queues</h2>&#13;
&#13;
<p>Although you can communicate between <a contenteditable="false" data-primary="race conditions" data-type="indexterm" id="rccd"/><a contenteditable="false" data-primary="queues" data-type="indexterm" id="qusue"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="race conditions" data-type="indexterm" id="mttwwr"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="queues" data-type="indexterm" id="mttwwcq"/>threads with lists, lists are not specifically designed for communication between threads, and their misuse can easily cause slow program execution or even errors resulting from race conditions.</p>&#13;
&#13;
<p>Lists are great for appending to or reading from, but they’re not so great for removing items at arbitrary points, especially from the beginning of the list. Using a line like:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">myList</code><code class="o">.</code><code class="n">pop</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>actually requires Python to rewrite the entire list, slowing program execution.</p>&#13;
&#13;
<p>More dangerous, lists also make it convenient to accidentally write in a line that isn’t thread-safe. For instance:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">myList</code><code class="p">[</code><code class="nb">len</code><code class="p">(</code><code class="n">myList</code><code class="p">)</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>may not actually get you the last item in the list in a multithreaded environment, or it may even throw an exception if the value for <code>len(myList)-1</code> is calculated immediately before another operation modifies the list.</p>&#13;
&#13;
<p>One might argue that the preceding statement can be more “Pythonically” written as <code>myList[-1]</code>, and of course, no one has <em>ever</em> accidentally written non-Pythonic code in a moment of weakness (especially not former Java developers like myself, thinking back to their days of patterns like <code>myList[myList.length-1]</code> )! But even if your code is beyond reproach, consider these other forms of nonthread-safe lines involving lists:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">my_list</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">my_list</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">+</code> <code class="mi">1</code>&#13;
<code class="n">my_list</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">my_list</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">])</code>&#13;
</pre>&#13;
&#13;
<p>Both of these may result in a race condition that can cause unexpected results. You might be tempted to try another approach and use some other variable types besides lists. For example:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Read the message in from the global list</code>&#13;
<code class="n">my_message</code> <code class="o">=</code> <code class="n">global_message</code>&#13;
<code class="c1"># Write a message back</code>&#13;
<code class="n">global_message</code> <code class="o">=</code> <code class="s1">'I'</code><code class="n">ve</code> <code class="n">retrieved</code> <code class="n">the</code> <code class="n">message</code><code class="s1">'</code><code class="w"/>&#13;
<code class="c1"># do something with my_message</code>&#13;
</pre>&#13;
&#13;
<p>This seems like an excellent solution until you realize that you might have inadvertently overwritten another <a contenteditable="false" data-primary="overwritten messages" data-type="indexterm" id="id901"/>message coming in from another thread, in the instant between the first and second lines, with the text “I’ve retrieved the message.” So now you just need to construct an elaborate series of personal message objects for each thread with some logic to figure out who gets what...or you could use the <code>Queue</code> module built for this exact purpose.</p>&#13;
&#13;
<p class="pagebreak-before">Queues are list-like <a contenteditable="false" data-primary="queues" data-secondary="LIFO (last in, first out)" data-type="indexterm" id="id902"/><a contenteditable="false" data-primary="queues" data-secondary="FIFO (first in, first out)" data-type="indexterm" id="id903"/><a contenteditable="false" data-primary="FIFO (first in, first out)" data-type="indexterm" id="id904"/><a contenteditable="false" data-primary="LIFO (last in, last out)" data-type="indexterm" id="id905"/><a contenteditable="false" data-primary="last in, last out (LILO)" data-type="indexterm" id="id906"/><a contenteditable="false" data-primary="first in, first out (FIFO)" data-type="indexterm" id="id907"/>objects that operate on either a first in, first out (FIFO) or a last in, first out (LIFO) approach. A queue receives messages from any thread via <code>queue.put('My message')</code> and can transmit the message to any thread that calls <code>queue.get()</code>.</p>&#13;
&#13;
<p>Queues are not designed to store static data but to transmit it in a thread-safe way. After the data is retrieved from the queue, it should exist only in the thread that retrieved it. For this reason, they are commonly used to delegate tasks or send temporary notifications.</p>&#13;
&#13;
<p>This can be useful in web crawling. For instance, let’s say that you want to persist the data collected by your scraper into a database, and you want each thread to be able to persist its data quickly. A single shared connection for all threads might cause issues (a single connection cannot handle requests in parallel), but it makes no sense to give every single scraping thread its own database connection. As your scraper grows in size (eventually you may be collecting data from a hundred different websites in a hundred different threads), this might translate into a lot of mostly idle database connections doing only an occasional write after a page loads.</p>&#13;
&#13;
<p>Instead, you can have a smaller number of database threads, each with its own connection, sitting around taking items from a queue and storing them. This provides a much more manageable set of database connections:</p>&#13;
&#13;
<pre class="pre" data-code-language="python" data-type="programlisting">&#13;
<code class="k">def</code> <code class="nf">storage</code><code class="p">(</code><code class="n">queue</code><code class="p">):</code>&#13;
    <code class="n">conn</code> <code class="o">=</code> <code class="n">pymysql</code><code class="o">.</code><code class="n">connect</code><code class="p">(</code><code class="n">host</code><code class="o">=</code><code class="s1">'127.0.0.1'</code><code class="p">,</code> <code class="n">unix_socket</code><code class="o">=</code><code class="s1">'/tmp/mysql.sock'</code><code class="p">,</code>&#13;
    <code class="n">user</code><code class="o">=</code><code class="s1">'root'</code><code class="p">,</code> <code class="n">passwd</code><code class="o">=</code><code class="s1">'password'</code><code class="p">,</code> <code class="n">db</code><code class="o">=</code><code class="s1">'mysql'</code><code class="p">,</code> <code class="n">charset</code><code class="o">=</code><code class="s1">'utf8'</code><code class="p">)</code>&#13;
    <code class="n">cur</code> <code class="o">=</code> <code class="n">conn</code><code class="o">.</code><code class="n">cursor</code><code class="p">()</code>&#13;
    <code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'USE wikipedia'</code><code class="p">)</code>&#13;
    <code class="k">while</code> <code class="mi">1</code><code class="p">:</code>&#13;
        <code class="k">if</code> <code class="ow">not</code> <code class="n">queue</code><code class="o">.</code><code class="n">empty</code><code class="p">():</code>&#13;
            <code class="n">path</code> <code class="o">=</code> <code class="n">queue</code><code class="o">.</code><code class="n">get</code><code class="p">()</code>&#13;
            <code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'SELECT * FROM pages WHERE url = </code><code class="si">%s</code><code class="s1">'</code><code class="p">,</code> <code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
            <code class="k">if</code> <code class="n">cur</code><code class="o">.</code><code class="n">rowcount</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>&#13;
                <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'Storing article </code><code class="si">{</code><code class="n">path</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
                <code class="n">cur</code><code class="o">.</code><code class="n">execute</code><code class="p">(</code><code class="s1">'INSERT INTO pages (url) VALUES (</code><code class="si">%s</code><code class="s1">)'</code><code class="p">,</code> <code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
                <code class="n">conn</code><code class="o">.</code><code class="n">commit</code><code class="p">()</code>&#13;
            <code class="k">else</code><code class="p">:</code>&#13;
                <code class="nb">print</code><code class="p">(</code><code class="s2">"Article already exists: </code><code class="si">{}</code><code class="s2">"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
&#13;
<code class="n">visited</code> <code class="o">=</code> <code class="nb">set</code><code class="p">()</code>&#13;
<code class="k">def</code> <code class="nf">get_links</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">bs</code><code class="p">):</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s1">'Getting links in </code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">thread_name</code><code class="p">))</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'bodyContent'</code><code class="p">})</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code>&#13;
        <code class="s1">'a'</code><code class="p">,</code>&#13;
        <code class="n">href</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'^(/wiki/)((?!:).)*$'</code><code class="p">)</code>&#13;
    <code class="p">)</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="p">[</code><code class="n">link</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'href'</code><code class="p">)</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code><code class="p">]</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">link</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code> <code class="k">if</code> <code class="n">link</code> <code class="ow">and</code> <code class="n">link</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">visited</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">path</code><code class="p">):</code>&#13;
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
    <code class="n">visited</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">path</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'</code><code class="si">{</code><code class="n">thread_name</code><code class="si">}</code><code class="s1">: Scraping </code><code class="si">{</code><code class="n">path</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
    <code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code>&#13;
        <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://en.wikipedia.org</code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">path</code><code class="p">)),</code>&#13;
        <code class="s1">'html.parser'</code>&#13;
    <code class="p">)</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">get_links</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">bs</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">:</code>&#13;
        <code class="p">[</code><code class="n">queue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">link</code><code class="p">)</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code><code class="p">]</code>&#13;
        <code class="n">newArticle</code> <code class="o">=</code> <code class="n">links</code><code class="p">[</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code><code class="o">-</code><code class="mi">1</code><code class="p">)]</code><code class="o">.</code><code class="n">attrs</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code>&#13;
        <code class="n">scrape_article</code><code class="p">(</code><code class="n">thread_name</code><code class="p">,</code> <code class="n">newArticle</code><code class="p">)</code>&#13;
&#13;
&#13;
<code class="n">queue</code> <code class="o">=</code> <code class="n">Queue</code><code class="p">()</code>&#13;
&#13;
&#13;
<code class="n">threads</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code>&#13;
    <code class="err">​</code>    <code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code>&#13;
<code class="err">​</code>    <code class="err">​</code>    <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Thread 1'</code><code class="p">,</code> <code class="s1">'/wiki/Kevin_Bacon'</code><code class="p">,)</code>&#13;
<code class="err">​</code>    <code class="p">),</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code>&#13;
<code class="err">​</code>    <code class="err">​</code>    <code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code>&#13;
<code class="err">​</code>    <code class="err">​</code>    <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Thread 2'</code><code class="p">,</code> <code class="s1">'/wiki/Monty_Python'</code><code class="p">,)</code>&#13;
<code class="err">​</code>    <code class="p">),</code>&#13;
    <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code>&#13;
<code class="err">​</code>    <code class="err">​</code>    <code class="n">target</code><code class="o">=</code><code class="n">storage</code><code class="p">,</code>&#13;
<code class="err">​</code>    <code class="err">​</code>    <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">queue</code><code class="p">,)</code>&#13;
<code class="err">​</code>    <code class="p">)</code>&#13;
<code class="p">]</code>&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>&#13;
&#13;
</pre>&#13;
&#13;
<p>This script creates three threads: two to scrape pages from Wikipedia in a random walk, and a third to store the collected data in a MySQL database. For more information about MySQL and data storage, see <a data-type="xref" href="ch09.html#c-9">Chapter 9</a>.</p>&#13;
&#13;
<p>This scraper is also simplified somewhat from the previous one. Rather than deal with both the title and the page’s URL, it concerns itself with the URL only. Also, as an acknowledgement to the fact that both threads might attempt to add the exact same URL to the <code>visited</code> list at the exact same time, I’ve turned this list into a set. Although it is not strictly thread-safe, the redundancies are built in so that any <a contenteditable="false" data-primary="race conditions" data-startref="rccd" data-type="indexterm" id="id908"/><a contenteditable="false" data-primary="queues" data-startref="qusue" data-type="indexterm" id="id909"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="race conditions" data-startref="mttwwr" data-type="indexterm" id="id910"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="queues" data-startref="mttwwcq" data-type="indexterm" id="id911"/>duplicates won’t have any effect on the end result.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="More Features of the Threading Module" data-type="sect2"><div class="sect2" id="id121">&#13;
<h2 class="pagebreak-before less_space">More Features of the Threading Module</h2>&#13;
&#13;
<p>The Python <code>threading</code> module is a higher-level interface built on the lower-level  <code>_thread</code> module. Although <code>_thread</code> is perfectly usable all on its own, it takes a little more effort and doesn’t provide the little things that make life so enjoyable—like convenience functions and nifty features.</p>&#13;
&#13;
<p>For example, you can use static functions <a contenteditable="false" data-primary="threading module" data-secondary="static functions" data-type="indexterm" id="id912"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="threading module" data-type="indexterm" id="mttwwm"/>like <code>enumerate</code> to get a list of all active threads initialized through the <code>threading</code> module without needing to keep track of them yourself. The <code>activeCount</code> function, similarly, provides the total number of threads. Many functions from <code>_thread</code> are given more convenient or memorable names, like <code>currentThread</code> instead of <code>get_ident</code> to get the name of the current thread.</p>&#13;
&#13;
<p>One of the nice things about the threading module is the ease of creating local thread data that is unavailable to the other threads. This might be a nice feature if you have several threads, each scraping a different website, and each keeping track of its own local list of visited pages.</p>&#13;
&#13;
<p>This local data can be created at any point within the thread function by calling <code>threading.local()</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">threading</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">crawler</code><code class="p">(</code><code class="n">url</code><code class="p">):</code>&#13;
    <code class="n">data</code> <code class="o">=</code> <code class="n">threading</code><code class="o">.</code><code class="n">local</code><code class="p">()</code>&#13;
    <code class="n">data</code><code class="o">.</code><code class="n">visited</code> <code class="o">=</code> <code class="p">[]</code>&#13;
    <code class="c1"># Crawl site</code>&#13;
    &#13;
<code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">crawler</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'http://brookings.edu'</code><code class="p">))</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
&#13;
</pre>&#13;
&#13;
<p>This solves the problem of race conditions happening between shared objects in threads. Whenever an object does not need to be shared, it should not be, and should be kept in local thread memory. To safely share objects between threads, the <code>Queue</code> from the previous section can still be used.</p>&#13;
&#13;
<p>The threading module acts as a thread babysitter of sorts, and it can be highly customized to define what that babysitting entails. The <code>isAlive</code> function by default looks to see if the thread is still active. It will be true until a thread completes crawling (or crashes).</p>&#13;
&#13;
<p class="pagebreak-before">Often, crawlers are designed to run for a very long time. The <code>isAlive</code> method can ensure that, if a thread crashes, it restarts:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">crawler</code><code class="p">)</code>&#13;
<code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
&#13;
<code class="k">while</code> <code class="kc">True</code><code class="p">:</code>&#13;
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="ow">not</code> <code class="n">t</code><code class="o">.</code><code class="n">isAlive</code><code class="p">():</code>&#13;
        <code class="n">t</code> <code class="o">=</code> <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">crawler</code><code class="p">)</code>&#13;
        <code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>Other monitoring methods can be added by extending the <code>threading.Thread</code> object:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">threading</code>&#13;
<code class="kn">import</code> <code class="nn">time</code>&#13;
&#13;
<code class="k">class</code> <code class="nc">Crawler</code><code class="p">(</code><code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">):</code>&#13;
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>&#13;
        <code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="o">.</code><code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">done</code> <code class="o">=</code> <code class="kc">False</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf">isDone</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>&#13;
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">done</code>&#13;
&#13;
    <code class="k">def</code> <code class="nf">run</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>&#13;
        <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
        <code class="bp">self</code><code class="o">.</code><code class="n">done</code> <code class="o">=</code> <code class="kc">True</code>&#13;
        <code class="k">raise</code> <code class="ne">Exception</code><code class="p">(</code><code class="s1">'Something bad happened!'</code><code class="p">)</code>&#13;
&#13;
<code class="n">t</code> <code class="o">=</code> <code class="n">Crawler</code><code class="p">()</code>&#13;
<code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
&#13;
<code class="k">while</code> <code class="kc">True</code><code class="p">:</code>&#13;
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="n">t</code><code class="o">.</code><code class="n">isDone</code><code class="p">():</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="s1">'Done'</code><code class="p">)</code>&#13;
        <code class="k">break</code>&#13;
    <code class="k">if</code> <code class="ow">not</code> <code class="n">t</code><code class="o">.</code><code class="n">isAlive</code><code class="p">():</code>&#13;
        <code class="n">t</code> <code class="o">=</code> <code class="n">Crawler</code><code class="p">()</code>&#13;
        <code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>This new <code>Crawler</code> class contains an <code>isDone</code> method that can be used to check if the crawler is done crawling. This may be useful if there are some additional logging methods that need to be finished so the thread cannot close, but the bulk of the crawling work is done. In general, <code>isDone</code> can be replaced with some sort of status or progress measure—how many pages logged, or the current page, for example.</p>&#13;
&#13;
<p>Any exceptions raised by <code>Crawler.run</code> will cause the class to be restarted until <code>isDone</code> is <code>True</code> and the program exits.</p>&#13;
&#13;
<p>Extending <code>threading.Thread</code> in your crawler classes can improve their robustness and flexibility, as well as your <a contenteditable="false" data-primary="multithreaded web crawling" data-startref="mttww" data-type="indexterm" id="id913"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="threading module" data-startref="mttwwm" data-type="indexterm" id="id914"/>ability to monitor any property of many crawlers at once.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Multiple Processes" data-type="sect1"><div class="sect1" id="id122">&#13;
<h1>Multiple Processes</h1>&#13;
&#13;
<p>The Python <code>Processing</code> module creates <a contenteditable="false" data-primary="Processing module" data-type="indexterm" id="pmdle"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="Processing module" data-type="indexterm" id="mttwpd"/>new process objects that can be started and joined from the main process. The following code uses the FizzBuzz example from the section on threading processes to demonstrate:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">multiprocessing</code> <code class="kn">import</code> <code class="n">Process</code>&#13;
<code class="kn">import</code> <code class="nn">time</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">print_time</code><code class="p">(</code><code class="n">threadName</code><code class="p">,</code> <code class="n">delay</code><code class="p">,</code> <code class="n">iterations</code><code class="p">):</code>&#13;
    <code class="n">start</code> <code class="o">=</code> <code class="nb">int</code><code class="p">(</code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">())</code>&#13;
    <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code><code class="n">iterations</code><code class="p">):</code>&#13;
        <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="n">delay</code><code class="p">)</code>&#13;
        <code class="n">seconds_elapsed</code> <code class="o">=</code> <code class="nb">str</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">())</code> <code class="o">-</code> <code class="n">start</code><code class="p">)</code>&#13;
        <code class="nb">print</code> <code class="p">(</code><code class="n">threadName</code> <code class="k">if</code> <code class="n">threadName</code> <code class="k">else</code> <code class="n">seconds_elapsed</code><code class="p">)</code>&#13;
&#13;
<code class="n">processes</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Counter'</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">100</code><code class="p">)),</code>&#13;
    <code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Fizz'</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">33</code><code class="p">)),</code>&#13;
    <code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">print_time</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'Buzz'</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">20</code><code class="p">))</code> &#13;
<code class="p">]</code>&#13;
&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>Remember that each process is treated as an individual independent program by the OS. If you view your processes through your OS’s activity monitor or task manager, you should see this reflected, as shown in <a data-type="xref" href="#five-python-processes-running">Figure 19-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="five-python-processes-running"><img alt="" class="iscreen_shot_2017-08-13_at_95753_ampng" src="assets/wsp3_1901.png"/>&#13;
<h6><span class="label">Figure 19-1. </span>Five Python processes running while running FizzBuzz</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">The fourth process with PID 76154 is a running Jupyter notebook instance, which should <a contenteditable="false" data-primary="Jupyter" data-secondary="Notebooks" data-tertiary="Processing module" data-type="indexterm" id="id915"/>appear if you are running this from the IPython notebook. The fifth process, 83560, is the main thread of execution, which starts up when the program is first executed. The PIDs are allocated by the OS sequentially. Unless you happen to have another program that quickly allocates a PID while the FizzBuzz script is running, you should see three more sequential PIDs—in this case 83561, 83562, and 83563.</p>&#13;
&#13;
<p>These PIDs also can be found in code by using the <code>os</code> module:</p>&#13;
&#13;
<pre data-code-language="python">&#13;
<code class="kn">import</code><code> </code><code class="nn">os</code><code>&#13;
</code><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>&#13;
</code><span class="n"><code class="c1"># prints the child PID</code><code>&#13;
</code><code class="n">os</code></span><span class="o"><code class="o">.</code></span><span class="n"><code class="n">getpid</code></span><span class="p"><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="c1"># prints the parent PID</code></span><code>&#13;
</code><code class="n">os</code><code class="o">.</code><code class="n">getppid</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code></pre>&#13;
&#13;
<p>Each process in your program should print a different PID for the line <code>os.getpid()</code>, but will print the same parent PID on <code>os.getppid()</code>.</p>&#13;
&#13;
<p>Technically, a couple of lines of code are not needed for this particular program. If the ending <code>join</code> statement is not included:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code></pre>&#13;
&#13;
<p>the parent process will still end and terminate the child processes with it automatically. However, this joining is needed if you wish to execute any code after these child processes complete.</p>&#13;
&#13;
<p>For example:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">'Program complete'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>If the <code>join</code> statement is not included, the output will be as follows:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
Program complete&#13;
1&#13;
2&#13;
</pre>&#13;
&#13;
<p>If the <code>join</code> statement is included, the program waits for each process to finish before continuing:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">'Program complete'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
...&#13;
Fizz&#13;
99&#13;
Buzz&#13;
100&#13;
Program complete&#13;
</pre>&#13;
&#13;
<p>If you want to stop program execution prematurely, you can of course use Ctrl-C to terminate the parent process. The termination of the parent process will also terminate any child processes that have been spawned, so using Ctrl-C is safe to do without worrying about accidentally leaving processes running in the background.</p>&#13;
&#13;
<section data-pdf-bookmark="Multiprocess Crawling" data-type="sect2"><div class="sect2" id="id123">&#13;
<h2>Multiprocess Crawling</h2>&#13;
&#13;
<p>The multithreaded Wikipedia crawling example <a contenteditable="false" data-primary="multiprocess web crawling" data-type="indexterm" id="mltpww"/>can be modified to use separate processes rather than separate threads:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">urllib.request</code> <code class="kn">import</code> <code class="n">urlopen</code>&#13;
<code class="kn">from</code> <code class="nn">bs4</code> <code class="kn">import</code> <code class="n">BeautifulSoup</code>&#13;
<code class="kn">import</code> <code class="nn">re</code>&#13;
<code class="kn">import</code> <code class="nn">random</code>&#13;
&#13;
<code class="kn">from</code> <code class="nn">multiprocessing</code> <code class="kn">import</code> <code class="n">Process</code>&#13;
<code class="kn">import</code> <code class="nn">os</code>&#13;
<code class="kn">import</code> <code class="nn">time</code>&#13;
&#13;
<code class="n">visited</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="k">def</code> <code class="nf">get_links</code><code class="p">(</code><code class="n">bs</code><code class="p">):</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'bodyContent'</code><code class="p">})</code>&#13;
        <code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'a'</code><code class="p">,</code> <code class="n">href</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'^(/wiki/)((?!:).)*$'</code><code class="p">))</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">link</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code> <code class="k">if</code> <code class="n">link</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">visited</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">path</code><code class="p">):</code>&#13;
    <code class="n">visited</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">path</code><code class="p">)</code>&#13;
    <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://en.wikipedia.org</code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
    <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
    <code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'Scraping </code><code class="si">{</code><code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s2">"h1"</code><code class="p">)</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code><code class="si">}</code><code class="s1"> in process </code><code class="si">{</code><code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">()</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">get_links</code><code class="p">(</code><code class="n">bs</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code> <code class="o">&gt;</code> <code class="mi">0</code><code class="p">:</code>&#13;
        <code class="n">scrape_article</code><code class="p">(</code><code class="n">links</code><code class="p">[</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">links</code><code class="p">)</code><code class="o">-</code><code class="mi">1</code><code class="p">)]</code><code class="o">.</code><code class="n">attrs</code><code class="p">[</code><code class="s1">'href'</code><code class="p">])</code>&#13;
&#13;
<code class="n">processes</code> <code class="o">=</code> <code class="p">[</code>&#13;
    <code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'/wiki/Kevin_Bacon'</code><code class="p">,)),</code>&#13;
    <code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="s1">'/wiki/Monty_Python'</code><code class="p">,))</code> &#13;
<code class="p">]</code>&#13;
<code class="p">[</code><code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p>Again, you are artificially slowing the process of the scraper by including a <code>time.sleep(5)</code> so that this can be used for example purposes without placing an unreasonably high load on Wikipedia’s servers.</p>&#13;
&#13;
<p>Here, you are replacing the user-defined <code>thread_name</code>, passed around as an argument, with <code>os.getpid()</code>, which does not need to be passed as an argument and can be accessed at any point.</p>&#13;
&#13;
<p class="pagebreak-before">This produces output like this:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
Scraping Kevin Bacon in process 4067&#13;
Scraping Monty Python in process 4068&#13;
Scraping Ewan McGregor in process 4067&#13;
Scraping Charisma Records in process 4068&#13;
Scraping Renée Zellweger in process 4067&#13;
Scraping Genesis (band) in process 4068&#13;
Scraping Alana Haim in process 4067&#13;
Scraping Maroon 5 in process 4068&#13;
</pre>&#13;
&#13;
<p>Crawling in separate processes is, in theory, slightly faster than crawling in separate threads for two major reasons:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Processes are not subject to locking by the GIL and can execute the same lines of code and modify the same (really, separate instantiations of the same) object at the same time.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Processes can run on multiple CPU cores, which may provide speed advantages if each of your processes or threads is processor intensive.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>However, these advantages come with one major disadvantage. In the preceding program, all found URLs are stored in a global <code>visited</code> list. When you were using multiple threads, this list was shared among all threads; and one thread, in the absence of a rare race condition, could not visit a page that had already been visited by another thread. However, each process now gets its own independent version of the visited list and is free to visit pages that have already been visited by other processes.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Communicating Between Processes" data-type="sect2"><div class="sect2" id="id124">&#13;
<h2>Communicating Between Processes</h2>&#13;
&#13;
<p>Processes operate in their own independent memory, which can cause problems if you want them to share information.</p>&#13;
&#13;
<p>Modifying the previous example to print the current output of the visited list, you can see this principle in action:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">path</code><code class="p">):</code> &#13;
    <code class="n">visited</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">path</code><code class="p">)</code>&#13;
    <code class="nb">print</code><code class="p">(</code><code class="s2">"Process </code><code class="si">{}</code><code class="s2"> list is now: </code><code class="si">{}</code><code class="s2">"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">(),</code> <code class="n">visited</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p>This results in output like the following:</p>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">&#13;
Process 84552 list is now: ['/wiki/Kevin_Bacon']&#13;
Process 84553 list is now: ['/wiki/Monty_Python']&#13;
Scraping Kevin Bacon in process 84552&#13;
/wiki/Desert_Storm&#13;
Process 84552 list is now: ['/wiki/Kevin_Bacon', '/wiki/Desert_Storm']&#13;
Scraping Monty Python in process 84553&#13;
/wiki/David_Jason&#13;
Process 84553 list is now: ['/wiki/Monty_Python', '/wiki/David_Jason']&#13;
</pre>&#13;
&#13;
<p>But there is a way to share information between processes on the same machine through two types of Python objects: queues and pipes.</p>&#13;
&#13;
<p>A <em>queue</em> is similar to the threading queue seen previously. Information can be put into it by one process and removed by another process. After this information has been removed, it’s gone from the queue. Because queues are designed as a method of “temporary data transmission,” they’re not well suited to hold a static reference such as a “list of web pages that have already been visited.”</p>&#13;
&#13;
<p>But what if this static list of web pages was replaced with some sort of a scraping delegator? The scrapers could pop off a task from one queue in the form of a path to scrape (for example, <em>/wiki/Monty_Python</em>) and in return, add a list of “found URLs” back onto a separate queue that would be processed by the scraping delegator so that only new URLs were added to the first task queue:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="k">def</code> <code class="nf">task_delegator</code><code class="p">(</code><code class="n">taskQueue</code><code class="p">,</code> <code class="n">urlsQueue</code><code class="p">):</code>&#13;
    <code class="c1">#Initialize with a task for each process</code>&#13;
    <code class="n">visited</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'/wiki/Kevin_Bacon'</code><code class="p">,</code> <code class="s1">'/wiki/Monty_Python'</code><code class="p">]</code>&#13;
    <code class="n">taskQueue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="s1">'/wiki/Kevin_Bacon'</code><code class="p">)</code>&#13;
    <code class="n">taskQueue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="s1">'/wiki/Monty_Python'</code><code class="p">)</code>&#13;
&#13;
    <code class="k">while</code> <code class="mi">1</code><code class="p">:</code>&#13;
        <code class="c1"># Check to see if there are new links in the urlsQueue</code>&#13;
        <code class="c1"># for processing</code>&#13;
        <code class="k">if</code> <code class="ow">not</code> <code class="n">urlsQueue</code><code class="o">.</code><code class="n">empty</code><code class="p">():</code>&#13;
            <code class="n">links</code> <code class="o">=</code> <code class="p">[</code><code class="n">link</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">urlsQueue</code><code class="o">.</code><code class="n">get</code><code class="p">()</code> <code class="k">if</code> <code class="n">link</code> <code class="ow">not</code> <code class="ow">in</code> <code class="n">visited</code><code class="p">]</code>&#13;
            <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code><code class="p">:</code>&#13;
                <code class="c1">#Add new link to the taskQueue</code>&#13;
                <code class="n">taskQueue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">link</code><code class="p">)</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">get_links</code><code class="p">(</code><code class="n">bs</code><code class="p">):</code>&#13;
    <code class="n">links</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'div'</code><code class="p">,</code> <code class="p">{</code><code class="s1">'id'</code><code class="p">:</code><code class="s1">'bodyContent'</code><code class="p">})</code><code class="o">.</code><code class="n">find_all</code><code class="p">(</code><code class="s1">'a'</code><code class="p">,</code>&#13;
        <code class="n">href</code><code class="o">=</code><code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="s1">'^(/wiki/)((?!:).)*$'</code><code class="p">))</code>&#13;
    <code class="k">return</code> <code class="p">[</code><code class="n">link</code><code class="o">.</code><code class="n">attrs</code><code class="p">[</code><code class="s1">'href'</code><code class="p">]</code> <code class="k">for</code> <code class="n">link</code> <code class="ow">in</code> <code class="n">links</code><code class="p">]</code>&#13;
&#13;
<code class="k">def</code> <code class="nf">scrape_article</code><code class="p">(</code><code class="n">taskQueue</code><code class="p">,</code> <code class="n">urlsQueue</code><code class="p">):</code>&#13;
    <code class="k">while</code> <code class="mi">1</code><code class="p">:</code>&#13;
        <code class="k">while</code> <code class="n">taskQueue</code><code class="o">.</code><code class="n">empty</code><code class="p">():</code>&#13;
            <code class="c1">#Sleep 100 ms while waiting for the task queue</code>&#13;
            <code class="c1">#This should be rare</code>&#13;
            <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mf">.1</code><code class="p">)</code>&#13;
        <code class="n">path</code> <code class="o">=</code> <code class="n">taskQueue</code><code class="o">.</code><code class="n">get</code><code class="p">()</code>&#13;
        <code class="n">html</code> <code class="o">=</code> <code class="n">urlopen</code><code class="p">(</code><code class="s1">'http://en.wikipedia.org</code><code class="si">{}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">path</code><code class="p">))</code>&#13;
        <code class="n">time</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mi">5</code><code class="p">)</code>&#13;
        <code class="n">bs</code> <code class="o">=</code> <code class="n">BeautifulSoup</code><code class="p">(</code><code class="n">html</code><code class="p">,</code> <code class="s1">'html.parser'</code><code class="p">)</code>&#13;
        <code class="n">title</code> <code class="o">=</code> <code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'h1'</code><code class="p">)</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code>&#13;
        <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s1">'Scraping </code><code class="si">{</code><code class="n">bs</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'h1'</code><code class="p">)</code><code class="o">.</code><code class="n">get_text</code><code class="p">()</code><code class="si">}</code><code class="s1"> in process </code><code class="si">{</code><code class="n">os</code><code class="o">.</code><code class="n">getpid</code><code class="p">()</code><code class="si">}</code><code class="s1">'</code><code class="p">)</code>&#13;
        <code class="n">links</code> <code class="o">=</code> <code class="n">get_links</code><code class="p">(</code><code class="n">bs</code><code class="p">)</code>&#13;
        <code class="c1">#Send these to the delegator for processing</code>&#13;
        <code class="n">urlsQueue</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="n">links</code><code class="p">)</code>&#13;
&#13;
&#13;
<code class="n">processes</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="n">taskQueue</code> <code class="o">=</code> <code class="n">Queue</code><code class="p">()</code>&#13;
<code class="n">urlsQueue</code> <code class="o">=</code> <code class="n">Queue</code><code class="p">()</code>&#13;
<code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">task_delegator</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">taskQueue</code><code class="p">,</code> <code class="n">urlsQueue</code><code class="p">,)))</code>&#13;
<code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">taskQueue</code><code class="p">,</code> <code class="n">urlsQueue</code><code class="p">,)))</code>&#13;
<code class="n">processes</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">Process</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="n">scrape_article</code><code class="p">,</code> <code class="n">args</code><code class="o">=</code><code class="p">(</code><code class="n">taskQueue</code><code class="p">,</code> <code class="n">urlsQueue</code><code class="p">,)))</code>&#13;
&#13;
<code class="k">for</code> <code class="n">p</code> <code class="ow">in</code> <code class="n">processes</code><code class="p">:</code>&#13;
    <code class="n">p</code><code class="o">.</code><code class="n">start</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p>Some structural differences exist between this scraper and the ones originally created. Rather than each process or thread following its own random walk from the starting point they were assigned, they work together to do a complete coverage crawl of the website. Each process can pull any “task” from the queue, not just links that they have found themselves.</p>&#13;
&#13;
<p>You can see this in action, as process 97024 scrapes <a contenteditable="false" data-primary="Processing module" data-startref="pmdle" data-type="indexterm" id="id916"/><a contenteditable="false" data-primary="multithreaded web crawling" data-secondary="Processing module" data-startref="mttwpd" data-type="indexterm" id="id917"/><a contenteditable="false" data-primary="communication between processes" data-startref="cmmbwp" data-type="indexterm" id="id918"/>both <em>Monty Python</em> and <em>Philadelphia</em> (a Kevin Bacon movie):</p>&#13;
&#13;
<pre>&#13;
Scraping Kevin Bacon in process 97023&#13;
Scraping Monty Python in process 97024&#13;
Scraping Kevin Bacon (disambiguation) in process 97023&#13;
Scraping Philadelphia in process 97024&#13;
Scraping Kevin Bacon filmography in process 97023&#13;
Scraping Kyra Sedgwick in process 97024&#13;
Scraping Sosie Bacon in process 97023&#13;
Scraping Edmund Bacon (architect) in process 97024&#13;
Scraping Michael Bacon (musician) in process 97023&#13;
Scraping Holly Near in process 97024&#13;
Scraping Leading actor in process 97023</pre>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Multiprocess Crawling—Another Approach" data-type="sect1"><div class="sect1" id="id125">&#13;
<h1>Multiprocess Crawling—Another Approach</h1>&#13;
&#13;
<p>All of the approaches discussed for multithreaded and multiprocess crawling assume that you require some sort of “parental guidance” over the child threads and processes. You can start them all at once, you can end them all at once, and you can send messages or share memory between them.</p>&#13;
&#13;
<p>But what if your scraper is designed in such a way that no guidance or communication is required? There may be very little reason to start going crazy with <code>import _thread</code> just yet.</p>&#13;
&#13;
<p>For example, let’s say you want to crawl two similar websites in parallel. You have a crawler written that can crawl either of these websites, determined by a small configuration change or perhaps a command-line argument. There’s absolutely no reason you can’t simply do the following:</p>&#13;
&#13;
<pre class="pagebreak-before" data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python<code class="w"> </code>my_crawler.py<code class="w"> </code>website1<code class="w"/></pre>&#13;
&#13;
<pre data-code-language="bash" data-type="programlisting">&#13;
$<code class="w"> </code>python<code class="w"> </code>my_crawler.py<code class="w"> </code>website2<code class="w"/></pre>&#13;
&#13;
<p>And voilà, you’ve just kicked off a multiprocess web crawler, while saving your CPU the overhead of keeping around a parent process to boot!</p>&#13;
&#13;
<p>Of course, this approach has downsides. If you want to run two web crawlers on the <em>same</em> website in this way, you <a contenteditable="false" data-primary="multiprocess web crawling" data-startref="mltpww" data-type="indexterm" id="id919"/>need some way of ensuring that they won’t accidentally start scraping the same pages. The solution might be to create a URL rule (“crawler 1 scrapes the blog pages, crawler 2 scrapes the product pages”) or divide the site in some way.</p>&#13;
&#13;
<p>Alternatively, you may be able to handle this coordination through some sort of intermediate database, such as <a href="https://redis.io/">Redis</a>. Before going to a new link, the crawler may make a request to the database to ask, “Has this page been crawled?” The crawler is using the database as an interprocess communication system. Of course, without careful consideration, this method may lead to race conditions or lag if the database connection is slow (likely only a problem if connecting to a remote <span class="keep-together">database).</span></p>&#13;
&#13;
<p>You may also find that this method isn’t quite as scalable. Using the <code>Process</code> module allows you to dynamically increase or decrease the number of processes crawling the site or even storing data. Kicking them off by hand requires either a person physically running the script or a separate managing script (whether a bash script, a cron job, or something else) doing this.</p>&#13;
&#13;
<p>However, I have used this method with great success in the past. For small, one-off projects, it is a great way to get a lot of information quickly, especially across multiple websites.</p>&#13;
</div></section>&#13;
</div></section></body></html>