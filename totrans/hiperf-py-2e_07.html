<html><head></head><body><div id="sbo-rt-content" class="calibre2"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Compiling to C" class="calibre3"><div class="preface" id="chapter-compiling">
<h1 class="calibre23"><span class="publishername">Chapter 7. </span>Compiling to C</h1>

<aside data-type="sidebar" epub:type="sidebar" class="calibre40"><div class="sidebar" id="idm46122417913880">
<h5 class="calibre41">Questions You’ll Be Able to Answer After This Chapter</h5>
<ul class="printings">
<li class="calibre21">
<p class="calibre42">How can I have my Python code run as lower-level code?</p>
</li>
<li class="calibre21">
<p class="calibre42">What is the difference between a JIT compiler and an AOT compiler?</p>
</li>
<li class="calibre21">
<p class="calibre42">What tasks can compiled Python code perform faster than native Python?</p>
</li>
<li class="calibre21">
<p class="calibre42">Why do type annotations speed up compiled Python code?</p>
</li>
<li class="calibre21">
<p class="calibre42">How can I write modules for Python using C or Fortran?</p>
</li>
<li class="calibre21">
<p class="calibre42">How can I use libraries from C or Fortran in Python?</p>
</li>
</ul>
</div></aside>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" id="cc_ch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The easiest way to get your code to run faster is to make it do less work.
Assuming you’ve already chosen good algorithms and you’ve reduced the amount of
data you’re processing, the easiest way to execute fewer instructions is to
compile your code down to machine code.</p>

<p class="author1">Python offers a number of options for this, including pure C-based compiling approaches
like <a data-type="indexterm" data-primary="Cython" data-secondary="compiling to C" id="idm46122417904728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Cython; LLVM-based compiling via <a data-type="indexterm" data-primary="Numba" data-secondary="compiling with" id="idm46122417903624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Numba; and the
replacement virtual machine <a data-type="indexterm" data-primary="PyPy" data-secondary="about" id="idm46122417902488" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PyPy, which includes a built-in just-in-time (JIT)
compiler. You need to balance the requirements of code adaptability and team
velocity when deciding which route to take.</p>

<p class="author1">Each of these tools adds a new dependency to your toolchain, and Cython requires you to write in a new language type (a hybrid of Python and C), which means you need a new skill. Cython’s new language may hurt your team’s velocity, as team members without knowledge of C may have trouble supporting this code; in practice, though, this is probably a minor concern, as you’ll use Cython only in well-chosen, small regions of your code.</p>

<p class="author1">It is worth noting that performing CPU and memory profiling on your code will probably start you thinking about higher-level algorithmic optimizations that you might apply. These algorithmic changes (such as additional logic to avoid computations or caching to avoid recalculation) could help you avoid doing unnecessary work in your code, and Python’s expressivity helps you to spot these algorithmic opportunities. Radim Řehůřek discusses how a Python implementation can beat a pure C implementation in <a data-type="xref" href="ch12.xhtml#lessons-from-field-radim" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Making Deep Learning Fly with RadimRehurek.com (2014)”</a>.</p>

<p class="author1">In this chapter we’ll review the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Cython, the most commonly used tool for compiling to C, covering both <code class="calibre26">numpy</code> and normal Python code (requires some knowledge of C)</p>
</li>
<li class="calibre21">
<p class="calibre27">Numba, a new compiler specialized for <code class="calibre26">numpy</code> code</p>
</li>
<li class="calibre21">
<p class="calibre27">PyPy, a stable just-in-time compiler for non-<code class="calibre26">numpy</code> code that is a replacement for the normal Python executable</p>
</li>
</ul>

<p class="author1">Later in the chapter we’ll look at foreign function interfaces, which allow C code to be compiled into extension modules for Python. Python’s native API is used with<a data-type="indexterm" data-primary="ctypes" id="idm46122417892872" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="cffi" id="idm46122417892168" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">ctypes</code> or with <code class="calibre26">cffi</code> (from the authors of PyPy), along with the <a data-type="indexterm" data-primary="f2py" id="idm46122417890440" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">f2py</code> Fortran-to-Python converter.</p>






<section data-type="sect1" data-pdf-bookmark="What Sort of Speed Gains Are Possible?" class="calibre3"><div class="preface" id="idm46122417889352">
<h1 class="calibre25">What Sort of Speed Gains Are Possible?</h1>

<p class="author1">Gains of an order of magnitude or more are quite possible if your problem yields
to a compiled approach. Here, we’ll look at various ways to achieve speedups of one to two orders of
magnitude on a single core, along with using multiple cores through
<a data-type="indexterm" data-primary="OpenMP" id="idm46122417887384" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>OpenMP.</p>

<p class="author1">Python code that tends to run faster after compiling is mathematical,
and it has lots of loops that repeat the same operations many times. Inside these loops, you’re probably making lots of temporary objects.</p>

<p class="author1">Code that calls out to external libraries (such as regular expressions, string
operations, and calls to database libraries) is unlikely to show any speedup after
compiling. Programs that are I/O-bound are also unlikely to show significant speedups.</p>

<p class="author1">Similarly, if your Python code focuses on calling vectorized <code class="calibre26">numpy</code> routines, it may not run any faster after compilation—it’ll run faster only if the code being compiled is mainly Python (and probably if it is mainly looping). We looked at <code class="calibre26">numpy</code> 
<span class="publishername">operations</span> in <a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>; compiling doesn’t really help because there aren’t many intermediate objects.</p>

<p class="author1">Overall, it is very unlikely that your compiled code will run any faster than a handcrafted C routine, but it is also unlikely to run much slower. It is quite possible that the generated C code from your Python will run as fast as a handwritten C routine, unless the C coder has particularly good knowledge of ways to tune the C code to the target machine’s architecture.</p>

<p class="author1">For math-focused code, it is possible that a handcoded Fortran routine will beat an equivalent C routine, but again, this probably requires expert-level knowledge. Overall, a compiled result (probably using Cython) will be as close to a handcoded-in-C result as most programmers will need.</p>

<p class="author1">Keep the diagram in <a data-type="xref" href="#FIG-04b-diminishing-returns" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-1</a> in mind when you profile and work on your algorithm. A small amount of work understanding your code through profiling should enable you to make smarter choices at an algorithmic level. After this, some focused work with a compiler should buy you an additional speedup. It will probably be possible to keep tweaking your algorithm, but don’t be surprised to see increasingly small improvements coming from increasingly large amounts of work on your part. Know when additional effort isn’t useful.</p>

<figure class="calibre46"><div id="FIG-04b-diminishing-returns" class="figure">
<img src="Images/hpp2_0701.png" alt="" class="calibre93"/>
<h6 class="calibre47"><span class="publishername">Figure 7-1. </span>Some effort profiling and compiling brings a lot of reward, but continued effort tends to pay increasingly less</h6>
</div></figure>

<p class="author1">If you’re dealing with Python code and batteries-included libraries without
<code class="calibre26">numpy</code>, Cython and PyPy are your main choices. If you’re working
with <code class="calibre26">numpy</code>, Cython and Numba are the right choices. These tools
all support Python 3.6+.</p>

<p class="author1">Some of the following examples require a little understanding of C compilers and
C code. If you lack this knowledge, you should learn a little C and compile
a working C program before diving in too deeply.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="JIT Versus AOT Compilers" class="calibre3"><div class="preface" id="jit_vs_compiler">
<h1 class="calibre25">JIT Versus AOT Compilers</h1>

<p class="author1"><a data-type="indexterm" data-primary="AOT compilers, JIT compilers versus" id="idm46122417873400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="compiling to C" data-secondary="JIT versus AOT compilers" id="idm46122417872632" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cython" data-secondary="compiling to C" id="idm46122417871672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="JIT compilers, AOT compilers versus" id="idm46122417870728" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Numba" data-secondary="compiling with" id="idm46122417870040" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyPy" data-secondary="about" id="idm46122417869096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The tools we’ll look at split roughly into two sets: tools for compiling ahead of time, or AOT
(Cython), and tools for compiling “just in time,” or JIT (Numba, PyPy).</p>

<p class="author1">By compiling AOT, you create a static library that’s specialized to
your machine. If you download <code class="calibre26">numpy</code>, <code class="calibre26">scipy</code>, or scikit-learn, it will compile parts of the library using Cython on your machine (or you’ll use
a prebuilt compiled library, if you’re using a distribution like Continuum’s
Anaconda). By compiling ahead of use, you’ll have a library that can instantly be
used to work on solving your problem.</p>

<p class="author1">By compiling JIT, you don’t have to do much (if any) work up front; you
let the compiler step in to compile just the right parts of the code at the time
of use. This means you have a<a data-type="indexterm" data-primary="cold start problem" id="idm46122417865528" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> “cold start” problem—if most of your program
could be compiled and currently none of it is, when you start running your
code, it’ll run very slowly while it compiles. If this happens every time you
run a script and you run the script many times, this cost can become
significant. PyPy suffers from this problem, so you may not want to use it for short but
frequently running scripts.</p>

<p class="author1">The current state of affairs shows us that compiling ahead of time buys us the
best speedups, but often this requires the most manual effort. Just-in-time
compiling offers some impressive speedups with very little manual intervention, but it can also run into the problem just described.
You’ll have to consider these trade-offs when choosing the right technology for
your problem.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Why Does Type Information Help the Code Run Faster?" class="calibre3"><div class="preface" id="idm46122417863368">
<h1 class="calibre25">Why Does Type Information Help the Code Run Faster?</h1>

<p class="author1"><a data-type="indexterm" data-primary="type information" id="idm46122417861800" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Python is dynamically typed—a variable can refer to an object of any type,
and any line of code can change the type of the object that is referred to.
This makes it difficult for the virtual machine to optimize how the code is
executed at the machine code level, as it doesn’t know which fundamental datatype
will be used for future operations. Keeping the code generic makes it run more
slowly.</p>

<p class="author1">In the following example, <code class="calibre26">v</code> is either a floating-point number or a pair of
floating-point numbers that represent a <code class="calibre26">complex</code> number. Both conditions could occur in
the same loop at different points in time, or in related serial sections of code:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">v</code> <code class="o">=</code> <code class="o">-</code><code class="mi">1.0</code>
<code class="kn">print</code><code class="p">(</code><code class="nb">type</code><code class="p">(</code><code class="n">v</code><code class="p">),</code> <code class="nb">abs</code><code class="p">(</code><code class="n">v</code><code class="p">))</code></pre>

<pre data-type="programlisting" class="calibre50">&lt;class 'float'&gt; 1.0</pre>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="n">v</code> <code class="o">=</code> <code class="mi">1</code><code class="o">-</code><code class="mi">1j</code>
<code class="kn">print</code><code class="p">(</code><code class="nb">type</code><code class="p">(</code><code class="n">v</code><code class="p">),</code> <code class="nb">abs</code><code class="p">(</code><code class="n">v</code><code class="p">))</code></pre>

<pre data-type="programlisting" class="calibre50">&lt;class 'complex'&gt; 1.4142135623730951</pre>

<p class="author1">The <a data-type="indexterm" data-primary="abs function" id="idm46122417832936" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">abs</code> function works differently depending on the underlying datatype. Using <code class="calibre26">abs</code>
for an integer or a floating-point number turns a negative
    value into a positive value. Using <code class="calibre26">abs</code> for a complex number involves taking the
    square root of the sum of the squared components:</p>
<div data-type="equation" class="calibre56">
<math alttext="left-bracket dollar-sign a b s left-parenthesis c right-parenthesis equals StartRoot c period r e a l squared plus c period i m a g squared EndRoot dollar-sign right-bracket">
  <mrow>
    <mi>a</mi>
    <mi>b</mi>
    <mi>s</mi>
    <mrow>
      <mo>(</mo>
      <mi>c</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <msqrt>
      <mrow>
        <mi>c</mi>
        <mo>.</mo>
        <mi>r</mi>
        <mi>e</mi>
        <mi>a</mi>
        <msup><mi>l</mi> <mn>2</mn> </msup>
        <mo>+</mo>
        <mi>c</mi>
        <mo>.</mo>
        <mi>i</mi>
        <mi>m</mi>
        <mi>a</mi>
        <msup><mi>g</mi> <mn>2</mn> </msup>
      </mrow>
    </msqrt>
  </mrow>
</math>
</div>

<p class="author1">The machine code for the <code class="calibre26">complex</code> example involves more instructions and will
take longer to run. Before calling <code class="calibre26">abs</code> on a variable, Python first has to
look up the type of the variable and then decide which version of a function to
call—this overhead adds up when you make a lot of repeated calls.</p>

<p class="author1">Inside Python, every fundamental object, such as an integer, will be wrapped up in a
higher-level Python object (e.g., an <code class="calibre26">int</code> for an integer). The higher-level
object has extra <span class="publishername">functions</span> like <a data-type="indexterm" data-primary="hash functions" data-secondary="properties of" id="idm46122417709688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">__hash__</code> to assist with storage and<a data-type="indexterm" data-primary="str function" id="idm46122417708296" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">__str__</code>
for printing.</p>

<p class="author1">Inside a section of code that is CPU-bound, it is often the case that the types
of variables do not change. This gives us an opportunity for static compilation
and faster code <span class="publishername">execution.</span></p>

<p class="author1">If all we want are a lot of intermediate mathematical operations, we don’t
need the higher-level functions, and we may not need the machinery for reference
counting either. We can drop down to the machine code level and do our
calculations quickly using machine code and bytes, rather than manipulating the
higher-level Python objects, which involves greater overhead. To do this, we
determine the types of our objects ahead of time so we can generate the correct
C code.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Using a C Compiler" class="calibre3"><div class="preface" id="idm46122417862744">
<h1 class="calibre25">Using a C Compiler</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="using compilers" id="idm46122417685560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In the following examples, we’ll use <a data-type="indexterm" data-primary="gcc" id="idm46122417684232" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">gcc</code> and <code class="calibre26">g++</code> from the GNU C Compiler
toolset. You could use an alternative compiler (e.g., Intel’s <code class="calibre26">icc</code> or
Microsoft’s <code class="calibre26">cl</code>) if you configure your environment correctly. Cython uses
<code class="calibre26">gcc</code>.</p>

<p class="author1"><code class="calibre26">gcc</code> is a very good choice for most platforms; it is well supported and quite
advanced. It is often possible to squeeze out more performance by using a tuned
compiler (e.g., Intel’s <code class="calibre26">icc</code> may produce faster code than <code class="calibre26">gcc</code> on Intel
devices), but the cost is that you have to gain more domain knowledge and learn
how to tune the flags on the alternative compiler.</p>

<p class="author1"><a data-type="indexterm" data-primary="C" data-seealso="foreign function interfaces" id="idm46122417679256" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>C and C++ are often used for static compilation rather than other languages like
Fortran because of their ubiquity and the wide range of supporting libraries. The
compiler and the converter, such as Cython, can study the annotated code to determine whether static optimization
steps (like inlining <span class="publishername">functions</span> and unrolling loops) can be applied.</p>

<p class="author1">Aggressive
analysis of the intermediate abstract syntax tree (performed by Numba and PyPy)
provides opportunities to combine knowledge of Python’s way of
expressing things to inform the underlying compiler how best to take advantage
of the patterns that have been seen.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Reviewing the Julia Set Example" class="calibre3"><div class="preface" id="idm46122417676376">
<h1 class="calibre25">Reviewing the Julia Set Example</h1>

<p class="author1"><a data-type="indexterm" data-primary="Julia set" id="idm46122417675080" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Back in <a data-type="xref" href="ch02.xhtml#chapter-profiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 2</a> we profiled the Julia set generator.
This code uses integers and complex numbers to produce an output image. The
calculation of the image is CPU-bound.</p>

<p class="author1">The main cost in the code was the CPU-bound nature of the inner loop that
calculates the <code class="calibre26">output</code> list. This list can be drawn as a square pixel array,
where each value represents the cost to generate that pixel.</p>

<p class="author1">The code for the inner function is shown in <a data-type="xref" href="#compiling-review-julia" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-1</a>.</p>
<div id="compiling-review-julia" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-1. </span>Reviewing the Julia function’s CPU-bound code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">On Ian’s laptop, the original Julia set calculation on a 1,000 × 1,000 grid with
<code class="calibre26">maxiter=300</code> takes approximately 8 seconds using a pure Python implementation
running on CPython 3.7.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Cython" class="calibre3"><div class="preface" id="compiling-cython">
<h1 class="calibre25">Cython</h1>

<p class="author1"><a href="http://cython.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Cython</a> is a compiler that converts type-annotated
Python into a compiled extension module. The type annotations are C-like. This
extension can be imported as a regular Python module using <code class="calibre26">import</code>. Getting
started is simple, but a learning curve must be climbed with each
additional level of complexity and optimization. For Ian, this is the tool of
choice for turning calculation-bound functions into faster code, because of its
wide usage, its maturity, and its OpenMP support.</p>

<p class="author1">With the <a data-type="indexterm" data-primary="OpenMP" id="idm46122417588152" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>OpenMP standard, it is possible to convert parallel problems into
multiprocessing-aware modules that run on multiple CPUs on one machine. The
threads are hidden from your Python code; they operate via the generated C code.</p>

<p class="author1">Cython (announced in 2007) is a fork of<a data-type="indexterm" data-primary="Pyrex" id="idm46122417586664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> Pyrex (announced in 2002) that expands the
capabilities beyond the original aims of Pyrex. Libraries that use Cython
include <a data-type="indexterm" data-primary="SciPy" id="idm46122417585688" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="scikit-learn" data-secondary="Cython and" id="idm46122417585016" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="lxml" id="idm46122417584072" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="ZeroMQ" id="idm46122417583400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>SciPy, scikit-learn, lxml, and ZeroMQ.</p>

<p class="author1">Cython can be used via a <a data-type="indexterm" data-primary="setup.py script" id="idm46122417582216" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">setup.py</em> script to compile a module. It can also be
used interactively in <a data-type="indexterm" data-primary="IPython" id="idm46122417581128" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>IPython via a “magic” command. Typically, the types are
annotated by the developer, although some automated annotation is possible.</p>








<section data-type="sect2" data-pdf-bookmark="Compiling a Pure Python Version Using Cython" class="calibre3"><div class="preface" id="idm46122417580024">
<h2 class="calibre43">Compiling a Pure Python Version Using Cython</h2>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="Cython" id="cc_cy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cython" id="cy_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cython" data-secondary="pure-Python conversion with" id="c_ppc" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The easy way to begin writing a compiled extension module involves three files.
Using our Julia set as an example, they are as follows:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">The calling Python code (the bulk of our Julia code from earlier)</p>
</li>
<li class="calibre21">
<p class="calibre27">The function to be compiled in a new <em class="hyperlink">.pyx</em> file</p>
</li>
<li class="calibre21">
<p class="calibre27">A <em class="hyperlink">setup.py</em> that contains the instructions for calling Cython to make
the extension module</p>
</li>
</ul>

<p class="author1">Using this approach, the <em class="hyperlink">setup.py</em> script is called to use Cython to
compile the <em class="hyperlink">.pyx</em> file into a compiled module. On Unix-like systems, the
compiled module will probably be a <em class="hyperlink">.so</em> file; on Windows it should be a <em class="hyperlink">.pyd</em>
(DLL-like Python library).</p>

<p class="author1">For the Julia example, we’ll use the following:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27"><em class="hyperlink">julia1.py</em> to build the input lists and call the calculation function</p>
</li>
<li class="calibre21">
<p class="calibre27"><em class="hyperlink">cythonfn.pyx</em>, which contains the CPU-bound function that we can annotate</p>
</li>
<li class="calibre21">
<p class="calibre27"><em class="hyperlink">setup.py</em>, which contains the build instructions</p>
</li>
</ul>

<p class="author1">The result of running <em class="hyperlink">setup.py</em> is a module that can be imported. In  our
<em class="hyperlink">julia1.py</em> script in <a data-type="xref" href="#compiling-cython-import" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-2</a>, we need only to make some tiny changes to <code class="calibre26">import</code> the new
module and call our function.</p>
<div id="compiling-cython-import" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-2. </span>Importing the newly compiled module into our main code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="o">...</code>
<code class="kn">import</code> <code class="nn">cythonfn</code>  <code class="c"># as defined in setup.py</code>
<code class="o">...</code>
<code class="kn">def</code> <code class="nf">calc_pure_python</code><code class="p">(</code><code class="n">desired_width</code><code class="p">,</code> <code class="n">max_iterations</code><code class="p">):</code>
    <code class="c"># ...</code>
    <code class="n">start_time</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">output</code> <code class="o">=</code> <code class="n">cythonfn</code><code class="o">.</code><code class="n">calculate_z</code><code class="p">(</code><code class="n">max_iterations</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">)</code>
    <code class="n">end_time</code> <code class="o">=</code> <code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">()</code>
    <code class="n">secs</code> <code class="o">=</code> <code class="n">end_time</code> <code class="o">-</code> <code class="n">start_time</code>
    <code class="kn">print</code><code class="p">(</code><code class="n">f</code><code class="s">"Took {secs:0.2f} seconds"</code><code class="p">)</code>
<code class="o">...</code></pre></div>

<p class="author1">In <a data-type="xref" href="#compiling-cython-pure-python" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-3</a>, we will start with a pure Python version without type annotations.</p>
<div id="compiling-cython-pure-python" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-3. </span>Unmodified pure Python code in cythonfn.pyx (renamed from .py) for Cython’s setup.py</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c"># cythonfn.pyx</code>
<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">The <em class="hyperlink">setup.py</em> script shown in <a data-type="xref" href="#compiling-cython-setup" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-4</a> is short; it defines how to convert <em class="hyperlink">cythonfn.pyx</em> into
<em class="hyperlink">calculate.so</em>.</p>
<div id="compiling-cython-setup" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-4. </span>setup.py, which converts cythonfn.pyx into C code for compilation by <span class="publishername">Cython</span></h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">distutils.core</code> <code class="kn">import</code> <code class="n">setup</code>
<code class="kn">from</code> <code class="nn">Cython.Build</code> <code class="kn">import</code> <code class="n">cythonize</code>

<code class="n">setup</code><code class="p">(</code><code class="n">ext_modules</code><code class="o">=</code><code class="n">cythonize</code><code class="p">(</code><code class="s">"cythonfn.pyx"</code><code class="p">,</code>
                            <code class="n">compiler_directives</code><code class="o">=</code><code class="p">{</code><code class="s">"language_level"</code><code class="p">:</code> <code class="s">"3"</code><code class="p">}))</code></pre></div>

<p class="author1">When we run the <em class="hyperlink">setup.py</em> script in <a data-type="xref" href="#compiling-cython-setup-build" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-5</a> with the argument <code class="calibre26">build_ext</code>, Cython will look
for <em class="hyperlink">cythonfn.pyx</em> and build <em class="hyperlink">cythonfn[…].so</em>. The <code class="calibre26">language_level</code> is hardcoded to <code class="calibre26">3</code> here to force Python 3.<em class="hyperlink">x</em> support.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Remember that this is a manual step—if you update your <em class="hyperlink">.pyx</em> or <em class="hyperlink">setup.py</em> and forget to rerun the build command, you won’t have an updated <em class="hyperlink">.so</em> module to import. If you’re unsure whether you compiled the code, check the timestamp for the <em class="hyperlink">.so</em> file. If in doubt, delete the generated C files and the <em class="hyperlink">.so</em> file and build them again.</p>
</div>
<div data-type="example" id="compiling-cython-setup-build" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-5. </span>Running setup.py to build a new compiled module</h5>
<pre data-type="programlisting" class="calibre59">$ <strong class="calibre83">python setup.py build_ext --inplace</strong>
Compiling cythonfn.pyx because it changed.
[1/1] Cythonizing cythonfn.pyx
running build_ext
building 'cythonfn' extension
gcc -pthread -B /home/ian/miniconda3/envs/high_performance_python_book_2e/...
gcc -pthread -shared -B /home/ian/miniconda3/envs/high_performance_python_...
</pre>
</div>

<p class="author1">The <a data-type="indexterm" data-primary="inplace argument" id="idm46122417313896" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">--inplace</code> argument tells Cython to build the compiled module into the
current directory rather than into a separate <em class="hyperlink">build</em> directory. After the build
has completed, we’ll have the intermediate <em class="hyperlink">cythonfn.c</em>, which is rather hard to
read, along with <em class="hyperlink">cythonfn[…].so</em>.</p>

<p class="author1">Now when the <em class="hyperlink">julia1.py</em> code is run, the compiled module is imported, and the
Julia set is calculated on Ian’s laptop in 4.7 seconds, rather than the more
usual 8.3 seconds. This is a useful improvement for very little effort.<a data-type="indexterm" data-primary="" data-startref="c_ppc" id="idm46122417310216" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="pyximport" class="calibre3"><div class="preface" id="idm46122417579432">
<h1 class="calibre25">pyximport</h1>

<p class="author1"><a data-type="indexterm" data-primary="pyximport" id="idm46122417307832" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>A simplified build system has been introduced via <code class="calibre26">pyximport</code>. If your code has a simple setup and doesn’t require third-party modules, you may be able to do away with <em class="hyperlink">setup.py</em> completely.</p>

<p class="author1">By importing <code class="calibre26">pyximport</code> as seen in <a data-type="xref" href="#compiling-cython-pyximport" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-6</a> and calling <code class="calibre26">install</code>, any subsequently imported <em class="hyperlink">.pyx</em> file will be automatically compiled. This <em class="hyperlink">.pyx</em> file can include annotations, or in this case, it can be the unannotated code. The result runs in 4.7 seconds, as before; the only difference is that we didn’t have to write a <em class="hyperlink">setup.py</em> file.</p>
<div id="compiling-cython-pyximport" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-6. </span>Using <code class="calibre26">pyximport</code> to replace setup.py</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">pyximport</code>
<code class="n">pyximport</code><code class="o">.</code><code class="n">install</code><code class="p">(</code><code class="n">language_level</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code>
<code class="kn">import</code> <code class="nn">cythonfn</code>
<code class="c"># followed by the usual code</code></pre></div>








<section data-type="sect2" data-pdf-bookmark="Cython Annotations to Analyze a Block of Code" class="calibre3"><div class="preface" id="idm46122417219512">
<h2 class="calibre43">Cython Annotations to Analyze a Block of Code</h2>

<p class="author1"><a data-type="indexterm" data-primary="Cython" data-secondary="annotations for code analysis" id="cy_aca" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The preceding example shows that we can quickly build a compiled module. For tight
loops and mathematical operations, this alone often leads to a speedup.
Obviously, though, we should not optimize blindly—we need to know which lines of code take a lot of time so we can
decide where to focus our efforts.</p>

<p class="author1">Cython has an annotation option that will output an HTML file we can view
in a browser. We use the command <code class="calibre26">cython -a cythonfn.pyx</code>, and
the output file <em class="hyperlink">cythonfn.html</em> is generated. Viewed in a browser, it looks
something like <a data-type="xref" href="#FIG-04b-cython-lists-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-2</a>. A similar image is available in the <a href="http://bit.ly/cythonize" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Cython documentation</a>.</p>

<figure class="calibre46"><div id="FIG-04b-cython-lists-1" class="figure">
<img src="Images/hpp2_0702.png" alt="" class="calibre94"/>
<h6 class="calibre47"><span class="publishername">Figure 7-2. </span>Colored Cython output of unannotated function</h6>
</div></figure>

<p class="author1">Each line can be expanded with a double-click to show the generated C code. More yellow
means “more calls into the Python virtual machine,” while more white means “more non-Python C code.”
The goal is to remove as many of the yellow lines as possible and end up with
as much white as possible.</p>

<p class="author1">Although “more yellow lines” means more calls into the virtual machine, this won’t necessarily cause your code to run slower. Each call into the virtual machine has a cost, but the cost of those calls will be significant only if the calls occur inside large loops. Calls outside large loops (for example, the line used to create <code class="calibre26">output</code> at the start of the function) are not expensive relative to the cost of the inner calculation loop. Don’t waste your time on the lines that don’t cause a slowdown.</p>

<p class="author1">In our example, the lines with the most calls back into the Python virtual machine (the “most yellow”) are lines 4 and 8. From our previous profiling work, we know that line 8 is likely to be called over 30 million times, so that’s a great candidate to focus on.</p>

<p class="author1">Lines 9, 10, and 11 are almost as yellow, and we also know they’re inside the tight inner loop. In total they’ll be responsible for the bulk of the execution time of this function, so we need to focus on these first. Refer back to <a data-type="xref" href="ch02.xhtml#profiling-line-profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using line_profiler for Line-by-Line Measurements”</a> if you need to remind yourself of how much time is spent in this section.</p>

<p class="author1">Lines 6 and 7 are less yellow, and since they’re called only 1 million times, they’ll have a much smaller effect on the final speed, so we can focus on them later. In fact, since they are <code class="calibre26">list</code> objects, there’s actually nothing we can do to speed up their access except, as you’ll see in <a data-type="xref" href="#compiling-cython-and-numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Cython and numpy”</a>, to replace the <code class="calibre26">list</code> objects with <code class="calibre26">numpy</code> arrays, which will buy a small speed advantage.</p>

<p class="author1">To better understand the yellow regions, you can expand each line.
In <a data-type="xref" href="#FIG-04b-cython-lists-1-expanded" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-3</a>, we can see that to create the <code class="calibre26">output</code> list, we iterate over
the length of <code class="calibre26">zs</code>, building new Python objects that are reference-counted by
the Python virtual machine. Even though these calls are expensive, they won’t really affect the execution time of this function.</p>

<p class="author1">To improve the execution time of our function, we need to start declaring the types of objects that are involved in the expensive inner loops. These loops can then make fewer of the relatively expensive calls back into the Python virtual machine, saving us time.</p>

<p class="author1">In general, the lines that probably cost the most CPU time are those:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27">Inside tight inner loops</p>
</li>
<li class="calibre21">
<p class="calibre27">Dereferencing <code class="calibre26">list</code>, <code class="calibre26">array</code>, or <code class="calibre26">np.array</code> items</p>
</li>
<li class="calibre21">
<p class="calibre27">Performing mathematical operations</p>
</li>
</ul>

<figure class="calibre46"><div id="FIG-04b-cython-lists-1-expanded" class="figure">
<img src="Images/hpp2_0703.png" alt="" class="calibre95"/>
<h6 class="calibre47"><span class="publishername">Figure 7-3. </span>C code behind a line of Python code</h6>
</div></figure>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">If you don’t know which lines are most frequently executed, using a<a data-type="indexterm" data-primary="line_profiler" id="idm46122417177624" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> profiling tool—<code class="calibre26">line_profiler</code>, discussed in <a data-type="xref" href="ch02.xhtml#profiling-line-profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using line_profiler for Line-by-Line Measurements”</a>, would be the most appropriate. You’ll learn which lines are executed most frequently and which lines cost the most inside the Python virtual machine, so you’ll have clear evidence of which lines you need to focus on to get the best speed gain.<a data-type="indexterm" data-primary="" data-startref="cy_aca" id="idm46122417175176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Adding Some Type Annotations" class="calibre3"><div class="preface" id="idm46122417228728">
<h2 class="calibre43">Adding Some Type Annotations</h2>

<p class="author1"><a data-type="xref" href="#FIG-04b-cython-lists-1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-2</a> <a data-type="indexterm" data-primary="Cython" data-secondary="adding type annotations" id="cy_ata" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>shows that almost every line of our function is calling back into the
Python virtual machine. All of our numeric work is also calling back into Python
as we are using the higher-level Python objects. We need to convert these into
local C objects, and then, after doing our numerical coding, we need to convert the
result back to a Python object.</p>

<p class="author1">In <a data-type="xref" href="#compiling-cython-primitive-types" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-7</a>, we see how to add some primitive types by using the <a data-type="indexterm" data-primary="cdef keyword" id="idm46122417168536" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">cdef</code> syntax.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">It is important to note that these types will be understood only by Cython and
<em class="hyperlink">not</em> by Python. Cython uses these types to convert the Python code to C objects,
which do not have to call back into the Python stack; this means the operations run at a
faster speed, but they lose flexibility and development speed.</p>
</div>

<p class="author1"><a data-type="indexterm" data-primary="int type" id="idm46122417165368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="unsigned int type" id="idm46122417164664" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="double complex type" id="idm46122417163992" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The types we add are as follows:</p>

<ul class="printings">
<li class="calibre21">
<p class="calibre27"><code class="calibre26">int</code> for a signed integer</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">unsigned int</code> for an integer that can only be positive</p>
</li>
<li class="calibre21">
<p class="calibre27"><code class="calibre26">double complex</code> for double-precision complex numbers</p>
</li>
</ul>

<p class="author1">The <code class="calibre26">cdef</code> keyword lets us declare variables inside the function body. These must be
declared at the top of the function, as that’s a requirement from the C language <span class="publishername">specification.</span></p>
<div id="compiling-cython-primitive-types" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-7. </span>Adding primitive C types to start making our compiled function run faster by doing more work in C and less via the Python virtual machine</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="nb">int</code> <code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">cdef</code> <code class="n">unsigned</code> <code class="nb">int</code> <code class="n">i</code><code class="p">,</code> <code class="n">n</code>
    <code class="n">cdef</code> <code class="n">double</code> <code class="nb">complex</code> <code class="n">z</code><code class="p">,</code> <code class="n">c</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="nb">abs</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">2</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">When adding Cython annotations, you’re adding non-Python code to the <em class="hyperlink">.pyx</em> file. This means you lose the interactive nature of developing Python in the interpreter. For those of you familiar with coding in C, we go back to the code-compile-run-debug cycle.</p>
</div>

<p class="author1">You might wonder if we could add a type annotation to the lists that we pass in.
We can use the <code class="calibre26">list</code> keyword, but this has no practical effect for this
example. The <code class="calibre26">list</code> objects still have to be interrogated at the Python level to
pull out their contents, and this is <span class="publishername">very slow.</span></p>

<p class="author1">The act of giving types to some of the primitive objects is reflected in the annotated output in <a data-type="xref" href="#FIG-04b-cython-lists-2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-4</a>. Critically, lines 11 and 12—two of our most frequently called lines—have now turned from yellow to white, indicating that they no longer call back to the Python virtual machine. We can anticipate a great speedup compared to the previous version.</p>

<figure class="calibre46"><div id="FIG-04b-cython-lists-2" class="figure">
<img src="Images/hpp2_0704.png" alt="" class="calibre96"/>
<h6 class="calibre47"><span class="publishername">Figure 7-4. </span>Our first type annotations</h6>
</div></figure>

<p class="author1">After compiling, this version takes 0.49 seconds to complete. With only a few
changes to the function, we are running at 15 times the speed of the original Python
version.</p>

<p class="author1">It is important to note that the reason we are gaining speed is that more of
the frequently performed operations are being pushed down to the C level—in
this case, the updates to <code class="calibre26">z</code> and <code class="calibre26">n</code>. This means that the C compiler can
optimize the way the lower-level functions are operating on the bytes that represent
these variables, without calling into the relatively slow Python virtual
machine.</p>

<p class="author1">As noted earlier in this chapter,<a data-type="indexterm" data-primary="abs function" id="idm46122417058680" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">abs</code> for a complex number involves taking the square root of
the sum of the squares of the real and imaginary components. In our test, we want
to see if the square root of the result is less than 2. Rather than taking the
square root, we can instead square the other side of the comparison, so we turn
<code class="calibre26">&lt; 2</code> into <code class="calibre26">&lt; 4</code>. This avoids having to calculate the square root as the
final part of the <code class="calibre26">abs</code> function.</p>

<p class="author1">In essence, we started with</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <msqrt>
      <mrow>
        <mi>c</mi>
        <mo>.</mo>
        <mi>r</mi>
        <mi>e</mi>
        <mi>a</mi>
        <msup><mi>l</mi> <mn>2</mn> </msup>
        <mo>+</mo>
        <mi>c</mi>
        <mo>.</mo>
        <mi>i</mi>
        <mi>m</mi>
        <mi>a</mi>
        <msup><mi>g</mi> <mn>2</mn> </msup>
      </mrow>
    </msqrt>
    <mo>&lt;</mo>
    <msqrt>
      <mn>4</mn>
    </msqrt>
  </mrow>
</math>
</div>

<p class="author1">and we have simplified the operation to</p>
<div data-type="equation" class="calibre56">
<math display="block">
  <mrow>
    <mi>c</mi>
    <mo>.</mo>
    <mi>r</mi>
    <mi>e</mi>
    <mi>a</mi>
    <msup><mi>l</mi> <mn>2</mn> </msup>
    <mo>+</mo>
    <mi>c</mi>
    <mo>.</mo>
    <mi>i</mi>
    <mi>m</mi>
    <mi>a</mi>
    <msup><mi>g</mi> <mn>2</mn> </msup>
    <mo>&lt;</mo>
    <mn>4</mn>
  </mrow>
</math>
</div>

<p class="author1">If we retained the <code class="calibre26">sqrt</code> operation in the following code, we would still see an
improvement in execution speed. One of the secrets to optimizing code is to make
it do as little work as possible. Removing a relatively expensive operation by
considering the ultimate aim of a function means that the C compiler can focus
on what it is good at, rather than trying to intuit the programmer’s ultimate
needs.</p>

<p class="author1">Writing equivalent but more specialized code to solve the same problem is known as <a data-type="indexterm" data-primary="strength reduction" id="idm46122417031512" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">strength reduction</em>. You trade worse flexibility (and possibly worse readability) for faster execution.</p>

<p class="author1">This mathematical unwinding leads to
<a data-type="xref" href="#augmentingwithtypes-cython-expanding-abs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-8</a>, in which we have replaced the
relatively expensive <code class="calibre26">abs</code> function with a simplified line of expanded
<span class="publishername">mathematics.</span></p>
<div id="augmentingwithtypes-cython-expanding-abs" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-8. </span>Expanding the <code class="calibre26">abs</code> function by using Cython</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="nb">int</code> <code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">cdef</code> <code class="n">unsigned</code> <code class="nb">int</code> <code class="n">i</code><code class="p">,</code> <code class="n">n</code>
    <code class="n">cdef</code> <code class="n">double</code> <code class="nb">complex</code> <code class="n">z</code><code class="p">,</code> <code class="n">c</code>
    <code class="n">output</code> <code class="o">=</code> <code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">*</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="p">(</code><code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">+</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">4</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">By annotating the code, we see that the <code class="calibre26">while</code> on line 10 (<a data-type="xref" href="#FIG-04b-cython-lists-4" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-5</a>) has become a little more yellow—it looks as though it might be doing more work rather than less. It isn’t immediately obvious how much of a speed gain we’ll get, but we know that this line is called over 30 million times, so we anticipate a good improvement.</p>

<p class="author1">This change has a dramatic effect—by reducing the number of Python calls in
the innermost loop, we greatly reduce the calculation time of the function. This new version completes in just 0.19 seconds,
an amazing 40× speedup over the original version. As ever, take a guide from what you see, but <em class="hyperlink">measure</em> to test all of your changes!</p>

<figure class="calibre46"><div id="FIG-04b-cython-lists-4" class="figure">
<img src="Images/hpp2_0705.png" alt="" class="calibre97"/>
<h6 class="calibre47"><span class="publishername">Figure 7-5. </span>Expanded math to get a final win</h6>
</div></figure>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">Cython supports several methods of compiling to C, some easier than the full-type-annotation method described here. You should familiarize yourself with the<a data-type="indexterm" data-primary="pure Python mode" id="idm46122416843368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <a href="https://oreil.ly/5y9_a" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">pure Python mode</a> if you’d like an easier start to using Cython, and look at <code class="calibre26">pyximport</code> to ease the introduction of Cython to colleagues.</p>
</div>

<p class="author1">For a final possible improvement on this piece of code, we can disable <a data-type="indexterm" data-primary="bounds checking" id="idm46122416840824" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>bounds
checking for each dereference in the list. The goal of the bounds checking is to
ensure that the program does not access data outside the allocated array—in
C it is easy to accidentally access memory outside the bounds of an array, and this will give
unexpected results (and probably a segmentation fault!).</p>

<p class="author1">By default, Cython protects the developer from accidentally addressing outside
the list’s limits. This protection costs a little bit of CPU time, but it occurs in
the outer loop of our function, so in total it won’t account for much time. Disabling bounds checking is usually safe unless you are performing your own
calculations for array addressing, in which case you will have to be careful to
stay within the bounds of the list.</p>

<p class="author1">Cython has a set of flags that can be expressed in various ways. The easiest is
to add them as single-line comments at the start of the <em class="hyperlink">.pyx</em> file. It is also
possible to use a decorator or compile-time flag to change these settings. To
disable bounds checking, we add a directive for Cython inside a comment at the
start of the <em class="hyperlink">.pyx</em> file:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="c">#cython: boundscheck=False</code>
<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="nb">int</code> <code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">):</code></pre>

<p class="author1">As noted, disabling the bounds checking will save only a little bit of time as it
occurs in the outer loop, not in the inner loop, which is more expensive. For
this example, it doesn’t save us any more time.</p>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">Try disabling bounds checking and wraparound checking if your CPU-bound code is in a loop that is dereferencing items frequently.<a data-type="indexterm" data-primary="" data-startref="cy_ata" id="idm46122416827240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Cython and numpy" class="calibre3"><div class="preface" id="compiling-cython-and-numpy">
<h1 class="calibre25">Cython and numpy</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="numpy" id="cc_cn" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cython" data-secondary="numpy and" id="cy_nu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="Cython and" id="nu_cy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="list objects" id="idm46122416777160" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">list</code> objects (for background, see <a data-type="xref" href="ch03.xhtml#chapter-lists-tuples" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 3</a>) have an overhead for each dereference, as the objects they reference
can occur anywhere in memory. In contrast, <code class="calibre26">array</code> objects store primitive types in contiguous blocks of RAM, which enables faster
addressing.</p>

<p class="author1">Python has the<a data-type="indexterm" data-primary="array module" id="idm46122416774200" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">array</code> module, which offers 1D storage for basic primitives
(including integers, floating-point numbers, characters, and Unicode strings).
NumPy’s <code class="calibre26">numpy.array</code> module allows multidimensional storage and a wider range
of primitive types, including complex numbers.</p>

<p class="author1">When iterating over an <code class="calibre26">array</code> object in a predictable fashion, the compiler can be
instructed to avoid asking Python to calculate the appropriate address and
instead to move to the next primitive item in the sequence by going directly to its memory
address. Since the data is laid out in a contiguous block, it is trivial to
calculate the address of the next item in C by using an offset, rather than asking
CPython to calculate the same result, which would involve a slow call back into
the virtual machine.</p>

<p class="author1">You should note that if you run the following <code class="calibre26">numpy</code> version <em class="hyperlink">without</em> any
Cython annotations (that is, if you just run it as a plain Python script), it’ll take about
21 seconds to run—far in excess of the plain Python <code class="calibre26">list</code> version, which takes
around 8 seconds. The slowdown is because of the overhead of dereferencing
individual elements in the <code class="calibre26">numpy</code> lists—it was never designed to be used this
way, even though to a beginner this might feel like the intuitive way of handling
operations. By compiling the code, we remove this overhead.</p>

<p class="author1">Cython has two special syntax forms for this. Older versions of Cython had a
special access type for <code class="calibre26">numpy</code> arrays, but more recently the generalized buffer
interface protocol has been introduced through the<a data-type="indexterm" data-primary="memoryview" id="idm46122416818264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">memoryview</code>—this allows
the same low-level access to any object that implements the buffer interface,
including <code class="calibre26">numpy</code> arrays and Python arrays.</p>

<p class="author1">An added bonus of the buffer interface is that blocks of memory can easily be
shared with other C libraries, without any need to convert them from Python
objects into another form.</p>

<p class="author1">The code block in <a data-type="xref" href="#augmentingwithtypes-cython-numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-9</a> looks a little
like the original implementation, except that we have added <code class="calibre26">memoryview</code>
annotations. The function’s second argument is <code class="calibre26">double complex[:] zs</code>, which
means we have a double-precision <code class="calibre26">complex</code> object using the buffer protocol
 as specified using <code class="calibre26">[]</code>, which contains a one-dimensional data block specified by
the single colon <code class="calibre26">:</code>.</p>
<div id="augmentingwithtypes-cython-numpy" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-9. </span>Annotated <code class="calibre26">numpy</code> version of the Julia calculation function</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c"># cythonfn.pyx</code>
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="n">cimport</code> <code class="n">numpy</code> <code class="kn">as</code> <code class="n">np</code>

<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="nb">int</code> <code class="n">maxiter</code><code class="p">,</code> <code class="n">double</code> <code class="nb">complex</code><code class="p">[:]</code> <code class="n">zs</code><code class="p">,</code> <code class="n">double</code> <code class="nb">complex</code><code class="p">[:]</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">cdef</code> <code class="n">unsigned</code> <code class="nb">int</code> <code class="n">i</code><code class="p">,</code> <code class="n">n</code>
    <code class="n">cdef</code> <code class="n">double</code> <code class="nb">complex</code> <code class="n">z</code><code class="p">,</code> <code class="n">c</code>
    <code class="n">cdef</code> <code class="nb">int</code><code class="p">[:]</code> <code class="n">output</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">empty</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">int32</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="p">(</code><code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">+</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">4</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">In addition to specifying the input arguments by using the buffer annotation syntax,
we also annotate the <code class="calibre26">output</code> variable, assigning a 1D <code class="calibre26">numpy</code> array to it via
<code class="calibre26">empty</code>. The call to <code class="calibre26">empty</code> will allocate a block of memory but will not
initialize the memory with sane values, so it could contain anything. We will
overwrite the contents of this array in the inner loop so we don’t need to
reassign it with a default value. This is slightly faster than allocating and
setting the contents of the array with a default value.</p>

<p class="author1">We also expanded the call to <code class="calibre26">abs</code> by using the faster, more explicit math
version. This version runs in 0.18 seconds—a slightly faster result
than the original Cythonized version of the pure Python Julia example in
<a data-type="xref" href="#augmentingwithtypes-cython-expanding-abs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-8</a>. The pure Python version has an
overhead every time it dereferences a Python <a data-type="indexterm" data-primary="complex object" id="idm46122416653032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">complex</code> object, but these
dereferences occur in the outer loop and so don’t account for much of the
execution time. After the outer loop, we make native versions of these variables,
and they operate at “C speed.” The inner loop for both this <code class="calibre26">numpy</code> example and
the former pure Python example are doing the same work on the same data, so the
time difference is accounted for by the outer loop dereferences and the creation
of the <code class="calibre26">output</code> arrays.</p>

<p class="author1">For reference, if we use the preceding code but don’t expand the <code class="calibre26">abs</code> math, then the Cythonized result takes 0.49 seconds. This result makes it identical to the earlier equivalent pure Python version’s runtime.<a data-type="indexterm" data-primary="" data-startref="cc_cy" id="idm46122416649800" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cy_ab" id="idm46122416648824" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cc_cn" id="idm46122416647880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cy_nu" id="idm46122416646936" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="nu_cy" id="idm46122416645992" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>








<section data-type="sect2" data-pdf-bookmark="Parallelizing the Solution with OpenMP on One Machine" class="calibre3"><div class="preface" id="compiling-cython-omp">
<h2 class="calibre43">Parallelizing the Solution with OpenMP on One Machine</h2>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="OpenMP" id="cc_omp" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="OpenMP" id="omp_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>As a final step in the evolution of this version of the code, let’s look at the
use of the OpenMP C++ extensions to parallelize our embarrassingly parallel
problem. If your problem fits this pattern, you can quickly take advantage
of multiple cores in your computer.</p>

<p class="author1">Open Multi-Processing (OpenMP is a well-defined cross-platform API that
supports parallel execution and memory sharing for <a data-type="indexterm" data-primary="C" id="idm46122416640088" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Fortran" data-seealso="foreign function interfaces" id="idm46122416639384" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>C, C++, and Fortran. It is
built into most modern C compilers, and if the C code is written appropriately, the parallelization occurs at the compiler level, so it comes with
relatively little effort to the developer through Cython.</p>

<p class="author1">With Cython, OpenMP can be added by using the <code class="calibre26">prange</code> (parallel range) operator and
adding the <code class="calibre26">-fopenmp</code> compiler directive to <em class="hyperlink">setup.py</em>. Work in a <code class="calibre26">prange</code> loop
can be performed in parallel because we disable the<a data-type="indexterm" data-primary="GIL (global interpreter lock)" id="idm46122416635656" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="global interpreter lock (GIL)" id="idm46122416634984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> (GIL). The GIL protects access to Python objects, preventing multiple threads or processes from accessing the same memory simultaneously, which might lead to corruption. By manually disabling the GIL, we’re asserting that we won’t corrupt our own memory. Be careful when you do this, and keep your code as simple as possible to avoid subtle bugs.</p>

<p class="author1">A modified version of the code with <code class="calibre26">prange</code> support is shown in <a data-type="xref" href="#augmentingwithtypes-cython-omp1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-10</a>.
<code class="calibre26">with nogil:</code> specifies the block, where the GIL is disabled; inside this block, we use<a data-type="indexterm" data-primary="prange" id="idm46122416631656" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">prange</code> to enable an OpenMP parallel <code class="calibre26">for</code> loop to independently calculate each <code class="calibre26">i</code>.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">When disabling the GIL, we must <em class="hyperlink">not</em> operate on regular Python objects (such as
lists); we must operate only on primitive objects and objects that support the
<a data-type="indexterm" data-primary="memoryview" id="idm46122416628056" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">memoryview</code> interface. If we operated on normal Python objects in parallel, we’d have to solve the associated memory-management problems that the GIL
deliberately avoids. Cython doesn’t prevent us from manipulating Python objects,
and only pain and confusion can result if you do this!</p>
</div>
<div id="augmentingwithtypes-cython-omp1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-10. </span>Adding <code class="calibre26">prange</code> to enable parallelization using OpenMP</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c"># cythonfn.pyx</code>
<code class="kn">from</code> <code class="nn">cython.parallel</code> <code class="kn">import</code> <code class="n">prange</code>
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>
<code class="n">cimport</code> <code class="n">numpy</code> <code class="kn">as</code> <code class="n">np</code>

<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="nb">int</code> <code class="n">maxiter</code><code class="p">,</code> <code class="n">double</code> <code class="nb">complex</code><code class="p">[:]</code> <code class="n">zs</code><code class="p">,</code> <code class="n">double</code> <code class="nb">complex</code><code class="p">[:]</code> <code class="n">cs</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="n">cdef</code> <code class="n">unsigned</code> <code class="nb">int</code> <code class="n">i</code><code class="p">,</code> <code class="n">length</code>
    <code class="n">cdef</code> <code class="n">double</code> <code class="nb">complex</code> <code class="n">z</code><code class="p">,</code> <code class="n">c</code>
    <code class="n">cdef</code> <code class="nb">int</code><code class="p">[:]</code> <code class="n">output</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">empty</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">int32</code><code class="p">)</code>
    <code class="n">length</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)</code>
    <code class="kn">with</code> <code class="n">nogil</code><code class="p">:</code>
        <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">prange</code><code class="p">(</code><code class="n">length</code><code class="p">,</code> <code class="n">schedule</code><code class="o">=</code><code class="s">"guided"</code><code class="p">):</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
            <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
            <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="mi">0</code>
            <code class="kn">while</code> <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="p">(</code><code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">+</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code> <code class="o">*</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">4</code><code class="p">:</code>
                <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
                <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">+=</code> <code class="mi">1</code>
    <code class="kn">return</code> <code class="n">output</code></pre></div>

<p class="author1">To compile <em class="hyperlink">cythonfn.pyx</em>, we have to modify the <em class="hyperlink">setup.py</em> script as shown in <a data-type="xref" href="#compiling-cython-openmp-setup" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-11</a>. We tell it
to inform the C compiler to use <code class="calibre26">-fopenmp</code> as an argument during compilation to
enable OpenMP and to link with the OpenMP libraries.</p>
<div id="compiling-cython-openmp-setup" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-11. </span>Adding the OpenMP compiler and linker flags to setup.py for Cython</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="c">#setup.py</code>
<code class="kn">from</code> <code class="nn">distutils.core</code> <code class="kn">import</code> <code class="n">setup</code>
<code class="kn">from</code> <code class="nn">distutils.extension</code> <code class="kn">import</code> <code class="n">Extension</code>
<code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>

<code class="n">ext_modules</code> <code class="o">=</code> <code class="p">[</code><code class="n">Extension</code><code class="p">(</code><code class="s">"cythonfn"</code><code class="p">,</code>
                         <code class="p">[</code><code class="s">"cythonfn.pyx"</code><code class="p">],</code>
                         <code class="n">extra_compile_args</code><code class="o">=</code><code class="p">[</code><code class="s">'-fopenmp'</code><code class="p">],</code>
                         <code class="n">extra_link_args</code><code class="o">=</code><code class="p">[</code><code class="s">'-fopenmp'</code><code class="p">])]</code>

<code class="kn">from</code> <code class="nn">Cython.Build</code> <code class="kn">import</code> <code class="n">cythonize</code>
<code class="n">setup</code><code class="p">(</code><code class="n">ext_modules</code><code class="o">=</code><code class="n">cythonize</code><code class="p">(</code><code class="n">ext_modules</code><code class="p">,</code>
                            <code class="n">compiler_directives</code><code class="o">=</code><code class="p">{</code><code class="s">"language_level"</code><code class="p">:</code> <code class="s">"3"</code><code class="p">},),</code>
      <code class="n">include_dirs</code><code class="o">=</code><code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">get_include</code><code class="p">()])</code></pre></div>

<p class="author1">With Cython’s <code class="calibre26">prange</code>, we can choose different scheduling approaches. With
<code class="calibre26">static</code>, the workload is distributed evenly across the available CPUs. Some of
our calculation regions are expensive in time, and some are cheap.  If we ask Cython
to schedule the work chunks equally using <code class="calibre26">static</code> across the CPUs, the
results for some regions will complete faster than others, and those threads will
then sit idle.</p>

<p class="author1">Both the <code class="calibre26">dynamic</code> and <code class="calibre26">guided</code> schedule options attempt to mitigate this
problem by allocating work in smaller chunks dynamically at runtime, so that
the CPUs are more evenly distributed when the workload’s calculation time is
variable. The correct choice will vary depending on the nature of
your workload.</p>

<p class="author1">By introducing OpenMP and using <code class="calibre26">schedule="guided"</code>, we drop our execution time to
approximately 0.05 seconds—the <code class="calibre26">guided</code> schedule will dynamically assign work, so
fewer threads will wait for new work.</p>

<p class="author1">We also could have disabled the bounds checking for this example by using <code class="calibre26">#cython:
boundscheck=False</code>, but it wouldn’t improve our runtime.<a data-type="indexterm" data-primary="" data-startref="cc_omp" id="idm46122416169496" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="omp_ab" id="idm46122416168552" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Numba" class="calibre3"><div class="preface" id="numba">
<h1 class="calibre25">Numba</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="Numba" id="cc_num" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Numba" data-secondary="about" id="num_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="http://numba.pydata.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Numba</a> from Continuum Analytics is a just-in-time compiler that specializes in <code class="calibre26">numpy</code> code, which it compiles via the LLVM compiler (<em class="hyperlink">not</em> via
<code class="calibre26">g++</code> or <code class="calibre26">gcc++</code>, as used by our earlier examples) at runtime. It doesn’t require a
precompilation pass, so when you run it against new code, it compiles each annotated function
for your hardware. The beauty is that you provide a decorator telling it which functions to focus on and then you let Numba take over. It aims to run on all standard <code class="calibre26">numpy</code> code.</p>

<p class="author1">Numba has been rapidly evolving since the first edition of this book. It is now fairly stable, so if you use <code class="calibre26">numpy</code> arrays and have nonvectorized code that iterates
over many items, Numba should give you a quick and very painless win. Numba does not bind to external <code class="calibre26">C</code> libraries (which Cython can do), but it can automatically generate code for GPUs (which Cython cannot).</p>

<p class="author1">One drawback when using Numba is the toolchain—it uses LLVM, and
this has many dependencies. We recommend that you use Continuum’s <a data-type="indexterm" data-primary="Anaconda Inc." id="idm46122416342968" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Anaconda
distribution, as everything is provided; otherwise, getting Numba installed in a fresh
environment can be a very time-consuming task.</p>

<p class="author1"><a data-type="xref" href="#augmentingwithtypes-numba1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-12</a> shows the addition of the <a data-type="indexterm" data-primary="@jit decorator" data-primary-sortas="jit" id="idm46122416340920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="@jit decorator" id="idm46122416339976" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">@jit</code> decorator to
our core Julia function. This is all that’s required; the fact that <code class="calibre26">numba</code> has
been imported means that the LLVM machinery kicks in at execution time to
compile this function behind the scenes.</p>
<div id="augmentingwithtypes-numba1" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-12. </span>Applying the <code class="calibre26">@jit</code> decorator to a function</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code> <code class="nn">numba</code> <code class="kn">import</code> <code class="n">jit</code>
<code class="o">...</code>
<code class="nd">@jit</code><code class="p">()</code>
<code class="kn">def</code> <code class="nf">calculate_z_serial_purepython</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">,</code> <code class="n">output</code><code class="p">):</code></pre></div>

<p class="author1">If the <code class="calibre26">@jit</code> decorator is removed, this is just the <code class="calibre26">numpy</code> version of
the Julia demo running with Python 3.7, and it takes 21 seconds. Adding the
<code class="calibre26">@jit</code> decorator drops the execution time to 0.75 seconds. This is very close
to the result we achieved with Cython, but without all of the annotation effort.</p>

<p class="author1">If we run the same function a second time in the same Python session, it runs even faster at 0.47 seconds—there’s no need to compile the target function on the second pass if the argument types are the same, so the overall execution speed is faster. On the second run, the Numba result is equivalent to the Cython with <code class="calibre26">numpy</code> result we obtained before (so it came out as fast as Cython for very little work!). PyPy has the same warm-up requirement.</p>

<p class="author1">If you’d like to read another view on what Numba offers, see <a data-type="xref" href="ch12.xhtml#lesson-from-field-numba" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Numba”</a>, where core developer Valentin Haenel talks about the <code class="calibre26">@jit</code> decorator, viewing the original Python source, and going further with parallel options and the <code class="calibre26">typed List</code> and <code class="calibre26">typed Dict</code> for pure Python compiled interoperability.</p>

<p class="author1">Just as with Cython, we can add OpenMP parallelization support with <a data-type="indexterm" data-primary="prange" id="idm46122416313416" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">prange</code>. <a data-type="xref" href="#augmentingwithtypes-numba1-prange" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-13</a> expands the decorator to require <code class="calibre26">nopython</code> and <code class="calibre26">parallel</code>. The <code class="calibre26">nopython</code> specifier means that if Numba cannot compile all of the code, it will fail. Without this, Numba can silently fall back on a Python mode that is slower; your code will run correctly, but you won’t see any speedups. Adding <code class="calibre26">parallel</code> enables support for <code class="calibre26">prange</code>. This version drops the general runtime from 0.47 seconds to 0.06 seconds. Currently Numba lacks support for OpenMP scheduling options (and with Cython, the <code class="calibre26">guided</code> scheduler runs slightly faster for this problem), but we expect support will be added in a future version.</p>
<div id="augmentingwithtypes-numba1-prange" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-13. </span>Using <code class="calibre26">prange</code> to add parallelization</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="nd">@jit</code><code class="p">(</code><code class="n">nopython</code><code class="o">=</code><code class="nb">False</code><code class="p">,</code> <code class="n">parallel</code><code class="o">=</code><code class="nb">True</code><code class="p">)</code>
<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">,</code> <code class="n">output</code><code class="p">):</code>
    <code class="sd">"""Calculate output list using Julia update rule"""</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">prange</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">zs</code><code class="p">)):</code>
        <code class="n">n</code> <code class="o">=</code> <code class="mi">0</code>
        <code class="n">z</code> <code class="o">=</code> <code class="n">zs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">c</code> <code class="o">=</code> <code class="n">cs</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="kn">while</code> <code class="n">n</code> <code class="o">&lt;</code> <code class="n">maxiter</code> <code class="ow">and</code> <code class="p">(</code><code class="n">z</code><code class="o">.</code><code class="n">real</code><code class="o">*</code><code class="n">z</code><code class="o">.</code><code class="n">real</code> <code class="o">+</code> <code class="n">z</code><code class="o">.</code><code class="n">imag</code><code class="o">*</code><code class="n">z</code><code class="o">.</code><code class="n">imag</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">4</code><code class="p">:</code>
            <code class="n">z</code> <code class="o">=</code> <code class="n">z</code> <code class="o">*</code> <code class="n">z</code> <code class="o">+</code> <code class="n">c</code>
            <code class="n">n</code> <code class="o">+=</code> <code class="mi">1</code>
        <code class="n">output</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="n">n</code></pre></div>

<p class="author1">When debugging with Numba, it is useful to note that you can ask Numba to show both the intermediate representation and the types for the function call.
 In <a data-type="xref" href="#augmentingwithtypes-numba2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-14</a>, we can see that <code class="calibre26">calculate_z</code> takes an <code class="calibre26">int64</code> and three <code class="calibre26">array</code> types.</p>
<div id="augmentingwithtypes-numba2" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-14. </span>Debugging inferred types</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">print</code><code class="p">(</code><code class="n">calculate_z</code><code class="o">.</code><code class="n">inspect_types</code><code class="p">())</code>
<code class="c"># calculate_z (int64, array(complex128, 1d, C),</code>
               <code class="n">array</code><code class="p">(</code><code class="n">complex128</code><code class="p">,</code> <code class="mi">1</code><code class="n">d</code><code class="p">,</code> <code class="n">C</code><code class="p">),</code> <code class="n">array</code><code class="p">(</code><code class="n">int32</code><code class="p">,</code> <code class="mi">1</code><code class="n">d</code><code class="p">,</code> <code class="n">C</code><code class="p">))</code></pre></div>

<p class="author1"><a data-type="xref" href="#augmentingwithtypes-numba3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-15</a> shows the continued output from the call to <code class="calibre26">inspect_types()</code>, where each line of compiled code is shown augmented by type information. This output is invaluable if you find that you can’t get <code class="calibre26">nopython=True</code> to work; here, you’ll be able to discover where your code isn’t recognized by Numba.</p>
<div id="augmentingwithtypes-numba3" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-15. </span>Viewing the intermediate representation from Numba</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="o">...</code>
<code class="kn">def</code> <code class="nf">calculate_z</code><code class="p">(</code><code class="n">maxiter</code><code class="p">,</code> <code class="n">zs</code><code class="p">,</code> <code class="n">cs</code><code class="p">,</code> <code class="n">output</code><code class="p">):</code>

    <code class="c"># --- LINE 14 ---</code>

    <code class="sd">"""Calculate output list using Julia update rule"""</code>

    <code class="c"># --- LINE 15 ---</code>
    <code class="c">#   maxiter = arg(0, name=maxiter)  :: int64</code>
    <code class="c">#   zs = arg(1, name=zs)  :: array(complex128, 1d, C)</code>
    <code class="c">#   cs = arg(2, name=cs)  :: array(complex128, 1d, C)</code>
    <code class="c">#   output = arg(3, name=output)  :: array(int32, 1d, C)</code>
    <code class="c">#   jump 2</code>
    <code class="c"># label 2</code>
    <code class="c">#   $2.1 = global(range: &lt;class 'range'&gt;)  :: Function(&lt;class 'range'&gt;)</code>
<code class="o">...</code></pre></div>

<p class="author1">Numba is a powerful JIT compiler that is now maturing. Do not expect magic on your first attempt—you may have to introspect the generated code to figure out how to make your code compile in <code class="calibre26">nopython</code> mode. Once you’ve solved this, you’ll likely see good wins. Your best approach will be to break your current code into small (&lt;10 line) and discrete functions and to tackle these one at a time. Do not try to throw a large function into Numba; you can debug the process far more quickly if you have only small, discrete chunks to review individually.</p>








<section data-type="sect2" data-pdf-bookmark="Numba to Compile NumPy for Pandas" class="calibre3"><div class="preface" id="compiling-numba-for-pandas">
<h2 class="calibre43">Numba to Compile NumPy for Pandas</h2>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="numpy" id="idm46122415932344" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="numpy" data-secondary="compiling for Pandas" id="idm46122415931400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>In <a data-type="xref" href="ch06_split_001.xhtml#pandas-ols" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Pandas”</a>, we looked at solving the slope calculation task for 100,000 rows of data in a Pandas DataFrame using <a data-type="indexterm" data-primary="OLS (Ordinary Least Squares)" id="idm46122415929384" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Ordinary Least Squares (OLS)" id="idm46122415928744" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Ordinary Least Squares. We can make that approach an order of magnitude faster by using Numba.</p>

<p class="author1">We can take the<a data-type="indexterm" data-primary="ols_lstsq_raw function" id="idm46122415927208" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">ols_lstsq_raw</code> function that we used before and, decorated with <code class="calibre26">numba.jit</code> as shown in <a data-type="xref" href="#pandas_ols_functions_numba" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-16</a>, can generate a compiled variant. Note the <code class="calibre26">nopython=True</code> argument—this forces Numba to raise an exception if we pass in a datatype that it doesn’t understand, where it would otherwise fall back to a pure Python mode silently. We don’t want it to run correctly but slowly on the wrong datatype if we pass in a Pandas Series; here we want to be informed that we’ve passed in the wrong data. In this edition, Numba can compile only NumPy datatypes, not Pandas types like Series.</p>
<div id="pandas_ols_functions_numba" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-16. </span>Solving Ordinary Least Squares with <code class="calibre26">numpy</code> on a Pandas DataFrame</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">def</code> <code class="nf">ols_lstsq_raw</code><code class="p">(</code><code class="n">row</code><code class="p">):</code>
    <code class="sd">"""Variant of `ols_lstsq` where row is a numpy array (not a Series)"""</code>
    <code class="n">X</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
    <code class="n">ones</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">row</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
    <code class="n">A</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">vstack</code><code class="p">((</code><code class="n">X</code><code class="p">,</code> <code class="n">ones</code><code class="p">))</code><code class="o">.</code><code class="n">T</code>
    <code class="n">m</code><code class="p">,</code> <code class="n">c</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">lstsq</code><code class="p">(</code><code class="n">A</code><code class="p">,</code> <code class="n">row</code><code class="p">,</code> <code class="n">rcond</code><code class="o">=-</code><code class="mi">1</code><code class="p">)[</code><code class="mi">0</code><code class="p">]</code>
    <code class="kn">return</code> <code class="n">m</code>

<code class="c"># generate a Numba compiled variant</code>
<code class="n">ols_lstsq_raw_values_numba</code> <code class="o">=</code> <code class="n">jit</code><code class="p">(</code><code class="n">ols_lstsq_raw</code><code class="p">,</code> <code class="n">nopython</code><code class="o">=</code><code class="nb">True</code><code class="p">)</code>

<code class="n">results</code> <code class="o">=</code> <code class="n">df</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">ols_lstsq_raw_values_numba</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">raw</code><code class="o">=</code><code class="nb">True</code><code class="p">)</code></pre></div>

<p class="author1">The first time we call this function in, we get the expected short delay while the function is compiled; processing 100,000 rows takes 2.3 seconds including compilation time. Subsequent calls to process 100,000 rows are very fast—the noncompiled <code class="calibre26">ols_lstsq_raw</code> takes 5.3 seconds per 100,000 rows, whereas after using Numba it takes 0.58 seconds. That’s nearly a tenfold speedup!<a data-type="indexterm" data-primary="" data-startref="cc_num" id="idm46122415919176" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="num_ab" id="idm46122415784024" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="PyPy" class="calibre3"><div class="preface" id="compiling-pypy">
<h1 class="calibre25">PyPy</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="PyPy" id="cc_pp" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyPy" data-secondary="about" id="pp_abt" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="http://pypy.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PyPy</a> is an alternative implementation of the Python
language that includes a tracing just-in-time compiler; it is compatible with Python 3.5+. Typically, it lags behind the most recent version of Python; at the time of writing this second edition Python 3.7 is standard, and PyPy supports up to Python 3.6.</p>

<p class="author1">PyPy is a drop-in
replacement for CPython and offers all the built-in modules. The project
comprises the RPython Translation Toolchain, which is used to build PyPy (and
could be used to build other interpreters). The JIT compiler in PyPy is
very effective, and good speedups can be seen with little or no work on your part. See
<a data-type="xref" href="ch12.xhtml#lessons-from-field-marko" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“PyPy for Successful Web and Data Processing Systems (2014)”</a> for a large PyPy deployment success story.</p>

<p class="author1">PyPy runs our pure Python Julia demo without any modifications. With CPython it
takes 8 seconds, and with PyPy it takes 0.9 seconds. This means that PyPy
achieves a result that’s very close to the Cython example in
<a data-type="xref" href="#augmentingwithtypes-cython-expanding-abs" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-8</a>, without <em class="hyperlink">any effort at all</em>—that’s pretty impressive! As we observed in our discussion of Numba, if the <span class="publishername">calculations</span> are run again <em class="hyperlink">in the same session</em>, then the second and subsequent runs are faster than the first one, as they are already compiled.</p>

<p class="author1">By expanding the math and removing the call to <code class="calibre26">abs</code>, the PyPy runtime drops to 0.2 seconds. This is equivalent to the Cython versions using pure Python and <code class="calibre26">numpy</code> without any work! Note that this result is true only if you’re not using <code class="calibre26">numpy</code> with PyPy.</p>

<p class="author1">The fact that PyPy supports all the built-in modules is interesting—this means
that <code class="calibre26">multiprocessing</code> works as it does in CPython. If you have a problem that
runs with the batteries-included modules and can run in parallel with
<code class="calibre26">multiprocessing</code>, you can expect that all the speed gains you might hope to get will be
available.</p>

<p class="author1">PyPy’s speed has evolved over time. The older chart in <a data-type="xref" href="#FIG-speed-pypy-org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-6</a> (from <a href="http://speed.pypy.org/" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">speed.pypy.org</em></a>) will give you an idea about PyPy’s maturity. These speed tests reflect a wide range of use cases, not just mathematical operations. It is clear that PyPy offers a faster experience than CPython.</p>

<figure class="calibre46"><div id="FIG-speed-pypy-org" class="figure">
<img src="Images/hpp2_0706.png" alt="" class="calibre98"/>
<h6 class="calibre47"><span class="publishername">Figure 7-6. </span>Each new version of PyPy offers speed improvements</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Garbage Collection Differences" class="calibre3"><div class="preface" id="idm46122415765128">
<h2 class="calibre43">Garbage Collection Differences</h2>

<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="garbage collector in" id="idm46122415763960" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="garbage collectors" id="idm46122415762984" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyPy" data-secondary="garbage collector in" id="idm46122415762312" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PyPy uses a different type of garbage collector than CPython, and this can cause some nonobvious behavior changes to your code. Whereas CPython uses reference counting, PyPy uses a modified mark-and-sweep approach that may clean up an unused object much later. Both are correct implementations of the Python specification; you just have to be aware that code modifications might be required when swapping.</p>

<p class="author1">Some coding approaches seen in CPython depend on the behavior of the reference counter—particularly the flushing of files, if you open and write to them without an explicit file close. With PyPy the same code will run, but the updates to the file might get flushed to disk later, when the garbage collector next runs. An alternative form that works in both PyPy and Python is to use a context manager using <code class="calibre26">with</code> to open and automatically close files. The <a href="http://bit.ly/PyPy_CPy_diff" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Differences Between PyPy and CPython page</a> on the PyPy website lists the details.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Running PyPy and Installing Modules" class="calibre3"><div class="preface" id="idm46122415758456">
<h2 class="calibre43">Running PyPy and Installing Modules</h2>

<p class="author1"><a data-type="indexterm" data-primary="PyPy" data-secondary="running and installing modules" id="pp_rim" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>If you’ve never run an alternative Python interpreter, you might benefit from a
short example. Assuming you’ve downloaded and extracted PyPy, you’ll now have
a folder structure containing a <em class="hyperlink">bin</em> directory. Run it as shown in <a data-type="xref" href="#compiling-pypy-run" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-17</a> to start PyPy.</p>
<div id="compiling-pypy-run" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-17. </span>Running PyPy to see that it implements Python 3.6</h5>

<pre data-type="programlisting" class="calibre59">...
$ pypy3
Python 3.6.1 (784b254d6699, Apr 14 2019, 10:22:42)
[PyPy 7.1.1-beta0 with GCC 6.2.0 20160901] on linux
Type "help", "copyright", "credits", or "license" for more information.
And now for something completely different
...</pre></div>

<p class="author1">Note that PyPy 7.1 runs as Python 3.6. Now we need to set up <code class="calibre26">pip</code>, and we’ll want to install IPython. The steps shown in
<a data-type="xref" href="#compiling-pypy-pip" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-18</a> are the same as you might have performed with CPython if you’ve installed <code class="calibre26">pip</code> without the help
of an existing distribution or package manager. Note that when running IPython, we get the same build number as we see when running <code class="calibre26">pypy3</code> in the preceding example.</p>

<p class="author1">You can see that IPython runs with PyPy just the same as with CPython, and using the <code class="calibre26">%run</code> syntax, we execute the Julia script inside IPython to achieve 0.2-second 
<span class="publishername">runtimes</span>.</p>
<div id="compiling-pypy-pip" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-18. </span>Installing <code class="calibre26">pip</code> for PyPy to install third-party modules like IPython</h5>

<pre data-type="programlisting" class="calibre59">...
$ pypy3 -m ensurepip
Collecting setuptools
Collecting pip
Installing collected packages: setuptools, pip
Successfully installed pip-9.0.1 setuptools-28.8.0

$ pip3 install ipython
Collecting ipython

$ ipython
Python 3.6.1 (784b254d6699, Apr 14 2019, 10:22:42)
Type 'copyright', 'credits', or 'license' for more information
IPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: %run julia1_nopil_expanded_math.py
Length of x: 1000
Total elements: 1000000
calculate_z_serial_purepython took 0.2143106460571289 seconds
Length of x: 1000
Total elements: 1000000
calculate_z_serial_purepython took 0.1965022087097168 seconds
...</pre></div>

<p class="author1">Note that PyPy supports projects like <code class="calibre26">numpy</code> that require C bindings through the CPython extension compatibility layer <a href="http://bit.ly/PyPy_compatibility" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">cpyext</code></a>, but it has
an overhead of 4–6×, which generally makes <code class="calibre26">numpy</code> too slow. If your code is mostly pure Python with only a few calls to <code class="calibre26">numpy</code>, you may still see significant overall gains. If your code, like the Julia example, makes many calls to <code class="calibre26">numpy</code>, then it’ll run significantly slower. The Julia benchmark here with <code class="calibre26">numpy</code> arrays runs 6× slower than when it is run with CPython.</p>

<p class="author1">If you need other packages, they should install thanks to the <code class="calibre26">cpyext</code> compatibility module, which is essentially PyPy’s version of <code class="calibre26">python.h</code>. It handles the different memory management requirements of PyPy and CPython; however, this management incurs a cost of 4–6× per managed call, so the speed advantages of <code class="calibre26">numpy</code> can be negated by this overhead. A new project named <code class="calibre26">HPy</code> (formerly <code class="calibre26">PyHandle</code>) aims to remove this overhead by providing a higher-level object handle—one not tied to CPython’s implementation—which can be shared with other projects like Cython.</p>

<p class="author1">If you want to understand PyPy’s performance characteristics, look at the <code class="calibre26">vmprof</code> lightweight sampling profiler. It is thread-safe and supports a web-based user 
<span class="publishername">interface</span>.</p>

<p class="author1">Another downside of PyPy is that it can use a lot of RAM. Each release is
better in this respect, but in practice it may use more RAM than CPython. RAM is
fairly cheap, though, so it makes sense to try to trade it for enhanced performance. Some
users have also reported <em class="hyperlink">lower</em> RAM usage when using PyPy. As ever, perform an
experiment using representative data if this is important to you.<a data-type="indexterm" data-primary="" data-startref="cc_pp" id="idm46122415734840" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pp_abt" id="idm46122415733864" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="pp_rim" id="idm46122415732920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="A Summary of Speed Improvements" class="calibre3"><div class="preface" id="idm46122415782648">
<h1 class="calibre25">A Summary of Speed Improvements</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="summary of options" id="idm46122415730776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>To summarize the previous results, in <a data-type="xref" href="#table_compiler_results1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Table 7-1</a> we see that PyPy on a pure Python math-based code sample is approximately 9× faster than CPython with no code changes, and it’s even faster if the <code class="calibre26">abs</code> line is simplified. Cython runs faster than PyPy in both instances but requires annotated code, which increases development and support effort.</p>
<table id="table_compiler_results1" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 7-1. </span>Julia (no <code class="calibre86">numpy</code>) results</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89"> </th>
<th class="calibre89">Speed</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">CPython</p></td>
<td class="calibre16"><p class="calibre17">8.00s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">Cython</p></td>
<td class="calibre16"><p class="calibre17">0.49s</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">Cython on expanded math</p></td>
<td class="calibre16"><p class="calibre17">0.19s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">PyPy</p></td>
<td class="calibre16"><p class="calibre17">0.90s</p></td>
</tr>
<tr class="calibre19">
<td class="calibre16"><p class="calibre17">PyPy on expanded math</p></td>
<td class="calibre16"><p class="calibre17">0.20s</p></td>
</tr>
</tbody>
</table>

<p class="author1">The Julia solver with <code class="calibre26">numpy</code> enables the investigation of OpenMP. In <a data-type="xref" href="#table_compiler_results2" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Table 7-2</a>, we see that both <a data-type="indexterm" data-primary="Numba" data-secondary="compiling to C" id="idm46122415714088" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Cython" data-secondary="compiling to C" id="idm46122415713112" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Cython and Numba run faster than the non-<code class="calibre26">numpy</code> versions with expanded math. When we add OpenMP, both Cython and Numba provide further speedups for very little additional coding.</p>
<table id="table_compiler_results2" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 7-2. </span>Julia (with <code class="calibre86">numpy</code> and expanded math) results</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89"/>
<th class="calibre89">Speed</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">CPython</p></td>
<td class="calibre16"><p class="calibre17">21.00s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">Cython</p></td>
<td class="calibre16"><p class="calibre17">0.18s</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">Cython and OpenMP “guided”</p></td>
<td class="calibre16"><p class="calibre17">0.05s</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">Numba (2nd &amp; subsequent runs)</p></td>
<td class="calibre16"><p class="calibre17">0.17s</p></td>
</tr>
<tr class="calibre19">
<td class="calibre16"><p class="calibre17">Numba and OpenMP</p></td>
<td class="calibre16"><p class="calibre17">0.06s</p></td>
</tr>
</tbody>
</table>

<p class="author1">For pure Python code, PyPy is an obvious first choice. For <code class="calibre26">numpy</code> code, Numba is a great first choice.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="When to Use Each Technology" class="calibre3"><div class="preface" id="idm46122415674584">
<h1 class="calibre25">When to Use Each Technology</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="when to use each technology" id="cc_wtu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>If you’re working on a numeric project, then each of these technologies
could be useful to you. <a data-type="xref" href="#table_compiler_summary" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Table 7-3</a> summarizes the main options.</p>
<table id="table_compiler_summary" class="stafflist_table">
<caption class="calibre85"><span class="publishername">Table 7-3. </span>Compiler options</caption>
<thead class="calibre87">
<tr class="calibre88">
<th class="calibre89"/>
<th class="calibre89">Cython</th>
<th class="calibre89">Numba</th>
<th class="calibre89">PyPy</th>
</tr>
</thead>
<tbody class="calibre14">
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">Mature</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">Widespread</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17"><code class="calibre99">numpy</code> support</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
</tr>
<tr class="calibre18">
<td class="calibre16"><p class="calibre17">Nonbreaking code changes</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
</tr>
<tr class="calibre15">
<td class="calibre16"><p class="calibre17">Needs C knowledge</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
</tr>
<tr class="calibre78">
<td class="calibre16"><p class="calibre17">Supports OpenMP</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">Y</p></td>
<td class="calibre16"><p class="calibre17">–</p></td>
</tr>
</tbody>
</table>

<p class="author1"><a data-type="indexterm" data-primary="Numba" data-secondary="when to use" id="idm46122415649400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Numba may offer quick wins for little effort, but it too has limitations that might stop it working well on your code. It is also a relatively young project.</p>

<p class="author1"><a data-type="indexterm" data-primary="Cython" data-secondary="when to use" id="idm46122415647864" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Cython probably offers the best results for the widest set of problems, but it does require more effort and has
an additional “support tax” due to mixing Python with C annotations.</p>

<p class="author1"><a data-type="indexterm" data-primary="PyPy" data-secondary="when to use" id="idm46122415646296" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PyPy is a strong option if you’re not using <code class="calibre26">numpy</code> or other hard-to-port C extensions.</p>

<p class="author1">If you’re deploying a production tool, you probably want to stick with well-understood tools—Cython should be your main choice, and you may want to check out <a data-type="xref" href="ch12.xhtml#lessons-from-field-radim" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Making Deep Learning Fly with RadimRehurek.com (2014)”</a>. PyPy is also being used in production settings (see <a data-type="xref" href="ch12.xhtml#lessons-from-field-marko" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“PyPy for Successful Web and Data Processing Systems (2014)”</a>).</p>

<p class="author1">If you’re working with light numeric requirements, note that Cython’s buffer
interface accepts <code class="calibre26">array.array</code> matrices—this is an easy way to pass a block
of data to Cython for fast numeric processing without having to add <code class="calibre26">numpy</code> as a
project 
<span class="publishername">dependency</span>.</p>

<p class="author1">Overall, Numba is maturing and is a promising project, whereas Cython is
mature. PyPy is regarded as being fairly mature now and should definitely be
evaluated for long-running processes.</p>

<p class="author1">In a class run by Ian, a capable student implemented a C version of the Julia algorithm and was disappointed to see it execute more slowly than his Cython version. It transpired that he was using 32-bit floats on a 64-bit machine—these run more slowly than 64-bit doubles on a 64-bit machine. The student, despite being a good C programmer, didn’t know that this could involve a speed cost. He changed his code, and the C version, despite being significantly shorter than the autogenerated Cython version, ran at roughly the same speed. The act of writing the raw C version, comparing its speed, and figuring out how to fix it took longer than using Cython in the first place.</p>

<p class="author1">This is just an anecdote; we’re not suggesting that Cython will generate the best code, and competent C programmers can probably figure out how to make <em class="hyperlink">their</em> code run faster than the version generated by Cython. It is worth noting, though, that the assumption that handwritten C will be faster than converted Python is not a safe assumption. You must always benchmark and make decisions using evidence. C compilers are pretty good at converting code into fairly efficient machine code, and Python is pretty good at letting you express your problem in an easy-to-understand language—combine these two powers sensibly.</p>








<section data-type="sect2" data-pdf-bookmark="Other Upcoming Projects" class="calibre3"><div class="preface" id="idm46122415636840">
<h2 class="calibre43">Other Upcoming Projects</h2>

<p class="author1"><a data-type="indexterm" data-primary="PyData compilers page" id="idm46122415635400" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The <a href="http://compilers.pydata.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PyData compilers page</a> lists a set of
high performance and compiler tools.</p>

<p class="author1"><a data-type="indexterm" data-primary="Pythran" id="idm46122415633576" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/Zi4r5" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Pythran</a> is an AOT compiler aimed at scientists who are using <code class="calibre26">numpy</code>. Using few annotations, it will compile Python numeric code to a faster binary—it produces speedups that are very similar to <code class="calibre26">Cython</code> but for much less work. Among other features, it always releases the GIL and can use both SIMD instructions and OpenMP. Like Numba, it doesn’t support classes. If you have tight, locally bound loops in Numpy, Pythran is certainly worth evaluating. The associated FluidPython project aims to make Pythran even easier to write and provides JIT capability.</p>

<p class="author1"><a data-type="indexterm" data-primary="Transonic" id="idm46122415630520" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/tT4Sf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Transonic</a> attempts to unify Cython, Pythran, and Numba, and potentially other compilers, behind one interface to enable quick evaluation of multiple compilers without having to rewrite code.</p>

<p class="author1"><a data-type="indexterm" data-primary="ShedSkin" id="idm46122415628680" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/BePH-" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">ShedSkin</a> is an AOT compiler aimed at nonscientific, pure Python code. It has no <code class="calibre26">numpy</code> support, but if your code is pure Python, ShedSkin produces speedups similar to those seen by PyPy (without using <code class="calibre26">numpy</code>). It supports Python 2.7 with some Python 3.<em class="hyperlink">x</em> support.</p>

<p class="author1"><a data-type="indexterm" data-primary="PyCUDA" id="idm46122415625560" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/Lg4H3" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PyCUDA</a> and <a data-type="indexterm" data-primary="PyOpenCL" id="idm46122415624200" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/8e3OA" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PyOpenCL</a> offer CUDA and OpenCL bindings into Python for direct access to GPUs. Both libraries are mature and support Python 3.4+.</p>

<p class="author1"><a data-type="indexterm" data-primary="Nuitka" id="idm46122415622376" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/dLPEw" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Nuitka</a> is a Python compiler
that aims to be an alternative to the usual CPython interpreter, with the option
of creating compiled executables. It supports all of Python 3.7, though in our
testing it didn’t produce any noticeable speed gains for our plain Python numerical
tests.</p>

<p class="author1">Our community is rather blessed with a wide array of compilation options.
While they all have trade-offs, they also offer a lot of power so that complex
projects can take advantage of the full power of CPUs and multicore
architectures.<a data-type="indexterm" data-primary="" data-startref="cc_wtu" id="idm46122415620056" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Graphics Processing Units (GPUs)" class="calibre3"><div class="preface" id="idm46122415673960">
<h1 class="calibre25">Graphics Processing Units (GPUs)</h1>

<p class="author1"><a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="about" id="idm46122415617704" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Graphics Processing Units (GPUs) are becoming incredibly popular
as a method to speed up arithmetic-heavy computational workloads. Originally
designed to help handle the heavy linear algebra requirements of 3D graphics,
GPUs are particularly well suited for solving easily parallelizable problems.</p>

<p class="author1">Interestingly, GPUs themselves are slower than most CPUs if we just look at
clock speeds. This may seem counterintuitive, but as we discussed in
<a data-type="xref" href="ch01_split_000.xhtml#computing-units" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Computing Units”</a>, clock speed is just one measurement of hardware’s ability
to compute. GPUs excel at massively parallelize tasks because of the
staggering number of 
<span class="publishername">compute</span> cores they have. CPUs generally have on the order
of 12 cores, while modern-day GPUs have thousands. For example, on the machine
used to run benchmarks for this section, the AMD Ryzen 7 1700 CPU has 8 cores,
each at 3.2 GHz, while the NVIDIA RTX 2080 TI GPU has 4,352 cores, each at 1.35 GHz.<sup class="calibre44"><a data-type="noteref" id="idm46122415613752-marker" href="ch07.xhtml#idm46122415613752" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup></p>

<p class="author1">This incredible amount of parallelism can speed up many numerical tasks by a
staggering amount. However, programming on these devices can be quite tough.
Because of the amount of parallelism, data locality needs to be considered and
can be make-or-break in terms of getting speedups. There are many tools out
there to write native GPU code <a data-type="indexterm" data-primary="Kernel" id="idm46122415612280" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>(also called <code class="calibre26">kernels</code>) in Python, such as <a data-type="indexterm" data-primary="CuPy" id="idm46122415611032" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://cupy.chainer.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">CuPy</a>. However, the needs of modern deep learning
algorithms have been pushing new interfaces into GPUs that are easy and
intuitive to use.</p>

<p class="author1">The two front-runners in terms of easy-to-use GPU mathematics libraries are
<a data-type="indexterm" data-primary="TensorFlow" id="idm46122415609064" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyTorch" id="idm46122415608360" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>TensorFlow and PyTorch. We will focus on PyTorch for its ease of use and great
speed.<sup class="calibre44"><a data-type="noteref" id="idm46122415607560-marker" href="ch07.xhtml#idm46122415607560" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup></p>








<section data-type="sect2" data-pdf-bookmark="Dynamic Graphs: PyTorch" class="calibre3"><div class="preface" id="idm46122415604664">
<h2 class="calibre43">Dynamic Graphs: PyTorch</h2>

<p class="author1"><a href="https://pytorch.org" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">PyTorch</a> is a static computational graph tensor
library that is particularly user-friendly and has a very intuitive API for
anyone familiar with <code class="calibre26">numpy</code>. In addition, since it is a tensor library, it has
all the same functionality as <code class="calibre26">numpy</code>, with the added advantages of being able to create
functions through its static computational graph and calculate derivatives of
those functions by using a mechanism called<a data-type="indexterm" data-primary="autograd" id="idm46122415601224" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">autograd</code>.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">The <code class="calibre26">autograd</code> functionality of PyTorch is left out since it isn’t relevant to our
discussion. However, this module is quite amazing and can take the
derivative of any arbitrary function made up of PyTorch operations. It can do it
on the fly and at any value. For a long time, taking derivatives of complex
functions could have been the makings of a PhD thesis; however, now we can do it
incredibly simply and efficiently. While this may also be off-topic for
your work, we recommend learning about <code class="calibre26">autograd</code> and automatic-differentiation in
general, as it truly is an incredible advancement in numerical computation.</p>
</div>

<p class="author1">By <a data-type="indexterm" data-primary="static computational graph" id="idm46122415596904" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><em class="hyperlink">static computational graph</em>, we mean that performing operations on PyTorch
objects creates a dynamic definition of a program that gets compiled to GPU code
in the background when it is executed (exactly like a JIT from
<a data-type="xref" href="#jit_vs_compiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“JIT Versus AOT Compilers”</a>). Since it is dynamic, changes to the Python code
automatically get reflected in changes in the GPU code without an explicit
compilation step needed. This hugely aids debugging and interactivity, as
compared to static graph libraries like TensorFlow.</p>

<p class="author1">In a static graph, like TensorFlow, we first set up our computation, then compile
it. From then on, our compute is fixed in stone, and we can change it only by
recompiling the entire thing. With the dynamic graph of PyTorch, we can
conditionally change our compute graph or build it up iteratively. This allows
us to have conditional debugging in our code or lets us play with the GPU in an
interactive session in IPython. The ability to flexibly control the GPU is a
complete game changer when dealing with complex GPU-based workloads.</p>

<p class="author1">As an example of the library’s ease of use as well as its speed, in <a data-type="xref" href="#compilation-diffusion-pytorch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-19</a> we port the <code class="calibre26">numpy</code> code from <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_naive" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-9</a> to use the GPU using PyTorch.</p>
<div id="compilation-diffusion-pytorch" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-19. </span>PyTorch 2D diffusion</h5>
<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code><code class="calibre26"> </code><code class="nn">torch</code><code class="calibre26">
</code><code class="kn">from</code><code class="calibre26"> </code><code class="nn">torch</code><code class="calibre26"> </code><code class="kn">import</code><code class="calibre26"> </code><code class="p">(</code><code class="n">roll</code><code class="p">,</code><code class="calibre26"> </code><code class="n">zeros</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO1-1a" href="#callout_compiling_to_c_CO1-1b"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">grid_shape</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">(</code><code class="mi">640</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">640</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="p">(</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">+</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="o">+</code><code class="calibre26"> </code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">-</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="o">+</code><code class="calibre26"> </code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">+</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="o">+</code><code class="calibre26"> </code><code class="n">roll</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="o">-</code><code class="mi">1</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="o">-</code><code class="calibre26"> </code><code class="mi">4</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">grid</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">+</code><code class="calibre26"> </code><code class="n">dt</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">D</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="n">laplacian</code><code class="p">(</code><code class="n">grid</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_low</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.4</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">block_high</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">int</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="calibre26"> </code><code class="o">*</code><code class="calibre26"> </code><code class="mi">0.5</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="p">[</code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">,</code><code class="calibre26"> </code><code class="n">block_low</code><code class="p">:</code><code class="n">block_high</code><code class="p">]</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="mi">0.005</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid</code><code class="o">.</code><code class="n">cuda</code><code class="p">(</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO1-2a" href="#callout_compiling_to_c_CO1-2b"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0.1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">return</code><code class="calibre26"> </code><code class="n">grid</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO1-1b" href="#co_compiling_to_c_CO1-1a"><img src="Images/1.png" alt="1" class="calibre74"/></a>,
<a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO1-2b" href="#co_compiling_to_c_CO1-2a"><img src="Images/2.png" alt="2" class="calibre74"/></a>
</dt>
<dd class="calibre75"><p class="calibre76">    The only changes needed.</p></dd>
</dl></div>

<p class="author1">Most of the work is done in the modified import, where we changed <code class="calibre26">numpy</code> to <code class="calibre26">torch</code>. In fact, if we just
wanted to run our optimized code on the CPU, we could stop here.<sup class="calibre44"><a data-type="noteref" id="idm46122415458168-marker" href="ch07.xhtml#idm46122415458168" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup> To use the GPU, we simply need to
move our data to the GPU, and then <code class="calibre26">torch</code> will automatically compile all computations
we do on that data into GPU code.</p>

<p class="author1">As we can see in <a data-type="xref" href="#pytorch_versus_numpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Figure 7-7</a>, this small code change has given us an incredible speedup.<sup class="calibre44"><a data-type="noteref" id="idm46122415455528-marker" href="ch07.xhtml#idm46122415455528" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup> For a 512 × 512 grid, we
have a 5.3× speedup, and for a 4,096 × 4,096 grid we have a 102× speedup! It is
interesting that the GPU code doesn’t seem to be as affected by increases to grid
size as the <code class="calibre26">numpy</code> code is.</p>

<figure class="calibre46"><div id="pytorch_versus_numpy" class="figure">
<img src="Images/hpp2_0707.png" alt="Comparison of Numpy and PyTorch on CPU and GPU (using an NVIDIA RTX 2080TI)" class="calibre100"/>
<h6 class="calibre47"><span class="publishername">Figure 7-7. </span>PyTorch versus <code class="calibre26">numpy</code> performance</h6>
</div></figure>

<p class="author1">This speedup is a result of how parallelizable the diffusion
problem is. As we said before, the GPU we are using has 4,362 independent
computation cores. It seems that once the diffusion problem is parallelized, none
of these GPU cores are being fully utilized.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">When timing the performance of GPU code, it is important to set the
environmental flag <code class="calibre26">CUDA_LAUNCH_BLOCKING=1</code>. By default, GPU operations are run
asynchronously to allow more operations to be pipelined together and thus to minimize the total utilization of the GPU and increase parallelization.
When the asynchronous behavior is enabled, we can guarantee that the
computations are done only when either the data is copied to another device or a <code class="calibre26">torch.cuda.synchronize()</code> <a data-type="indexterm" data-primary="torch.cuda.synchronize() command" id="idm46122415447464" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>command is issued. By enabling the preceding
environmental variable, we can make sure that computations are completed when
they are issued and that we are indeed measuring compute time.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Basic GPU Profiling" class="calibre3"><div class="preface" id="gpu-profiling">
<h2 class="calibre43">Basic GPU Profiling</h2>

<p class="author1"><a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="basic profiling" id="idm46122415444712" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>One way to verify exactly how much of the GPU we are utilizing is by using the
<a data-type="indexterm" data-primary="nvidia-smi command" id="idm46122415443640" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">nvidia-smi</code> command to inspect the resource utilization of the GPU. The two
values we are most interested in are the power usage and the GPU utilization:</p>

<pre data-type="programlisting" class="calibre50">$ nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.44       Driver Version: 440.44       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:06:00.0 Off |                  N/A |
| 30%   58C    P2    96W / 260W |   1200MiB / 11018MiB |     95%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     26329      C   .../.pyenv/versions/3.7.2/bin/python        1189MiB |
+-----------------------------------------------------------------------------+</pre>

<p class="author1">GPU utilization, here at 95%, is a slightly mislabeled field. It tells us what
percentage of the last second has been spent running at least one kernel. So it
isn’t telling us what percentage of the GPU’s total computational power we’re
using but rather how much time was spent <em class="hyperlink">not</em> being idle. This is a very useful
measurement to look at when debugging memory transfer issues and making sure
that the CPU is providing the GPU with enough work.</p>

<p class="author1">Power usage, on the other hand, is a good proxy for judging how much of the GPU’s
compute power is being used. As a rule of thumb, the more power the GPU is

<span class="publishername">drawing</span>, the more compute it is currently doing. If the GPU is waiting for data
from the CPU or using only half of the available cores, power use will be
reduced from the maximum.</p>

<p class="author1">Another useful tool is <a data-type="indexterm" data-primary="gpustat tool" id="idm46122415437304" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a href="https://oreil.ly/3Sa1r" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">gpustat</code></a>. This project provides a nice
view into many of NVIDIA’s stats using a much friendlier interface than
<code class="calibre26">nvidia-smi</code>.</p>

<p class="author1">To help understand what specifically is causing slowdowns in your PyTorch code,
the project provides a special profiling tool. Running your code with <code class="calibre26">python -m
torch.utils.bottleneck</code> will show both CPU and GPU runtime stats to help you
identify potential optimizations to either portion of your code.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Performance Considerations of GPUs" class="calibre3"><div class="preface" id="idm46122415433960">
<h2 class="calibre43">Performance Considerations of GPUs</h2>

<p class="author1"><a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="performance considerations of" id="idm46122415432424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Since a GPU is a completely auxiliary piece of hardware on the computer, with
its own architecture as compared with the CPU, there are many GPU-specific
performance considerations to keep in mind.</p>

<p class="author1">The biggest speed consideration for GPUs is the transfer time of data from the
system memory to the GPU memory. When we use <code class="calibre26">tensor.to(<em class="calibre66">DEVICE</em>)</code>, we are
triggering a transfer of data that may take some time depending on the
speed of the GPU’s bus and the amount of data being transferred.</p>

<p class="author1">Other operations may trigger a transfer as well. In particular,
<code class="calibre26">tensor.items()</code> and <code class="calibre26">tensor.tolist()</code> often cause problems when introduced for
debugging purposes. In fact, running <code class="calibre26">tensor.numpy()</code> to convert a PyTorch
tensor into a <code class="calibre26">numpy</code> array specifically requires an explicit copy out of the GPU,
which ensures you understand the potential penalty.</p>

<p class="author1">As an example, let’s add a <code class="calibre26">grid.cpu()</code> call inside the solver loop of
our diffusion code:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50">    <code class="n">grid</code> <code class="o">=</code> <code class="n">grid</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">grid</code> <code class="o">=</code> <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="mi">0.1</code><code class="p">)</code>
        <code class="n">grid</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code></pre>

<p class="author1">To ensure that we have a fair comparison, we will also add
<a data-type="indexterm" data-primary="torch.cuda.synchronize() command" id="idm46122415407144" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">torch.cuda.synchronize()</code> to the control code so that we are simply testing the
time to copy the data from the CPU. In addition to this slowing down your code by
triggering a data transfer from the GPU to the system memory, your code will
slow down because the GPU will pause code execution that would have continued in
the background until the transfer is complete.</p>

<p class="author1">This change to the code for a 2,048 × 2,048 grid slows down our code by 2.54×! Even
though our GPU has an advertised bandwidth of 616.0 GB/s, this overhead can
quickly add up. In addition, other overhead costs are associated with a
memory copy. First, we are creating a hard stop to any potential pipelining of
our code execution. Then, because we are no longer pipelining, our data on the
GPU must all be synchronized out of the memory of the individual CUDA cores.
Finally, space on system memory needs to be prepared to receive the new data
from the GPU.</p>

<p class="author1">While this seems like a ridiculous addition to make to our code, this sort of
thing happens all the time. In fact, one of the biggest things slowing down
PyTorch code when it comes to deep learning is copying training data from the
host into the GPU. Often the training data is simply too big to fit on the
GPU, and doing these constant data transfers is an unavoidable penalty.</p>

<p class="author1">There are ways to alleviate the overhead from this inevitable data transfer when
the problem is going from CPU to GPU. First, the memory region can be marked
as <code class="calibre26">pinned</code>. This can be done by calling the <a data-type="indexterm" data-primary="Tensor.pin_memory() method" id="idm46122415398712" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">Tensor.pin_memory()</code> method,
which returns a copy of the CPU tensor that is copied to a “page locked” region of
memory. This page-locked region can be copied to the GPU much more quickly, and it can
be copied asynchronously so as to not disturb any computations being done by the
GPU. While training a deep learning model, data loading is generally done with
the <code class="calibre26">DataLoader</code> class, which conveniently has a <code class="calibre26">pin_memory</code> parameter that
can automatically do this for all your training data.<sup class="calibre44"><a data-type="noteref" id="idm46122415396520-marker" href="ch07.xhtml#idm46122415396520" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">5</a></sup></p>

<p class="author1">The most important step is to profile your code by using the tools outlined in
<a data-type="xref" href="#gpu-profiling" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Basic GPU Profiling”</a>. When your code is spending most of its time doing data
transfers, you will see a low power draw, a smaller GPU utilization (as reported
by <code class="calibre26">nvidia-smi</code>), and most of your time being spent in the <code class="calibre26">to</code> function (as
reported by <code class="calibre26">bottleneck</code>). Ideally, you will be using the maximum amount of
power the GPU can support and have 100% utilization. This is possible even when
large amounts of data transfer are required—even when training deep learning
models with a large number of images!</p>
<div data-type="caution" class="calibre37"><h6 class="calibre38">Caution</h6>
<p class="author1">GPUs are not particularly good at running multiple tasks at the same time. When
starting up a task that requires heavy use of the GPU, ensure that no other
tasks are utilizing it by running 
<span class="publishername"><code class="calibre26">nvidia-smi</code></span>. However, if you are running a
graphical environment, you may have no choice but to have your desktop and GPU
code use the GPU at the same time.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="When to Use GPUs" class="calibre3"><div class="preface" id="idm46122415433368">
<h2 class="calibre43">When to Use GPUs</h2>

<p class="author1"><a data-type="indexterm" data-primary="GPUs (graphics processing units)" data-secondary="when to use" id="gpu_wtu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>We’ve seen that GPUs can be incredibly quick; however, memory considerations can
be quite devastating to this runtime. This seems to indicate that if your task requires mainly linear algebra and matrix manipulations (like multiplication,
addition, and Fourier transforms), then GPUs are a fantastic tool. This is
particularly true if the calculation can happen on the GPU uninterrupted for a
period of time before being copied back into system memory.</p>

<p class="author1">As an example of a task that requires a lot of branching, we can imagine code
where every step of the computation requires the previous result. If we compare running <a data-type="xref" href="#very-branching-no-gpu" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-20</a> using <a data-type="indexterm" data-primary="numpy" data-secondary="PyTorch versus" id="idm46122415385544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="PyTorch" id="idm46122415384568" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>PyTorch versus using NumPy, we see that NumPy is
consistently faster (98% faster for the included example!). This makes sense
given the architecture of the GPU. While the GPU can run many more tasks at once
than the CPU can, each of those tasks runs more slowly on the GPU than on the CPU. This
example task can run only one computation at a time, so having many compute
cores doesn’t help at all; it’s better to simply have one very fast core.</p>
<div id="very-branching-no-gpu" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-20. </span>Highly branching task</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code> <code class="nn">torch</code>

<code class="kn">def</code> <code class="nf">task</code><code class="p">(</code><code class="n">A</code><code class="p">,</code> <code class="n">target</code><code class="p">):</code>
    <code class="sd">"""</code>
<code class="sd">    Given an int array of length N with values from (0, N] and a target value,</code>
<code class="sd">    iterates through the array, using the current value to find the next array</code>
<code class="sd">    item to look at, until we have seen a total value of at least `target`.</code>
<code class="sd">    Returns how many iterations until the value was reached.</code>
<code class="sd">    """</code>
    <code class="n">result</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="n">i</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="n">N</code> <code class="o">=</code> <code class="mi">0</code>
    <code class="kn">while</code> <code class="n">result</code> <code class="o">&lt;</code> <code class="n">target</code><code class="p">:</code>
        <code class="n">r</code> <code class="o">=</code> <code class="n">A</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">result</code> <code class="o">+=</code> <code class="n">r</code>
        <code class="n">i</code> <code class="o">=</code> <code class="n">A</code><code class="p">[</code><code class="n">i</code><code class="p">]</code>
        <code class="n">N</code> <code class="o">+=</code> <code class="mi">1</code>
    <code class="kn">return</code> <code class="n">N</code>

<code class="kn">if</code> <code class="calibre26">__name__</code> <code class="o">==</code> <code class="s">"__main__"</code><code class="p">:</code>
    <code class="n">N</code> <code class="o">=</code> <code class="mi">1000</code>

    <code class="n">A_py</code> <code class="o">=</code> <code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">rand</code><code class="p">(</code><code class="n">N</code><code class="p">)</code> <code class="o">*</code> <code class="n">N</code><code class="p">)</code><code class="o">.</code><code class="n">type</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">int</code><code class="p">)</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="s">'cuda:0'</code><code class="p">)</code>
    <code class="n">A_np</code> <code class="o">=</code> <code class="n">A_py</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code>

    <code class="n">task</code><code class="p">(</code><code class="n">A_py</code><code class="p">,</code> <code class="mi">500</code><code class="p">)</code>
    <code class="n">task</code><code class="p">(</code><code class="n">A_np</code><code class="p">,</code> <code class="mi">500</code><code class="p">)</code></pre></div>

<p class="author1">In addition, because of the limited memory of the GPU, it is not a good tool for tasks that require
exceedingly large amounts of data, many conditional manipulations of the data, or
changing data. Most GPUs made for computational
tasks have around 12 GB of memory, which puts a significant limitation on “large
amounts of data.” However, as technology improves, the size of GPU memory
increases, so hopefully this limitation becomes less drastic in the future.</p>

<p class="author1">The general recipe for evaluating whether to use the GPU consists of the following steps:</p>
<ol class="calibre4">
<li class="calibre5">
<p class="calibre27">Ensure that the memory use of the problem will fit within the GPU (in
<a data-type="xref" href="ch02.xhtml#memory_profiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Using memory_profiler to Diagnose Memory Usage”</a>, we explore profiling memory use).</p>
</li>
<li class="calibre5">
<p class="calibre27">Evaluate whether the algorithm requires a lot of branching conditions versus
vectorized operations. As a rule of thumb, <code class="calibre26">numpy</code> functions generally vectorize
very well, so if your algorithm can be written in terms of <code class="calibre26">numpy</code> calls, your
code probably will vectorize well! You can also check the <code class="calibre26">branches</code> result
when running <code class="calibre26">perf</code> (as explained in <a data-type="xref" href="ch06_split_000.xhtml#understanding_perf" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Understanding perf”</a>).</p>
</li>
<li class="calibre5">
<p class="calibre27">Evaluate how much data needs to be moved between the GPU and the CPU.
Some questions to ask here are “How much computation can I do before I need to
plot/save results?” and “Are there times my code will have to copy the data to
run in a library I know isn’t GPU-compatible?”</p>
</li>
<li class="calibre5">
<p class="calibre27">Make sure PyTorch supports the operations you’d like to do! PyTorch
implements a large portion of the <code class="calibre26">numpy</code> API, so this shouldn’t be an issue. For
the most part, the API is even the same, so you don’t need to change your code at
all. However, in some cases either PyTorch doesn’t support an operation
(such as dealing with complex numbers) or the API is slightly different (for
example, with generating random numbers).</p>
</li>

</ol>

<p class="author1">Considering these four points will help give you confidence that a GPU approach
would be worthwhile. There are no hard rules for when the GPU will work better
than the CPU, but these questions will help you gain some intuition. However,
PyTorch also makes converting code to use the GPU painless, so the barrier to
entry is quite low, even if you are just evaluating the GPU’s performance.<a data-type="indexterm" data-primary="" data-startref="gpu_wtu" id="idm46122415236264" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Foreign Function Interfaces" class="calibre3"><div class="preface" id="idm46122415235160">
<h1 class="calibre25">Foreign Function Interfaces</h1>

<p class="author1"><a data-type="indexterm" data-primary="compiling to C" data-secondary="foreign function interfaces" id="cc_ffi" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="foreign function interfaces" id="ffi_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Sometimes the automatic solutions just don’t cut it, and you need to write
custom C or Fortran code yourself. This could be because the compilation
methods don’t find some potential optimizations, or because you want to take
advantage of libraries or language features that aren’t available in Python.  In
all of these cases, you’ll need to use foreign function interfaces, which give
you access to code written and compiled in another language.</p>

<p class="author1">For the rest of this chapter, we will attempt to use an external library to
solve the 2D diffusion equation in the same way we did in
<a data-type="xref" href="ch06_split_000.xhtml#matrix_computation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Chapter 6</a>.<sup class="calibre44"><a data-type="noteref" id="idm46122415229448-marker" href="ch07.xhtml#idm46122415229448" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">6</a></sup> The code for this library, shown in <a data-type="xref" href="#c_diffusion_2d" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-21</a>, could be
representative of a library you’ve installed or code that you have written.
The methods we’ll look at serve as great ways to take small parts of your code
and move them to another language in order to do very targeted language-based
optimizations.</p>
<div id="c_diffusion_2d" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-21. </span>Sample C code for solving the 2D diffusion problem</h5>

<pre data-type="programlisting" data-code-language="c" class="calibre59"><code class="kt">void</code> <code class="nf">evolve</code><code class="p">(</code><code class="kt">double</code> <code class="n">in</code><code class="p">[][</code><code class="mi">512</code><code class="p">],</code> <code class="kt">double</code> <code class="n">out</code><code class="p">[][</code><code class="mi">512</code><code class="p">],</code> <code class="kt">double</code> <code class="n">D</code><code class="p">,</code> <code class="kt">double</code> <code class="n">dt</code><code class="p">)</code> <code class="p">{</code>
    <code class="kt">int</code> <code class="n">i</code><code class="p">,</code> <code class="n">j</code><code class="p">;</code>
    <code class="kt">double</code> <code class="n">laplacian</code><code class="p">;</code>
    <code class="kn">for</code> <code class="p">(</code><code class="n">i</code><code class="o">=</code><code class="mi">1</code><code class="p">;</code> <code class="n">i</code><code class="o">&lt;</code><code class="mi">511</code><code class="p">;</code> <code class="n">i</code><code class="o">++</code><code class="p">)</code> <code class="p">{</code>
        <code class="kn">for</code> <code class="p">(</code><code class="n">j</code><code class="o">=</code><code class="mi">1</code><code class="p">;</code> <code class="n">j</code><code class="o">&lt;</code><code class="mi">511</code><code class="p">;</code> <code class="n">j</code><code class="o">++</code><code class="p">)</code> <code class="p">{</code>
            <code class="n">laplacian</code> <code class="o">=</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="o">-</code><code class="mi">1</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="o">+</code><code class="mi">1</code><code class="p">]</code> <code class="o">+</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> \
                        <code class="o">-</code> <code class="mi">4</code> <code class="o">*</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">];</code>
            <code class="n">out</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">=</code> <code class="n">in</code><code class="p">[</code><code class="n">i</code><code class="p">][</code><code class="n">j</code><code class="p">]</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="n">dt</code> <code class="o">*</code> <code class="n">laplacian</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre></div>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">We fix the grid size to be 512 × 512 in order to simplify the example code. To accept an arbitrarily sized grid, you must pass in the <code class="calibre26">in</code> and <code class="calibre26">out</code>
parameters as double pointers and include function arguments for the actual
size of the grid.</p>
</div>

<p class="author1">To use this code, we must compile it into a shared module that
creates a <em class="hyperlink">.so</em> file.  We can do this using <code class="calibre26">gcc</code> (or any other C compiler) by
following these steps:</p>

<pre data-type="programlisting" class="calibre50">$ gcc -O3 -std=gnu11 -c diffusion.c
$ gcc -shared -o diffusion.so diffusion.o</pre>

<p class="author1">We can place this final shared library file anywhere
that is accessible to our Python code, but standard *nix organization stores
shared libraries in <em class="hyperlink">/usr/lib</em> and <em class="hyperlink">/usr/local/lib</em>.</p>








<section data-type="sect2" data-pdf-bookmark="ctypes" class="calibre3"><div class="preface" id="idm46122415069160">
<h2 class="calibre43">ctypes</h2>

<p class="author1"><a data-type="indexterm" data-primary="ctypes" id="ct_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="foreign function interfaces" data-secondary="ctypes" id="ffi_ct" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>The
most basic foreign function interface in CPython is through the <code class="calibre26">ctypes</code> module.<sup class="calibre44"><a data-type="noteref" id="idm46122415064632-marker" href="ch07.xhtml#idm46122415064632" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">7</a></sup> The bare-bones nature of this module can be quite inhibitive at times—you are in
charge of doing everything, and it can take quite a while to make sure that you
have everything in order. This extra level of complexity is evident in our
<code class="calibre26">ctypes</code> diffusion code, shown in <a data-type="xref" href="#ctypes_2D_diffusion_code" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-22</a>.</p>
<div id="ctypes_2D_diffusion_code" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-22. </span><code class="calibre26">ctypes</code> 2D diffusion code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">import</code><code class="calibre26"> </code><code class="nn">ctypes</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">grid_shape</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">(</code><code class="mi">512</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">512</code><code class="p">)</code><code class="calibre26">
</code><code class="n">_diffusion</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ctypes</code><code class="o">.</code><code class="n">CDLL</code><code class="p">(</code><code class="s">"</code><code class="s">diffusion.so</code><code class="s">"</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO1-1" href="#callout_compiling_to_c_CO1-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">
</code><code class="c"># Create references to the C types that we will need to simplify future code</code><code class="calibre26">
</code><code class="n">TYPE_INT</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ctypes</code><code class="o">.</code><code class="n">c_int</code><code class="calibre26">
</code><code class="n">TYPE_DOUBLE</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ctypes</code><code class="o">.</code><code class="n">c_double</code><code class="calibre26">
</code><code class="n">TYPE_DOUBLE_SS</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ctypes</code><code class="o">.</code><code class="n">POINTER</code><code class="p">(</code><code class="n">ctypes</code><code class="o">.</code><code class="n">POINTER</code><code class="p">(</code><code class="n">ctypes</code><code class="o">.</code><code class="n">c_double</code><code class="p">)</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="c"># Initialize the signature of the evolve function to:</code><code class="calibre26">
</code><code class="c"># void evolve(int, int, double**, double**, double, double)</code><code class="calibre26">
</code><code class="n">_diffusion</code><code class="o">.</code><code class="n">evolve</code><code class="o">.</code><code class="n">argtypes</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">[</code><code class="n">TYPE_DOUBLE_SS</code><code class="p">,</code><code class="calibre26"> </code><code class="n">TYPE_DOUBLE_SS</code><code class="p">,</code><code class="calibre26"> </code><code class="n">TYPE_DOUBLE</code><code class="p">,</code><code class="calibre26">
</code><code class="calibre26">                              </code><code class="n">TYPE_DOUBLE</code><code class="p">]</code><code class="calibre26">
</code><code class="n">_diffusion</code><code class="o">.</code><code class="n">evolve</code><code class="o">.</code><code class="n">restype</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="nb">None</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1.0</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># First we convert the Python types into the relevant C types</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">assert</code><code class="calibre26"> </code><code class="n">grid</code><code class="o">.</code><code class="n">shape</code><code class="calibre26"> </code><code class="o">==</code><code class="calibre26"> </code><code class="p">(</code><code class="mi">512</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">512</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">cdt</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">TYPE_DOUBLE</code><code class="p">(</code><code class="n">dt</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">cD</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">TYPE_DOUBLE</code><code class="p">(</code><code class="n">D</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">pointer_grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">grid</code><code class="o">.</code><code class="n">ctypes</code><code class="o">.</code><code class="n">data_as</code><code class="p">(</code><code class="n">TYPE_DOUBLE_SS</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO1-2" href="#callout_compiling_to_c_CO1-2"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">pointer_out</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">out</code><code class="o">.</code><code class="n">ctypes</code><code class="o">.</code><code class="n">data_as</code><code class="p">(</code><code class="n">TYPE_DOUBLE_SS</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="c"># Now we can call the function</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">_diffusion</code><code class="o">.</code><code class="n">evolve</code><code class="p">(</code><code class="n">pointer_grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">pointer_out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">cD</code><code class="p">,</code><code class="calibre26"> </code><code class="n">cdt</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO1-3" href="#callout_compiling_to_c_CO1-3"><img src="Images/3.png" alt="3" class="calibre74"/></a></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO1-1" href="#co_compiling_to_c_CO1-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">This is similar to importing the <code class="calibre26">diffusion.so</code> library. Either this file is in one of the standard system paths for library files or we can enter an absolute path.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO1-2" href="#co_compiling_to_c_CO1-2"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76"><code class="calibre26">grid</code> and <code class="calibre26">out</code> are both <code class="calibre26">numpy</code> arrays.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO1-3" href="#co_compiling_to_c_CO1-3"><img src="Images/3.png" alt="3" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">We finally have all the setup necessary and can call the C function directly.</p></dd>
</dl></div>

<p class="author1">This first thing we do is “import” our shared library.  This is done with
the <code class="calibre26">ctypes.CDLL</code> call.  In this line, we can specify any shared library that
Python can access (for example, the <code class="calibre26">ctypes-opencv</code> module loads the <code class="calibre26">libcv.so</code>
library).  From this, we get a <a data-type="indexterm" data-primary="diffusion object" id="idm46122414855544" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">_diffusion</code> object that contains all the members
that the shared library contains.  In this example, <code class="calibre26">diffusion.so</code> contains only
one function,<a data-type="indexterm" data-primary="evolve function" id="idm46122414853880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">evolve</code>, which is now made available to us as a property of the
<code class="calibre26">_diffusion</code> object.  If <code class="calibre26">diffusion.so</code> had many functions and properties, we
could access them all through the <code class="calibre26">_diffusion</code> object.</p>

<p class="author1">However, even though the <code class="calibre26">_diffusion</code> object has the <code class="calibre26">evolve</code> function
available within it, Python doesn’t know how to use it.  C is statically typed,
and the function has a very specific signature.  To properly work with
the <code class="calibre26">evolve</code> function, we must explicitly set the input argument types and the
return type.  This can become quite tedious when developing libraries in tandem
with the Python interface, or when dealing with a quickly changing library.
Furthermore, since <code class="calibre26">ctypes</code> can’t check if you have given it the correct types, your code may silently fail or segfault if you make a mistake!</p>

<p class="author1">Furthermore, in addition to setting the arguments and return type of the
function object, we also need to convert any data we care to use with it (this
is called<a data-type="indexterm" data-primary="casting" id="idm46122414848104" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <em class="hyperlink">casting</em>).  Every argument we send to the function must be carefully
casted into a native C type.  Sometimes this can get quite tricky, since
Python is very relaxed about its variable types.  For example, if we had <code class="calibre26">num1 =
1e5</code>, we would have to know that this is a Python <code class="calibre26">float</code>, and thus we should use a
<code class="calibre26">ctype.c_float</code>.  On the other hand, for <code class="calibre26">num2 = 1e300</code>, we would have to use
<code class="calibre26">ctype.c_double</code>, because it would overflow a standard C <code class="calibre26">float</code>.</p>

<p class="author1">That being said, <code class="calibre26">numpy</code> provides a <code class="calibre26">.ctypes</code> property to its arrays that
makes it easily compatible with <code class="calibre26">ctypes</code>.  If <code class="calibre26">numpy</code> didn’t provide this
functionality, we would have had to initialize a <code class="calibre26">ctypes</code> array of the correct
type and then find the location of our original data and have our new <code class="calibre26">ctypes</code>
object point there.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">Unless the object you are turning into a <code class="calibre26">ctype</code> object implements a buffer<a data-type="indexterm" data-primary="array module" id="idm46122414839096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
(as do the <code class="calibre26">array</code> module, <code class="calibre26">numpy</code> arrays, <code class="calibre26">io.StringIO</code>, etc.), your data will
be copied into the new object.  In the case of casting an <code class="calibre26">int</code> to a <code class="calibre26">float</code>, this
doesn’t mean much for the performance of your code.  However, if you are casting
a very long Python list, this can incur quite a penalty!  In these cases,
using the <code class="calibre26">array</code> module or a <code class="calibre26">numpy</code> array, or even building up your own buffered
object using the <code class="calibre26">struct</code> module, would help.  This does, however, hurt
the readability of your code, since these objects are generally less flexible than
their native Python counterparts.</p>
</div>

<p class="author1">This memory management can get even more complicated if you have to send the
library a complicated data structure.  For example, if your library expects a C
<code class="calibre26">struct</code> representing a point in space with the properties <code class="calibre26">x</code> and <code class="calibre26">y</code>, you
would have to define the following:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code> <code class="nn">ctypes</code> <code class="kn">import</code> <code class="n">Structure</code>

<code class="kn">class</code> <code class="nc">cPoint</code><code class="p">(</code><code class="n">Structure</code><code class="p">):</code>
    <code class="n">_fields_</code> <code class="o">=</code> <code class="p">(</code><code class="s">"x"</code><code class="p">,</code> <code class="n">c_int</code><code class="p">),</code> <code class="p">(</code><code class="s">"y"</code><code class="p">,</code> <code class="n">c_int</code><code class="p">)</code></pre>

<p class="author1">At this point you could start creating C-compatible objects by initializing a
<a data-type="indexterm" data-primary="cPoint object" id="idm46122414799880" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">cPoint</code> object (i.e., <code class="calibre26">point = cPoint(10, 5)</code>).  This isn’t a terrible amount of
work, but it can become tedious and results in some fragile code.  What happens
if a new version of the library is released that slightly changes the structure?
This will make your code very hard to maintain and generally results in
stagnant code, where the developers simply decide never to upgrade the underlying
libraries that are being used.</p>

<p class="author1">For these reasons, using the <code class="calibre26">ctypes</code> module is great if you already have a good
understanding of C and want to be able to tune every aspect of the interface.
It has great portability since it is part of the standard library, and if your
task is simple, it provides simple solutions. Just be careful because the
complexity of <code class="calibre26">ctypes</code> solutions (and similar low-level solutions) quickly becomes unmanageable.<a data-type="indexterm" data-primary="" data-startref="ct_ab" id="idm46122414796552" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ffi_ct" id="idm46122414795576" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="cffi" class="calibre3"><div class="preface" id="idm46122415068504">
<h2 class="calibre43">cffi</h2>

<p class="author1"><a data-type="indexterm" data-primary="cffi" id="cffi_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="foreign function interfaces" data-secondary="cffi" id="ffi_cffi" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Realizing that <code class="calibre26">ctypes</code> can be quite cumbersome to use at times, <code class="calibre26">cffi</code> attempts
to simplify many of the standard operations that programmers use.  It does this
by having an internal C parser that can understand function and structure
definitions.</p>

<p class="author1">As a result, we can simply write the C code that defines the structure of the
library we wish to use, and then <code class="calibre26">cffi</code> will do all the heavy work for us: it
imports the module and makes sure we specify the correct types to the resulting
functions.  In fact, this work can be almost trivial if the source for the
library is available, since the header files (the files ending in <em class="hyperlink">.h</em>) will include all the relevant definitions we need.<sup class="calibre44"><a data-type="noteref" id="idm46122414779272-marker" href="ch07.xhtml#idm46122414779272" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">8</a></sup>
<a data-type="xref" href="#cffi_2D_diffusion_code" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-23</a> shows the <code class="calibre26">cffi</code> version of the 2D diffusion code.</p>
<div id="cffi_2D_diffusion_code" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-23. </span><code class="calibre26">cffi</code> 2D diffusion code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="kn">from</code><code class="calibre26"> </code><code class="nn">cffi</code><code class="calibre26"> </code><code class="kn">import</code><code class="calibre26"> </code><code class="n">FFI</code><code class="p">,</code><code class="calibre26"> </code><code class="n">verifier</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">grid_shape</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="p">(</code><code class="mi">512</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">512</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="n">ffi</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">FFI</code><code class="p">(</code><code class="p">)</code><code class="calibre26">
</code><code class="n">ffi</code><code class="o">.</code><code class="n">cdef</code><code class="p">(</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="s">"</code><code class="s">void evolve(double **in, double **out, double D, double dt);</code><code class="s">"</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO2-1" href="#callout_compiling_to_c_CO2-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="p">)</code><code class="calibre26">
</code><code class="n">lib</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ffi</code><code class="o">.</code><code class="n">dlopen</code><code class="p">(</code><code class="s">"</code><code class="s">../diffusion.so</code><code class="s">"</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="o">=</code><code class="mi">1.0</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">pointer_grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ffi</code><code class="o">.</code><code class="n">cast</code><code class="p">(</code><code class="s">"</code><code class="s">double**</code><code class="s">"</code><code class="p">,</code><code class="calibre26"> </code><code class="n">grid</code><code class="o">.</code><code class="n">ctypes</code><code class="o">.</code><code class="n">data</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO2-2" href="#callout_compiling_to_c_CO2-2"><img src="Images/2.png" alt="2" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">pointer_out</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ffi</code><code class="o">.</code><code class="n">cast</code><code class="p">(</code><code class="s">"</code><code class="s">double**</code><code class="s">"</code><code class="p">,</code><code class="calibre26"> </code><code class="n">out</code><code class="o">.</code><code class="n">ctypes</code><code class="o">.</code><code class="n">data</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">lib</code><code class="o">.</code><code class="n">evolve</code><code class="p">(</code><code class="n">pointer_grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">pointer_out</code><code class="p">,</code><code class="calibre26"> </code><code class="n">D</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dt</code><code class="p">)</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO2-1" href="#co_compiling_to_c_CO2-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">The contents of this definition can normally be acquired from the manual of the library that you are using or by looking at the library’s header files.</p></dd>
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO2-2" href="#co_compiling_to_c_CO2-2"><img src="Images/2.png" alt="2" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">While we still need to cast nonnative Python objects for use with our C module, the syntax is very familiar to those with experience in C.</p></dd>
</dl></div>

<p class="author1">In the preceding code, we can think of the <code class="calibre26">cffi</code> initialization as being
two-stepped.  First, we create an <code class="calibre26">FFI</code> object and give it all the global C
declarations we need.  This can include datatypes in addition to function
signatures.  These signatures don’t necessarily contain any code; they simply
need to define what the code will look like. Then we can import a shared
library containing the actual implementation of the functions by using <code class="calibre26">dlopen</code>.
This means we could have told <code class="calibre26">FFI</code> about the function signature for the
<code class="calibre26">evolve</code> function and then loaded up two different implantations and stored
them in different objects (which is fantastic for debugging and profiling!).</p>

<p class="author1">In addition to easily importing a shared C library, <code class="calibre26">cffi</code> allows you to write C
code and have it be dynamically compiled using the <a data-type="indexterm" data-primary="verify function" id="idm46122414540120" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><code class="calibre26">verify</code> function.  This has
many immediate benefits—for example, you can easily rewrite small portions of your code to be
in C without invoking the large machinery of a separate C library.
Alternatively, if there is a library you wish to use, but some glue code in C is
required to have the interface work perfectly, you can inline it into
your <code class="calibre26">cffi</code> code, as shown in <a data-type="xref" href="#cffi_with_inline_2D_diffusion_code" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-24</a>, to have
everything be in a centralized location.  In addition, since the code is being
dynamically compiled, you can specify compile instructions to every chunk of
code you need to compile.  Note, however, that this compilation has a one-time
penalty every time the <code class="calibre26">verify</code> function is run to actually perform the

<span class="publishername">compilation</span>.</p>
<div id="cffi_with_inline_2D_diffusion_code" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-24. </span><code class="calibre26">cffi</code> with inline 2D diffusion code</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="n">ffi</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">FFI</code><code class="p">(</code><code class="p">)</code><code class="calibre26">
</code><code class="n">ffi</code><code class="o">.</code><code class="n">cdef</code><code class="p">(</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="s">"</code><code class="s">void evolve(double **in, double **out, double D, double dt);</code><code class="s">"</code><code class="calibre26">
</code><code class="p">)</code><code class="calibre26">
</code><code class="n">lib</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">ffi</code><code class="o">.</code><code class="n">verify</code><code class="p">(</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="calibre26">r</code><code class="sd">"""
void evolve(double in[][512], double out[][512], double D, double dt) {
    int i, j;
    double laplacian;
    for (i=1; i&lt;511; i++) {
        for (j=1; j&lt;511; j++) {
            laplacian = in[i+1][j] + in[i-1][j] + in[i][j+1] + in[i][j-1] \
                        - 4 * in[i][j];
            out[i][j] = in[i][j] + D * dt * laplacian;
        }
    }
}
"""</code><code class="p">,</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">extra_compile_args</code><code class="o">=</code><code class="p">[</code><code class="s">"</code><code class="s">-O3</code><code class="s">"</code><code class="p">]</code><code class="p">,</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO3-1" href="#callout_compiling_to_c_CO3-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="p">)</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO3-1" href="#co_compiling_to_c_CO3-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">Since we are just-in-time compiling this code, we can also provide relevant compilation flags.</p></dd>
</dl></div>

<p class="author1">Another benefit of the <code class="calibre26">verify</code> functionality is that it plays nicely with
complicated <code class="calibre26">cdef</code> statements.  For example, if we were using a library with a complicated <span class="publishername">structure</span> but wanted to use only a part of it, we could use the partial struct definition.  To do
this, we add a <code class="calibre26">...</code> in the struct definition in <code class="calibre26">ffi.cdef</code> and <code class="calibre26">#include</code> the
relevant header file in a later <code class="calibre26">verify</code>.</p>

<p class="author1">For example, suppose we were working with a library with header <code class="calibre26">complicated.h</code> that
included a structure that looked like this:</p>

<pre data-type="programlisting" data-code-language="c" class="calibre50"><code class="kn">struct</code> <code class="n">Point</code> <code class="p">{</code>
    <code class="kt">double</code> <code class="n">x</code><code class="p">;</code>
    <code class="kt">double</code> <code class="n">y</code><code class="p">;</code>
    <code class="kt">bool</code> <code class="n">isActive</code><code class="p">;</code>
    <code class="kt">char</code> <code class="o">*</code><code class="n">id</code><code class="p">;</code>
    <code class="kt">int</code> <code class="n">num_times_visited</code><code class="p">;</code>
<code class="p">}</code></pre>

<p class="author1">If we cared only about the <code class="calibre26">x</code> and <code class="calibre26">y</code> properties, we could write some simple
<code class="calibre26">cffi</code> code that cares only about those values:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code> <code class="nn">cffi</code> <code class="kn">import</code> <code class="n">FFI</code>

<code class="n">ffi</code> <code class="o">=</code> <code class="n">FFI</code><code class="p">()</code>
<code class="n">ffi</code><code class="o">.</code><code class="n">cdef</code><code class="p">(</code><code class="calibre26">r</code><code class="s">"""</code>
<code class="s">    struct Point {</code>
<code class="s">        double x;</code>
<code class="s">        double y;</code>
<code class="s">        ...;</code>
<code class="s">    };</code>
<code class="s">    struct Point do_calculation();</code>
<code class="s">"""</code><code class="p">)</code>
<code class="n">lib</code> <code class="o">=</code> <code class="n">ffi</code><code class="o">.</code><code class="n">verify</code><code class="p">(</code><code class="calibre26">r</code><code class="s">"""</code>
<code class="s">    #include &lt;complicated.h&gt;</code>
<code class="s">"""</code><code class="p">)</code></pre>

<p class="author1">We could then run the<a data-type="indexterm" data-primary="do_calculation function" id="idm46122414467432" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">do_calculation</code> function from the <code class="calibre26">complicated.h</code> library
and have returned to us a<a data-type="indexterm" data-primary="Point object" id="idm46122414316920" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">Point</code> object with its <code class="calibre26">x</code> and <code class="calibre26">y</code> properties
accessible.  This is amazing for portability, since this code will run just fine
on systems with a different implementation of <code class="calibre26">Point</code> or when new versions of
<code class="calibre26">complicated.h</code> come out, as long as they all have the <code class="calibre26">x</code> and <code class="calibre26">y</code> properties.</p>

<p class="author1">All of these niceties really make <code class="calibre26">cffi</code> an amazing tool to have when you’re working
with C code in Python.  It is much simpler than <code class="calibre26">ctypes</code>, while still giving you
the same amount of fine-grained control you may want when working directly with
a foreign function interface.<a data-type="indexterm" data-primary="" data-startref="cffi_ab" id="idm46122414311672" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ffi_cffi" id="idm46122414310696" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="f2py" class="calibre3"><div class="preface" id="idm46122414794040">
<h2 class="calibre43">f2py</h2>

<p class="author1"><a data-type="indexterm" data-primary="f2py" id="fpy_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="foreign function interfaces" data-secondary="f2py" id="ffi_fpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="Fortran" id="fort_ab" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>For many scientific applications, Fortran
is still the gold standard. While its days of being a general-purpose language
are over, it still has many niceties that make vector operations easy to write
and quite quick.  In addition, many performance math libraries are written
in Fortran <a data-type="indexterm" data-primary="Basic Linear Algebra Subprograms (BLAS)" id="idm46122414304424" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="BLAS (Basic Linear Algebra Subprograms)" id="idm46122414303736" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="LAPACK library" id="idm46122414303048" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>(<a href="https://oreil.ly/WwULF" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">LAPACK</a>,
<a href="https://oreil.ly/9-pR7" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">BLAS</a>, etc.), all of which are fundamental in
libraries such as SciPy, and being able to use them in your performance Python
code may be critical.</p>

<p class="author1">For such situations, <a href="https://oreil.ly/h5cwN" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><code class="calibre26">f2py</code></a>
provides a dead-simple way of importing Fortran code into Python.  This module
is able to be so simple because of the explicitness of types in Fortran.  Since
the types can be easily parsed and understood, <code class="calibre26">f2py</code> can easily make a CPython
module that uses the native foreign function support within C to use the Fortran
code.  This means that when you are using <code class="calibre26">f2py</code>, you are actually
autogenerating a C module that knows how to use Fortran code!  As a
result, a lot of the confusion inherent in the <code class="calibre26">ctypes</code> and <code class="calibre26">cffi</code>
solutions simply doesn’t exist.</p>

<p class="author1">In <a data-type="xref" href="#f2py_diffusion" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-25</a>, we can see some simple <code class="calibre26">f2py</code>-compatible code for solving
the diffusion equation.  In fact, all native Fortran code is <code class="calibre26">f2py</code>-compatible;
however, the annotations to the function arguments (the statements prefaced by
<code class="calibre26">!f2py</code>) simplify the resulting Python module and make for an easier-to-use
interface.  The annotations implicitly tell <code class="calibre26">f2py</code> whether we intend for an argument
to be only an output or only an input, or to be something we want to modify in place
or hidden completely.  The hidden type is particularly useful for the sizes of
vectors: while Fortran may need those numbers explicitly, our Python code
already has this information on hand.  When we set the type as “hidden,” <code class="calibre26">f2py</code>
can automatically fill those values for us, essentially keeping them hidden from
us in the final Python interface.</p>
<div id="f2py_diffusion" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-25. </span>Fortran 2D diffusion code with <code class="calibre26">f2py</code> annotations</h5>

<pre data-type="programlisting" data-code-language="fortran" class="calibre59"><code class="kn">SUBROUTINE </code><code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code><code class="p">,</code> <code class="n">D</code><code class="p">,</code> <code class="n">dt</code><code class="p">,</code> <code class="n">N</code><code class="p">,</code> <code class="n">M</code><code class="p">)</code>
    <code class="c2">!f2py threadsafe</code>
    <code class="c2">!f2py intent(in) grid</code>
    <code class="c2">!f2py intent(inplace) next_grid</code>
    <code class="c2">!f2py intent(in) D</code>
    <code class="c2">!f2py intent(in) dt</code>
    <code class="c2">!f2py intent(hide) N</code>
    <code class="c2">!f2py intent(hide) M</code>
    <code class="kt">INTEGER</code> <code class="kn">::</code> <code class="n">N</code><code class="p">,</code> <code class="n">M</code>
    <code class="kt">DOUBLE PRECISION</code><code class="p">,</code> <code class="kn">DIMENSION</code><code class="p">(</code><code class="n">N</code><code class="p">,</code><code class="n">M</code><code class="p">)</code> <code class="kn">::</code> <code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code>
    <code class="kt">DOUBLE PRECISION</code><code class="p">,</code> <code class="kn">DIMENSION</code><code class="p">(</code><code class="n">N</code><code class="o">-</code><code class="mi">2</code><code class="p">,</code> <code class="n">M</code><code class="o">-</code><code class="mi">2</code><code class="p">)</code> <code class="kn">::</code> <code class="n">laplacian</code>
    <code class="kt">DOUBLE PRECISION</code> <code class="kn">::</code> <code class="n">D</code><code class="p">,</code> <code class="n">dt</code>

    <code class="n">laplacian</code> <code class="o">=</code> <code class="n">grid</code><code class="p">(</code><code class="mi">3</code><code class="p">:</code><code class="n">N</code><code class="p">,</code> <code class="mi">2</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="n">grid</code><code class="p">(</code><code class="mi">1</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">2</code><code class="p">,</code> <code class="mi">2</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="p">&amp;</code>
                <code class="n">grid</code><code class="p">(</code><code class="mi">2</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">3</code><code class="p">:</code><code class="n">M</code><code class="p">)</code> <code class="o">+</code> <code class="n">grid</code><code class="p">(</code><code class="mi">2</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">2</code><code class="p">)</code> <code class="o">-</code> <code class="mi">4</code> <code class="o">*</code> <code class="n">grid</code><code class="p">(</code><code class="mi">2</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code>
    <code class="n">next_grid</code><code class="p">(</code><code class="mi">2</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code> <code class="o">=</code> <code class="n">grid</code><code class="p">(</code><code class="mi">2</code><code class="p">:</code><code class="n">N</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">:</code><code class="n">M</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code> <code class="o">+</code> <code class="n">D</code> <code class="o">*</code> <code class="n">dt</code> <code class="o">*</code> <code class="n">laplacian</code>
<code class="kn">END SUBROUTINE </code><code class="n">evolve</code></pre></div>

<p class="author1">To build the code into a Python module, we run the following
command:</p>
<pre data-type="programlisting" class="calibre50">$ <strong class="calibre83">f2py -c -m diffusion --fcompiler=gfortran --opt='-O3' diffusion.f90</strong></pre>
<div data-type="tip" class="calibre35"><h6 class="calibre36">Tip</h6>
<p class="author1">We specifically use <code class="calibre26">gfortran</code> in the preceding call to <code class="calibre26">f2py</code>. Make sure it is
installed on your system or that you change the corresponding argument to use
the Fortran compiler you have installed.</p>
</div>

<p class="author1">This will create a library file pinned to your Python version and operating
system (<em class="hyperlink">diffusion.cpython-37m-x86_64-linux-gnu.so</em>, in our case) that can be
imported directly into Python.</p>

<p class="author1">If we play around with the resulting module interactively, we can see the
niceties that <code class="calibre26">f2py</code> has given us, thanks to our annotations and its ability to
parse the Fortran code:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="o">&gt;&gt;&gt;</code> <code class="kn">import</code> <code class="nn">diffusion</code>

<code class="o">&gt;&gt;&gt;</code> <code class="n">diffusion</code><code class="err">?</code>
<code class="n">Type</code><code class="p">:</code>        <code class="n">module</code>
<code class="n">String</code> <code class="n">form</code><code class="p">:</code> <code class="o">&lt;</code><code class="n">module</code> <code class="s">'diffusion'</code> <code class="kn">from</code> <code class="s">'[..]cpython-37m-x86_64-linux-gnu.so'</code><code class="o">&gt;</code>
<code class="n">File</code><code class="p">:</code>        <code class="p">[</code><code class="o">..</code><code class="n">cut</code><code class="o">..</code><code class="p">]</code><code class="o">/</code><code class="n">diffusion</code><code class="o">.</code><code class="n">cpython</code><code class="o">-</code><code class="mi">37</code><code class="n">m</code><code class="o">-</code><code class="n">x86_64</code><code class="o">-</code><code class="n">linux</code><code class="o">-</code><code class="n">gnu</code><code class="o">.</code><code class="n">so</code>
<code class="n">Docstring</code><code class="p">:</code>
<code class="n">This</code> <code class="n">module</code> <code class="s">'diffusion'</code> <code class="ow">is</code> <code class="n">auto</code><code class="o">-</code><code class="n">generated</code> <code class="kn">with</code> <code class="n">f2py</code> <code class="p">(</code><code class="n">version</code><code class="p">:</code><code class="mi">2</code><code class="p">)</code><code class="o">.</code>
<code class="n">Functions</code><code class="p">:</code>
  <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="n">scratch</code><code class="p">,</code><code class="n">d</code><code class="p">,</code><code class="n">dt</code><code class="p">)</code>
<code class="o">.</code>

<code class="o">&gt;&gt;&gt;</code> <code class="n">diffusion</code><code class="o">.</code><code class="n">evolve</code><code class="err">?</code>
<code class="n">Call</code> <code class="n">signature</code><code class="p">:</code> <code class="n">diffusion</code><code class="o">.</code><code class="n">evolve</code><code class="p">(</code><code class="o">*</code><code class="n">args</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
<code class="n">Type</code><code class="p">:</code>           <code class="n">fortran</code>
<code class="n">String</code> <code class="n">form</code><code class="p">:</code>    <code class="o">&lt;</code><code class="n">fortran</code> <code class="nb">object</code><code class="o">&gt;</code>
<code class="n">Docstring</code><code class="p">:</code>
<code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="n">scratch</code><code class="p">,</code><code class="n">d</code><code class="p">,</code><code class="n">dt</code><code class="p">)</code>

<code class="n">Wrapper</code> <code class="kn">for</code> <code class="s">``</code><code class="n">evolve</code><code class="s">``</code><code class="o">.</code>

<code class="n">Parameters</code>
<code class="n">grid</code> <code class="p">:</code> <code class="nb">input</code> <code class="n">rank</code><code class="o">-</code><code class="mi">2</code> <code class="n">array</code><code class="p">(</code><code class="s">'d'</code><code class="p">)</code> <code class="kn">with</code> <code class="n">bounds</code> <code class="p">(</code><code class="n">n</code><code class="p">,</code><code class="n">m</code><code class="p">)</code>
<code class="n">scratch</code> <code class="p">:</code>  <code class="n">rank</code><code class="o">-</code><code class="mi">2</code> <code class="n">array</code><code class="p">(</code><code class="s">'d'</code><code class="p">)</code> <code class="kn">with</code> <code class="n">bounds</code> <code class="p">(</code><code class="n">n</code><code class="p">,</code><code class="n">m</code><code class="p">)</code>
<code class="n">d</code> <code class="p">:</code> <code class="nb">input</code> <code class="nb">float</code>
<code class="n">dt</code> <code class="p">:</code> <code class="nb">input</code> <code class="nb">float</code></pre>

<p class="author1">This code shows that the result from the <code class="calibre26">f2py</code> generation is automatically
documented, and the interface is quite simplified.  For example, instead of us
having to extract the sizes of the vectors, <code class="calibre26">f2py</code> has figured out how to
automatically find this information and simply hides it in the resulting
interface.  In fact, the resulting<a data-type="indexterm" data-primary="evolve function" id="idm46122414020840" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/> <code class="calibre26">evolve</code> function looks exactly the same in
its signature as the pure Python version we wrote in <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>.</p>

<p class="author1">The only thing we must be careful of is the ordering of the <code class="calibre26">numpy</code> arrays in
memory.  Since most of what we do with <code class="calibre26">numpy</code> and Python focuses on code
derived from C, we always use the C convention for ordering data in memory<a data-type="indexterm" data-primary="column-major ordering" id="idm46122413873480" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="ordering, row-major versus column-major" id="idm46122413872776" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="row-major ordering" id="idm46122413872136" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>
(called <em class="hyperlink">row-major ordering</em>).  Fortran uses a different convention
(<em class="hyperlink">column-major ordering</em>) that we must make sure our vectors abide by.  These
orderings simply state whether, for a 2D array, columns or rows are contiguous
in memory.<sup class="calibre44"><a data-type="noteref" id="idm46122413870280-marker" href="ch07.xhtml#idm46122413870280" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">9</a></sup>  Luckily, this simply means we specify the <code class="calibre26">order='F'</code>
parameter to <code class="calibre26">numpy</code> when declaring our vectors.</p>
<div data-type="caution" class="calibre37"><h6 class="calibre38">Caution</h6>
<p class="author1">The difference in ordering basically changes which is the outer loop when
iterating over a multidimensional array. In Python and C, if you define an
array as <code class="calibre26">array[X][Y]</code>, your outer loop will be over <code class="calibre26">X</code> and your inner loop
will be over <code class="calibre26">Y</code>. In <code class="calibre26">fortran</code>, your outer loop will be over <code class="calibre26">Y</code> and your inner loop
will be over <code class="calibre26">X</code>. If you use the wrong loop ordering, you will at best suffer a
major performance penalty because of an increase in <code class="calibre26">cache-misses</code> (see
<a data-type="xref" href="ch06_split_000.xhtml#matrix_memory_fragmentation" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“Memory Fragmentation”</a>) and at worst access the wrong
data!</p>
</div>

<p class="author1">This results in the following code to use our Fortran subroutine.  This code
looks exactly the same as what we used in <a data-type="xref" href="ch06_split_000.xhtml#matrix_numpy_memory1" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 6-14</a>, except for
the import from the <code class="calibre26">f2py</code>-derived library and the explicit Fortran ordering of
our data:</p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code><code class="calibre26"> </code><code class="nn">diffusion</code><code class="calibre26"> </code><code class="kn">import</code><code class="calibre26"> </code><code class="n">evolve</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="kn">def</code><code class="calibre26"> </code><code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">scratch</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">double</code><code class="p">,</code><code class="calibre26"> </code><code class="n">order</code><code class="o">=</code><code class="s">"</code><code class="s">F</code><code class="s">"</code><code class="p">)</code><code class="calibre26">  </code><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="co_compiling_to_c_CO4-1" href="#callout_compiling_to_c_CO4-1"><img src="Images/1.png" alt="1" class="calibre74"/></a><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">grid</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">,</code><code class="calibre26"> </code><code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">double</code><code class="p">,</code><code class="calibre26"> </code><code class="n">order</code><code class="o">=</code><code class="s">"</code><code class="s">F</code><code class="s">"</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="n">initialize_grid</code><code class="p">(</code><code class="n">grid</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">
</code><code class="calibre26">    </code><code class="kn">for</code><code class="calibre26"> </code><code class="n">i</code><code class="calibre26"> </code><code class="ow">in</code><code class="calibre26"> </code><code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">)</code><code class="p">:</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">scratch</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">1.0</code><code class="p">,</code><code class="calibre26"> </code><code class="mi">0.1</code><code class="p">)</code><code class="calibre26">
</code><code class="calibre26">        </code><code class="n">grid</code><code class="p">,</code><code class="calibre26"> </code><code class="n">scratch</code><code class="calibre26"> </code><code class="o">=</code><code class="calibre26"> </code><code class="n">scratch</code><code class="p">,</code><code class="calibre26"> </code><code class="n">grid</code></pre>
<dl class="calibre28">
<dt class="calibre29"><a class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6" id="callout_compiling_to_c_CO4-1" href="#co_compiling_to_c_CO4-1"><img src="Images/1.png" alt="1" class="calibre74"/></a></dt>
<dd class="calibre75"><p class="calibre76">Fortran orders numbers differently in memory, so we must remember to set our <code class="calibre26">numpy</code> arrays to use that standard.<a data-type="indexterm" data-primary="" data-startref="fpy_ab" id="idm46122413631368" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ffi_fpy" id="idm46122413630392" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="fort_ab" id="idm46122413648120" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p></dd>
</dl>
</div></section>













<section data-type="sect2" data-pdf-bookmark="CPython Module" class="calibre3"><div class="preface" id="idm46122414309160">
<h2 class="calibre43">CPython Module</h2>

<p class="author1"><a data-type="indexterm" data-primary="CPython" data-secondary="module" id="cpy_mod" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="foreign function interfaces" data-secondary="CPython module" id="ffi_cpy" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/>Finally, we can always go right down to the CPython API level and write a
CPython module.  This requires us to write code in the same way that CPython is
developed and take care of all of the interactions between our code and
the implementation of CPython.</p>

<p class="author1">This has the advantage that it is incredibly portable, depending on the Python version.
We don’t require any external modules or libraries, just a C compiler and
Python!  However, this doesn’t necessarily scale well to new versions of Python.
For example, CPython modules written for Python 2.7 won’t work with Python 3, and
vice versa.</p>
<div data-type="note" epub:type="note" class="calibre35"><h6 class="calibre36">Note</h6>
<p class="author1">In fact, much of the slowdown in the Python 3 rollout was rooted in
the difficulty in making this change. When creating a CPython module, you are
coupled very closely to the actual Python implementation, and large changes in
the language (such as the change from 2.7 to 3) require large modifications to
your module.</p>
</div>

<p class="author1">That portability comes at a big cost, though—you are responsible for every
aspect of the interface between your Python code and the module.  This can make
even the simplest tasks take dozens of lines of code.  For example, to interface
with the diffusion library from <a data-type="xref" href="#c_diffusion_2d" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-21</a>, we must write 28 lines of
code simply to read the arguments to a function and parse them
(<a data-type="xref" href="#compiling_cpython_module" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-26</a>). Of course, this does mean that you have
incredibly fine-grained control over what is happening.  This goes all the way
down to being able to manually change the reference counts for Python’s garbage
collection (which can be the cause of a lot of pain when creating CPython
modules that deal with native Python types).  Because of this, the resulting
code tends to be minutely faster than other interface methods.</p>
<div data-type="warning" epub:type="warning" class="calibre37"><h6 class="calibre38">Warning</h6>
<p class="author1">All in all, this method should be left as a last resort.  While it is quite
informative to write a CPython module, the resulting code is not as reusable or
maintainable as other potential methods.  Making subtle changes in the module
can often require completely reworking it.  In fact, we include the
module code and the required <em class="hyperlink">setup.py</em> to compile it
(<a data-type="xref" href="#compiling_cpython_module_setup" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-27</a>) as a cautionary tale.</p>
</div>
<div id="compiling_cpython_module" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-26. </span>CPython module to interface to the 2D diffusion library</h5>

<pre data-type="programlisting" data-code-language="c" class="calibre59"><code class="c">// python_interface.c</code>
<code class="c">// - cpython module interface for diffusion.c</code>

<code class="cp1">#define NPY_NO_DEPRECATED_API    NPY_1_7_API_VERSION</code>

<code class="cp1">#include &lt;Python.h&gt;</code>
<code class="cp1">#include &lt;numpy/arrayobject.h&gt;</code>
<code class="cp1">#include "diffusion.h"</code>

<code class="c">/* Docstrings */</code>
<code class="kn">static</code> <code class="kt">char</code> <code class="n">module_docstring</code><code class="p">[]</code> <code class="o">=</code>
   <code class="s">"Provides optimized method to solve the diffusion equation"</code><code class="p">;</code>
<code class="kn">static</code> <code class="kt">char</code> <code class="n">cdiffusion_evolve_docstring</code><code class="p">[]</code> <code class="o">=</code>
   <code class="s">"Evolve a 2D grid using the diffusion equation"</code><code class="p">;</code>

<code class="n">PyArrayObject</code> <code class="o">*</code><code class="nf">py_evolve</code><code class="p">(</code><code class="n">PyObject</code> <code class="o">*</code><code class="p">,</code> <code class="n">PyObject</code> <code class="o">*</code><code class="p">);</code>

<code class="c">/* Module specification */</code>
<code class="kn">static</code> <code class="n">PyMethodDef</code> <code class="n">module_methods</code><code class="p">[]</code> <code class="o">=</code>
<code class="p">{</code>
   <code class="c">/* { method name , C function              , argument types , docstring       } */</code>
   <code class="p">{</code> <code class="s">"evolve"</code><code class="p">,</code> <code class="p">(</code><code class="n">PyCFunction</code><code class="p">)</code><code class="n">py_evolve</code><code class="p">,</code> <code class="n">METH_VARARGS</code><code class="p">,</code> <code class="n">cdiffusion_evolve_docstring</code> <code class="p">},</code>
   <code class="p">{</code> <code class="nb">NULL</code><code class="p">,</code>     <code class="nb">NULL</code><code class="p">,</code>                              <code class="mi">0</code><code class="p">,</code> <code class="nb">NULL</code>                        <code class="p">}</code>
<code class="p">};</code>

<code class="kn">static</code> <code class="kn">struct</code> <code class="n">PyModuleDef</code> <code class="n">cdiffusionmodule</code> <code class="o">=</code>
<code class="p">{</code>
   <code class="n">PyModuleDef_HEAD_INIT</code><code class="p">,</code>
   <code class="s">"cdiffusion"</code><code class="p">,</code>      <code class="c">/* name of module */</code>
   <code class="n">module_docstring</code><code class="p">,</code>  <code class="c">/* module documentation, may be NULL */</code>
   <code class="o">-</code><code class="mi">1</code><code class="p">,</code>                <code class="c">/* size of per-interpreter state of the module,</code>
<code class="c">                       * or -1 if the module keeps state in global variables. */</code>
   <code class="n">module_methods</code>
<code class="p">};</code>

<code class="n">PyArrayObject</code> <code class="o">*</code><code class="nf">py_evolve</code><code class="p">(</code><code class="n">PyObject</code> <code class="o">*</code><code class="n">self</code><code class="p">,</code> <code class="n">PyObject</code> <code class="o">*</code><code class="n">args</code><code class="p">)</code>
<code class="p">{</code>
   <code class="n">PyArrayObject</code> <code class="o">*</code><code class="n">data</code><code class="p">;</code>
   <code class="n">PyArrayObject</code> <code class="o">*</code><code class="n">next_grid</code><code class="p">;</code>
   <code class="kt">double</code>         <code class="n">dt</code><code class="p">,</code> <code class="n">D</code> <code class="o">=</code> <code class="mi">1.0</code><code class="p">;</code>

   <code class="c">/* The "evolve" function will have the signature:</code>
<code class="c">    *     evolve(data, next_grid, dt, D=1)</code>
<code class="c">    */</code>
   <code class="kn">if</code> <code class="p">(</code><code class="o">!</code><code class="n">PyArg_ParseTuple</code><code class="p">(</code><code class="n">args</code><code class="p">,</code> <code class="s">"OOd|d"</code><code class="p">,</code> <code class="o">&amp;</code><code class="n">data</code><code class="p">,</code> <code class="o">&amp;</code><code class="n">next_grid</code><code class="p">,</code> <code class="o">&amp;</code><code class="n">dt</code><code class="p">,</code> <code class="o">&amp;</code><code class="n">D</code><code class="p">))</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code> <code class="s">"Invalid arguments"</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>

   <code class="c">/* Make sure that the numpy arrays are contiguous in memory */</code>
   <code class="kn">if</code> <code class="p">(</code><code class="o">!</code><code class="n">PyArray_Check</code><code class="p">(</code><code class="n">data</code><code class="p">)</code> <code class="o">||</code> <code class="o">!</code><code class="n">PyArray_ISCONTIGUOUS</code><code class="p">(</code><code class="n">data</code><code class="p">))</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code> <code class="s">"data is not a contiguous array."</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>
   <code class="kn">if</code> <code class="p">(</code><code class="o">!</code><code class="n">PyArray_Check</code><code class="p">(</code><code class="n">next_grid</code><code class="p">)</code> <code class="o">||</code> <code class="o">!</code><code class="n">PyArray_ISCONTIGUOUS</code><code class="p">(</code><code class="n">next_grid</code><code class="p">))</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code> <code class="s">"next_grid is not a contiguous array."</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>

   <code class="c">/* Make sure that grid and next_grid are of the same type and have the same</code>
<code class="c">    * dimensions</code>
<code class="c">    */</code>
   <code class="kn">if</code> <code class="p">(</code><code class="n">PyArray_TYPE</code><code class="p">(</code><code class="n">data</code><code class="p">)</code> <code class="o">!=</code> <code class="n">PyArray_TYPE</code><code class="p">(</code><code class="n">next_grid</code><code class="p">))</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code>
                      <code class="s">"next_grid and data should have same type."</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>
   <code class="kn">if</code> <code class="p">(</code><code class="n">PyArray_NDIM</code><code class="p">(</code><code class="n">data</code><code class="p">)</code> <code class="o">!=</code> <code class="mi">2</code><code class="p">)</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code> <code class="s">"data should be two dimensional"</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>
   <code class="kn">if</code> <code class="p">(</code><code class="n">PyArray_NDIM</code><code class="p">(</code><code class="n">next_grid</code><code class="p">)</code> <code class="o">!=</code> <code class="mi">2</code><code class="p">)</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code> <code class="s">"next_grid should be two dimensional"</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>
   <code class="kn">if</code> <code class="p">((</code><code class="n">PyArray_DIM</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="mi">0</code><code class="p">)</code> <code class="o">!=</code> <code class="n">PyArray_DIM</code><code class="p">(</code><code class="n">next_grid</code><code class="p">,</code> <code class="mi">0</code><code class="p">))</code> <code class="o">||</code>
       <code class="p">(</code><code class="n">PyArray_DIM</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code> <code class="o">!=</code> <code class="n">PyArray_DIM</code><code class="p">(</code><code class="n">next_grid</code><code class="p">,</code> <code class="mi">1</code><code class="p">)))</code>
   <code class="p">{</code>
      <code class="n">PyErr_SetString</code><code class="p">(</code><code class="n">PyExc_RuntimeError</code><code class="p">,</code>
                      <code class="s">"data and next_grid must have the same dimensions"</code><code class="p">);</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>

   <code class="n">evolve</code><code class="p">(</code>
      <code class="n">PyArray_DATA</code><code class="p">(</code><code class="n">data</code><code class="p">),</code>
      <code class="n">PyArray_DATA</code><code class="p">(</code><code class="n">next_grid</code><code class="p">),</code>
      <code class="n">D</code><code class="p">,</code>
      <code class="n">dt</code>
      <code class="p">);</code>

   <code class="n">Py_XINCREF</code><code class="p">(</code><code class="n">next_grid</code><code class="p">);</code>
   <code class="kn">return</code><code class="p">(</code><code class="n">next_grid</code><code class="p">);</code>
<code class="p">}</code>

<code class="c">/* Initialize the module */</code>
<code class="n">PyMODINIT_FUNC</code>
<code class="nf">PyInit_cdiffusion</code><code class="p">(</code><code class="kt">void</code><code class="p">)</code>
<code class="p">{</code>
   <code class="n">PyObject</code> <code class="o">*</code><code class="n">m</code><code class="p">;</code>

   <code class="n">m</code> <code class="o">=</code> <code class="n">PyModule_Create</code><code class="p">(</code><code class="o">&amp;</code><code class="n">cdiffusionmodule</code><code class="p">);</code>
   <code class="kn">if</code> <code class="p">(</code><code class="n">m</code> <code class="o">==</code> <code class="nb">NULL</code><code class="p">)</code>
   <code class="p">{</code>
      <code class="kn">return</code><code class="p">(</code><code class="nb">NULL</code><code class="p">);</code>
   <code class="p">}</code>

   <code class="c">/* Load `numpy` functionality. */</code>
   <code class="n">import_array</code><code class="p">();</code>

   <code class="kn">return</code><code class="p">(</code><code class="n">m</code><code class="p">);</code>
<code class="p">}</code></pre></div>

<p class="author1">To build this code, we need to create a <em class="hyperlink">setup.py</em> script that
uses the <code class="calibre26">distutils</code> module to figure out how to build the code such that it is
Python-compatible (<a data-type="xref" href="#compiling_cpython_module_setup" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-27</a>).  In addition to the standard <code class="calibre26">distutils</code> module, <code class="calibre26">numpy</code>
provides its own module to help with adding <code class="calibre26">numpy</code> integration in your CPython
modules.</p>
<div id="compiling_cpython_module_setup" data-type="example" class="calibre56">
<h5 class="calibre58"><span class="publishername">Example 7-27. </span>Setup file for the CPython module diffusion interface</h5>

<pre data-type="programlisting" data-code-language="python" class="calibre59"><code class="sd">"""</code>
<code class="sd">setup.py for cpython diffusion module.  The extension can be built by running</code>

<code class="sd">    $ python setup.py build_ext --inplace</code>

<code class="sd">which will create the __cdiffusion.so__ file, which can be directly imported into</code>
<code class="sd">Python.</code>
<code class="sd">"""</code>

<code class="kn">from</code> <code class="nn">distutils.core</code> <code class="kn">import</code> <code class="n">setup</code><code class="p">,</code> <code class="n">Extension</code>
<code class="kn">import</code> <code class="nn">numpy.distutils.misc_util</code>

<code class="n">__version__</code> <code class="o">=</code> <code class="s">"0.1"</code>

<code class="n">cdiffusion</code> <code class="o">=</code> <code class="n">Extension</code><code class="p">(</code>
    <code class="s">'cdiffusion'</code><code class="p">,</code>
    <code class="n">sources</code> <code class="o">=</code> <code class="p">[</code><code class="s">'cdiffusion/cdiffusion.c'</code><code class="p">,</code> <code class="s">'cdiffusion/python_interface.c'</code><code class="p">],</code>
    <code class="n">extra_compile_args</code> <code class="o">=</code> <code class="p">[</code><code class="s">"-O3"</code><code class="p">,</code> <code class="s">"-std=c11"</code><code class="p">,</code> <code class="s">"-Wall"</code><code class="p">,</code> <code class="s">"-p"</code><code class="p">,</code> <code class="s">"-pg"</code><code class="p">,</code> <code class="p">],</code>
    <code class="n">extra_link_args</code> <code class="o">=</code> <code class="p">[</code><code class="s">"-lc"</code><code class="p">],</code>
<code class="p">)</code>

<code class="n">setup</code> <code class="p">(</code>
    <code class="n">name</code> <code class="o">=</code> <code class="s">'diffusion'</code><code class="p">,</code>
    <code class="n">version</code> <code class="o">=</code> <code class="n">__version__</code><code class="p">,</code>
    <code class="n">ext_modules</code> <code class="o">=</code> <code class="p">[</code><code class="n">cdiffusion</code><code class="p">,],</code>
    <code class="n">packages</code> <code class="o">=</code> <code class="p">[</code><code class="s">"diffusion"</code><code class="p">,</code> <code class="p">],</code>
    <code class="n">include_dirs</code> <code class="o">=</code> <code class="n">numpy</code><code class="o">.</code><code class="n">distutils</code><code class="o">.</code><code class="n">misc_util</code><code class="o">.</code><code class="n">get_numpy_include_dirs</code><code class="p">(),</code>
<code class="p">)</code></pre></div>

<p class="author1">The result from this is a <em class="hyperlink">cdiffusion.so</em> file that can be imported directly
from Python and used quite easily.  Since we had complete control over the
signature of the resulting function and exactly how our C code interacted with
the library, we were able to (with some hard work) create a module that is
easy to use:<a data-type="indexterm" data-primary="" data-startref="cc_ffi" id="idm46122413275848" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ffi_ab" id="idm46122413021096" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="cpy_mod" id="idm46122413020184" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/><a data-type="indexterm" data-primary="" data-startref="ffi_cpy" id="idm46122413019240" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>

<pre data-type="programlisting" data-code-language="python" class="calibre50"><code class="kn">from</code> <code class="nn">cdiffusion</code> <code class="kn">import</code> <code class="n">evolve</code>

<code class="kn">def</code> <code class="nf">run_experiment</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
    <code class="n">next_grid</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">double</code><code class="p">)</code>
    <code class="n">grid</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">zeros</code><code class="p">(</code><code class="n">grid_shape</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">double</code><code class="p">)</code>

    <code class="c"># ... standard initialization ...</code>

    <code class="kn">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">num_iterations</code><code class="p">):</code>
        <code class="n">evolve</code><code class="p">(</code><code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code><code class="p">,</code> <code class="mi">1.0</code><code class="p">,</code> <code class="mi">0.1</code><code class="p">)</code>
        <code class="n">grid</code><code class="p">,</code> <code class="n">next_grid</code> <code class="o">=</code> <code class="n">next_grid</code><code class="p">,</code> <code class="n">grid</code></pre>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Wrap-Up" class="calibre3"><div class="preface" id="idm46122413646424">
<h1 class="calibre25">Wrap-Up</h1>

<p class="author1">The various strategies introduced in this chapter allow you to specialize your
code to different degrees in order to reduce the number of instructions the CPU
must execute and to increase the efficiency of your programs.  Sometimes this can be
done algorithmically, although often it must be done manually
(see <a data-type="xref" href="#jit_vs_compiler" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">“JIT Versus AOT Compilers”</a>).  Furthermore, sometimes these methods must be employed
simply to use libraries that have already been written in other languages.
Regardless of the motivation, Python allows us to benefit from the speedups that
other languages can offer on some problems, while still maintaining
verbosity and flexibility when needed.</p>

<p class="author1">We also looked into how to use the GPU to use purpose-specific hardware
to solve problems faster than a CPU could alone. These devices are very
specialized and can have very different performance considerations than
classical high performance programming. However, we’ve seen that new libraries
like PyTorch make evaluating the GPU much simpler than it ever has been.</p>

<p class="author1">It is important to note, though, that these optimizations are done to
optimize the efficiency of compute instructions only.  If you have I/O-bound
processes coupled to a compute-bound problem, simply compiling your code may not
provide any reasonable speedups.  For these problems, we must rethink our
solutions and potentially use parallelism to run different tasks at the same time.<a data-type="indexterm" data-primary="" data-startref="cc_ch" id="idm46122412983720" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"/></p>
</div></section>







<div data-type="footnotes" class="calibre52"><p data-type="footnote" id="idm46122415613752" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415613752-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">1</a></sup> The RTX 2080 TI also includes 544 tensor cores specifically created to help with mathematical operations that are particularly useful for deep learning.</p><p data-type="footnote" id="idm46122415607560" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415607560-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">2</a></sup> For comparisons of the performance of TensorFlow and PyTorch, see <a href="https://oreil.ly/8NOJW" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">https://oreil.ly/8NOJW</em></a> and <a href="https://oreil.ly/4BKM5" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6"><em class="hyperlink">https://oreil.ly/4BKM5</em></a>.</p><p data-type="footnote" id="idm46122415458168" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415458168-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">3</a></sup> PyTorch CPU performance isn’t terribly great unless you install from source. When installing from source, optimized linear algebra libraries are used to give speeds comparable to NumPy.</p><p data-type="footnote" id="idm46122415455528" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415455528-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">4</a></sup> As with any JIT, the first time a function is called, it will have the overhead of having to compile the code. In <a data-type="xref" href="#compilation-diffusion-pytorch" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">Example 7-19</a>, we profile the functions multiple times and ignore the first time in order to measure only the runtime speeds.</p><p data-type="footnote" id="idm46122415396520" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415396520-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">5</a></sup> The <code class="calibre26">DataLoader</code> object also supports running with multiple workers. Having several workers is recommended if data is being loaded from disk in order to minimize I/O time.</p><p data-type="footnote" id="idm46122415229448" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415229448-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">6</a></sup> For simplicity, we will not implement the boundary conditions.</p><p data-type="footnote" id="idm46122415064632" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122415064632-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">7</a></sup> This is CPython-dependent. Other versions of Python may have their own versions of <code class="calibre26">ctypes</code>, which may work differently.</p><p data-type="footnote" id="idm46122414779272" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122414779272-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">8</a></sup> In Unix systems, header files for system libraries can be found in <em class="hyperlink">/usr/include</em>.</p><p data-type="footnote" id="idm46122413870280" class="calibre53"><sup class="calibre54"><a href="ch07.xhtml#idm46122413870280-marker" class="pcalibre2 pcalibre calibre45 pcalibre3 pcalibre1">9</a></sup> For more information, see <a href="http://bit.ly/row-major_order" class="pcalibre2 pcalibre pcalibre3 pcalibre1 calibre6">the Wikipedia page</a> on row-major and column-major ordering.</p></div></div></section></div>



  </body></html>