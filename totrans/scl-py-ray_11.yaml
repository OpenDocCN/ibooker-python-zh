- en: Chapter 10\. How Ray Powers Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now have a solid grasp of everything in Ray needed to get your data ready
    to train ML models. In this chapter, you will learn how to use the popular Ray
    libraries [scikit-learn](https://oreil.ly/2a56M), [XGBoost](https://oreil.ly/TAofd),
    and [PyTorch](https://oreil.ly/ziXhR). This chapter is not intended to introduce
    these libraries, so if you aren’t familiar with any of them, you should pick one
    (and we suggest scikit-learn) to read up on first. Even for those familiar with
    these libraries, refreshing your memory by consulting your favorite tools’ documentation
    will be beneficial. This chapter is about how Ray is used to power ML, rather
    than a tutorial on ML.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you are interested in going deeper into ML with Ray, [*Learning Ray*](https://oreil.ly/k5ItW)
    by Max Pumperla et al. (O’Reilly) is a full-length book focused on ML with Ray
    that can expand your ML skillset.
  prefs: []
  type: TYPE_NORMAL
- en: Ray has two built-in libraries for ML. You will learn how to use Ray’s reinforcement
    learning library, [RLlib](https://oreil.ly/3Rv0B), with TensorFlow and use generic
    hyperparameter tuning via [Tune](https://oreil.ly/9ISlc), which can be used with
    any ML library.
  prefs: []
  type: TYPE_NORMAL
- en: Using scikit-learn with Ray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: scikit-learn is one of the most widely used tools in the ML community, offering
    dozens of easy-to-use ML algorithms. It was initially developed by David Cournapeau
    as a Google Summer of Code project in 2007\. It provides a wide range of supervised
    and unsupervised learning algorithms via a consistent interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scikit-learn ML algorithms include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs: []
  type: TYPE_NORMAL
- en: For grouping unlabeled data such as k-means
  prefs: []
  type: TYPE_NORMAL
- en: Supervised models
  prefs: []
  type: TYPE_NORMAL
- en: Including generalized linear models, discriminant analysis, naive Bayes, lazy
    methods, neural networks, support vector machines, and decision trees
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble methods
  prefs: []
  type: TYPE_NORMAL
- en: For combining the predictions of multiple supervised models
  prefs: []
  type: TYPE_NORMAL
- en: 'scikit-learn also contains important tooling to support ML:'
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: For estimating the performance of supervised models on unseen data
  prefs: []
  type: TYPE_NORMAL
- en: Datasets
  prefs: []
  type: TYPE_NORMAL
- en: For test datasets and for generating datasets with specific properties for investigating
    model behavior
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction
  prefs: []
  type: TYPE_NORMAL
- en: For reducing the number of attributes in data for summarization, visualization,
    and feature selection such as principal component analysis
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs: []
  type: TYPE_NORMAL
- en: For defining attributes in image and text data
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection
  prefs: []
  type: TYPE_NORMAL
- en: For identifying meaningful attributes from which to create supervised models
  prefs: []
  type: TYPE_NORMAL
- en: Parameter tuning
  prefs: []
  type: TYPE_NORMAL
- en: For getting the most out of supervised models
  prefs: []
  type: TYPE_NORMAL
- en: Manifold learning
  prefs: []
  type: TYPE_NORMAL
- en: For summarizing and depicting complex multidimensional data
  prefs: []
  type: TYPE_NORMAL
- en: Although you can use most of the scikit-learn APIs directly with Ray for tuning
    the model’s hyperparameters, things get a bit more involved when you want to parallelize
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: If we take the basic code used for the creation of the model in [Chapter 7](ch07.html#ch07),
    and try to optimize parameters for the decision tree, our code will look like
    [Example 10-1](#skex).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-1\. [Using scikit-learn to build our wine-quality model](https://oreil.ly/z1KPe)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that here, in `GridSearchCV`, we are using the parameter `n_jobs=-1`, which
    instructs the implementation to run model evaluation in parallel using all available
    processors.^([1](ch10.html#idm45354765564752)) Running model evaluation in parallel,
    even on a single machine, can result in an order-of-magnitude performance improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this does not work out of the box with Ray clusters. `GridSearchCV`
    uses [Joblib](https://oreil.ly/s9x0Y) for parallel execution (as do many other
    scikit-learn algorithms). Joblib does not work with Ray out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Ray [implements a backend for Joblib](https://oreil.ly/80Dwb) with a Ray actors
    pool (see [Chapter 4](ch04.html#ch04)) instead of local processes. This allows
    you to simply change the Joblib backend to switch scikit-learn from using local
    processes to Ray.
  prefs: []
  type: TYPE_NORMAL
- en: Concretely, to make [Example 10-1](#skex) run using Ray, you need to register
    the Ray backend for Joblib and use it for the `GridSearchCV` execution, as in
    [Example 10-2](#skex_joblib).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-2\. [Using a Ray Joblib backend with scikit-learn to build the wine-quality
    model](https://oreil.ly/cqR34)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Using Boosting Algorithms with Ray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Boosting algorithms are well suited to parallel computing as they train multiple
    models. You can train each submodel independently and then train another model
    on how to combine the results. These are the two most popular boosting libraries
    today:'
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost
  prefs: []
  type: TYPE_NORMAL
- en: An optimized distributed gradient boosting library designed to be highly efficient,
    flexible, and portable. It implements ML algorithms under the [gradient boosting
    framework](https://oreil.ly/ceOze). XGBoost provides a parallel tree boosting—also
    known as gradient boosting decision tree (GBDT) and gradient boosting machines
    (GBM)—that solves many data science problems quickly and accurately. The same
    code runs on many distributed environments—including Hadoop, Sun Grid Engine (SGE),
    and Message Passing Interface (MPI)—and can solve problems beyond billions of
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[LightGBM](https://oreil.ly/PdV9o)'
  prefs: []
  type: TYPE_NORMAL
- en: A fast, distributed, high-performance [gradient boosting framework](https://oreil.ly/XZdQD)
    based on a decision tree algorithm, used for ranking, classification, and many
    other ML tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will compare how Ray parallelizes training with XGBoost and LightGBM, but
    comparing the details of the libraries is beyond the scope of this book. If you’re
    interested in the difference between the libraries, a good comparison is found
    in [“XGBoost vs. LighGBM: How Are They Different”](https://oreil.ly/yk800) by
    Sumit Saha.'
  prefs: []
  type: TYPE_NORMAL
- en: Using XGBoost
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuing with our wine-quality example, we build a model using XGBoost, and
    the code to do so is presented in [Example 10-3](#xgboost_example).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-3\. [Using XGBoost to build our wine-quality model](https://oreil.ly/s6ORf)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'One of the reasons XGBoost is so performant is that it uses [OpenMP](https://oreil.ly/saVa9)
    to create tree branches independently, which does not directly support Ray. Ray
    integrates with XGBoost by providing an xgboost-ray library that replaces OpenMP
    with Ray actor pools. You can use this library either with XGBoost or scikit-learn
    APIs. In the latter case, the library provides a drop-in replacement for the following
    estimators:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RayXGBClassifier`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RayXGRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RayXGBRFClassifier`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RayXGBRFRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RayXGBRanker`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also provides `RayParams`, which allows you to explicitly define the execution
    parameters for Ray. Using this library, we can modify [Example 10-3](#xgboost_example)
    to make it work with Ray as shown in [Example 10-4](#xgboost_ray).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-4\. [Using the XGBoost Ray library to build our wine-quality model](https://oreil.ly/EgHdZ)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here we used `RayParams` to specify the size of Ray’s actor pool used for parallelization.
    Alternatively, you can use the `n_jobs` parameter in `RayXGBClassifier` to achieve
    the same.
  prefs: []
  type: TYPE_NORMAL
- en: Using LightGBM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Building our wine-quality model using LightGBM is presented in [Example 10-5](#lightGBM).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-5\. [Using LightGBM to build our wine-quality model](https://oreil.ly/oHzxy)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to XGBoost, LightGBM uses OpenMP for parallelization. As a result,
    Ray offers the [Distributed LightGBM on Ray library](https://oreil.ly/l6wuQ),
    which implements parallelization using Ray’s actor pool. Similar to the xgboost-ray
    library, this library supports both native and scikit-learn APIs. In the latter
    case, the library implements the following estimators:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RayLGBMClassifier`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RayLGBMRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with XGBoost, `RayParams` is provided, allowing you to define execution parameters
    for Ray. Using this library, we can modify [Example 10-5](#lightGBM) to make it
    work with Ray as in [Example 10-6](#lightGBM_ray).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-6\. [Using the LightGBM Ray library to build our wine-quality model](https://oreil.ly/pocKo)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here we used `RayParams` to specify the size of Ray’s actor pool used for parallelization.
    Alternatively, you can use the `n_jobs` parameter in `RayLGBMClassifier` to achieve
    the same.
  prefs: []
  type: TYPE_NORMAL
- en: Using PyTorch with Ray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another very popular machine learning framework is [PyTorch](https://oreil.ly/fMTL8),
    an open source Python library for deep learning developed and maintained by Facebook.
    PyTorch is simple and flexible, making it a favorite for many academics and researchers
    in the development of new deep learning models and applications.
  prefs: []
  type: TYPE_NORMAL
- en: Many extensions for specific applications (such as text, computer vision, and
    audio data) have been implemented for PyTorch. A lot of pretrained models also
    exist that you can use directly. If you are not familiar with PyTorch, take a
    look at Jason Brownlee’s [PyTorch tutorial](https://oreil.ly/zzXb6) for an introduction
    to its structure, capabilities, and usage for solving various problems.
  prefs: []
  type: TYPE_NORMAL
- en: We will continue with our wine-quality problem and show how to use PyTorch to
    build a multilayer perceptron (MLP) model for predicting wine quality. To do this,
    you need to start from creating a custom PyTorch [Dataset class](https://oreil.ly/E1MGh)
    that can be extended and customized to load your dataset. For our wine-quality
    example, the custom dataset class is shown in [Example 10-7](#torch_data).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-7\. [PyTorch dataset class for loading wine-quality data](https://oreil.ly/hkLLE)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that here, in addition to the minimum requirements, we have implemented
    `get_splits`, a method that splits an original dataset into two: one for training
    and one for testing.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have defined your data class, you can use PyTorch to make a model.
    To define a model in PyTorch, you extend the base PyTorch [Module class](https://oreil.ly/ShyFD).
    The model class for our purposes is presented in [Example 10-8](#torch_model).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-8\. [PyTorch model class for wine quality](https://oreil.ly/CZX2A)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This class constructor builds the model by defining its layers and their connectivity.
    The `forward` method defines how to forward-propagate input through the model.
    With these two classes in place, the overall code looks like [Example 10-9](#torch_train).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-9\. [PyTorch implementation of wine-quality model building](https://oreil.ly/6TIHG)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[Example 10-9](#torch_train) works, but Ray is integrated with [Lightning](https://oreil.ly/SCakx)
    (formerly called PyTorch Lightning), not PyTorch. Lightning structures your PyTorch
    code so it can abstract the details of training. This makes AI research scalable
    and fast to iterate on.'
  prefs: []
  type: TYPE_NORMAL
- en: To convert [Example 10-9](#torch_train) to Lightning, we first need to modify
    [Example 10-8](#torch_model). In Lightning, it needs to be derived from [`lightning_module`](https://oreil.ly/sFSCd),
    not `module`, which means that we need to add two methods to our model ([Example 10-10](#ltorch_add)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-10\. [Lightning model’s additional functions for wine quality](https://oreil.ly/1eTnI)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here the `training_step` method defines a single step, while `configure_optimized`
    defines which optimizer to use. When you compare this to [Example 10-8](#torch_model),
    you will notice that some of that example’s code is moved into these two methods
    (here instead of the `BCELoss` optimizer, we are using the `Adam` optimizer).
    With this updated model class, the model training looks like [Example 10-11](#ltorch_train).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-11\. [Lightning implementation of wine-quality model building](https://oreil.ly/T7xza)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that unlike [Example 10-9](#torch_train), where training is implemented
    programmatically, Lightning introduces a trainer class, which internally implements
    a trainer loop. This approach allows all required optimization to be in the training
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: Both PyTorch and Lightning are using Joblib to distribute training through the
    built-in [`ddp_cpu` backend](https://oreil.ly/RNLuq) or, more generally, [Horovod](https://oreil.ly/x8Ba2).
    As with other libraries, to allow distributed Lightning on Ray, Ray has a library
    [Distributed PyTorch Lightning Training](https://oreil.ly/Ii51T) that adds new
    Lightning plug-ins for distributed training using Ray. These plug-ins allow you
    to quickly and easily parallelize training while still getting all the benefits
    of Lightning and using your desired training protocol, either `ddp_cpu` or Horovod.
  prefs: []
  type: TYPE_NORMAL
- en: Once you add the plug-ins to your Lightning trainer, you can configure them
    to parallelize training to all the cores in your laptop, or across a massive multinode,
    multi-GPU cluster with no additional code changes. This library also comes with
    integration with [Ray Tune](https://oreil.ly/ZJDeP) so you can perform distributed
    hyperparameter tuning experiments.
  prefs: []
  type: TYPE_NORMAL
- en: The `RayPlugin` class provides Distributed Data Parallel (DDP) training on a
    Ray cluster. PyTorch DDP is used as the distributed training protocol by PyTorch,
    and Ray is used in this case to launch and manage the training worker processes.
    The base code using this plug-in is shown in [Example 10-12](#ltorch_train_2).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-12\. [Enabling the Lightning implementation of our wine-quality model
    building to run on Ray](https://oreil.ly/oF44p)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The two additional plug-ins included in the library are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: HorovodRayPlugin
  prefs: []
  type: TYPE_NORMAL
- en: Integrates with Horovod as the distributed training protocol.
  prefs: []
  type: TYPE_NORMAL
- en: RayShardedPlugin
  prefs: []
  type: TYPE_NORMAL
- en: Integrates with [FairScale](https://oreil.ly/drOkZ) to provide sharded DDP training
    on a Ray cluster. With sharded training, you can leverage the scalability of data-parallel
    training while drastically reducing memory usage when training large models.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning with Ray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ray was initially created as a platform for *reinforcement learning* (RL), which
    is one of the hottest research topics in the field of modern artificial intelligence,
    and its popularity is only growing. RL is a type of machine learning technique
    that enables an agent to learn in an interactive environment by trial and error
    using feedback from its own actions and experiences; see [Figure 10-1](#different-types-of-machine-learning).
  prefs: []
  type: TYPE_NORMAL
- en: '![spwr 1001](assets/spwr_1001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-1\. Types of machine learning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Both supervised and reinforcement learning create a mapping between input and
    output. But whereas supervised learning uses a set of known inputs and output
    for training, reinforcement learning uses rewards and punishments as signals for
    positive and negative behavior. Both unsupervised and reinforcement learning leverage
    experiment data, but they have different goals. While in unsupervised learning
    we are finding similarities and differences between data points, in reinforcement
    learning we are trying to find a suitable action model that would maximize the
    total cumulative reward and improve the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key components of an RL implementation are as follows and are depicted
    in [Figure 10-2](#reinforcement-model-implementation):'
  prefs: []
  type: TYPE_NORMAL
- en: Environment
  prefs: []
  type: TYPE_NORMAL
- en: Physical world in which the agent operates
  prefs: []
  type: TYPE_NORMAL
- en: State
  prefs: []
  type: TYPE_NORMAL
- en: Current state of the agent
  prefs: []
  type: TYPE_NORMAL
- en: Reward
  prefs: []
  type: TYPE_NORMAL
- en: Feedback to the agent from the environment
  prefs: []
  type: TYPE_NORMAL
- en: Policy
  prefs: []
  type: TYPE_NORMAL
- en: Method to map the agent’s state to the actions
  prefs: []
  type: TYPE_NORMAL
- en: Value
  prefs: []
  type: TYPE_NORMAL
- en: Future reward that an agent would receive by taking an action in a particular
    state
  prefs: []
  type: TYPE_NORMAL
- en: '![spwr 1002](assets/spwr_1002.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-2\. Reinforcement model implementation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: RL is a huge topic, and its details are beyond the scope of this book (we are
    just trying to explain how to start using the library with a simple example),
    but if you are interested in learning more about it, [“Reinforcement Learning
    101”](https://oreil.ly/YvgzA) by Shweta Bhatt is an excellent starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Ray’s RLlib is a library for RL, which allows for production-level, highly distributed
    RL workloads while providing unified and simple APIs for a large variety of applications
    for different industries. It supports both [model-free](https://oreil.ly/tA22j)
    and [model-based](https://oreil.ly/n7mB9) reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in [Figure 10-3](#rllib-components), RLlib is built on top of Ray and
    offers off-the-shelf, highly distributed algorithms, policies, loss functions,
    and default models.
  prefs: []
  type: TYPE_NORMAL
- en: '![spwr 1003](assets/spwr_1003.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10-3\. RLlib components
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A *policy* encapsulates the core numerical components of RL algorithms. It includes
    a policy model that determines actions based on environment changes and a loss
    function defining the result of the action based on the post-processed environment.
    Depending on the environment, RL can have a single agent and property, a single
    policy for multiple agents, or multiple policies, each controlling one or more
    agents.
  prefs: []
  type: TYPE_NORMAL
- en: Everything agents interact with is called an *environment*. The environment
    is the outside world and comprises everything outside the agent.
  prefs: []
  type: TYPE_NORMAL
- en: Given an environment and policy, policy evaluation is done by the *worker*.
    RLlib provides a [RolloutWorker class](https://oreil.ly/WgnmE) that is used in
    most RLlib algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, RLlib provides [trainer classes](https://oreil.ly/JRjMw) that
    hold a policy for environment interaction. Through the trainer interface, the
    policy can be trained, checkpointed, or an action computed. In multiagent training,
    the trainer manages the querying and optimization of multiple policies at once.
    The trainer classes coordinate the distributed workflow of running rollouts and
    optimizing policies. They do this by leveraging Ray [parallel iterators](https://oreil.ly/2TTeo).
  prefs: []
  type: TYPE_NORMAL
- en: Beyond environments defined in Python, Ray supports batch training on [offline
    datasets](https://oreil.ly/u88nx) through *input readers*. This is an important
    use case for RL when it’s not possible to run traditional training and roll out
    in a physical environment (like a chemical plant or assembly line) and a suitable
    simulator doesn’t exist. In this approach, data for past activity is used to train
    a policy.
  prefs: []
  type: TYPE_NORMAL
- en: From single processes to large clusters, all data interchange in RLlib uses
    [sample batches](https://oreil.ly/kP0sH). Sample batches encode one or more fragments
    of data. Typically, RLlib collects batches of size `rollout_fragment_length` from
    rollout workers and concatenates one or more of these batches into a batch of
    size `train_batch_size` that is the input to stochastic gradient descent (SGD).
  prefs: []
  type: TYPE_NORMAL
- en: 'The main features of RLlib are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Support for the most popular deep-learning frameworks including PyTorch and
    TensorFlow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of highly distributed learning, RLlib algorithms—[PPO](https://oreil.ly/5oJU8)
    or [IMPALA](https://oreil.ly/dkaNw)—allow you to set the `num_workers` config
    parameter, such that your workloads can run on hundreds of CPUs or nodes, thus
    parallelizing and speeding up learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Support for [multiagent RL](https://oreil.ly/wc9dO) allows for training your
    agents supporting any of the following strategies:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cooperative with [shared](https://oreil.ly/XZDTC) or [separate](https://oreil.ly/ofB4R)
    policies and/or value functions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adversarial scenarios using [self-play](https://oreil.ly/c7hyz) and [league-based
    training](https://oreil.ly/wBnHl)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Independent learning](https://oreil.ly/2RRS2) of neutral/coexisting agents'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Support APIs for an external pluggable simulators environment that comes with
    a pluggable, off-the-shelf [client](https://oreil.ly/aaQ6s) ∕ [server](https://oreil.ly/eMn1j)
    setup that allows you to run hundreds of independent simulators on the “outside”
    connecting to a central RLlib policy-server that learns and serves actions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, RLlib provides simple APIs to customize all aspects of your training
    and experimental workflows. For example, you may code your own [environments](https://oreil.ly/15Cx0)
    in Python by using [OpenAI’s Gym](https://oreil.ly/ECLhC) or [DeepMind’s OpenSpiel](https://oreil.ly/eI9y9),
    provide custom [TensorFlow/Keras](https://oreil.ly/EQUpK) or [PyTorch](https://oreil.ly/nE4r3)
    models, and write your own [policy and loss definitions](https://oreil.ly/pbPyT)
    or define custom [exploratory behavior](https://oreil.ly/QUtq7).
  prefs: []
  type: TYPE_NORMAL
- en: Simple code for implementing RL training to address the inverted pendulum—i.e.,
    [CartPole](https://oreil.ly/lJIDX)—problem (the environment exists in OpenAI’s
    Gym) is shown in [Example 10-13](#rl_train).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-13\. [CartPole reinforcement learning](https://oreil.ly/d6tHJ)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[Example 10-13](#rl_train) starts by creating a configuration for a trainer.
    The configuration defines an environment,^([3](ch10.html#idm45354762991600)) the
    number of workers (we use four), framework (we use TensorFlow 2), model, train
    batch size, and additional execution parameters. This configuration is used for
    the creation of the trainer. We then execute several training iterations and display
    results. That’s all it takes to implement simple RL.'
  prefs: []
  type: TYPE_NORMAL
- en: You can easily extend this simple example by creating your specific [environment](https://oreil.ly/APjBE)
    or introducing your own [algorithms](https://oreil.ly/OFzk0).
  prefs: []
  type: TYPE_NORMAL
- en: Numerous examples of Ray RLlIB usage are described in [“Best Reinforcement Learning
    Talks from Ray Summit 2021”](https://oreil.ly/4I1Dv) by Michael Galarnyk.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter Tuning with Ray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When creating an ML model, you are often faced with a variety of choices, from
    the type of model to feature selection techniques. A natural extension of ML is
    to use similar techniques to find the right values (or parameters) for the choices
    in building our model. Parameters that define the model architecture are referred
    to as *hyperparameters*, and the process of searching for the ideal model architecture
    is referred to as *hyperparameter tuning*. Unlike the model parameters that specify
    how to transform the input data into the desired output, hyperparameters define
    how to structure the model.
  prefs: []
  type: TYPE_NORMAL
- en: As with boosting algorithms, hyperparameter tuning is especially well suited
    to parallelization because it involves training and comparing many models. Depending
    on the search technique, training these separate models can be an “embarrassingly
    parallel” problem, as there is little to no communication needed between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The degree of the polynomial feature that should be used for the linear model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum depth allowed for a decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum number of samples required at a leaf node in a decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of neurons for a neural network layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of layers for a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The learning rate for gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ray Tune](https://oreil.ly/PzkxQ) is the Ray-based native library for hyperparameter
    tuning. The main features of Tune are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It provides distributed, asynchronous optimization out of the box leveraging
    Ray.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same code can be scaled from a single machine to a large, distributed cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It offers state-of-the-art algorithms including (but not limited to) [ASHA](https://oreil.ly/lY6nX),
    [BOHB](https://oreil.ly/iAiK9), and [Population-Based Training](https://oreil.ly/PrsmS).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It integrates with [TensorBoard](https://oreil.ly/FM7uR) or [MLflow](https://oreil.ly/pzYA6)
    to visualize tuning results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It integrates with many optimization libraries such as [Ax/Botorch](https://oreil.ly/25sEx),
    [Hyperopt](https://oreil.ly/gCJ2I), and [Bayesian Optimization](https://oreil.ly/xA9nC)
    and enables their transparently scaling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It supports many ML frameworks, including PyTorch, TensorFlow, XGBoost, LightGBM,
    and Keras.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are the main components of Tune:'
  prefs: []
  type: TYPE_NORMAL
- en: Trainable
  prefs: []
  type: TYPE_NORMAL
- en: 'A training function, with an objective function. Tune offers two interface
    APIs for a trainable: functional and class.'
  prefs: []
  type: TYPE_NORMAL
- en: Search space
  prefs: []
  type: TYPE_NORMAL
- en: Valid values for your hyperparameters, and you can specify how these values
    are sampled (e.g., from a uniform distribution or a normal distribution). Tune
    offers various functions to define search spaces and sampling methods.
  prefs: []
  type: TYPE_NORMAL
- en: Search algorithm
  prefs: []
  type: TYPE_NORMAL
- en: An algorithm used for the optimization of hyperparameters. Tune has Search Algorithms
    that integrate with many popular optimization libraries, such as [Nevergrad](https://oreil.ly/x5oaM)
    and [Hyperopt](https://oreil.ly/G2bGl). Tune automatically converts the provided
    search space into the search spaces the search algorithms/underlying library expect.
  prefs: []
  type: TYPE_NORMAL
- en: Trial
  prefs: []
  type: TYPE_NORMAL
- en: Execution or run of a logical representation of a single hyperparameter configuration.
    Each trial is associated with an instance of a trainable. And a collection of
    trials make up an experiment. Tune uses Ray actors as a worker node’s processes
    to run multiple trials in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment analysis
  prefs: []
  type: TYPE_NORMAL
- en: An object, returned by Tune, that has methods that can be used for analyzing
    your training. It can be integrated with TensorBoard and MLflow for results visualization.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show how to use Tune, let’s optimize our PyTorch implementation of wine-quality
    model building ([Example 10-8](#torch_model)). We will try to optimize two parameters
    of the optimizer used to build the model: `lr` and `momentum`.'
  prefs: []
  type: TYPE_NORMAL
- en: First we restructure our code ([Example 10-9](#torch_train)) to introduce three
    additional functions ([Example 10-14](#tune_additions)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-14\. [Implementing support functions for our PyTorch wine-quality
    model](https://oreil.ly/dEMDF)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we have introduced three supporting functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`model_train`'
  prefs: []
  type: TYPE_NORMAL
- en: Encapsulates model training.
  prefs: []
  type: TYPE_NORMAL
- en: '`model_test`'
  prefs: []
  type: TYPE_NORMAL
- en: Encapsulates model-quality evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '`train_winequality`'
  prefs: []
  type: TYPE_NORMAL
- en: Implements all steps for model training and reports them to Tune. This allows
    Tune to make decisions in the middle of training.
  prefs: []
  type: TYPE_NORMAL
- en: With these three functions in place, integration with Tune is very straightforward
    ([Example 10-15](#tune_additions_2)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-15\. [Integrating model building with Tune](https://oreil.ly/1zhR6)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'After loading the dataset, the code defines a search space—​a space for possible
    hyperparameters—​and invokes tuning by using the `tune.run` method. The parameters
    here are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Callable
  prefs: []
  type: TYPE_NORMAL
- en: Defines a training function (`train_winequality`, in our case).
  prefs: []
  type: TYPE_NORMAL
- en: '`num_samples`'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates the maximum number of runs for Tune.
  prefs: []
  type: TYPE_NORMAL
- en: '`scheduler`'
  prefs: []
  type: TYPE_NORMAL
- en: Here we use [ASHA](https://oreil.ly/frU6p), a scalable algorithm for [principled
    early stopping](https://oreil.ly/ASVYC). To make the optimization process more
    efficient, the ASHA scheduler terminates trials that are less promising and allocates
    more time and resources to more promising trials.
  prefs: []
  type: TYPE_NORMAL
- en: '`config`'
  prefs: []
  type: TYPE_NORMAL
- en: Contains the search space for the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Running the preceding code produces the result shown in [Example 10-16](#tune_result).
  prefs: []
  type: TYPE_NORMAL
- en: Example 10-16\. Tuning the model result
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, although we have defined 50 iterations for the model search,
    using ASHA significantly improves performance because it uses significantly fewer
    runs on average (in this example, more than 50% used only one iteration).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how Ray constructs are leveraged for scaling execution
    of the different ML libraries (scikit-learn, XGBoost, LightGBM, and Lightning)
    using the full capabilities of multimachine Ray clusters.
  prefs: []
  type: TYPE_NORMAL
- en: We showed you simple examples of porting your existing ML code to Ray, as well
    as some of the internals of how Ray extends ML libraries to scale. We also showed
    simple examples of using Ray-specific implementations of RL and hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: We hope that looking at these relatively simple examples will give you a better
    idea of how to best use Ray in your day-to-day implementations.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch10.html#idm45354765564752-marker)) In this example, we are using `GridSearchCV`,
    which implements an exhaustive search. Although this works for this simple example,
    scikit-learn currently provides a new library, [Tune-sklearn](https://oreil.ly/p5p8d),
    that provides more powerful [tune algorithms](https://oreil.ly/aQoEw) providing
    a significant tuning speedup. This said, the same Joblib backend works for these
    algorithms the same way.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch10.html#idm45354764269024-marker)) In our testing, for XGBoost execution
    time was 0.15 versus 14.4 seconds, and for LightGBM it was 0.24 versus 12.4 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch10.html#idm45354762991600-marker)) Here we use an existing [OpenAI Gym
    environment](https://oreil.ly/BSXIK), so we can just use its name.
  prefs: []
  type: TYPE_NORMAL
