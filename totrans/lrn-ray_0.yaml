- en: Chapter 1\. An Overview of Ray
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 章\. Ray 概述
- en: A distributed system is one in which the failure of a computer you didn’t even
    know existed can render your own computer unusable.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分布式系统是指你甚至都不知道存在的计算机出现故障，可能会使你自己的计算机无法使用。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Leslie Lamport
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 莱斯利·兰波特
- en: One of the reasons we need efficient distributed computing is that we’re collecting
    ever more data with a large variety at increasing speeds. The storage systems,
    data processing and analytics engines that have emerged in the last decade are
    crucially important to the success of many companies. Interestingly, most “big
    data” technologies are built for and operated by (data) engineers, that are in
    charge of data collection and processing tasks. The rationale is to free up data
    scientists to do what they’re best at. As a data science practitioner you might
    want to focus on training complex machine learning models, running efficient hyperparameter
    selection, building entirely new and custom models or simulations, or serving
    your models to showcase them. At the same time you simply might *have to* scale
    them to a compute cluster. To do that, the distributed system of your choice needs
    to support all of these fine-grained “big compute” tasks, potentially on specialized
    hardware. Ideally, it also fits into the big data tool chain you’re using and
    is fast enough to meet your latency requirements. In other words, distributed
    computing has to be powerful and flexible enough for complex data science workloads — and
    Ray can help you with that.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要高效的分布式计算的原因之一是，我们正在以越来越快的速度收集越来越多种类的数据。过去十年中出现的存储系统、数据处理和分析引擎对许多公司的成功至关重要。有趣的是，大多数“大数据”技术是由（数据）工程师构建和操作的，他们负责数据收集和处理任务。其理念是为了让数据科学家可以专注于他们擅长的工作。作为数据科学从业者，您可能希望专注于训练复杂的机器学习模型、运行高效的超参数选择、构建全新和定制的模型或仿真，或者提供您的模型以展示它们。同时，您可能*必须*将它们扩展到计算集群。为此，您选择的分布式系统需要支持所有这些细粒度的“大计算”任务，可能还需要使用专门的硬件。理想情况下，它还应该适合您正在使用的大数据工具链，并且足够快以满足您的延迟要求。换句话说，分布式计算必须强大且灵活，以处理复杂的数据科学工作负载，而
    Ray 可以帮助您实现这一点。
- en: Python is likely the most popular language for data science today, and it’s
    certainly the one I find the most useful for my daily work. By now it’s over 30
    years old, but has a still growing and active community. The rich [PyData ecosystem](https://pydata.org/)
    is an essential part of a data scientist’s toolbox. How can you make sure to scale
    out your workloads while still leveraging the tools you need? That’s a difficult
    problem, especially since communities can’t be forced to just toss their toolbox,
    or programming language. That means distributed computing tools for data science
    have to be built for their existing community.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Python 很可能是今天数据科学中最流行的语言，对我来说，在日常工作中它是最实用的。现在它已经超过 30 年了，但仍然拥有一个不断增长和活跃的社区。丰富的
    [PyData 生态系统](https://pydata.org/) 是数据科学家工具箱的重要组成部分。你如何确保扩展你的工作负载同时仍然利用你需要的工具？这是一个棘手的问题，特别是因为社区不能被迫抛弃他们的工具箱或编程语言。这意味着数据科学的分布式计算工具必须为其现有的社区构建。
- en: What Is Ray?
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ray 是什么？
- en: What I like about Ray is that it checks all the above boxes. It’s a flexible
    distributed computing framework build for the Python data science community. Ray
    is easy to get started and keeps simple things simple. Its core API is as lean
    as it gets and helps you reason effectively about the distributed programs you
    want to write. You can efficiently parallelize Python programs on your laptop,
    and run the code you tested locally on a cluster practically without any changes.
    Its high-level libraries are easy to configure and can seamlessly be used together.
    Some of them, like Ray’s reinforcement learning library, would have a bright future
    as standalone projects, distributed or not. While Ray’s core is built in C++,
    it’s been a Python-first framework since day one, integrates with many important
    data science tools, and can count on a growing ecosystem.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢 Ray 的原因是它符合以上所有要求。它是为 Python 数据科学社区构建的灵活分布式计算框架。Ray 容易上手，保持简单事物的简单。它的核心
    API 尽可能精简，帮助您有效地思考要编写的分布式程序。您可以在笔记本电脑上有效地并行执行 Python 程序，并且几乎无需任何更改即可在集群上运行您在本地测试过的代码。它的高级库易于配置，并且可以无缝地一起使用。其中一些，如
    Ray 的强化学习库，将有一个光明的未来作为独立项目，无论是分布式还是非分布式。虽然 Ray 的核心是用 C++ 构建的，但从一开始就是以 Python 为主的框架，与许多重要的数据科学工具集成，并且可以依靠一个不断增长的生态系统。
- en: Distributed Python is not new, and Ray is not the first framework in this space
    (nor will it be the last), but it is special in what it has to offer. Ray is particularly
    strong when you combine several of its modules and have custom, machine learning
    heavy workloads that would be difficult to implement otherwise. It makes distributed
    computing easy enough to run your complex workloads flexibly by leveraging the
    Python tools you know and want to use. In other words, by *learning Ray* you get
    to know *flexible distributed Python for data science*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式Python并不新鲜，Ray也不是这个领域的第一个框架（也不会是最后一个），但它在提供内容方面确实与众不同。当你结合Ray的多个模块并拥有自定义的、机器学习密集型工作负载时，Ray表现尤为出色，否则这些工作将难以实现。它通过利用你已知且想要使用的Python工具，轻松地运行复杂工作负载，使分布式计算灵活多变。换句话说，通过*学习Ray*，你可以了解*数据科学中灵活的分布式Python*。
- en: In this chapter you’ll get a first glimpse at what Ray can do for you. We will
    discuss the three layers that make up Ray, namely its core engine, its high-level
    libraries and its ecosystem. Throughout the chapter we’ll show you first code
    examples to give you a feel for Ray, but we defer any in-depth treatment of Ray’s
    APIs and components to later chapters. You can view this chapter as an overview
    of the whole book as well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将初步了解Ray可以为你做些什么。我们将讨论组成Ray的三个层次，即其核心引擎、高级库和生态系统。在整个章节中，我们将展示首个代码示例，让你对Ray有所感觉，但我们将深入讨论Ray的API和组件留到后面的章节。你可以把本章视为整本书的概述。
- en: What Led to Ray?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么导致了Ray的出现？
- en: Programming distributed systems is hard. It requires specific knowledge and
    experience you might not have. Ideally, such systems get out of your way and provide
    abstractions to let you focus on your job. But in practice “all non-trivial abstractions,
    to some degree, are leaky” ([Spolsky](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)),
    and getting clusters of computers to do what you want is undoubtedly difficult.
    Many software systems require resources that far exceed what single servers can
    do. Even if one server was enough, modern systems need to be failsafe and provide
    features like high availability. That means your applications might have to run
    on multiple machines, or even datacenters, just to make sure they’re running reliably.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 编写分布式系统很困难。它需要你可能没有的特定知识和经验。理想情况下，这样的系统应该不会干扰你，而是提供抽象层让你专注于工作。但实际上，“所有非平凡的抽象，在某种程度上，都会泄漏”（[Spolsky](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)），让计算机集群按照你的意愿工作无疑是困难的。许多软件系统需要远远超出单个服务器所能提供的资源。即使一个服务器足够了，现代系统也需要具备故障安全性，并提供高可用性等功能。这意味着你的应用程序可能需要在多台甚至多个数据中心上运行，以确保它们的可靠性。
- en: Even if you’re not too familiar with machine learning (ML) or more generally
    artificial intelligence (AI) as such, you must have heard of recent breakthroughs
    in the field. To name just two, systems like [Deepmind’s AlphaFold](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)
    for solving the protein folding problem, or [OpenAI’s Codex](https://openai.com/blog/openai-codex/)
    that’s helping software developers with the tedious parts of their job, have made
    the news lately. You might also have heard that ML systems generally require large
    amounts of data to be trained. OpenAI has shown exponential growth in compute
    needed to train AI models in their paper [“AI and Compute”](https://openai.com/blog/ai-and-compute/).
    The operations needed for AI systems in their study is measured in petaflops (thousands
    of trillion operations per second), and has been *doubling every 3.4 months* since
    2012.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你对机器学习（ML）或更广义的人工智能（AI）不太熟悉，你一定听说过这个领域的最新突破。仅举两个例子，像[Deepmind的AlphaFold](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)解决蛋白质折叠问题，或者[OpenAI的Codex](https://openai.com/blog/openai-codex/)帮助软件开发人员处理繁琐的工作，近期都成为了新闻。你可能也听说过，ML系统通常需要大量数据来进行训练。OpenAI在他们的论文[“AI
    and Compute”](https://openai.com/blog/ai-and-compute/)中展示了AI模型训练所需的计算能力呈指数增长，这些操作以petaflops（每秒数千万亿次操作）计量，自2012年以来每3.4个月*翻倍*。
- en: Compare this to Moore’s Law^([1](ch01.xhtml#idm44990045517696)), which states
    that the number of transistors in computers would double every two years. Even
    if you’re bullish on Moore’s law, you can see how there’s a clear need for distributed
    computing in ML. You should also understand that many tasks in ML can be naturally
    decomposed to run in parallel. So, why not speed things up if you can?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 将这与摩尔定律^([1](ch01.xhtml#idm44990045517696))进行比较，该定律规定计算机中的晶体管数量每两年翻一番。即使你对摩尔定律持乐观态度，你也能看出在机器学习中有分布式计算的明显需求。你还应该了解到，许多机器学习任务可以自然地分解为并行运行。因此，如果可以加快速度，为什么不这样做呢？
- en: Distributed computing is generally perceived as hard. But why is that? Shouldn’t
    it be realistic to find good abstractions to run your code on clusters, without
    having to constantly think about individual machines and how they interoperate?
    What if we specifically focused on AI workloads?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式计算通常被认为很难。但是为什么会这样呢？难道不应该找到良好的抽象方法在集群上运行代码，而不必不断考虑各个单独的机器及其相互操作吗？如果我们专门关注人工智能工作负载会怎样呢？
- en: Researchers at [RISELab](https://rise.cs.berkeley.edu/) at UC Berkeley created
    Ray to address these questions. None of the tools existing at the time met their
    needs. They were looking for easy ways to speed up their workloads by distributing
    them to compute clusters. The workloads they had in mind were quite flexible in
    nature and didn’t fit into the analytics engines available. At the same time,
    RISELab wanted to build a system that took care of how the work was distributed.
    With reasonable default behaviors in place, researchers should be able to focus
    on their work. And ideally they should have access to all their favorite tools
    in Python. For this reason, Ray was built with an emphasis on high-performance
    and heterogeneous workloads. [Anyscale](https://www.anyscale.com/), the company
    behind Ray, is building a managed Ray Platform and offers hosted solutions for
    your Ray applications. Let’s have a look at an example of what kinds of applications
    Ray was designed for.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 加州大学伯克利分校的[RISELab](https://rise.cs.berkeley.edu/)的研究人员创建了Ray来解决这些问题。当时存在的工具都不能满足他们的需求。他们正在寻找一种简单的方式将工作负载分发到计算集群中以加快处理速度。他们考虑的工作负载性质相当灵活，不适合现有的分析引擎。与此同时，RISELab希望建立一个系统来处理工作分发的细节。通过合理的默认行为，研究人员应能够专注于他们的工作。理想情况下，他们应该能够使用Python中所有他们喜爱的工具。因此，Ray的设计强调高性能和异构工作负载。[Anyscale](https://www.anyscale.com/)，Ray背后的公司，正在构建一个托管Ray应用程序的托管平台，并提供托管解决方案。让我们来看看Ray设计用于哪些应用程序的示例。
- en: Flexible Workloads in Python and Reinforcement Learning
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python和强化学习中的灵活工作负载
- en: One of my favorite apps on my phone can automatically classify or “label” individual
    plants in our garden. It works by simply showing it a picture of the plant in
    question. That’s immensely helpful, as I’m terrible at distinguishing them all.
    (I’m not bragging about the size of my garden, I’m just bad at it.) In the last
    couple of years we’ve seen a surge of impressive applications like that.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我手机上的一个我最喜欢的应用可以自动分类或“标记”我们花园中的各种植物。它的工作原理很简单，只需展示相关植物的图片即可。这非常有帮助，因为我擅长的不是分辨它们。（我并不是在炫耀我的花园有多大，只是我分辨不好。）在过去几年中，我们见证了许多类似的令人印象深刻的应用程序的激增。
- en: Ultimately, the promise of AI is to build intelligent agents that go far beyond
    classifying objects. Imagine an AI application that not only knows your plants,
    but can take care of to them, too. Such an application would have to
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，人工智能的承诺是建立超越分类对象的智能代理。想象一下，一个人工智能应用不仅了解您的植物，还可以照顾它们。这样的应用程序必须
- en: Operate in dynamic environments (like the change of seasons)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在动态环境中运行（如季节变化）
- en: React to changes in the environment (like a heavy storm or pests attacking your
    plants)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对环境变化做出反应（如剧烈风暴或害虫攻击您的植物）
- en: Take sequences of actions (like watering and fertilizing plants)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行一系列操作（如浇水和施肥）
- en: Accomplish long-term goals (like prioritizing plant health)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成长期目标（如优先考虑植物健康）
- en: By observing its environment such an AI would also learn to explore the possible
    actions it could take and come up with better solutions over time. If you feel
    like this example is artificial or too far out, it’s not difficult to come up
    with examples on your own that share all the above requirements. Think of managing
    and optimizing a supply chain, strategically restocking a warehouse considering
    fluctuating demands, or orchestrating the processing steps in an assembly line.
    Another famous example of what you could expect from an AI would be Stephen Wozniak’s
    famous “Coffee Test”. If you’re invited to a friend’s house, you can navigate
    to the kitchen, spot the coffee machine and all necessary ingredients, figure
    out how to brew a cup of coffee, and sit down to enjoy it. A machine should be
    able to do the same, except the last part might be a bit of a stretch. What other
    examples can you think of?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察环境，这样的人工智能也会学习探索其可能采取的行动，并随着时间的推移提出更好的解决方案。如果你觉得这个例子太假或者离实际太远，自己也不难想出符合上述所有要求的例子。想想如何管理和优化供应链，在考虑波动需求时战略性地补充仓库存货，或者编排装配线中的加工步骤。另一个可以从人工智能期望中看到的著名例子是史蒂芬·沃兹尼亚克的著名“咖啡测试”。如果你被邀请去朋友家，你可以找到厨房，找到咖啡机和所有必要的配料，弄清楚如何冲一杯咖啡，并坐下来享用。一台机器应该能做同样的事情，尽管最后一部分可能有点难度。你能想到哪些其他例子呢？
- en: You can frame all the above requirements naturally in a subfield of machine
    learning called reinforcement learning (RL). We’ve dedicated all of [Chapter 4](ch04.xhtml#chapter_04)
    to RL. For now, it’s enough to understand that it’s about agents interacting with
    their environment by observing it and emitting actions. In RL, agents evaluate
    their environments by attributing a reward (e.g., how healthy is my plant on a
    scale from 1 to 10). The term “reinforcement” comes from the fact that agents
    will hopefully learn to seek out behaviour that leads to good outcomes (high reward),
    and shy away from punishing situations (low or negative reward). The interaction
    of agents with their environment is usually modeled by creating a computer simulation
    of it. These simulations can become complicated quite quickly, as you might imagine
    from the examples we’ve given.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在机器学习的一个子领域——强化学习（RL）中自然地表述所有上述要求。我们在[第四章](ch04.xhtml#chapter_04)中专门讨论了RL。现在，理解它与代理通过观察环境并发出动作进行互动有关就足够了。在RL中，代理通过分配奖励来评估他们的环境（例如，我的植物在1到10的尺度上有多健康）。术语“强化”来自于代理有望学会寻求导致良好结果（高奖励）的行为，并回避惩罚性情况（低或负奖励）。代理与其环境的交互通常通过创建其计算模拟来建模。正如你可以从我们提供的例子中想象的那样，这些模拟很快就会变得复杂起来。
- en: We don’t have gardening robots like the one I’ve sketched yet. And we don’t
    know which AI paradigm will get us there.^([2](ch01.xhtml#idm44990045384464))
    What I do know is that the world is full of complex, dynamic and interesting examples
    that we need to tackle. For that we need computational frameworks that help us
    do that, and Ray was built to do exactly that. RISELab created Ray to build and
    run complex AI applications at scale, and reinforcement learning has been an integral
    part of Ray from the start.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有像我描绘的那种园艺机器人。我们也不知道哪种人工智能范式会让我们达到那里。我知道的是，世界充满了复杂、动态和有趣的例子，我们需要应对这些问题。为此，我们需要帮助我们做到这一点的计算框架，而Ray正是为此而建立的。RISELab创建Ray以在规模上构建和运行复杂的人工智能应用程序，而强化学习从一开始就是Ray的一个组成部分。
- en: 'Three Layers: Core, Libraries and Ecosystem'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 三层：核心、库和生态系统
- en: Now that you know why Ray was built and what its creators had in mind, let’s
    look at the three layers of Ray.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道为什么Ray被建立以及其创作者的初衷，让我们来看看Ray的三个层次。
- en: A low-level, distributed computing framework for Python with a concise core
    API.^([3](ch01.xhtml#idm44990045356496))
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用简明的核心API为Python提供的低级分布式计算框架。^([3](ch01.xhtml#idm44990045356496))
- en: A set of high-level libraries for data science built and maintained by the creators
    of Ray.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由Ray的创建者构建和维护的一组高级数据科学库。
- en: A growing ecosystem of integrations and partnerships with other notable projects.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个与其他著名项目进行整合和合作的不断增长的生态系统。
- en: There’s a lot to unpack here, and we’ll look into each of these layers individually
    in the remainder of this chapter. You can imagine Ray’s core engine with its API
    at the center of things, on which everything else builds. Ray’s data science libraries
    build on top of it. In practice, most data scientists will use these higher level
    libraries directly and won’t often need to resort to the core API. The growing
    number of third-party integrations for Ray is another great entrypoint for experienced
    practitioners. Let’s look into each one of the layers one by one.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多内容需要解开，我们将在本章节的剩余部分逐个探讨这些层次。您可以将 Ray 的核心引擎及其 API 想象为中心，其他所有东西都是在其基础上构建的。Ray
    的数据科学库则是在其之上构建的。在实践中，大多数数据科学家将直接使用这些更高级别的库，并且不经常需要回到核心 API。对于经验丰富的从业者来说，Ray 的第三方集成数量不断增加，是另一个很好的切入点。让我们逐个看看这些层次。
- en: A Distributed Computing Framework
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式计算框架
- en: At its core, Ray is a distributed computing framework. We’ll provide you with
    just the basic terminology here, and talk about Ray’s architecture in depth in
    [Chapter 2](ch02.xhtml#chapter_02). In short, Ray sets up and manages clusters
    of computers so that you can run distributed tasks on them. A ray cluster consists
    of nodes that are connected to each other via a network. You program against the
    so-called *driver*, the program root, which lives on the *head node*. The driver
    can run *jobs*, that is a collection of tasks, that are run on the nodes in the
    cluster. Specifically, the individual tasks of a job are run on *worker* processes
    on *worker nodes*. Figure [Figure 1-1](#fig_simple_cluster) illustrates the basic
    structure of a Ray cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 的核心是一个分布式计算框架。在这里，我们只介绍基本术语，并在[第二章](ch02.xhtml#chapter_02)中深入讨论 Ray 的架构。简而言之，Ray
    设置并管理计算机群集，以便您可以在其上运行分布式任务。一个 Ray 群集由通过网络连接的节点组成。您将程序编写到所谓的 *driver*，即程序根节点上，该节点位于
    *head node* 上。*driver* 可以运行 *jobs*，即在群集节点上运行的任务集合。具体来说，一个 job 的各个任务在 *worker nodes*
    上的 *worker* 进程上运行。图 [图 1-1](#fig_simple_cluster) 描述了 Ray 群集的基本结构。
- en: '![Ray cluster schematics](assets/simple_cluster.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![Ray 群集示意图](assets/simple_cluster.png)'
- en: Figure 1-1\. The basic components of a Ray cluster
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-1\. Ray 簇的基本组件
- en: What’s interesting is that a Ray cluster can also be a *local cluster*, i.e.
    a cluster consisting just of your own computer. In this case, there’s just one
    node, namely the head node, which has the driver process and some worker processes.
    The default number of worker processes is the number of CPUs available on your
    machine.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Ray 群集也可以是一个 *本地群集*，即仅由您自己的计算机组成的群集。在这种情况下，只有一个节点，即头节点，它具有驱动程序进程和一些工作进程。默认的工作进程数量是您机器上可用的
    CPU 数量。
- en: 'With that knowledge at hand, it’s time to get your hands dirty and run your
    first local Ray cluster. Installing Ray^([4](ch01.xhtml#idm44990042817344)) on
    any of the major operating systems should work seamlessly using `pip`:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些知识，现在是时候动手运行您的第一个本地 Ray 群集了。在任何主流操作系统上使用 `pip` 安装 Ray^([4](ch01.xhtml#idm44990042817344))
    应该是无缝的：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With a simple `pip install ray` you would have installed just the very basics
    of Ray. Since we want to explore some advanced features, we installed the “extras”
    `rllib`, `serve` and `tune`, which we’ll discuss in a bit. Depending on your system
    configuration you may not need the quotation marks in the above installation command.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单的 `pip install ray` 命令，您只安装了 Ray 的基本组件。由于我们希望探索一些高级功能，我们还安装了“extras” 中的
    `rllib`、`serve` 和 `tune`，稍后我们将讨论它们。根据您的系统配置，您可能不需要上述安装命令中的引号。
- en: 'Next, go ahead and start a Python session. You could use the `ipython` interpreter,
    which I find to be the most suitable environment for following along simple examples.
    If you don’t feel like typing in the commands yourself, you can also jump into
    the [jupyter notebook for this chapter](https://github.com/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb)
    and run the code there. The choice is up to you, but in any case please remember
    to use Python version `3.7` or later. In your Python session you can now easily
    import and initialize Ray as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，请启动一个 Python 会话。您可以使用 `ipython` 解释器，我觉得它非常适合跟随简单示例。如果您不想自己输入命令，也可以转到[本章节的
    jupyter notebook](https://github.com/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb)
    并在那里运行代码。选择权在您，但无论如何，请记住使用 Python 版本 `3.7` 或更高版本。在您的 Python 会话中，您现在可以轻松导入并初始化
    Ray，如下所示：
- en: Example 1-1\.
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-1\.
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With those two lines of code you’ve started a Ray cluster on your local machine.
    This cluster can utilize all the cores available on your computer as workers.
    In this case you didn’t provide any arguments to the `init` function. If you wanted
    to run Ray on a “real” cluster, you’d have to pass more arguments to `init`. The
    rest of your code would stay the same.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两行代码，你已经在本地机器上启动了一个 Ray 集群。这个集群可以作为工作节点利用你计算机上所有可用的核心。在这种情况下，你没有向 `init`
    函数提供任何参数。如果你想在一个“真实”的集群上运行 Ray，你需要向 `init` 传递更多参数。其余的代码将保持不变。
- en: 'After running this code you should see output of the following form (we use
    ellipses to remove the clutter):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码后，你应该会看到以下形式的输出（我们使用省略号删除了杂乱的内容）：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This indicates that your Ray cluster is up and running. As you can see from
    the first line of the output, Ray comes with its own, pre-packaged dashboard.
    In all likelihood you can check it out at [*http://127.0.0.1:8265*](http://127.0.0.1:8265),
    unless your output shows a different port. If you want you can take your time
    to explore the dashboard for a little. For instance, you should see all your CPU
    cores listed and the total utilization of your (trivial) Ray application. We’ll
    come back to the dashboard in later chapters.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明你的 Ray 集群已经启动并运行。从输出的第一行可以看出，Ray 自带一个预打包的仪表板。很可能你可以在 [*http://127.0.0.1:8265*](http://127.0.0.1:8265)
    查看它，除非你的输出显示了不同的端口。如果愿意，你可以花些时间探索这个仪表板。例如，你应该看到列出了所有 CPU 核心以及你（简单的）Ray 应用程序的总利用率。我们将在后续章节中回到仪表板。
- en: We’re not quite ready to dive into all the details of a Ray cluster here. To
    jump ahead just a little, you might see the `raylet_ip_address`, which is a reference
    to a so-called *Raylet*, which is responsible for scheduling tasks on your worker
    nodes. Each Raylet has a store for distributed objects, which is hinted at by
    the `object_store_address` above. Once tasks are scheduled, they get executed
    by worker processes. In [Chapter 2](ch02.xhtml#chapter_02) you’ll get a much better
    understanding of all these components and how they make up a Ray cluster.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里还没有完全准备好深入了解 Ray 集群的所有细节。稍微提前一点，你可能会看到 `raylet_ip_address`，它是所谓的 *Raylet*
    的引用，负责在你的工作节点上安排任务。每个 Raylet 都有一个用于分布式对象的存储，上面的 `object_store_address` 暗示了这一点。任务一旦被安排，就会由工作进程执行。在
    [第二章](ch02.xhtml#chapter_02) 中，你将更好地理解所有这些组件以及它们如何组成一个 Ray 集群。
- en: Before moving on, we should also briefly mention that the Ray core API is very
    accessible and easy to use. But since it is also a rather low-level interface,
    it takes time to build interesting examples with it. [Chapter 2](ch02.xhtml#chapter_02)
    has an extensive first example to get you started with the Ray core API, and in
    [Chapter 3](ch03.xhtml#chapter_03) you’ll see how to build a more interesting
    Ray application for reinforcement learning.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们还应该简要提到 Ray 核心 API 非常易于访问和使用。但由于它也是一个相对底层的接口，使用它构建有趣的示例需要一些时间。[第二章](ch02.xhtml#chapter_02)
    中有一个广泛的第一个示例，可以帮助你开始使用 Ray 核心 API，在 [第三章](ch03.xhtml#chapter_03) 中，你将看到如何构建一个更有趣的
    Ray 强化学习应用程序。
- en: Right now your Ray cluster doesn’t do much, but that’s about to change. After
    giving you a quick introduction to the data science workflow in the following
    section, you’ll run your first concrete Ray examples.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你的 Ray 集群还没有做太多事情，但这将很快改变。在下一节快速介绍数据科学工作流程之后，你将运行你的第一个具体的 Ray 示例。
- en: A Suite of Data Science Libraries
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一套数据科学库
- en: Moving on to the second layer of Ray, in this section we’ll introduce all the
    data science libraries that Ray comes with. To do so, let’s first take a bird’s
    eye view on what it means to do data science. Once you understand this context,
    it’s much easier to place Ray’s higher-level libraries and see how they can be
    useful to you. If you have a good idea of the data science process, you can safely
    skip ahead to section [“Data Processing with Ray Data”](#section_data_processing).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 转向 Ray 的第二层，本节将介绍 Ray 自带的所有数据科学库。为此，让我们首先俯瞰一下做数据科学意味着什么。一旦理解了这个背景，理解 Ray 的高级库并看到它们如何对你有用就容易得多了。如果你对数据科学过程有很好的理解，可以直接跳到
    [“使用 Ray Data 进行数据处理”](#section_data_processing) 部分。
- en: Machine Learning and the Data Science Workflow
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习与数据科学工作流程
- en: The somewhat elusive term “data science” (DS) evolved quite a bit in recent
    years, and you can find many definitions of varying usefulness online.^([5](ch01.xhtml#idm44990042948624))
    To me, it’s *the practice of gaining insights and building real-world applications
    by leveraging data*. That’s quite a broad definition, and you don’t have to agree
    with me. My point is that data science is an inherently practical and applied
    field that centers around building and understanding things, which makes fairly
    little sense in a *purely* academic context. In that sense, describing practitioners
    of this field as “data scientists” is about as bad of a misnomer as describing
    hackers as “computer scientists”.^([6](ch01.xhtml#idm44990044482384))
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: “数据科学”（DS）这个有些难以捉摸的术语近年来发生了很大变化，你可以在网上找到许多不同用途的定义。[^5] 对我来说，它是*通过利用数据获得见解并构建真实应用*的实践。这是一个非常广泛的定义，你不一定同意我的观点。我的观点是，数据科学是一个围绕构建和理解事物的实践和应用领域，这在*纯粹*学术背景下几乎没有意义。从这个意义上讲，将这个领域的从业者描述为“数据科学家”就像将黑客描述为“计算机科学家”一样不合适。[^6]
- en: 'Since you are familiar with Python and hopefully bring a certain craftsmanship
    attitude with you, we can approach the Ray’s data science libraries from a very
    pragmatic angle. Doing data science in practice is an iterative process that goes
    something like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你对Python很熟悉，希望你带有一定的工匠精神，我们可以从非常实用的角度来探讨Ray的数据科学库。在实践中进行数据科学是一个迭代的过程，大致如下：
- en: Requirements engineering
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 需求工程
- en: You talk to stakeholders to identify the problems you need to solve and clarify
    the requirements for this project.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要与利益相关者交流，明确需要解决的问题，并为这个项目澄清需求。
- en: Data collection
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集
- en: Then you source, collect and inspect the data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你收集、检查和审视数据。
- en: Data processing
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理
- en: Afterwards you process the data such that you can tackle the problem.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你处理数据，以便能够解决问题。
- en: Model building
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建
- en: You then move on to build a model (in the broadest sense) using the data. That
    could be a dashboard with important metrics, a visualisation, or a machine learning
    model, among many other things.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，你开始使用数据构建模型（广义上），这可以是一个包含重要指标的仪表盘，一个可视化效果，或者一个机器学习模型，还有许多其他形式。
- en: Model evaluation
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估
- en: The next step is to evaluate your model against the requirements in the first
    step.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤是根据第一步的要求评估你的模型。
- en: Deployment
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 部署
- en: If all goes well (it likely doesn’t), you deploy your solution in a production
    environment. You should understand this as an ongoing process that needs to be
    monitored, not as a one-off step.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利（很可能不会），你将在生产环境中部署解决方案。你应该将其视为需要监控的持续过程，而不是一次性步骤。
- en: Otherwise, you need to circle back and start from the top. The most likely outcome
    is that you need to improve your solution in various ways, even after initial
    deployment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，你需要回到起点重新开始。最有可能的结果是，即使在初次部署之后，你也需要在各种方面改进解决方案。
- en: 'Machine learning is not necessarily part of this process, but you can see how
    building smart applications or gaining insights might benefit from ML. Building
    a face detection app into your social media platform, for better or worse, might
    be one example of that. When the data science process just described explicitly
    involves building machine learning models, you can further specify some steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习并不一定是这个过程的一部分，但你可以看到构建智能应用或获得见解如何从机器学习中受益。在你的社交媒体平台中建立人脸检测应用，无论是好是坏，可能就是一个例子。当明确包括构建机器学习模型的数据科学过程时，你可以进一步指定一些步骤：
- en: Data processing
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理
- en: To train machine learning models, you need data in a format that is understood
    by your ML model. The process of transforming and selecting what data should be
    fed into your model is often called *feature engineering*. This step can be messy.
    You’ll benefit a lot if you can rely on common tools to do the job.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练机器学习模型，你需要数据以一种能被你的ML模型理解的格式。转换和选择应该被馈送到模型中的数据的过程通常称为*特征工程*。这一步骤可能会很混乱。如果你能依靠常用工具来完成这项工作，你将受益匪浅。
- en: Model training
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练
- en: In ML you need to train your algorithms on data that got processed in the last
    step. This includes selecting the right algorithm for the job, and it helps if
    you can choose from a wide variety.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，你需要在上一步处理的数据上训练算法。这包括选择适合任务的正确算法，如果你能从多种算法中选择，那将会很有帮助。
- en: Hyperparameter tuning
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优
- en: Machine learning models have parameters that are tuned in the model training
    step. Most ML models also have another set of parameters, called *hyperparameters*
    that can be modified prior to training. These parameters can heavily influence
    the performance of your resulting ML model and need to be tuned properly. There
    are good tools to help automate that process.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型具有在模型训练步骤中调整的参数。大多数 ML 模型还有另一组参数，称为*超参数*，可以在训练之前修改。这些参数可以严重影响您所得到的 ML
    模型的性能，需要适当地进行调整。有很好的工具可以帮助自动化这个过程。
- en: Model serving
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务
- en: Trained models need to be deployed. To serve a model means to make it available
    to whoever needs access by whatever means necessary. In prototypes, you often
    use simple HTTP servers, but there are many specialised software packages for
    ML model serving.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后的模型需要部署。服务一个模型意味着通过任何必要的手段使其对需要访问的人员可用。在原型中，通常使用简单的 HTTP 服务器，但也有许多专门的 ML
    模型服务软件包。
- en: This list is by no means exhaustive. Don’t worry if you’ve never gone through
    these steps or struggle with the terminology, we’ll come back to this in much
    more detail in later chapters. If you want to understand more about the holistic
    view of the data science process when building machine learning applications,
    the book [Building Machine Learning Powered Applications](https://www.oreilly.com/library/view/building-machine-learning/9781492045106/)
    is dedicated to it entirely.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表并不全面。如果你从未经历过这些步骤或对术语感到困惑，不要担心，我们将在后面的章节中详细讨论。如果你想更深入地了解构建机器学习应用程序时数据科学流程的整体视图，书籍[《Building
    Machine Learning Powered Applications》](https://www.oreilly.com/library/view/building-machine-learning/9781492045106/)专门讨论了这个问题。
- en: 'Figure [Figure 1-2](#fig_ds_experimentation) gives an overview of the steps
    we just discussed:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [Figure 1-2](#fig_ds_experimentation) 概述了我们刚讨论的步骤：
- en: '![Data science experimentation workflow](assets/ds_workflow.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![数据科学实验工作流](assets/ds_workflow.png)'
- en: Figure 1-2\. An overview of the data science experimentation workflow using
    machine learning
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 使用机器学习进行数据科学实验工作流程的概述
- en: At this point you might be wondering how any of this relates to Ray. The good
    news is that Ray has a dedicated library for each of the four ML-specific tasks
    above, covering data processing, model training, hyperparameter tuning and model
    serving. And the way Ray is designed, all these libraries are *distributed by
    construction*. Let’s walk through each of them one-by-one.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可能想知道这些与 Ray 有什么关系。好消息是 Ray 为上述四种专门的机器学习任务各自提供了专用库，涵盖了数据处理、模型训练、超参数调整和模型服务。而
    Ray 的设计方式，所有这些库都是*分布式构建*的。接下来我们逐一介绍每一个。
- en: Data Processing with Ray Data
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Ray Data 进行数据处理
- en: The first high-level library of Ray we talk about is called “Ray Data”. This
    library contains a data structure aptly called `Dataset`, a multitude of connectors
    for loading data from various formats and systems, an API for transforming such
    datasets, a way to build data processing pipelines with them, and many integrations
    with other data processing frameworks. The `Dataset` abstraction builds on the
    powerful [Arrow framework](https://arrow.apache.org/).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 的第一个高级库被称为“Ray Data”。这个库包含一个称为`Dataset`的数据结构，用于加载各种格式和系统的数据的多种连接器，用于转换这些数据集的API，用于构建数据处理管道以及与其他数据处理框架的许多集成。`Dataset`抽象构建在强大的[Arrow
    框架](https://arrow.apache.org/)之上。
- en: 'To use Ray Data, you need to install Arrow for Python, for instance by running
    `pip install pyarrow`. We’ll now discuss a simple example that creates a distributed
    `Dataset` on your local Ray cluster from a Python data structure. Specifically,
    you’ll create a dataset from a Python dictionary containing a string `name` and
    an integer-valued `data` for `10000` entries:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Ray Data，你需要安装 Python 的 Arrow，例如通过运行`pip install pyarrow`。我们现在将讨论一个简单的示例，从
    Python 数据结构创建一个在本地 Ray 集群上分布式的`Dataset`。具体来说，你将从一个包含字符串`name`和整数`data`的 Python
    字典创建一个包含`10000`个条目的数据集：
- en: Example 1-2\.
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-2\.
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO1-1)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO1-1)'
- en: Creating a `Dataset` by using `from_items` from the `ray.data` module.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ray.data`模块中的`from_items`创建一个`Dataset`。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO1-2)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO1-2)'
- en: Printing the first 10 items of the `Dataset`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 打印`Dataset`的前 10 个条目。
- en: 'To `show` a `Dataset` means to print some of its values. You should see precisely
    `5` so-called `ArrowRow` elements on your command line, like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`show`一个`Dataset`意味着打印它的一些值。你应该在命令行上精确地看到`5`个所谓的`ArrowRow`元素，如下所示：'
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Great, now you have some distributed rows, but what can you do with that data?
    The `Dataset` API bets heavily on functional programming, as it is very well suited
    for data transformations. Even though Python 3 made a point of hiding some of
    its functional programming capabilities, you’re probably familiar with functionality
    such as `map`, `filter` and others. If not, it’s easy enough to pick up. `map`
    takes each element of your dataset and transforms is into something else, in parallel.
    `filter` removes data points according to a boolean filter function. And the slightly
    more elaborate `flat_map` first maps values similarly to `map`, but then also
    “flattens” the result. For instance, if `map` would produce a list of lists, `flat_map`
    would flatten out the nested lists and give you just a list. Equipped with these
    three functional API calls, let’s see how easily you can transform your dataset
    `ds`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了一些分布式的行数据，但是你能用这些数据做什么呢？`Dataset` API 在函数式编程方面表现得非常出色，因为它非常适合数据转换。尽管 Python
    3 在隐藏一些函数式编程能力时有所改进，但你可能已经熟悉诸如 `map`、`filter` 等功能。如果还不熟悉，学起来也很容易。`map` 对数据集的每个元素进行转换，并行进行。`filter`
    根据布尔过滤函数删除数据点。稍微复杂一点的 `flat_map` 首先类似于 `map` 映射值，然后还会“展平”结果。例如，如果 `map` 会生成一个列表的列表，`flat_map`
    将会展平嵌套列表并给出一个单一的列表。有了这三个函数式 API 调用，让我们看看你能多轻松地转换你的数据集 `ds`：
- en: Example 1-3\. Transforming a `Dataset` with common functional programming routines
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-3。使用常见的函数式编程例程转换 `Dataset`。
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO2-1)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO2-1)'
- en: We `map` each row of `ds` to only keep the square value of its `data` entry.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `ds` 的每一行映射为仅保留其 `data` 条目的平方值。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO2-2)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO2-2)'
- en: Then we `filter` the `squares` to only keep even numbers (a total of 5000 elements).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们筛选出 `squares` 中的偶数（共 5000 个元素）。
- en: '[![3](assets/3.png)](#co_an_overview_of_ray_CO2-3)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_an_overview_of_ray_CO2-3)'
- en: We then use `flat_map` to augment the remaining values with their respective
    cubes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `flat_map` 用其各自的立方体增强剩余值。
- en: '[![4](assets/4.png)](#co_an_overview_of_ray_CO2-4)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_an_overview_of_ray_CO2-4)'
- en: To `take` a total of `10` values means to leave Ray and return a Python list
    with these values that we can print.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`take` 总共 `10` 个值意味着离开 Ray 并返回一个可以打印这些值的 Python 列表。'
- en: The drawback of `Dataset` transformations is that each step gets executed synchronously.
    In example [Example 1-3](#ray_data_transform) this is a non-issue, but for complex
    tasks that e.g. mix reading files and processing data, you want an execution that
    can overlap individual tasks. `DatasetPipeline` does exactly that. Let’s rewrite
    the last example into a pipeline.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset` 转换的缺点是每个步骤都是同步执行的。在示例 [Example 1-3](#ray_data_transform) 中，这不是问题，但对于复杂的任务，例如混合读取文件和处理数据，您希望执行可以重叠各个任务。`DatasetPipeline`
    正是这样做的。让我们将最后一个例子重写为一个流水线。'
- en: Example 1-4\.
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-4。
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO3-1)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO3-1)'
- en: You can turn a `Dataset` into a pipeline by calling `.window()` on it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在其上调用 `.window()` 将 `Dataset` 转换为流水线。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO3-2)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO3-2)'
- en: Pipeline steps can be chained to yield the same result as before.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线步骤可以链接以产生与以前相同的结果。
- en: There’s a lot more to be said about Ray Data, especially its integration with
    notable data processing systems, but we’ll have to defer an in-depth discussion
    until [Chapter 7](ch07.xhtml#chapter_07).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 数据还有很多要说的，特别是它与显著数据处理系统的集成，但我们必须推迟深入讨论直到 [Chapter 7](ch07.xhtml#chapter_07)。
- en: Model Training
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练。
- en: Moving on to the next set of libraries, let’s look at the distributed training
    capabilities of Ray. For that, you have access to two libraries. One is dedicated
    to reinforcement learning specifically, the other one has a different scope and
    is aimed primarily at supervised learning tasks.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们看看 Ray 的分布式训练能力。为此，您可以访问两个库。一个专门用于强化学习，另一个则具有不同的范围，主要针对监督学习任务。
- en: Reinforcement learning with Ray RLlib
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Ray RLlib 进行强化学习。
- en: Let’s start with *Ray RLlib* for reinforcement learning. This library is powered
    by the modern ML frameworks TensorFlow and PyTorch, and you can choose which one
    to use. Both frameworks seem to converge more and more conceptually, so you can
    pick the one you like most without losing much in the process. Throughout the
    book we use TensorFlow for consistency. Go ahead and install it with `pip install
    tensorflow` right now.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 *Ray RLlib* 开始进行强化学习。这个库由现代 ML 框架 TensorFlow 和 PyTorch 提供支持，你可以选择使用其中之一。这两个框架在概念上似乎越来越收敛，所以你可以根据自己的喜好选择其中一个，而不会在过程中失去太多。在整本书中，为了保持一致性，我们使用
    TensorFlow。现在就可以通过 `pip install tensorflow` 安装它。
- en: One of the easiest ways to run examples with RLlib is to use the command line
    tool `rllib`, which we’ve already implicitly installed earlier with `pip`. Once
    you run more complex examples in [Chapter 4](ch04.xhtml#chapter_04), you will
    mostly rely on its Python API, but for now we just want to get a first taste of
    running RL experiments.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RLlib 中运行示例的最简单方法之一是使用命令行工具 `rllib`，我们之前已经通过 `pip` 隐式安装过了。一旦你在 [第四章](ch04.xhtml#chapter_04)
    中运行更复杂的示例，你将主要依赖其 Python API，但现在我们只是想初步尝试运行 RL 实验。
- en: We’ll look at a fairly classical control problem of balancing a pendulum. Imagine
    you have a pendulum like the one in figure [Figure 1-3](#fig_pendulum), fixed
    at as single point and subject to gravity. You can manipulate that pendulum by
    giving it a push from the left or the right. If you assert just the right amount
    of force, the pendulum might remain in an upright position. That’s our goal -
    and the question is whether we can teach a reinforcement learning algorithm to
    do so for us.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论一个相当经典的控制问题，即平衡摆动摆的问题。想象一下，你有一个像图 [图 1-3](#fig_pendulum) 中所示的摆锤，固定在一个点上并受重力作用。你可以通过从左侧或右侧推动摆锤来操纵它。如果你施加恰到好处的力量，摆锤可能会保持竖直位置。这是我们的目标
    - 我们要解决的问题是是否能教会一个强化学习算法来为我们做到这一点。
- en: '![Pendulum](assets/pendulum.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![Pendulum](assets/pendulum.png)'
- en: Figure 1-3\. Controlling a simple pendulum by asserting force to the left or
    the right
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 控制一个简单的摆锤，通过向左或向右施加力来实现
- en: Specifically, we want to train a reinforcement learning agent that can push
    to the left or right, thereby acting on its environment (manipulating the pendulum)
    to reach the “upright position” goal for which it will be rewarded. To tackle
    this problem with Ray RLlib, store the following content in a file called `pendulum.yml`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们希望训练一个能够向左或向右推动的强化学习代理，从而通过作用于其环境（操纵摆锤）来达到“竖直位置”目标，进而获得奖励。要使用 Ray RLlib
    解决这个问题，可以将以下内容保存在名为 `pendulum.yml` 的文件中。
- en: Example 1-5\.
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-5\.
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO4-1)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO4-1)'
- en: The `Pendulum-v1` environment simulates the pendulum problem we just described.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`Pendulum-v1` 环境模拟了我们刚刚描述的摆动问题。'
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO4-2)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO4-2)'
- en: We use a powerful RL algorithm called Proximal Policy Optimization, or PPO.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一种强大的 RL 算法叫做 Proximal Policy Optimization，即 PPO。
- en: '[![3](assets/3.png)](#co_an_overview_of_ray_CO4-3)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_an_overview_of_ray_CO4-3)'
- en: After every five “training iterations” we checkpoint a model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 每经过五次“训练迭代”我们就会对模型进行检查点保存。
- en: '[![4](assets/4.png)](#co_an_overview_of_ray_CO4-4)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_an_overview_of_ray_CO4-4)'
- en: Once we reach a reward of `-800` , we stop the experiment.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们达到 `-800` 的奖励，我们将停止实验。
- en: '[![5](assets/5.png)](#co_an_overview_of_ray_CO4-5)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_an_overview_of_ray_CO4-5)'
- en: The PPO needs some RL-specific configuration to make it work for this problem.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: PPO 需要一些 RL 特定的配置才能解决这个问题。
- en: 'The details of this configuration file don’t matter much at this point, don’t
    get distracted by them. The important part is that you specify the built-in `Pendulum-v1`
    environment and sufficient RL-specific configuration to ensure the training procedure
    works. The configuration is a simplified version of one of Ray’s [tuned examples](https://github.com/ray-project/ray/tree/master/rllib/tuned_examples).
    We chose this one because it doesn’t require any special hardware and finishes
    in a matter of minutes. If your computer is powerful enough, you can try to run
    the tuned example as well, which should yield much better results. To train this
    pendulum example you can now simply run:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置文件的详细信息在这一点上并不重要，请不要被它们分散注意力。重要的部分是你要指定内置的`Pendulum-v1`环境以及足够的RL特定配置，以确保训练过程顺利进行。配置是Ray的一个简化版本的[tuned
    examples](https://github.com/ray-project/ray/tree/master/rllib/tuned_examples)之一。我们选择了这个配置，因为它不需要任何特殊的硬件，并且在几分钟内完成。如果你的计算机足够强大，你也可以尝试运行这个调整后的示例，它应该会得到更好的结果。要训练这个摆例子，你现在可以简单地运行：
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you want, you can check the output of this Ray program and see how the different
    metrics evolve during the training procedure. In case you don’t want to create
    this file on your own, and want to run an experiment which gives you much better
    results, you can also run this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你可以检查这个Ray程序的输出，并查看训练过程中不同指标的演变。如果你不想自己创建这个文件，并且想要运行一个能给你更好结果的实验，你也可以这样运行：
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In any case, assuming the training program finished, we can now check how well
    it worked. To visualize the trained pendulum you need to install one more Python
    library with `pip install pyglet`. The only other thing you need to figure out
    is where Ray stored your training progress. When you run `rllib train` for an
    experiment, Ray will create a unique experiment ID for you and stores results
    in a sub-folder of `~/ray-results` by default. For the training configuration
    we used, you should see a folder with results that looks like `~/ray_results/pendulum-ppo/PPO_Pendulum-v1_<experiment_id>`.
    During the training procedure intermediate model checkpoints get generated in
    the same folder. For instance, I have a folder on my machine called:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，假设训练程序已经完成，我们现在可以检查它的表现如何。要可视化训练过的摆，你需要安装另一个Python库，使用`pip install pyglet`。你需要弄清楚的另一件事是Ray存储了你的训练进展的地方。当你运行`rllib
    train`进行实验时，Ray会为你创建一个唯一的实验ID，并默认将结果存储在`~/ray-results`的子文件夹中。对于我们使用的训练配置，你应该看到一个结果文件夹，看起来像是`~/ray_results/pendulum-ppo/PPO_Pendulum-v1_<experiment_id>`。在训练过程中，中间的模型检查点会在同一个文件夹中生成。例如，在我的机器上有一个文件夹：
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once you figured out the experiment ID and chose a checkpoint ID (as a rule
    of thumb the larger the ID, the better the results), you can evaluate the training
    performance of your pendulum training run like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你找到实验ID并选择了检查点ID（作为经验法则，ID越大，结果越好），你可以像这样评估你的摆训练运行的训练性能：
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You should see an animation of a pendulum controlled by an agent that looks
    like figure [Figure 1-3](#fig_pendulum). Since we opted for a quick training procedure
    instead of maximizing performance, you should see the agent struggle with the
    pendulum exercise. We could have done much better, and if you’re interested to
    scan Ray’s tuned examples for the `Pendulum-v1` environment, you’ll find an abundance
    of solutions to this exercise. The point of this example was to show you how simple
    it can be to train and evaluate reinforcement learning tasks with RLlib, using
    just two command line calls to `rllib`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一个由代理控制的摆的动画，看起来像[图1-3](#fig_pendulum)。由于我们选择了快速的训练过程而不是最大化性能，你应该看到代理在摆运动中有些困难。我们本可以做得更好，如果你有兴趣浏览Ray调整后的示例来针对`Pendulum-v1`环境，你会找到许多这个练习的解决方案。这个示例的重点是向你展示使用RLlib来训练和评估强化学习任务可以有多简单，只需两个命令行调用到`rllib`。
- en: Distributed training with Ray Train
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Ray进行分布式训练
- en: 'Ray RLlib is dedicated to reinforcement learning, but what do you do if you
    need to train models for other types of machine learning, like supervised learning?
    You can use another Ray library for distributed training in this case, called
    *Ray Train*. At this point, we don’t have built up enough knowledge of frameworks
    such as `TensorFlow` to give you a concrete and informative example for Ray Train.
    We’ll discuss all of that in [Chapter 6](ch06.xhtml#chapter_06), when it’s time
    to. But we can at least roughly sketch what a distributed training “wrapper” for
    an ML model would look like, which is simple enough conceptually:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Ray RLlib专注于强化学习，但如果你需要为其他类型的机器学习，比如监督学习，训练模型，你可以在这种情况下使用另一个Ray库进行分布式训练，称为*Ray
    Train*。目前，我们对诸如`TensorFlow`之类的框架尚不了解，无法为Ray Train给出具体和有信息的例子。在[第6章](ch06.xhtml#chapter_06)讨论时，我们会讨论所有这些。但我们至少可以大致勾画一下ML模型的分布式训练“包装器”会是什么样子，概念上足够简单：
- en: Example 1-6\.
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例1-6。
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO5-1)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO5-1)'
- en: First, define your ML model training function. We simply pass here.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，定义你的ML模型训练函数。我们这里简单传递。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO5-2)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO5-2)'
- en: Then initialize a `Trainer` instance with TensorFlow as the backend.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后用TensorFlow作为后端初始化一个`Trainer`实例。
- en: '[![3](assets/3.png)](#co_an_overview_of_ray_CO5-3)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_an_overview_of_ray_CO5-3)'
- en: Lastly, scale out your training function on a Ray cluster.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在Ray集群上扩展你的训练函数。
- en: If you’re interested in distributed training, you could jump ahead to [Chapter 6](ch06.xhtml#chapter_06).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对分布式训练感兴趣，你可以跳到[第6章](ch06.xhtml#chapter_06)。
- en: Hyperparameter Tuning
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调整
- en: 'Naming things is hard, but the Ray team hit the spot with *Ray Tune*, which
    you can use to tune all sorts of parameters. Specifically, it was built to find
    good hyperparameters for machine learning models. The typical setup is as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 命名事物很难，但Ray团队通过*Ray Tune*找到了关键点，你可以用它来调整各种参数。具体而言，它被设计用于为机器学习模型找到良好的超参数。典型的设置如下：
- en: You want to run an extremely computationally expensive training function. In
    ML it’s not uncommon to run training procedures that take days, if not weeks,
    but let’s say you’re dealing with just a couple of minutes.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想运行一个非常耗费计算资源的训练函数。在ML中，运行需要数天甚至数周的训练过程并不罕见，但我们假设你只需几分钟。
- en: As result of training, you compute a so-called objective function. Usually you
    either want to maximize your gains or minimize your losses in terms of performance
    of your experiment.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为训练的结果，你计算一个所谓的目标函数。通常你要么希望最大化你的收益，要么最小化你的损失，以你实验的性能为准。
- en: The tricky bit is that your training function might depend on certain parameters,
    hyperparameters, that influence the value of your objective function.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难点在于你的训练函数可能依赖于某些参数、超参数，这些影响你的目标函数值。
- en: You may have a hunch what individual hyperparameters should be, but tuning them
    all can be difficult. Even if you can restrict these parameters to a sensible
    range, it’s usually prohibitive to test a wide range of combinations. Your training
    function is simply too expensive.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能有关于个别超参数应该是什么的直觉，但调整它们可能很困难。即使你可以将这些参数限制在合理的范围内，测试各种组合通常是不可行的。你的训练函数简直太昂贵了。
- en: What can you do to efficiently sample hyperparameters and get “good enough”
    results on your objective? The field concerned with solving this problem is called
    *hyperparameter optimization* (HPO), and Ray Tune has an enormous suite of algorithms
    for tackling it. Let’s look at a first example of Ray Tune used for the situation
    we just explained. The focus is yet again on Ray and its API, and not on a specific
    ML task (which we simply simulate for now).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你能做些什么来有效地采样超参数，并在你的目标上获得“足够好”的结果？专注于解决这个问题的领域称为*超参数优化*（HPO），而Ray Tune拥有大量用于解决此问题的算法。让我们看一个Ray
    Tune的第一个例子，用于我们刚刚解释的情况。重点再次在Ray及其API上，而不是特定的ML任务（我们现在只是模拟）。
- en: Example 1-7\. Minimizing an objective for an expensive training function with
    Ray Tune
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例1-7。使用Ray Tune最小化昂贵训练函数的目标
- en: '[PRE13]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO6-1)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO6-1)'
- en: We simulate an expensive training function that depends on two hyperparameters
    `x` and `y`, read from a `config`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模拟一个昂贵的训练函数，它依赖于从`config`读取的两个超参数`x`和`y`。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO6-2)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO6-2)'
- en: After sleeping for 5 seconds to simulate training and computing the objective
    we report back the score to `tune`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在睡眠了 5 秒钟以模拟训练和计算目标后，我们将分数报告给 `tune`。
- en: '[![3](assets/3.png)](#co_an_overview_of_ray_CO6-3)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_an_overview_of_ray_CO6-3)'
- en: The objective computes the mean of the squares of `x` and `y` and returns the
    square root of this term. This type of objective is fairly common in ML.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 目标函数计算 `x` 和 `y` 的平方的平均值，并返回该项的平方根。这种类型的目标函数在机器学习中非常常见。
- en: '[![4](assets/4.png)](#co_an_overview_of_ray_CO6-4)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_an_overview_of_ray_CO6-4)'
- en: We then use `tune.run` to initialize hyperparameter optimization on our `training_function`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着使用 `tune.run` 来初始化我们的 `training_function` 的超参数优化。
- en: '[![5](assets/5.png)](#co_an_overview_of_ray_CO6-5)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_an_overview_of_ray_CO6-5)'
- en: A key part is to provide a parameter space for `x` and `y` for `tune` to search
    over.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键部分是为 `tune` 提供 `x` 和 `y` 的参数空间以进行搜索。
- en: The Tune example in [Example 1-7](#ray_tune) finds the best possible choices
    of parameters `x` and `y` for a `training_function` with a given `objective` we
    want to minimize. Even though the objective function might look a little intimidating
    at first, since we compute the sum of squares of `x` and `y`, all values will
    be non-negative. That means the smallest value is obtained at `x=0` and `y=0`
    which evaluates the objective function to `0`.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[Example 1-7](#ray_tune) 中的 Tune 示例为一个具有给定 `objective` 的 `training_function`
    找到了最佳的参数 `x` 和 `y` 的选择。尽管目标函数一开始可能看起来有点吓人，因为我们计算 `x` 和 `y` 的平方和，所有的值都是非负的。这意味着在
    `x=0` 和 `y=0` 处获得最小值，这会使目标函数的值为 `0`。'
- en: We do a so-called *grid search* over all possible parameter combinations. As
    we explicitly pass in five possible values for both `x` and `y` that’s a total
    of `25` combinations that get fed into the training function. Since we instruct
    `training_function` to sleep for `10` seconds, testing all combinations of hyperparameters
    sequentially would take more than four minutes total. Since Ray is smart about
    parallelizing this workload, on my laptop this whole experiment only takes about
    `35` seconds. Now, imagine each training run would have taken several hours, and
    we’d have 20 instead of two hyperparameters. That makes grid search infeasible,
    especially if you don’t have educated guesses on the parameter range. In such
    situations you’ll have to use more elaborate HPO methods from Ray Tune, as discussed
    in [Chapter 5](ch05.xhtml#chapter_05).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行所谓的 *网格搜索*，遍历所有可能的参数组合。因为我们为 `x` 和 `y` 明确传递了五个可能的值，这总共有 `25` 个组合会传递给训练函数。由于我们指示
    `training_function` 睡眠 `10` 秒钟，顺序测试所有超参数组合将总共需要超过四分钟。由于 Ray 在并行化这个工作负载方面很聪明，在我的笔记本电脑上，整个实验只需要大约
    `35` 秒。现在想象一下，每个训练运行都需要几个小时，我们有20个而不是两个超参数。这使得网格搜索变得不可行，特别是如果你对参数范围没有明智的猜测。在这种情况下，你将不得不使用
    Ray Tune 中更复杂的超参数优化方法，正如 [Chapter 5](ch05.xhtml#chapter_05) 中讨论的那样。
- en: Model Serving
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型服务
- en: The last of Ray’s high-level libraries we’ll discuss specializes on model serving
    and is simply called *Ray Serve*. To see an example of it in action, you need
    a trained ML model to serve. Luckily, nowadays you can find many interesting models
    on the internet that have already been trained for you. For instance, *Hugging
    Face* has a variety of models available for you to download directly in Python.
    The model we’ll use is a language model called *GPT-2* that takes text as input
    and produces text to continue or complete the input. For example, you can prompt
    a question and GPT-2 will try to complete it.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 的高级库中的最后一个我们将讨论的专注于模型服务，简称为 *Ray Serve*。要看它在实际中的示例，你需要一个训练好的机器学习模型来提供服务。幸运的是，现在你可以在互联网上找到许多有趣的已经为你训练好的模型。例如，*Hugging
    Face* 提供了许多可直接在 Python 中下载的模型。我们将使用的模型是一个称为 *GPT-2* 的语言模型，它接受文本作为输入，并生成继续或完成输入的文本。例如，你可以提示一个问题，GPT-2
    将尝试完成它。
- en: Serving such a model is a good way to make it accessible. You may not now how
    to load and run a TensorFlow model on your computer, but you do now how to ask
    a question in plain English. Model serving hides the implementation details of
    a solution and lets users focus on providing inputs and understanding outputs
    of a model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 提供这样一个模型是使其易于访问的一个好方法。你可能不知道如何在你的电脑上加载和运行 TensorFlow 模型，但你现在知道如何用简单的英语提问。模型服务隐藏了解决方案的实现细节，让用户可以专注于提供输入和理解模型的输出。
- en: 'To proceed, make sure to run `pip install transformers` to install the Hugging
    Face library that has the model we want to use. With that we can now import and
    start an instance of Ray’s `serve` library, load and deploy a GPT-2 model and
    ask it for the meaning of life, like so:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续，请确保运行`pip install transformers`来安装Hugging Face库，该库包含我们想要使用的模型。有了这个，我们现在可以导入并启动Ray的`serve`库的实例，加载并部署一个GPT-2模型，并询问它生命的意义，就像这样：
- en: Example 1-8\.
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例1-8。
- en: '[PRE14]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_an_overview_of_ray_CO7-1)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_an_overview_of_ray_CO7-1)'
- en: We start `serve` locally.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本地启动`serve`。
- en: '[![2](assets/2.png)](#co_an_overview_of_ray_CO7-2)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_an_overview_of_ray_CO7-2)'
- en: The `@serve.deployment` decorator turns a function with a `request` parameter
    into a `serve` deployment.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`@serve.deployment`装饰器将一个带有`request`参数的函数转换为一个`serve`部署。'
- en: '[![3](assets/3.png)](#co_an_overview_of_ray_CO7-3)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_an_overview_of_ray_CO7-3)'
- en: Loading `language_model` inside the `model` function for every request is inefficient,
    but it’s the quickest way to show you a deployment.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次请求中加载`model`函数内的`language_model`是低效的，但这是展示部署的最快方法。
- en: '[![4](assets/4.png)](#co_an_overview_of_ray_CO7-4)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_an_overview_of_ray_CO7-4)'
- en: We ask the model to give us at most `100` characters to continue our query.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求模型给出最多`100`个字符来继续我们的查询。
- en: '[![5](assets/5.png)](#co_an_overview_of_ray_CO7-5)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_an_overview_of_ray_CO7-5)'
- en: Then we formally deploy the model so that it can start receiving requests over
    HTTP.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们正式部署模型，使其可以开始通过HTTP接收请求。
- en: '[![6](assets/6.png)](#co_an_overview_of_ray_CO7-6)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_an_overview_of_ray_CO7-6)'
- en: We use the indispensable `requests` library to get a response for any question
    you might have.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用不可或缺的`requests`库来获取您可能有的任何问题的响应。
- en: 'In [Link to Come] you will learn how to properly deploy models in various scenarios,
    but for now I encourage you to play around with this example and test different
    queries. Running the last two lines of code repeatedly will give you different
    answers practically every time. Here’s a darkly poetic gem, raising more questions,
    that I queried on my machine and slightly censored for underaged readers:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在[待定链接]中，您将学习如何在各种场景下正确地部署模型，但现在我鼓励您尝试这个示例并测试不同的查询。重复运行最后两行代码将会在实际操作中每次得到不同的答案。这是一颗深邃的诗意宝石，引发更多的问题，我在我的机器上查询过并稍作年龄限制的审查：
- en: '[PRE15]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This concludes our whirlwind tour of Ray’s data science libraries, the second
    of Ray’s layers. Before we wrap up this chapter, let’s have a very brief look
    at the third layer, the growing ecosystem around Ray.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们结束了对Ray数据科学库的风驰电掣的介绍，这是Ray的第二层。在我们结束本章之前，让我们简要地看一看第三层，即围绕Ray的不断增长的生态系统。
- en: A Growing Ecosystem
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个不断增长的生态系统
- en: Ray’s high-level libraries are powerful and deserve a much deeper treatment
    throughout the book. While their usefulness for the data science experimentation
    lifecycle is undeniable, I also don’t want to give off the impression that Ray
    is all you need from now on. In fact, I believe the best and most successful frameworks
    are the ones that integrate well with existing solutions and ideas. It’s better
    to focus on your core strengths and leverage other tools for what’s missing in
    your solution. There’s usually no reason to re-invent the wheel.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Ray的高级库功能强大，本书中应该对其进行更深入的探讨。虽然它们在数据科学实验生命周期中的用处不可否认，但我也不想给人留下Ray从现在开始就是您唯一需要的印象。事实上，我认为最好和最成功的框架是与现有解决方案和思想良好整合的框架。更好地专注于您的核心优势，并利用其他工具弥补解决方案中缺失的部分。通常没有理由重新发明轮子。
- en: How Ray Integrates and Extends
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ray如何整合和扩展
- en: To give you an example for how Ray integrates with other tools, consider that
    Ray Data is a relatively new addition to its libraries. If you want to boil it
    down, and maybe oversimplify a little, Ray is a compute-first framework. In contrast,
    distributed frameworks like Apache Spark^([7](ch01.xhtml#idm44990033933984)) or
    Dask can be considered data-first. Pretty much anything you do with Spark starts
    with the definition of a distributed dataset and transformations thereof. Dask
    bets on bringing common data structures like Pandas dataframes or Numpy arrays
    to a distributed setup. Both are immensely powerful in their own regard, and we’ll
    give you a more detailed and fair comparison to Ray in [Link to Come]. The gist
    of it is that Ray Data does not attempt to replace these tools. Instead, it integrates
    well with both. As you’ll come to see, that’s a common theme with Ray.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给您一个Ray如何与其他工具集成的示例，可以考虑Ray Data是其库中的一个相对较新的添加。如果要简化一下，也许有点过于简单化，Ray可以被视为一个以计算为先的框架。相比之下，像Apache
    Spark^([7](ch01.xhtml#idm44990033933984))或Dask等分布式框架可以被视为以数据为先。几乎您在Spark中做的任何事情都以定义分布式数据集及其转换开始。Dask则致力于将常见数据结构如Pandas数据帧或Numpy数组引入到分布式设置中。从各自的角度来看，它们都非常强大，我们将在[Link
    to Come]中为您提供更详细和公平的比较与Ray。关键在于，Ray Data并不试图取代这些工具。相反，它与两者都很好地集成。正如您将要看到的那样，这是Ray的一个常见主题。
- en: Ray as Distributed Interface
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ray作为分布式接口
- en: One aspect of Ray that’s vastly understated in my eyes is that its libraries
    seamlessly integrate common tools as *backends*. Ray often creates common interfaces,
    instead of trying to create new standards^([8](ch01.xhtml#idm44990033930720)).
    These interfaces allow you to run tasks in a distributed fashion, a property most
    of the respective backends don’t have, or not to the same extent. For instance,
    Ray RLlib and Train are backed by the full power of TensorFlow and PyTorch. Ray
    Tune supports algorithms from practically every notable HPO tool available, including
    Hyperopt, Optuna, Nevergrad, Ax, SigOpt and many others. None of these tools are
    distributed by default, but Tune unifies them in a common interface. Ray Serve
    can be used with frameworks such as FastAPI, and Ray Data is backed by Arrow and
    comes with many integrations to other frameworks, such as Spark and Dask. Overall
    this seems to be a robust design pattern that can be used to extend current Ray
    projects or integrate new backends in the future.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Ray中一个我认为极大低估的方面是，其库无缝集成了常见工具作为*后端*。Ray通常创建通用接口，而不是试图创建新的标准^([8](ch01.xhtml#idm44990033930720))。这些接口允许您以分布式方式运行任务，这是大多数相应后端所不具备的，或者不具备相同的程度。例如，Ray
    RLlib和Train支持来自TensorFlow和PyTorch的全部功能。Ray Tune支持来自几乎所有著名的超参数优化工具的算法，包括Hyperopt、Optuna、Nevergrad、Ax、SigOpt等等。这些工具默认情况下都不是分布式的，但Tune在一个通用接口中统一了它们。Ray
    Serve可以与FastAPI等框架一起使用，Ray Data由Arrow支持，并与Spark和Dask等其他框架有着许多集成。总的来说，这似乎是一个可以用来扩展当前Ray项目或将新后端集成进来的健壮设计模式。
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: To sum up what we’ve discussed in this chapter, [Figure 1-4](#fig_ray_layers)
    gives you an overview of the three layers of Ray as we laid them out. Ray’s core
    distributed execution engine sits at the center of the framework. For practical
    data science workflows you can use Ray Data for data processing, Ray RLlib for
    reinforcement learning, Ray Train for distributed model training, Ray Tune for
    hyperparameter tuning and Ray Serve for model serving. You’ve seen examples for
    each of these libraries and have an idea of what their APIs entail. On top of
    that, Ray’s ecosystem has many extensions that we’ll look more into later on.
    Maybe you can already spot a few tools you know and like in [Figure 1-4](#fig_ray_layers)^([9](ch01.xhtml#idm44990033926608))?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下本章讨论的内容，[图1-4](#fig_ray_layers) 给出了Ray的三个层次的概述。Ray的核心分布式执行引擎位于框架的中心。对于实际的数据科学工作流程，您可以使用Ray
    Data进行数据处理，使用Ray RLlib进行强化学习，使用Ray Train进行分布式模型训练，使用Ray Tune进行超参数调优，以及使用Ray Serve进行模型服务。您已经看到了每个库的示例，并对它们的API有了初步的了解。此外，Ray的生态系统还有许多扩展，我们稍后会更详细地讨论。也许您已经在[图1-4](#fig_ray_layers)^([9](ch01.xhtml#idm44990033926608))中发现了一些您了解和喜欢的工具？
- en: '![Ray layers](assets/ray_layers.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![Ray图层](assets/ray_layers.png)'
- en: 'Figure 1-4\. Ray in three layers: its core API, the libraries RLlib, Tune,
    Ray Train, Ray Serve, Ray Data, and some of the many third-party integrations'
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. Ray的三个层次：其核心API，库RLlib、Tune、Ray Train、Ray Serve、Ray Data以及许多第三方集成
- en: ^([1](ch01.xhtml#idm44990045517696-marker)) Moore’s Law held for a long time,
    but there might be signs that it’s slowing down. We’re not here to argue it, though.
    What’s important is not that our computers generally keep getting faster, but
    the relation to the amount of compute we need.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.xhtml#idm44990045517696-marker)) 摩尔定律长期以来都有效，但可能已经显示出放缓的迹象。不过我们不打算在这里讨论它。重要的不是我们的计算机通常变得更快，而是与我们需要的计算量之间的关系。
- en: ^([2](ch01.xhtml#idm44990045384464-marker)) For the experts among you, I don’t
    claim that RL is the answer. RL is just a paradigm that naturally fits into this
    discussion of AI goals.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.xhtml#idm44990045384464-marker)) 对于你们中的专家，我并不声称强化学习是答案。强化学习只是一种自然适合于讨论人工智能目标的范式。
- en: ^([3](ch01.xhtml#idm44990045356496-marker)) This is a Python book, so we’ll
    exclusively focus on it. But you should at least know that Ray also has a Java
    API, which at this point is less mature than its Python equivalent.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch01.xhtml#idm44990045356496-marker)) 本书是关于 Python 的，因此我们将专注于 Python。但你至少应该知道
    Ray 也有一个 Java API，目前相对于其 Python 版本来说，还不够成熟。
- en: ^([4](ch01.xhtml#idm44990042817344-marker)) We’re using Ray version `1.9.0`
    at this point, as it’s the latest version available as of this writing.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch01.xhtml#idm44990042817344-marker)) 我们目前使用的是 Ray 版本 `1.9.0`，因为这是本文写作时最新的版本。
- en: ^([5](ch01.xhtml#idm44990042948624-marker)) I never liked the categorization
    of data science as an intersection of disciplines, like maths, coding and business.
    Ultimately, that doesn’t tell you what practitioners *do*. It doesn’t do a cook
    justice to tell them they sit at the intersection of agriculture, thermodynamics
    and human relations. It’s not wrong, but also not very helpful.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch01.xhtml#idm44990042948624-marker)) 我从未喜欢过将数据科学归类为学科交叉点，比如数学、编码和商业的交集。最终，这并不能告诉你从业者们*做*什么。告诉厨师他们坐在农业、热力学和人际关系的交集上，并不完全正确，也并不是非常有帮助。
- en: ^([6](ch01.xhtml#idm44990044482384-marker)) As a fun exercise, I recommend reading
    Paul Graham’s famous [“Hackers and Painters”](http://www.paulgraham.com/hp.xhtml)
    essay on this topic and replace “computer science” with “data science”. What would
    hacking 2.0 be?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch01.xhtml#idm44990044482384-marker)) 作为一项有趣的练习，我建议阅读保罗·格雷厄姆（Paul Graham）著名的[《黑客与画家》](http://www.paulgraham.com/hp.xhtml)一文，将“计算机科学”替换为“数据科学”。那么黑客2.0会是什么样子呢？
- en: ^([7](ch01.xhtml#idm44990033933984-marker)) Spark has been created by another
    lab in Berkeley, AMPLab. The internet is full of blog posts claiming that Ray
    should therefore be seen as a replacement of Spark. It’s better to think of them
    as tools with different strengths that are both likely here to stay.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch01.xhtml#idm44990033933984-marker)) Spark 是由加州大学伯克利分校的 AMPLab 创建的。互联网上充斥着关于
    Ray 应该被视为 Spark 替代品的博客文章。最好将它们视为具有不同优势的工具，两者都很可能会继续存在。
- en: ^([8](ch01.xhtml#idm44990033930720-marker)) Before the deep learning framework
    [Keras](https://keras.io) became an official part of a corporate flagship, it
    started out as a convenient API specification for various lower-level frameworks
    such as Theano, CNTK, or TensorFlow. In that sense Ray RLlib has the chance to
    become Keras for RL. Ray Tune might just be Keras for HPO. The missing piece for
    more adoption is probably a more elegant API for both.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch01.xhtml#idm44990033930720-marker)) 在深度学习框架[Keras](https://keras.io)正式成为企业旗舰的一部分之前，它起初是各种低级框架（如
    Theano、CNTK 或 TensorFlow）的方便 API 规范。从这个意义上说，Ray RLlib 有可能成为 RL 的 Keras。Ray Tune
    或许只是超参数优化的 Keras。更广泛采用的缺失可能是更优雅的 API。
- en: ^([9](ch01.xhtml#idm44990033926608-marker)) Note that “Ray Train” has been called
    “raysgd” in older versions of Ray, and does not have a new logo yet.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch01.xhtml#idm44990033926608-marker)) 请注意，“Ray Train”在较早版本的 Ray 中被称为“raysgd”，并且还没有新的标志。
