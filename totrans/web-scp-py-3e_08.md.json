["```py\nfrom bs4 import BeautifulSoup\nfrom urllib.request import urlopen\n\nclass Content:\n    def __init__(self, url, title, body):\n        self.url = url\n        self.title = title\n        self.body = body\n\n    def print(self):\n        print(f'TITLE: {self.title}')\n        print(f'URL: {self.url}')\n        print(f'BODY: {self.body}')\n\ndef scrapeCNN(url):\n    bs = BeautifulSoup(urlopen(url))\n    title = bs.find('h1').text\n    body = bs.find('div', {'class': 'article__content'}).text\n    print('body: ')\n    print(body)\n    return Content(url, title, body)\n\ndef scrapeBrookings(url):\n    bs = BeautifulSoup(urlopen(url))\n    title = bs.find('h1').text\n    body = bs.find('div', {'class': 'post-body'}).text\n    return Content(url, title, body)\n\nurl = 'https://www.brookings.edu/research/robotic-rulemaking/'\ncontent = scrapeBrookings(url)\ncontent.print()\n\nurl = 'https://www.cnn.com/2023/04/03/investing/\\\ndogecoin-elon-musk-twitter/index.html'\ncontent = scrapeCNN(url)\ncontent.print()\n\n```", "```py\nclass Content:\n    \"\"\"\n    Common base class for all articles/pages\n    \"\"\"\n    def __init__(self, url, title, body):\n        self.url = url\n        self.title = title\n        self.body = body\n\n    def print(self):\n        \"\"\"\n        Flexible printing function controls output\n        \"\"\"\n        print('URL: {}'.format(self.url))\n        print('TITLE: {}'.format(self.title))\n        print('BODY:\\n{}'.format(self.body))\n\nclass Website:\n    \"\"\" \n    Contains information about website structure\n    \"\"\"\n    def __init__(self, name, url, titleTag, bodyTag):\n        self.name = name\n        self.url = url\n        self.titleTag = titleTag\n        self.bodyTag = bodyTag\n\n```", "```py\nclass Crawler:\n    def getPage(url):\n        try:\n            html = urlopen(url)\n        except Exception:\n            return None\n        return BeautifulSoup(html, 'html.parser')\n\n    def safeGet(bs, selector):\n        \"\"\"\n        Utility function used to get a content string from a Beautiful Soup\n        object and a selector. Returns an empty string if no object\n        is found for the given selector\n        \"\"\"\n        selectedElems = bs.select(selector)\n        if selectedElems is not None and len(selectedElems) > 0:\n            return '\\n'.join([elem.get_text() for elem in selectedElems])\n        return ''\n\n```", "```py\nclass Crawler:\n\n    ...\n\n    def getContent(website, path):\n        \"\"\"\n        Extract content from a given page URL\n        \"\"\"\n        url = website.url+path\n        bs = Crawler.getPage(url)\n        if bs is not None:\n            title = Crawler.safeGet(bs, website.titleTag)\n            body = Crawler.safeGet(bs, website.bodyTag)\n            return Content(url, title, body)\n        return Content(url, '', '')\n\n```", "```py\nsiteData = [\n    ['O\\'Reilly', 'https://www.oreilly.com', 'h1', 'div.title-description'],\n    ['Reuters', 'https://www.reuters.com', 'h1', 'div.ArticleBodyWrapper'],\n    ['Brookings', 'https://www.brookings.edu', 'h1', 'div.post-body'],\n    ['CNN', 'https://www.cnn.com', 'h1', 'div.article__content']\n]\nwebsites = []\nfor name, url, title, body in siteData:\n    websites.append(Website(name, url, title, body))\n\nCrawler.getContent(\n    websites[0], \n    '/library/view/web-scraping-with/9781491910283'\n    ).print()\nCrawler.getContent(\n    websites[1],\n    '/article/us-usa-epa-pruitt-idUSKBN19W2D0'\n    ).print()\nCrawler.getContent(\n    websites[2],\n    '/blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/'\n    ).print()\nCrawler.getContent(\n    websites[3], \n    '/2023/04/03/investing/dogecoin-elon-musk-twitter/index.html'\n    ).print()\n\n```", "```py\nclass Content:\n    \"\"\"Common base class for all articles/pages\"\"\"\n\n    def __init__(self, topic, url, title, body):\n        self.topic = topic\n        self.title = title\n        self.body = body\n        self.url = url\n\n    def print(self):\n        \"\"\"\n        Flexible printing function controls output\n        \"\"\"\n        print('New article found for topic: {}'.format(self.topic))\n        print('URL: {}'.format(self.url))\n        print('TITLE: {}'.format(self.title))\n        print('BODY:\\n{}'.format(self.body))    \n\n```", "```py\nclass Website:\n    \"\"\"Contains information about website structure\"\"\"\n\n    def __init__(self, name, url, searchUrl, resultListing,\n​    ​    resultUrl, absoluteUrl, titleTag, bodyTag):\n        self.name = name\n        self.url = url\n        self.searchUrl = searchUrl\n        self.resultListing = resultListing\n        self.resultUrl = resultUrl\n        self.absoluteUrl=absoluteUrl\n        self.titleTag = titleTag\n        self.bodyTag = bodyTag\n\n```", "```py\nclass Crawler:\n    def __init__(self, website):\n        self.site = website\n        self.found = {}\n\n    def getContent(self, topic, url):\n        \"\"\"\n        Extract content from a given page URL\n        \"\"\"\n        bs = Crawler.getPage(url)\n        if bs is not None:\n            title = Crawler.safeGet(bs, self.site.titleTag)\n            body = Crawler.safeGet(bs, self.site.bodyTag)\n            return Content(topic, url, title, body)\n        return Content(topic, url, '', '')\n\n    def search(self, topic):\n        \"\"\"\n        Searches a given website for a given topic and records all pages found\n        \"\"\"\n        bs = Crawler.getPage(self.site.searchUrl + topic)\n        searchResults = bs.select(self.site.resultListing)\n        for result in searchResults:\n            url = result.select(self.site.resultUrl)[0].attrs['href']\n            # Check to see whether it's a relative or an absolute URL\n            url = url if self.site.absoluteUrl else self.site.url + url\n            if url not in self.found:\n                self.found[url] = self.getContent(topic, url)\n            self.found[url].print()\n\n```", "```py\nsiteData = [\n    ['Reuters', 'http://reuters.com',\n     'https://www.reuters.com/search/news?blob=',\n     'div.search-result-indiv', 'h3.search-result-title a', \n      False, 'h1', 'div.ArticleBodyWrapper'],\n    ['Brookings', 'http://www.brookings.edu',\n     'https://www.brookings.edu/search/?s=',\n        'div.article-info', 'h4.title a', True, 'h1', 'div.core-block']\n]\nsites = []\nfor name, url, search, rListing, rUrl, absUrl, tt, bt in siteData:\n    sites.append(Website(name, url, search, rListing, rUrl, absUrl, tt, bt))\n\ncrawlers = [Crawler(site) for site in sites]\ntopics = ['python', 'data%20science']\n\nfor topic in topics:\n    for crawler in crawlers:\n        crawler.search(topic)\n\n```", "```py\nNew article found for topic: python\nURL: http://reuters.com/article/idUSKCN11S04G\nTITLE: Python in India demonstrates huge appetite\nBODY:\nBy 1 Min ReadA 20 feet rock python was caught on camera ...\n\n```", "```py\nclass Website:\n    def __init__(self, name, url, targetPattern, absoluteUrl, titleTag, bodyTag):\n        self.name = name\n        self.url = url\n        self.targetPattern = targetPattern\n        self.absoluteUrl = absoluteUrl\n        self.titleTag = titleTag\n        self.bodyTag = bodyTag\n\nclass Content:\n    def __init__(self, url, title, body):\n        self.url = url\n        self.title = title\n        self.body = body\n\n    def print(self):\n        print(f'URL: {self.url}')\n        print(f'TITLE: {self.title}')\n        print(f'BODY:\\n{self.body}')\n\n```", "```py\nclass Crawler:\n    def __init__(self, site):\n      self.site = site\n      self.visited = {}\n\n    def getPage(url):\n      try:\n            html = urlopen(url)\n      except Exception as e:\n            print(e)\n            return None\n      return BeautifulSoup(html, 'html.parser')\n\n    def safeGet(bs, selector):\n      selectedElems = bs.select(selector)\n      if selectedElems is not None and len(selectedElems) > 0:\n            return '\\n'.join([elem.get_text() for elem in selectedElems])\n      return ''\n\n    def getContent(self, url):\n      \"\"\"\n      Extract content from a given page URL\n      \"\"\"\n      bs = Crawler.getPage(url)\n      if bs is not None:\n          title = Crawler.safeGet(bs, self.site.titleTag)\n          body = Crawler.safeGet(bs, self.site.bodyTag)\n          return Content(url, title, body)\n        return Content(url, '', '')\n\n    def crawl(self):\n        \"\"\"\n        Get pages from website home page\n        \"\"\"\n        bs = Crawler.getPage(self.site.url)\n        targetPages = bs.findAll('a', href=re.compile(self.site.targetPattern))\n        for targetPage in targetPages:\n          url = targetPage.attrs['href']\n          url = url if self.site.absoluteUrl else f'{self.site.url}{targetPage}'\n          if url not in self.visited:\n                self.visited[url] = self.getContent(url)\n                self.visited[url].print()\n\nbrookings = Website(\n    'Brookings', 'https://brookings.edu', '\\/(research|blog)\\/',\n     True, 'h1', 'div.post-body')\ncrawler = Crawler(brookings)\ncrawler.crawl()\n\n```", "```py\nclass Website:\n    def __init__(self, name, url, titleTag, bodyTag, pageType):\n        self.name = name\n        self.url = url\n        self.titleTag = titleTag\n        self.bodyTag = bodyTag\n        self.pageType = pageType\n\n```", "```py\nclass Product(Website):\n    \"\"\"Contains information for scraping a product page\"\"\"\n    def __init__(self, name, url, titleTag, productNumberTag, priceTag):\n        Website.__init__(self, name, url, TitleTag)\n        self.productNumberTag = productNumberTag\n        self.priceTag = priceTag\n\nclass Article(Website):\n    \"\"\"Contains information for scraping an article page\"\"\"\n    def __init__(self, name, url, titleTag, bodyTag, dateTag):\n        Website.__init__(self, name, url, titleTag)\n        self.bodyTag = bodyTag\n        self.dateTag = dateTag\n\n```"]