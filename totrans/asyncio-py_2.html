<html><head></head><body><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. The Truth About Threads"><div class="chapter" id="idm46363041383400">
<h1><span class="label">Chapter 2. </span>The Truth About Threads</h1>

<blockquote>
<p>
Let’s be frank for a moment—you really don’t want to use Curio. All
things equal, you should probably be programming with threads. Yes,
threads. THOSE threads. Seriously. I’m not kidding.</p>
<p data-type="attribution">Dave Beazley, <a href="https://oreil.ly/oXJaC">“Developing with Curio”</a></p>
</blockquote>

<p>If you’ve never heard of threads<a data-type="indexterm" data-primary="threading" id="ix_thrdtr"/><a data-type="indexterm" data-primary="Beazley, Dave" id="idm46363041335112"/><a data-type="indexterm" data-primary="Curio" id="idm46363041334440"/><a data-type="indexterm" data-primary="threads" data-secondary="about" id="idm46363041333768"/> before, here’s a basic description: threads are a feature provided by an operating system (OS), made available to
software developers so that they may indicate to the OS which parts of their program may be run in parallel. The OS decides how to share CPU resources
with each of the parts, much as the OS decides to share CPU resources
with all the other different programs (processes) running at the same time.</p>

<p>Since you’re reading an Asyncio book, this must be the part where I tell you,
“Threads are terrible, and you should never use them,” right?  Unfortunately,
the situation is not so simple. We need to weigh the benefits and risks of
using threads, just like with any technology choice.</p>

<p>This book is not supposed to be about threads at all. But there are two problems here:
Asyncio is offered as an alternative to threading, so it’s hard
to understand the value proposition without some comparison; and
even when using Asyncio, you will still likely have to deal with
threads and processes, so you need to know something about
threading.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The context of this discussion is exclusively concurrency
in network programming applications.<a data-type="indexterm" data-primary="concurrency" data-secondary="in network programming applications" data-secondary-sortas="network" id="idm46363041329672"/><a data-type="indexterm" data-primary="preemptive multithreading" id="idm46363041328360"/> Preemptive multithreading is also
used in other domains, where the trade-offs are entirely different.</p>
</div>






<section data-type="sect1" data-pdf-bookmark="Benefits of Threading"><div class="sect1" id="idm46363041327176">
<h1>Benefits of Threading</h1>

<p>These are the main <a data-type="indexterm" data-primary="threading" data-secondary="benefits of" id="ix_thrdtrbene"/>benefits of threading:</p>
<dl>
<dt>Ease of reading code</dt>
<dd>
<p>Your code can run concurrently, but still be set
  out in a very simple, top-down linear sequence of commands to the point
  where—and this is key—you can pretend, within the body of your
  functions, that no concurrency is happening.</p>
</dd>
<dt>Parallelism with shared memory</dt>
<dd>
<p>Your code can exploit multiple CPUs while
  still having threads share memory.<a data-type="indexterm" data-primary="memory" data-secondary="shared, parallelism with" id="idm46363041320808"/><a data-type="indexterm" data-primary="parallelism with shared memory, threading and" id="idm46363041319816"/> This is important in many workloads where
  it would be too costly to move large amounts of data between the separate
  memory spaces of different processes, for example.</p>
</dd>
<dt>Know-how and existing code</dt>
<dd>
<p>There is a large body of knowledge and best
  practices available for writing threaded applications. There is also a huge amount of
  existing “blocking” code that depends on multithreading for concurrent
  operation.</p>
</dd>
</dl>

<p>Now, with <em>Python</em>, the point about parallelism is questionable
because the Python interpreter uses a global lock, called the <em>global
interpreter lock</em> (GIL), to protect the internal state of the interpreter
itself.<a data-type="indexterm" data-primary="Python" data-secondary="parallelism with shared memory, GIL and" id="idm46363041419704"/><a data-type="indexterm" data-primary="global interpreter lock (GIL)" data-secondary="side effect of" id="idm46363041418712"/> That is, it provides protection from the potential catastrophic effects of race
conditions between multiple threads. A side effect of the lock is that
it ends up pinning all threads in your program to a single CPU. As you
might imagine, this negates any parallelism performance benefits
(unless you use tools like Cython or Numba to maneuver around the
limitation).</p>

<p>The first point regarding perceived simplicity, however, is
significant: threading in Python <em>feels</em> exceptionally simple, and if
you haven’t been burned before by impossibly hard race condition
bugs, threading offers a very attractive concurrency model. Even if you
have been burned in the past, threading remains a compelling option
because you will likely have learned (the hard way) how to keep your
code both simple and safe.</p>

<p>I don’t have space to get into safer threaded programming here, but
generally<a data-type="indexterm" data-primary="concurrent.futures module, ThreadPoolExecutor class" id="idm46363041415336"/><a data-type="indexterm" data-primary="ThreadPoolExecutor class" id="idm46363041414664"/><a data-type="indexterm" data-primary="submit method, ThreadPoolExecutor class" id="idm46363041414024"/> speaking, the best practice for using threads is to use the
<code>ThreadPoolExecutor</code> class from the <code>concurrent.futures</code> module,
passing all required data in through the <code>submit()</code> method. <a data-type="xref" href="#threadbest">Example 2-1</a>
shows a basic example.</p>
<div id="threadbest" data-type="example">
<h5><span class="label">Example 2-1. </span>Best practice for threading</h5>

<pre data-type="programlisting" data-code-language="python3"><code class="kn">from</code> <code class="nn">concurrent.futures</code> <code class="k">import</code> <code class="n">ThreadPoolExecutor</code> <code class="k">as</code> <code class="n">Executor</code>

<code class="k">def</code> <code class="nf">worker</code><code class="p">(</code><code class="n">data</code><code class="p">):</code>
    <code class="o">&lt;</code><code class="n">process</code> <code class="n">the</code> <code class="n">data</code><code class="o">&gt;</code>
<code class="k">with</code> <code class="n">Executor</code><code class="p">(</code><code class="n">max_workers</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code> <code class="k">as</code> <code class="n">exe</code><code class="p">:</code>
    <code class="n">future</code> <code class="o">=</code> <code class="n">exe</code><code class="o">.</code><code class="n">submit</code><code class="p">(</code><code class="n">worker</code><code class="p">,</code> <code class="n">data</code><code class="p">)</code></pre></div>

<p>The <code>ThreadPoolExecutor</code> offers an extremely simple interface for running
functions in a thread—and the best part is that, if needed, you can convert
the pool of threads into a pool of subprocesses simply by using
<code>ProcessPoolExecutor</code> instead.<a data-type="indexterm" data-primary="subprocesses, converting pool of threads to" id="idm46363041405752"/><a data-type="indexterm" data-primary="ProcessPoolExecutor class" id="idm46363041405144"/> It has the same API as <code>ThreadPoolExecutor</code>,
which means that your code will be little affected by the change. The
executor API is also used in <code>asyncio</code> and is described in the next chapter (see <a data-type="xref" href="ch03.html#quickstart-executor">Example 3-3</a>).</p>

<p>In general, you’ll prefer your tasks to be somewhat short-lived, so that
when your program needs to shut down, you can simply call
<code>Executor.shutdown(wait=True)</code> and wait a second or two to allow the
executor to complete.<a data-type="indexterm" data-primary="Executor.shutdown method" id="idm46363041401784"/></p>

<p>Most importantly: if at all possible, you should try to prevent your threaded code
(in the preceding example, the <code>worker()</code> function) from accessing or writing
to any global variables!<a data-type="indexterm" data-primary="global variables, preventing threaded code from accessing or writing to" id="idm46363039880424"/><a data-type="indexterm" data-primary="Hettinger, Raymond" id="idm46363039879752"/></p>
<div data-type="tip"><h6>Tip</h6>
<p>Raymond Hettinger presented several great guidelines for safer threaded code
at <a href="https://oreil.ly/ZZVps">PyCon Russia 2016</a>
and <a href="https://oreil.ly/JDplJ">PyBay 2017</a>. I strongly
urge you to add these videos to your watch list.<a data-type="indexterm" data-primary="PyCon Russia 2016" id="idm46363039876696"/><a data-type="indexterm" data-primary="PyBay 2017" id="idm46363039875992"/><a data-type="indexterm" data-primary="threading" data-secondary="benefits of" data-startref="ix_thrdtrbene" id="idm46363039875320"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Drawbacks of Threading"><div class="sect1" id="idm46363041326584">
<h1>Drawbacks of Threading</h1>
<blockquote>
  <p>[N]ontrivial multithreaded programs are incomprehensible to humans.
It is true that the programming model can be improved through the use
of design patterns, better granularity of atomicity (e.g.,
transactions), improved languages, and formal methods. However, these
techniques merely chip away at the unnecessarily enormous
non-determinism of the threading model. The model remains
intrinsically intractable.</p>

<p data-type="attribution">Edward A. Lee <a href="http://bit.ly/2CFOv8a">“The Problem with Threads”</a></p>
</blockquote>

<p>The drawbacks of threading <a data-type="indexterm" data-primary="threading" data-secondary="drawbacks of" id="ix_thrddrwb"/>have been mentioned in a few other places
already, but for completeness let’s collect them here anyway:</p>
<dl>
<dt>Threading is difficult</dt>
<dd>
<p>Threading bugs and race conditions in threaded programs are <em>the
  hardest</em> kinds of bugs to fix.<a data-type="indexterm" data-primary="bugs in threading, difficulty of fixing" data-secondary-sortas="threading" id="idm46363039866120"/><a data-type="indexterm" data-primary="race conditions" data-secondary="in threaded programs, difficulty of fixing" data-secondary-sortas="threaded" id="idm46363039865144"/> With experience, it is possible to
  design new software that is less prone to these problems, but in
  nontrivial, naively designed software, they can be nearly impossible
  to fix, even by experts. Really!</p>
</dd>
<dt>Threads are resource-intensive</dt>
<dd>
<p>Threads require extra operating system resources to create, such as preallocated,
  per-thread stack space that consumes process virtual memory up front.<a data-type="indexterm" data-primary="resource-intensive threads" id="idm46363041092504"/> This is
  a big problem with 32-bit operating systems, because
  the address<a data-type="indexterm" data-primary="operating systems" data-secondary="address space per process, limitations on" id="idm46363041091672"/> space per process is limited to 3 GB.<sup><a data-type="noteref" id="idm46363041090568-marker" href="ch02.html#idm46363041090568">1</a></sup>
  Nowadays, with the widespread availability of 64-bit
  operating systems, virtual memory isn’t as precious as it used to be
  (addressable space for virtual memory is typically 48 bits; i.e., 256 TiB). On modern desktop operating systems, the physical memory required for stack space for each
  thread isn’t even allocated by the OS until it is required, including
  stack space per thread. For example, on
  a modern, 64-bit Fedora 29 Linux with 8 GB memory, creating 10,000
  do-nothing threads with this short snippet:</p>

<pre data-type="programlisting" data-code-language="python3"><code class="c1"># threadmem.py</code>
<code class="kn">import</code> <code class="nn">os</code>
<code class="kn">from</code> <code class="nn">time</code> <code class="k">import</code> <code class="n">sleep</code>
<code class="kn">from</code> <code class="nn">threading</code> <code class="k">import</code> <code class="n">Thread</code>
<code class="n">threads</code> <code class="o">=</code> <code class="p">[</code>
  <code class="n">Thread</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="k">lambda</code><code class="p">:</code> <code class="n">sleep</code><code class="p">(</code><code class="mi">60</code><code class="p">))</code> <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">10000</code><code class="p">)</code>
<code class="p">]</code>
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">start</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code>
<code class="nb">print</code><code class="p">(</code><code class="n">f</code><code class="s1">'PID = {os.getpid()}'</code><code class="p">)</code>
<code class="p">[</code><code class="n">t</code><code class="o">.</code><code class="n">join</code><code class="p">()</code> <code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">threads</code><code class="p">]</code></pre>

<p>leads to the following information in <code>top</code>:</p>

<pre data-type="programlisting">MiB Mem : 7858.199 total, 1063.844 free, 4900.477 used
MiB Swap: 7935.996 total, 4780.934 free, 3155.062 used

  PID USER      PR  NI    VIRT    RES    SHR COMMAND
15166 caleb     20   0 80.291g 131.1m   4.8m python3</pre>

<p>Preallocated virtual memory is a staggering ~80 GB (due to 8 MB stack space per
thread!), but resident memory is only ~130 MB. On a 32-bit Linux system, I would
be unable to create this many because of the 3 GB user-space address-space limit,
<em>regardless</em> of actual consumption of physical memory. To get around this
problem on 32-bit systems, it is sometimes necessary to decrease the <span class="keep-together">preconfigured</span> stack
size, which you can still do in Python today, with <span class="keep-together"><code>threading.stack_size([size])</code>.</span> Obviously, decreasing stack size has implications for runtime safety with
respect to the degree to which function calls may be nested, including
recursion. Single-threaded coroutines have none of these problems and are
a far superior alternative for concurrent I/O.</p>
</dd>
<dt>Threading can affect throughput</dt>
<dd>
<p>At very high concurrency levels (say, &gt;5,000 threads), there <span class="keep-together">can also</span>
  be an impact on throughput due to
  <a href="https://oreil.ly/eFQKQ">context-switching</a>
  costs, assuming you can figure out how to configure your operating system
  to even allow you to create that many threads! It has become so
  tedious on recent macOS versions, for example, to test the preceding 10,000
  do-nothing-threads example, that I gave up trying to raise the limits
  at all.</p>
</dd>
<dt>Threading is inflexible</dt>
<dd>
<p>The operating system will continually
  share CPU time with all threads regardless of whether a
  thread is ready to do work or not. For instance, a thread may be
  waiting for data on a socket, but the OS scheduler may still switch
  to and from that thread thousands of times before any actual work
  needs to be done. (In the async world, the <code>select()</code> system call is
  used to check whether a socket-awaiting coroutine needs a turn;
  if not, that coroutine isn’t even woken up, avoiding any
  switching costs completely.)</p>
</dd>
</dl>

<p>None of this information is new, and the problems with threading as a
programming model are not platform-specific either. For example, this
is what the <a href="http://bit.ly/2Fr3eXK">Microsoft Visual C++ documentation</a> says
about threading:</p>
<blockquote>
<p>The central concurrency mechanism in the Windows API is the thread.
You typically use the CreateThread function to create threads.<a data-type="indexterm" data-primary="concurrency" data-secondary="threads as central mechanism in Windows" id="idm46363039827688"/><a data-type="indexterm" data-primary="Windows systems, threads as central concurrency mechanism" id="idm46363039826696"/>
Although threads are relatively easy to create and use, the operating
system allocates a significant amount of time and other resources to
manage them. Additionally, although each thread is guaranteed to
receive the same execution time as any other thread at the same
priority level, the associated overhead requires that you create
sufficiently large tasks. For smaller or more fine-grained tasks, the
overhead that is associated with concurrency can outweigh the benefit
of running the tasks in parallel.</p></blockquote>

<p>But—I hear you protest—this is <em>Windows</em>, right? Surely a Unix
system doesn’t have these problems? <a data-type="indexterm" data-primary="Unix systems" data-secondary="concurrency and threading" id="idm46363039824632"/><a data-type="indexterm" data-primary="Threading Programming Guide (Mac Developers)" id="idm46363039823592"/><a data-type="indexterm" data-primary="Mac computers, concurrency and threading" id="idm46363039822888"/>Here follows a similar
recommendation from the Mac Developer Library’s <a href="https://oreil.ly/W3mBM">Threading Programming Guide</a>:</p>
<blockquote>
<p>Threading has a real cost to your program (and the system) in terms of
memory use and performance. <a data-type="indexterm" data-primary="performance" data-secondary="threads and system performance" id="idm46363039820552"/><a data-type="indexterm" data-primary="memory" data-secondary="allocation for threads" id="idm46363039819512"/>Each thread requires the allocation of memory
in both the kernel memory space and your program’s memory space. The
core structures needed to manage your thread and coordinate its scheduling
are stored in the kernel using wired memory. Your thread’s stack space
and per-thread data is stored in your program’s memory space. Most of
these structures are created and initialized when you first create the
thread—a process that can be relatively expensive because of the required
interactions with the kernel.<a data-type="indexterm" data-primary="Concurrency Programming Guide (Apple)" id="idm46363039817912"/></p></blockquote>

<p>They go even further in the <a href="https://oreil.ly/fcGNL">Concurrency Programming Guide</a>
(emphasis mine):</p>
<blockquote>
<p>In the past, introducing concurrency to an application required the creation
of one or more additional threads. Unfortunately, writing threaded code is
challenging. Threads are a low-level tool that must be managed manually. Given
that the optimal number of threads for an application can change dynamically
based on the current system load and the underlying hardware, implementing a
correct threading solution becomes <em>extremely difficult</em>, if not impossible to
achieve. In addition, the synchronization <span class="keep-together">mechanisms</span> typically used with
threads add complexity and risk to software designs without any guarantees of
improved performance.<a data-type="indexterm" data-primary="concurrency" data-secondary="large-scale, threading as inefficient mechanism" id="idm46363039813720"/><a data-type="indexterm" data-primary="code" data-secondary="threading making code hard to read" id="idm46363039812712"/></p></blockquote>

<p>These themes repeat throughout:</p>

<ul>
<li>
<p>Threading makes code hard to reason about.</p>
</li>
<li>
<p>Threading is an inefficient model for large-scale concurrency (thousands
of concurrent tasks).</p>
</li>
</ul>

<p>Next, let’s look at a case study involving threads that highlights
the first and most important point.<a data-type="indexterm" data-primary="threading" data-secondary="drawbacks of" data-startref="ix_thrddrwb" id="idm46363039808520"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Case Study: Robots and Cutlery"><div class="sect1" id="robotcut">
<h1>Case Study: Robots and Cutlery</h1>
<blockquote>
  <p>Second, and more important, we did not (and still do not) believe in the standard multithreading model, which is preemptive concurrency
with shared memory: we still think that no one can write correct
programs in a language where “a = a + 1” is not deterministic.</p>

<p data-type="attribution">Roberto Ierusalimschy et al., <a href="http://bit.ly/2Fq9M8P">“The Evolution of Lua”</a></p>
</blockquote>

<p>At the start of this book, I told the story of a restaurant in which
humanoid robots—ThreadBots—did all the work. In that analogy, each
worker was a thread. In the case study in <a data-type="xref" href="#robcut">Example 2-2</a>, we’re going to look at <em>why</em>
threading is considered unsafe.<a data-type="indexterm" data-primary="Robots and Cutlery case study" id="ix_RoboCut"/><a data-type="indexterm" data-primary="threading" data-secondary="Robots and Cutlery case study" id="ix_thrdcs"/></p>
<div id="robcut" data-type="example">
<h5><span class="label">Example 2-2. </span>ThreadBot programming for table service</h5>

<pre data-type="programlisting" data-code-language="python3"><code class="kn">import</code><code> </code><code class="nn">threading</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">queue</code><code> </code><code class="k">import</code><code> </code><code class="n">Queue</code><code>
</code><code>
</code><code class="k">class</code><code> </code><code class="nc">ThreadBot</code><code class="p">(</code><code class="n">threading</code><code class="o">.</code><code class="n">Thread</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO1-1" href="#callout_the_truth_about_threads_CO1-1"><img src="assets/1.png" alt="1"/></a><code>
</code><code>  </code><code class="k">def</code><code> </code><code class="nf">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="nb">super</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="n">target</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">manage_table</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO1-2" href="#callout_the_truth_about_threads_CO1-2"><img src="assets/2.png" alt="2"/></a><code>
</code><code>    </code><code class="bp">self</code><code class="o">.</code><code class="n">cutlery</code><code> </code><code class="o">=</code><code> </code><code class="n">Cutlery</code><code class="p">(</code><code class="n">knives</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO1-3" href="#callout_the_truth_about_threads_CO1-3"><img src="assets/3.png" alt="3"/></a><code>
</code><code>    </code><code class="bp">self</code><code class="o">.</code><code class="n">tasks</code><code> </code><code class="o">=</code><code> </code><code class="n">Queue</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO1-4" href="#callout_the_truth_about_threads_CO1-4"><img src="assets/4.png" alt="4"/></a><code>
</code><code>
</code><code>  </code><code class="k">def</code><code> </code><code class="nf">manage_table</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="k">while</code><code> </code><code class="kc">True</code><code class="p">:</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO1-5" href="#callout_the_truth_about_threads_CO1-5"><img src="assets/5.png" alt="5"/></a><code>
</code><code>      </code><code class="n">task</code><code> </code><code class="o">=</code><code> </code><code class="bp">self</code><code class="o">.</code><code class="n">tasks</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="p">)</code><code>
</code><code>      </code><code class="k">if</code><code> </code><code class="n">task</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">prepare table</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>        </code><code class="n">kitchen</code><code class="o">.</code><code class="n">give</code><code class="p">(</code><code class="n">to</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">cutlery</code><code class="p">,</code><code> </code><code class="n">knives</code><code class="o">=</code><code class="mi">4</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code> </code><a class="co" id="co_the_truth_about_threads_CO1-6" href="#callout_the_truth_about_threads_CO1-6"><img src="assets/6.png" alt="6"/></a><code>
</code><code>      </code><code class="k">elif</code><code> </code><code class="n">task</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">clear table</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>        </code><code class="bp">self</code><code class="o">.</code><code class="n">cutlery</code><code class="o">.</code><code class="n">give</code><code class="p">(</code><code class="n">to</code><code class="o">=</code><code class="n">kitchen</code><code class="p">,</code><code> </code><code class="n">knives</code><code class="o">=</code><code class="mi">4</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code>
</code><code>      </code><code class="k">elif</code><code> </code><code class="n">task</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">shutdown</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>        </code><code class="k">return</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_the_truth_about_threads_CO1-1" href="#co_the_truth_about_threads_CO1-1"><img src="assets/1.png" alt="1"/></a></dt>
<dd><p>A <code>ThreadBot</code> is a subclass of a thread.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO1-2" href="#co_the_truth_about_threads_CO1-2"><img src="assets/2.png" alt="2"/></a></dt>
<dd><p>The target function of the thread is the <code>manage_table()</code> method,
defined later in the file.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO1-3" href="#co_the_truth_about_threads_CO1-3"><img src="assets/3.png" alt="3"/></a></dt>
<dd><p>This bot is going to be waiting tables and will need to be responsible
for some cutlery. Each bot keeps track of the cutlery that it took
from the kitchen here. (The <code>Cutlery</code> class will be defined later.)</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO1-4" href="#co_the_truth_about_threads_CO1-4"><img src="assets/4.png" alt="4"/></a></dt>
<dd><p>The bot will also be assigned tasks. They will be added to this task
queue, and the bot will perform them during its main processing loop,
next.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO1-5" href="#co_the_truth_about_threads_CO1-5"><img src="assets/5.png" alt="5"/></a></dt>
<dd><p>The primary routine of this bot is this infinite loop. If you need
to shut down a bot, you have to give them the <code>shutdown</code> task.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO1-6" href="#co_the_truth_about_threads_CO1-6"><img src="assets/6.png" alt="6"/></a></dt>
<dd><p>There are only three tasks defined for this bot. This one,
<code>prepare table</code>, is what the bot must do to get a new table ready
for service. For our test, the only requirement is to get sets of
cutlery from the kitchen and place them on the table.
<code>clear table</code> is used when a table is to be cleared: the
bot must return the used cutlery back to the kitchen. <code>shutdown</code> just
shuts down the bot.</p></dd>
</dl></div>

<p><a data-type="xref" href="#defcut">Example 2-3</a> shows the definition of the <code>Cutlery</code> object.</p>
<div id="defcut" data-type="example">
<h5><span class="label">Example 2-3. </span>Definition of the Cutlery object</h5>

<pre data-type="programlisting" data-code-language="python3"><code class="kn">from</code><code> </code><code class="nn">attr</code><code> </code><code class="k">import</code><code> </code><code class="n">attrs</code><code class="p">,</code><code> </code><code class="n">attrib</code><code>
</code><code>
</code><code class="nd">@attrs</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-1" href="#callout_the_truth_about_threads_CO2-1"><img src="assets/1.png" alt="1"/></a><code>
</code><code class="k">class</code><code> </code><code class="nc">Cutlery</code><code class="p">:</code><code>
</code><code>    </code><code class="n">knives</code><code> </code><code class="o">=</code><code> </code><code class="n">attrib</code><code class="p">(</code><code class="n">default</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-2" href="#callout_the_truth_about_threads_CO2-2"><img src="assets/2.png" alt="2"/></a><code>
</code><code>    </code><code class="n">forks</code><code> </code><code class="o">=</code><code> </code><code class="n">attrib</code><code class="p">(</code><code class="n">default</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">give</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">to</code><code class="p">:</code><code> </code><code class="s1">'</code><code class="s1">Cutlery</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">knives</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-3" href="#callout_the_truth_about_threads_CO2-3"><img src="assets/3.png" alt="3"/></a><code>
</code><code>        </code><code class="bp">self</code><code class="o">.</code><code class="n">change</code><code class="p">(</code><code class="o">-</code><code class="n">knives</code><code class="p">,</code><code> </code><code class="o">-</code><code class="n">forks</code><code class="p">)</code><code>
</code><code>        </code><code class="n">to</code><code class="o">.</code><code class="n">change</code><code class="p">(</code><code class="n">knives</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">change</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">knives</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-4" href="#callout_the_truth_about_threads_CO2-4"><img src="assets/4.png" alt="4"/></a><code>
</code><code>            </code><code class="bp">self</code><code class="o">.</code><code class="n">knives</code><code> </code><code class="o">+</code><code class="o">=</code><code> </code><code class="n">knives</code><code>
</code><code>            </code><code class="bp">self</code><code class="o">.</code><code class="n">forks</code><code> </code><code class="o">+</code><code class="o">=</code><code> </code><code class="n">forks</code><code>
</code><code>
</code><code class="n">kitchen</code><code> </code><code class="o">=</code><code> </code><code class="n">Cutlery</code><code class="p">(</code><code class="n">knives</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">forks</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-5" href="#callout_the_truth_about_threads_CO2-5"><img src="assets/5.png" alt="5"/></a><code>
</code><code class="n">bots</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">ThreadBot</code><code class="p">(</code><code class="p">)</code><code> </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code><code class="p">]</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-6" href="#callout_the_truth_about_threads_CO2-6"><img src="assets/6.png" alt="6"/></a><code>
</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">sys</code><code>
</code><code class="k">for</code><code> </code><code class="n">bot</code><code> </code><code class="ow">in</code><code> </code><code class="n">bots</code><code class="p">:</code><code>
</code><code>    </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="n">sys</code><code class="o">.</code><code class="n">argv</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-7" href="#callout_the_truth_about_threads_CO2-7"><img src="assets/7.png" alt="7"/></a><code>
</code><code>        </code><code class="n">bot</code><code class="o">.</code><code class="n">tasks</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="s1">'</code><code class="s1">prepare table</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="n">bot</code><code class="o">.</code><code class="n">tasks</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="s1">'</code><code class="s1">clear table</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>    </code><code class="n">bot</code><code class="o">.</code><code class="n">tasks</code><code class="o">.</code><code class="n">put</code><code class="p">(</code><code class="s1">'</code><code class="s1">shutdown</code><code class="s1">'</code><code class="p">)</code><code>  </code><a class="co" id="co_the_truth_about_threads_CO2-8" href="#callout_the_truth_about_threads_CO2-8"><img src="assets/8.png" alt="8"/></a><code>
</code><code>
</code><code class="nb">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Kitchen inventory before service:</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">kitchen</code><code class="p">)</code><code>
</code><code class="k">for</code><code> </code><code class="n">bot</code><code> </code><code class="ow">in</code><code> </code><code class="n">bots</code><code class="p">:</code><code>
</code><code>    </code><code class="n">bot</code><code class="o">.</code><code class="n">start</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="k">for</code><code> </code><code class="n">bot</code><code> </code><code class="ow">in</code><code> </code><code class="n">bots</code><code class="p">:</code><code>
</code><code>    </code><code class="n">bot</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="nb">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Kitchen inventory after service:</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">kitchen</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_the_truth_about_threads_CO2-1" href="#co_the_truth_about_threads_CO2-1"><img src="assets/1.png" alt="1"/></a></dt>
<dd><p><code>attrs</code>, which is an open source Python library that has nothing
to do with threads or <code>asyncio</code>, is a
really wonderful library for making class creation easy. Here,
the <code>@attrs</code> decorator will ensure that this <code>Cutlery</code> class will
get all the usual boilerplate code (like <code>__init__()</code>) automatically
set up.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-2" href="#co_the_truth_about_threads_CO2-2"><img src="assets/2.png" alt="2"/></a></dt>
<dd><p>The <code>attrib()</code> function provides an easy way to create attributes,
including defaults, which you might normally have handled as keyword
arguments in the <code>__init__()</code> method.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-3" href="#co_the_truth_about_threads_CO2-3"><img src="assets/3.png" alt="3"/></a></dt>
<dd><p>This method is used to transfer knives and forks from one
<code>Cutlery</code> object to another. Typically, it will be used by bots to obtain
cutlery from the kitchen for new tables, and to return the cutlery back
to the kitchen after a table is cleared.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-4" href="#co_the_truth_about_threads_CO2-4"><img src="assets/4.png" alt="4"/></a></dt>
<dd><p>This is a very simple utility function for altering the inventory
data in the object instance.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-5" href="#co_the_truth_about_threads_CO2-5"><img src="assets/5.png" alt="5"/></a></dt>
<dd><p>We’ve defined <code>kitchen</code> as the identifier for the kitchen inventory
of cutlery. Typically, each of the bots will obtain cutlery from
this location. It is also required that they return cutlery to
this store when a table is cleared.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-6" href="#co_the_truth_about_threads_CO2-6"><img src="assets/6.png" alt="6"/></a></dt>
<dd><p>This script is executed when testing. For our test, we’ll be using
10 ThreadBots.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-7" href="#co_the_truth_about_threads_CO2-7"><img src="assets/7.png" alt="7"/></a></dt>
<dd><p>We get the number of tables as a command-line parameter, and then
give each bot that number of tasks for preparing and clearing tables
in the restaurant.</p></dd>
<dt><a class="co" id="callout_the_truth_about_threads_CO2-8" href="#co_the_truth_about_threads_CO2-8"><img src="assets/8.png" alt="8"/></a></dt>
<dd><p>The <code>shutdown</code> task will make the bots stop (so that <code>bot.join()</code> a bit
further down will return). The rest of the script prints diagnostic
messages and starts up the bots.</p></dd>
</dl></div>

<p>Your strategy for testing the code basically involves running a group of
ThreadBots over a sequence of table service. Each ThreadBot must do the following:</p>

<ul>
<li>
<p><em>Prepare</em> a “table for four,” which means obtaining four sets of knives
and forks from the kitchen.</p>
</li>
<li>
<p><em>Clear</em> a table, which means returning the set of four knives and forks
from a table back to the kitchen.</p>
</li>
</ul>

<p>If you run a bunch of ThreadBots over a bunch of tables a specific
number of times, you expect that after all the work is done, all of
the knives and forks should be back in the kitchen and accounted for.</p>

<p>Wisely, you decide to test that, with one hundred tables to be prepared
and cleared by each ThreadBot and all of them operating at the same
time, because you want to ensure that they can work together and
nothing goes wrong. This is the output of that test:</p>
<pre data-type="programlisting">
$ <strong>python cutlery_test.py 100</strong>
Kitchen inventory before service: Cutlery(knives=100, forks=100)
Kitchen inventory after service: Cutlery(knives=100, forks=100)
</pre>

<p>All the knives and forks end up back in the kitchen! So, you
congratulate yourself on writing good code and deploy the bots.
Unfortunately, <em>in practice</em>, every now and then you find that you <em>do
not</em> end up with all cutlery accounted for when the restaurant closes.
You notice the problem gets worse when you add more bots and/or the
place gets busier. Frustrated, you run your tests again, changing
nothing except the size of the test (10,000 tables!):</p>
<pre data-type="programlisting">
$ <strong>python cutlery_test.py 10000</strong>
Kitchen inventory before service: Cutlery(knives=100, forks=100)
Kitchen inventory after service: Cutlery(knives=96, forks=108)
</pre>

<p>Oops. Now you see that there is indeed a problem. With 10,000 tables
served, you end up with the wrong number of knives and forks left in the
kitchen. For reproducibility, you check that the error is consistent:</p>
<pre data-type="programlisting">
$ <strong>python cutlery_test.py 10000</strong>
Kitchen inventory before service: Cutlery(knives=100, forks=100)
Kitchen inventory after service: Cutlery(knives=112, forks=96)
</pre>

<p>There are still errors, but <em>by different amounts</em> compared to the
previous run. That’s just ridiculous! Remember, these bots are
exceptionally well constructed and they don’t make mistakes.  What
could be going wrong?</p>

<p>Let’s summarize the situation:</p>

<ul>
<li>
<p>Your ThreadBot code is very simple and easy to read. The logic is fine.</p>
</li>
<li>
<p>You have a working test (with 100 tables) that reproducibly passes.</p>
</li>
<li>
<p>You have a longer test (with 10,000 tables) that reproducibly fails.</p>
</li>
<li>
<p>The longer test fails in <em>different, nonreproducible ways</em>.</p>
</li>
</ul>

<p>These are a few typical signs of a race condition bug. Experienced
readers will already have seen the cause, so let’s investigate that
now. It all comes down to this method inside our <code>Cutlery</code> class:</p>

<pre data-type="programlisting" data-code-language="python3"><code class="k">def</code> <code class="nf">change</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">knives</code><code class="p">,</code> <code class="n">forks</code><code class="p">):</code>
    <code class="bp">self</code><code class="o">.</code><code class="n">knives</code> <code class="o">+=</code> <code class="n">knives</code>
    <code class="bp">self</code><code class="o">.</code><code class="n">forks</code> <code class="o">+=</code> <code class="n">forks</code></pre>

<p>The inline summation, <code>+=</code>, is implemented internally (inside the C
code for the Python interpreter itself) as a few separate steps:</p>
<ol>
<li>
<p>Read the current value, <code>self.knives</code>, into a temporary location.</p>
</li>
<li>
<p>Add the new value, <code>knives</code>, to the value in that temporary location.</p>
</li>
<li>
<p>Copy the new total from the temporary location back into the original
location.</p>
</li>

</ol>

<p>The problem with preemptive multitasking is that any thread busy with
these steps can be interrupted <em>at any time</em>, and a different thread can
be given the opportunity to work through the same steps.</p>

<p>In this case, suppose ThreadBot <em>A</em> does step 1, and then the OS scheduler
pauses <em>A</em> and switches to ThreadBot <em>B</em>. <em>B</em> <em>also</em> reads the
current value of <code>self.knives</code>; then execution goes back to <em>A</em>.
<em>A</em> increments its total and writes it back—but then <em>B</em> continues
from where it got paused (after step 1), and it increments and
writes back <em>its</em> new total, thereby <em>erasing</em> the change made
by <em>A</em>!</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>While this may sound complex,
this example of a race condition is just about the
simplest possible case. We were able to check <em>all</em> the code, and we
even have tests that can reproduce the problem on demand. In the real
world, in large projects, try to imagine how much more difficult it
can become!</p>
</div>

<p>This problem can be fixed by placing a <em>lock</em> around the modification of
the shared state (imagine we added a <code>threading.Lock</code> to the
<code>Cutlery</code> class):</p>

<pre data-type="programlisting" data-code-language="python3"><code class="k">def</code> <code class="nf">change</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">knives</code><code class="p">,</code> <code class="n">forks</code><code class="p">):</code>
    <code class="k">with</code> <code class="bp">self</code><code class="o">.</code><code class="n">lock</code><code class="p">:</code>
      <code class="bp">self</code><code class="o">.</code><code class="n">knives</code> <code class="o">+=</code> <code class="n">knives</code>
      <code class="bp">self</code><code class="o">.</code><code class="n">forks</code> <code class="o">+=</code> <code class="n">forks</code></pre>

<p>But this requires you to know all the places where state will be
shared between multiple threads. This approach is viable when you
control all the source code, but it becomes very difficult when many
third-party libraries are used—which is likely in Python thanks to the wonderful open source ecosystem.</p>

<p>Note that it was not possible to see the race condition by looking at
the source code alone. This is because the source code provides no
hints about where execution is going to switch between threads. That
wouldn’t be useful anyway, because the OS can switch between threads
just about anywhere.</p>

<p>Another, much better, solution—and the point of async programming—is
to modify our code so that we use only one ThreadBot and
configure it to move between <em>all</em> the tables as necessary. For our case
study, this means that the knives and forks in the kitchen will get modified by only a single thread.</p>

<p>And even better, in our async programs, we’ll be able to see exactly
where context will switch between multiple concurrent coroutines,
because the <code>await</code> keyword indicates such places explicitly.  I’ve
decided against showing an async version of this case study here,
because <a data-type="xref" href="ch03.html#walkthrough">Chapter 3</a> explains how to use <code>asyncio</code> in
depth. But if your curiosity is insatiable, there is an annotated example in <a data-type="xref" href="app02.html#corobot">Example B-1</a>; it’ll probably only make sense after you
read the next chapter!<a data-type="indexterm" data-primary="Robots and Cutlery case study" data-startref="ix_RoboCut" id="idm46363038767928"/><a data-type="indexterm" data-primary="threading" data-secondary="Robots and Cutlery case study" data-startref="ix_thrdcs" id="idm46363038767016"/><a data-type="indexterm" data-primary="threading" data-startref="ix_thrdtr" id="idm46363038765832"/></p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm46363041090568"><sup><a href="ch02.html#idm46363041090568-marker">1</a></sup> The theoretical address space for a 32-bit process is 4 GB, but the operating system typically reserves some of that. Often, only 3 GB is left to the process   as addressable virtual memory, but on some operating systems it can be   as low as 2 GB. Please take the numbers mentioned in this section   as generalizations and not absolutes. There are far too many   platform-specific (and historically sensitive) details to get into here.</p></div></div></section></body></html>