- en: Chapter 4\. Writing Your First Web Scraper
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 章：编写您的第一个 Web 爬虫
- en: Once you start web scraping, you start to appreciate all the little things that
    browsers do for you. The web, without its layers of HTML formatting, CSS styling,
    JavaScript execution, and image rendering, can look a little intimidating at first. In
    this chapter, we’ll begin to look at how to format and interpret this bare data
    without the help of a web browser.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您开始网页抓取，您会开始感激浏览器为您完成的所有小事情。初始阶段，没有 HTML 格式化、CSS 样式、JavaScript 执行和图像渲染的 Web
    看起来可能有些令人望而却步。在本章中，我们将开始探讨如何在没有 Web 浏览器帮助的情况下格式化和解释这些裸数据。
- en: This chapter starts with the basics of sending a `GET` request (a request to
    fetch, or “get,” the content of a web page) to a web server for a specific page,
    reading the HTML output from that page, and doing some simple data extraction
    in order to isolate the content you are looking for.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章从发送 `GET` 请求的基础开始（请求获取或“获取” Web 页面的内容），从 Web 服务器获取特定页面的 HTML 输出，并进行一些简单的数据提取，以便分离您寻找的内容。
- en: Installing and Using Jupyter
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装并使用 Jupyter
- en: The code for this course can be found at [*https://github.com/REMitchell/python-scraping*](https://github.com/REMitchell/python-scraping).
    In most cases, code samples are in the form of Jupyter Notebook files, with an
    *.ipynb* extension.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此课程的代码可以在 [*https://github.com/REMitchell/python-scraping*](https://github.com/REMitchell/python-scraping)
    找到。在大多数情况下，代码示例以 Jupyter Notebook 文件的形式展示，并使用 *.ipynb* 扩展名。
- en: If you haven’t used them already, Jupyter Notebooks are an excellent way to
    organize and work with many small but related pieces of Python code, as shown
    in [Figure 4-1](#fig0401).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有使用过，Jupyter Notebooks 是组织和处理许多小但相关 Python 代码片段的绝佳方式，如 [图 4-1](#fig0401)
    所示。
- en: '![](assets/wsp3_0401.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/wsp3_0401.png)'
- en: Figure 4-1\. A Jupyter Notebook running in the browser
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1：Jupyter Notebook 在浏览器中运行
- en: Each piece of code is contained in a box called a *cell*. The code within each
    cell can be run by typing Shift + Enter, or by clicking the Run button at the
    top of the page.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代码片段都包含在称为 *cell* 的框中。可以通过键入 Shift + Enter 或单击页面顶部的“运行”按钮来运行每个单元格中的代码。
- en: Project Jupyter began as a spin-off project from the IPython (Interactive Python)
    project in 2014\. These notebooks were designed to run Python code in the browser
    in an accessible and interactive way that would lend itself to teaching and presenting.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 Jupyter 在 2014 年从 IPython（交互式 Python）项目分支出来。这些笔记本设计用于在浏览器中以可访问和交互的方式运行 Python
    代码，非常适合教学和演示。
- en: 'To install Jupyter Notebooks:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Jupyter Notebooks：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After installation, you should have access to the `jupyter` command, which
    will allow you to start the web server. Navigate to the directory containing the
    downloaded exercise files for this book, and run:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，您应该可以访问 `jupyter` 命令，该命令将允许您启动 Web 服务器。导航到包含本书下载的练习文件的目录，并运行：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will start the web server on port 8888\. If you have a web browser running,
    a new tab should open automatically. If it doesn’t, copy the URL shown in the
    terminal, with the provided token, to your web browser.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在端口 8888 上启动 Web 服务器。如果您已经运行了 Web 浏览器，新标签页应该会自动打开。如果没有，请将终端中显示的带有提供的令牌的 URL
    复制到您的 Web 浏览器中。
- en: Connecting
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接
- en: In the first section of this book, we took a deep dive into how the internet
    sends packets of data across wires from a browser to a web server and back again.
    When you open a browser, type in `**google.com**`, and hit Enter, that’s exactly
    what’s happening—data, in the form of an HTTP request, is being transferred from
    your computer, and Google’s web server is responding with an HTML file that represents
    the data at the root of *google.com*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分中，我们深入探讨了互联网如何通过电缆将数据包从浏览器发送到 Web 服务器，然后再发送回来。当您打开浏览器，输入 `**google.com**`，然后按
    Enter 键时，正是发生了这种情况——数据以 HTTP 请求的形式从您的计算机传输，Google 的 Web 服务器则以 HTML 文件的形式响应表示 *google.com*
    的数据。
- en: But where, in this exchange of packets and frames, does the web browser actually
    come into play? Absolutely nowhere. In fact, ARPANET (the first public packet-switched
    network) predated the first web browser, Nexus, by at least 20 years.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在数据包和帧的交换中，Web 浏览器到底如何发挥作用？完全没有。事实上，ARPANET（第一个公共分组交换网络）比第一个 Web 浏览器 Nexus
    至少早 20 年。
- en: 'Yes, the web browser is a useful application for creating these packets of
    information, telling your operating system to send them off and interpreting the
    data you get back as pretty pictures, sounds, videos, and text. However, a web
    browser is just code, and code can be taken apart, broken into its basic components,
    rewritten, reused, and made to do anything you want. A web browser can tell the
    processor to send data to the application that handles your wireless (or wired)
    interface, but you can do the same thing in Python with just three lines of code:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，网络浏览器是一个有用的应用程序，用于创建这些信息包，告诉您的操作系统将它们发送出去，并解释您收到的数据为漂亮的图片、声音、视频和文本。但是，网络浏览器只是代码，代码可以被拆解、分解为其基本组件、重写、重复使用，并使其执行任何您想要的操作。网络浏览器可以告诉处理您的无线（或有线）接口的应用程序发送数据到处理器，但您可以在
    Python 中只用三行代码做同样的事情：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To run this, you can use the [IPython notebook](https://github.com/REMitchell/python-scraping/blob/master/Chapter01_BeginningToScrape.ipynb)
    for [Chapter 1](ch01.html#c-1) in the GitHub repository, or you can save it locally
    as *scrapetest.py* and run it in your terminal by using this command:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此命令，您可以在 GitHub 存储库的 [第 1 章](ch01.html#c-1) 中使用 [IPython 笔记本](https://github.com/REMitchell/python-scraping/blob/master/Chapter01_BeginningToScrape.ipynb)，或者您可以将其本地保存为
    *scrapetest.py* 并在终端中使用以下命令运行它：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note that if you also have Python 2.x installed on your machine and are running
    both versions of Python side by side, you may need to explicitly call Python 3.x
    by running the command this way:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果您的计算机上同时安装了 Python 2.x 并且并排运行了两个版本的 Python，则可能需要通过以下方式显式调用 Python 3.x
    来运行命令：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This command outputs the complete HTML code for *page1* located at the URL *http://pythonscraping.com/pages/page1.html*.
    More accurately, this outputs the HTML file *page1.html*, found in the directory
    *<web root>/pages*, on the server located at the domain name [*http://pythonscraping.com*](http://pythonscraping.com).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令输出位于 URL *http://pythonscraping.com/pages/page1.html* 的 *page1* 的完整 HTML
    代码。更准确地说，这输出位于域名 [*http://pythonscraping.com*](http://pythonscraping.com) 的服务器上的目录
    *<web root>/pages* 中的 HTML 文件 *page1.html*。
- en: Why is it important to start thinking of these addresses as “files” rather than
    “pages”? Most modern web pages have many resource files associated with them.
    These could be image files, JavaScript files, CSS files, or any other content
    that the page you are requesting is linked to. When a web browser hits a tag such
    as `<img src="cute​Kit⁠ten.jpg">`, the browser knows that it needs to make another
    request to the server to get the data at the location *cuteKitten.jpg* in order
    to fully render the page for the user.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么将这些地址视为“文件”而不是“页面”很重要？大多数现代网页都有许多与其关联的资源文件。这些可以是图像文件、JavaScript 文件、CSS 文件或您正在请求的页面链接到的任何其他内容。当网络浏览器命中诸如
    `<img src="cute​Kit⁠ten.jpg">` 的标签时，浏览器知道它需要向服务器发出另一个请求，以获取位于位置 *cuteKitten.jpg*
    的数据，以便为用户完全渲染页面。
- en: Of course, your Python script doesn’t have the logic to go back and request
    multiple files (yet); it can read only the single HTML file that you’ve directly
    requested.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您的 Python 脚本目前还没有逻辑去回去请求多个文件；它只能读取您直接请求的单个 HTML 文件。
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'means what it looks like it means: it looks at the Python module request (found
    within the *urllib* library) and imports only the function `urlopen`.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着看起来就像它的字面意思一样：它查看 Python 模块 request（在 *urllib* 库中找到）并仅导入函数 `urlopen`。
- en: '*urllib* is a standard Python library (meaning you don’t have to install anything
    extra to run this example) and contains functions for requesting data across the
    web, handling cookies, and even changing metadata such as headers and your user
    agent. We will be using urllib extensively throughout the book, so I recommend
    you read the [Python documentation for the library](https://docs.python.org/3/library/urllib.html).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*urllib* 是一个标准的 Python 库（这意味着您不必安装任何额外的内容来运行此示例），包含了用于在网络上请求数据、处理 cookies 甚至更改元数据（如标头和用户代理）的函数。在本书中，我们将广泛使用
    urllib，因此我建议您阅读该库的 [Python 文档](https://docs.python.org/3/library/urllib.html)。'
- en: '`urlopen` is used to open a remote object across a network and read it. Because
    it is a fairly generic function (it can read HTML files, image files, or any other
    file stream with ease), we will be using it quite frequently throughout the book.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlopen` 用于打开跨网络的远程对象并读取它。因为它是一个相当通用的函数（可以轻松读取 HTML 文件、图像文件或任何其他文件流），所以我们将在本书中经常使用它。'
- en: An Introduction to BeautifulSoup
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BeautifulSoup 简介
- en: Beautiful Soup, so rich and green,
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 美丽的汤，如此丰富而绿色，
- en: Waiting in a hot tureen!
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在一个热的碗里等待！
- en: Who for such dainties would not stoop?
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了这样的佳肴，谁不愿俯身？
- en: Soup of the evening, beautiful Soup!
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 傍晚的浓汤，美丽的浓汤！
- en: The *BeautifulSoup* library was named after a Lewis Carroll poem of the same
    name in *Alice’s Adventures in Wonderland*. In the story, this poem is sung by
    a character called the Mock Turtle (itself a pun on the popular Victorian dish
    Mock Turtle Soup made not of turtle but of cow).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*BeautifulSoup* 库以同名的刘易斯·卡罗尔诗歌《爱丽丝漫游奇境记》中的一首诗命名。在故事中，这首诗是由一个叫做模拟海龟的角色唱的（这个名字本身就是对维多利亚时期流行的模拟海龟汤的一个双关）。'
- en: Like its Wonderland namesake, BeautifulSoup tries to make sense of the nonsensical;
    it helps format and organize the messy web by fixing bad HTML and presenting us
    with easily traversable Python objects representing XML structures.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与其奇境中的同名者一样，BeautifulSoup 尝试理解荒谬之物；它通过修复糟糕的 HTML 并为我们提供易于遍历的 Python 对象来帮助格式化和组织混乱的网络。
- en: Installing BeautifulSoup
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 BeautifulSoup
- en: Because the BeautifulSoup library is not a default Python library, it must be
    installed. If you’re already experienced at installing Python libraries, please
    use your favorite installer and skip ahead to the next section, [“Running BeautifulSoup”](#runningBsoup).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 BeautifulSoup 库不是默认的 Python 库，所以必须安装它。如果你已经有经验安装 Python 库，请使用你喜欢的安装程序并跳到下一节，“运行
    BeautifulSoup”。
- en: For those who have not installed Python libraries (or need a refresher), this
    general method will be used for installing multiple libraries throughout the book,
    so you may want to reference this section in the future.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些尚未安装 Python 库（或需要复习的人），这个通用方法将用于在整本书中安装多个库，因此你可能想在未来参考这一部分。
- en: We will be using the BeautifulSoup 4 library (also known as BS4) throughout
    this book. The complete documentation, as well as installation instructions, for
    BeautifulSoup 4 can be found at [Crummy.com](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在整本书中使用 BeautifulSoup 4 库（也称为 BS4）。你可以在[Crummy.com](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)找到完整的文档和
    BeautifulSoup 4 的安装说明。
- en: If you’ve spent much time writing Python, you’ve probably used the package installer
    for Python ([pip](https://pypi.org/project/pip/)). If you haven’t, I highly recommend
    that you install pip in order to install BeautifulSoup and other Python packages
    used throughout this book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你花了很多时间写 Python，你可能已经使用过 Python 的包安装程序（[pip](https://pypi.org/project/pip/)）。如果还没有，我强烈建议你安装
    pip，以便安装 BeautifulSoup 和本书中使用的其他 Python 包。
- en: 'Depending on the Python installer you used, pip may already be installed on
    your computer. To check, try:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你使用的 Python 安装程序，pip 可能已经安装在你的计算机上。要检查，请尝试：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This command should result in the pip help text being printed to your terminal.
    If the command isn’t recognized, you may need to install pip. Pip can be installed
    in a variety of ways, such as with `apt-get` on Linux or `brew` on macOS. Regardless
    of your operating system, you can also download the pip bootstrap file at [*https://bootstrap.pypa.io/get-pip.py*](https://bootstrap.pypa.io/get-pip.py),
    save this file as *get-pip.py*, and run it with Python:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令应该导致在你的终端打印出 pip 帮助文本。如果命令未被识别，你可能需要安装 pip。可以使用多种方式安装 pip，例如在 Linux 上使用`apt-get`或在
    macOS 上使用`brew`。无论你的操作系统如何，你也可以在[*https://bootstrap.pypa.io/get-pip.py*](https://bootstrap.pypa.io/get-pip.py)下载
    pip 引导文件，并将其保存为*get-pip.py*，然后用 Python 运行它：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Again, note that if you have both Python 2.x and 3.x installed on your machine,
    you might need to call `python3` explicitly:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，如果你的机器上同时安装了 Python 2.x 和 3.x，你可能需要显式地调用`python3`：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, use pip to install BeautifulSoup:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用 pip 安装 BeautifulSoup：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you have two versions of Python, along with two versions of pip, you may
    need to call `pip3` to install the Python 3.x versions of packages:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你同时拥有两个版本的 Python 和两个版本的 pip，则可能需要调用`pip3`来安装 Python 3.x 版本的包：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And that’s it! BeautifulSoup will now be recognized as a Python library on
    your machine. You can test this by opening a Python terminal and importing it:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是全部啦！BeautifulSoup 现在将被识别为你机器上的 Python 库。你可以通过打开 Python 终端并导入它来测试：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The import should complete without errors.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 导入应该完成而没有错误。
- en: Running BeautifulSoup
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行 BeautifulSoup
- en: 'The most commonly used object in the BeautifulSoup library is, appropriately,
    the `BeautifulSoup` object. Let’s take a look at it in action, modifying the example
    found in the beginning of this chapter:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: BeautifulSoup 库中最常用的对象是适当地称为`BeautifulSoup`对象。让我们看看它在本章开头示例中的应用：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that this returns only the first instance of the `h1` tag found on the
    page. By convention, only one `h1` tag should be used on a single page, but conventions
    are often broken on the web, so you should be aware that this will retrieve only
    the first instance of the tag, and not necessarily the one that you’re looking
    for.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这仅返回页面上找到的第一个 `h1` 标签实例。按照惯例，单个页面上应仅使用一个 `h1` 标签，但通常会在网络上违反惯例，因此您应注意，这仅检索标签的第一个实例，并不一定是您要查找的实例。
- en: 'As in previous web scraping examples, you are importing the `urlopen` function
    and calling `html.read()` to get the HTML content of the page. In addition to
    the text string, BeautifulSoup can use the file object directly returned by `urlopen`,
    without needing to call `.read()` first:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的网页抓取示例类似，您正在导入 `urlopen` 函数并调用 `html.read()` 获取页面的 HTML 内容。除了文本字符串外，BeautifulSoup
    还可以直接使用由 `urlopen` 返回的文件对象，而不需要先调用 `.read()`：
- en: '[PRE14]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This HTML content is then transformed into a `BeautifulSoup` object with the
    following structure:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将此 HTML 内容转换为 `BeautifulSoup` 对象，其结构如下：
- en: '**html** → *<html><head>...</head><body>...</body></html>*'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**html** → *<html><head>...</head><body>...</body></html>*'
- en: '**head** → *<head><title>A Useful Page<title></head>*'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**head** → *<head><title>A Useful Page<title></head>*'
- en: '**title** → *<title>A Useful Page</t**itle>*'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**title** → *<title>A Useful Page</t**itle>*'
- en: '**body** → *<body><h1>An Int...</h1><div>Lorem ip...</div></body>*'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**body** → *<body><h1>An Int...</h1><div>Lorem ip...</div></body>*'
- en: '**h1** → *<h1>An Interesting Title</h1>*'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**h1** → *<h1>An Interesting Title</h1>*'
- en: '**div** → *<div>Lorem Ipsum dolor...</div>*'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**div** → *<div>Lorem Ipsum dolor...</div>*'
- en: 'Note that the `h1` tag that you extract from the page is nested two layers
    deep into your `BeautifulSoup` object structure (`html` → `body` → `h1`). However,
    when you actually fetch it from the object, you call the `h1` tag directly:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，从页面中提取的 `h1` 标签嵌套在您的 `BeautifulSoup` 对象结构的两层深度内（`html` → `body` → `h1`）。但是，当您实际从对象中获取它时，直接调用
    `h1` 标签：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In fact, any of the following function calls would produce the same output:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，以下任何一个函数调用都会产生相同的输出：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When you create a `BeautifulSoup` object, two arguments are passed in:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 `BeautifulSoup` 对象时，会传入两个参数：
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first is the HTML string that the object is based on, and the second specifies
    the parser that you want BeautifulSoup to use to create that object. In the majority
    of cases, it makes no difference which parser you choose.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是基于对象的 HTML 字符串，第二个指定您希望 BeautifulSoup 使用的解析器来创建该对象。在大多数情况下，选择哪个解析器并不重要。
- en: '`html.parser` is a parser that is included with Python 3 and requires no extra
    installations to use. Except where required, we will use this parser throughout
    the book.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`html.parser` 是 Python 3 中附带的解析器，无需额外安装即可使用。除非另有要求，我们将在整本书中使用此解析器。'
- en: 'Another popular parser is [`lxml`](http://lxml.de/parsing.html). This can be
    installed through pip:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个流行的解析器是 [`lxml`](http://lxml.de/parsing.html)。可以通过 pip 安装它：
- en: '[PRE18]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`lxml` can be used with BeautifulSoup by changing the parser string provided:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 可通过更改提供的解析器字符串在 BeautifulSoup 中使用 `lxml` 解析器：
- en: '[PRE19]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`lxml` has some advantages over `html.parser` in that it is generally better
    at parsing “messy” or malformed HTML code. It is forgiving and fixes problems
    like unclosed tags, tags that are improperly nested, and missing head or body
    tags.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`lxml` 在解析“混乱”或格式不正确的 HTML 代码方面比 `html.parser` 有一些优势。它是宽容的，并修复诸如未关闭标签、不正确嵌套的标签以及缺少
    head 或 body 标签等问题。'
- en: '`lxml` is also somewhat faster than `html.parser`, although speed is not necessarily
    an advantage in web scraping, given that the speed of the network itself will
    almost always be your largest bottleneck.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`lxml` 在速度上也比 `html.parser` 稍快，尽管在网页抓取中，速度并不一定是优势，因为网络速度几乎总是最大的瓶颈。'
- en: Avoid Over-Optimizing Web Scraping Code
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免过度优化网页抓取代码
- en: Elegant algorithms are lovely to behold, but when it comes to web scraping,
    they may not have a practical impact. A few microseconds of processing time will
    likely be dwarfed by the—sometimes *actual*—seconds of network latency that a
    network request takes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅的算法很令人愉悦，但在网页抓取中，它们可能没有实际影响。处理时间的几微秒可能会被网络请求的秒级延迟所淹没。
- en: Good web scraping code generally focuses on robust and easily readable implementations,
    rather than clever processing optimizations.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的网页抓取代码通常侧重于健壮且易于阅读的实现，而不是巧妙的处理优化。
- en: One of the disadvantages of `lxml` is that it needs to be installed separately
    and depends on third-party C libraries to function. This can cause problems for
    portability and ease of use, compared to `html.parser`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`lxml`的一个缺点是需要单独安装，并且依赖第三方C库来运行。与`html.parser`相比，这可能会导致可移植性和易用性问题。'
- en: Another popular HTML parser is `html5lib`. Like `lxml`, `html5lib` is an extremely
    forgiving parser that takes even more initiative with correcting broken HTML.
    It also depends on an external dependency and is slower than both `lxml` and `html.parser`.
    Despite this, it may be a good choice if you are working with messy or handwritten
    HTML sites.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个流行的HTML解析器是`html5lib`。与`lxml`类似，`html5lib`是一个非常宽容的解析器，甚至更主动地修复损坏的HTML。它也依赖于外部依赖项，比`lxml`和`html.parser`都慢。尽管如此，如果您要处理混乱或手写的HTML网站，它可能是一个不错的选择。
- en: 'It can be used by installing and passing the string `html5lib` to the BeautifulSoup
    object:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以通过安装并将字符串`html5lib`传递给BeautifulSoup对象来使用：
- en: '[PRE20]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: I hope this small taste of BeautifulSoup has given you an idea of the power
    and simplicity of this library. Virtually any information can be extracted from
    any HTML (or XML) file, as long as it has an identifying tag surrounding it or
    near it. [Chapter 5](ch05.html#c-5) delves more deeply into more-complex BeautifulSoup
    function calls and presents regular expressions and how they can be used with
    BeautifulSoup in order to extract information from websites.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个BeautifulSoup的简介让您对这个库的功能和简易性有了一些了解。几乎可以从任何HTML（或XML）文件中提取任何信息，只要它有一个标识性标签围绕它或靠近它。[第五章](ch05.html#c-5)更深入地探讨了更复杂的BeautifulSoup函数调用，并介绍了正则表达式及其如何与BeautifulSoup一起用于从网站提取信息。
- en: Connecting Reliably and Handling Exceptions
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可靠连接和异常处理
- en: The web is messy. Data is poorly formatted, websites go down, and closing tags
    go missing. One of the most frustrating experiences in web scraping is to go to
    sleep with a scraper running, dreaming of all the data you’ll have in your database
    the next day—only to find that the scraper hit an error on some unexpected data
    format and stopped execution shortly after you stopped looking at the screen.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是混乱的。数据格式糟糕，网站宕机，闭合标签丢失。在网络爬取中最令人沮丧的经历之一是，当您在睡觉时让爬虫运行，梦想着第二天数据库中将拥有的所有数据，却发现爬虫在某些意外数据格式上出现错误，并在您停止查看屏幕后不久停止执行。
- en: In situations like these, you might be tempted to curse the name of the developer
    who created the website (and the oddly formatted data), but the person you should
    really be kicking is yourself for not anticipating the exception in the first
    place!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，您可能会被诱使诅咒创建网站的开发者的名字（以及奇怪的数据格式），但实际上应该踢的人是您自己，因为您没有预料到这个异常！
- en: 'Let’s look at the first line of our scraper, after the import statements, and
    figure out how to handle any exceptions this might throw:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的爬虫的第一行，在导入语句之后，找出如何处理可能引发的任何异常：
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Two main things can go wrong in this line:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码可能会出现两个主要问题：
- en: The page is not found on the server (or there was an error in retrieving it).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器上找不到页面（或者在检索时出错）。
- en: The server is not found at all.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根本找不到服务器。
- en: 'In the first situation, an HTTP error will be returned. This HTTP error may
    be “404 Page Not Found,” “500 Internal Server Error,” and so forth. In all of
    these cases, the `urlopen` function will throw the generic exception `HTTPError`.
    You can handle this exception in the following way:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，将返回一个HTTP错误。这个HTTP错误可能是“404 页面未找到”，“500 内部服务器错误”等。在所有这些情况下，`urlopen`函数将抛出通用异常`HTTPError`。您可以通过以下方式处理此异常：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: If an HTTP error code is returned, the program now prints the error and does
    not execute the rest of the program under the `else` statement.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果返回了HTTP错误代码，程序现在会打印错误，并且不会在`else`语句下执行程序的其余部分。
- en: 'If the server is not found at all (if, for example, *http://www.pythonscraping.com*
    is down, or the URL is mistyped), `urlopen` will throw an `URLError`. This indicates
    that no server could be reached at all, and, because the remote server is responsible
    for returning HTTP status codes, an `HTTPError` cannot be thrown, and the more
    serious `URLError` must be caught. You can add a check to see whether this is
    the case:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果根本找不到服务器（例如，*http://www.pythonscraping.com* 不存在，或者URL输错了），`urlopen` 将抛出一个`URLError`。这表示根本无法连接到任何服务器，因为远程服务器负责返回HTTP状态代码，所以不会抛出`HTTPError`，而是必须捕获更严重的`URLError`。您可以添加检查以查看是否出现了这种情况：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Of course, if the page is retrieved successfully from the server, there is still
    the issue of the content on the page not being quite what you expected. Every
    time you access a tag in a `BeautifulSoup` object, it’s smart to add a check to
    make sure the tag actually exists. If you attempt to access a tag that does not
    exist, BeautifulSoup will return a `None` object. The problem is, attempting to
    access a tag on a `None` object itself will result in an `AttributeError` being
    thrown.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果成功从服务器检索到页面，仍然存在页面内容不完全符合预期的问题。每次访问 `BeautifulSoup` 对象中的标签时，都应该智能地添加检查以确保标签确实存在。如果尝试访问不存在的标签，BeautifulSoup
    将返回一个 `None` 对象。问题在于，尝试在 `None` 对象上访问标签本身将导致抛出 `AttributeError`。
- en: 'The following line (where `nonExistentTag` is a made-up tag, not the name of
    a real BeautifulSoup function):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 下面这行代码（其中 `nonExistentTag` 是一个虚构的标签，不是 BeautifulSoup 中真实的函数名）：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'returns a `None` object. This object is perfectly reasonable to handle and
    check for. The trouble comes if you don’t check for it but instead go on and try
    to call another function on the `None` object, as illustrated here:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个 `None` 对象。这个对象完全可以处理和检查。问题出现在如果您没有检查它，而是继续尝试在这个 `None` 对象上调用另一个函数，正如这里所示：
- en: '[PRE25]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This returns an exception:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致异常抛出：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'So how can you guard against these two situations? The easiest way is to explicitly
    check for both situations:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如何防范这两种情况？最简单的方法是显式检查这两种情况：
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This checking and handling of every error does seem laborious at first, but
    it’s easy to add a little reorganization to this code to make it less difficult
    to write (and, more important, much less difficult to read). This code, for example,
    is our same scraper written in a slightly different way:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然最初每次错误的检查和处理都显得有些费力，但通过对代码稍作重新组织，可以使其更易于编写（更重要的是，更易于阅读）。例如，以下代码是稍微不同方式编写的同一个爬虫：
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In this example, you’re creating a function `getTitle`, which returns either
    the title of the page, or a `None` object if there was a problem retrieving it.
    Inside `getTitle`, you check for an `HTTPError`, as in the previous example, and
    encapsulate two of the BeautifulSoup lines inside one `try` statement. An `AttributeError`
    might be thrown from either of these lines (if the server did not exist, `html`
    would be a `None` object, and `html.read()` would throw an `AttributeError`).
    You could, in fact, encompass as many lines as you want inside one `try` statement
    or call another function entirely, which can throw an `AttributeError` at any
    point.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您正在创建一个名为 `getTitle` 的函数，它返回页面的标题或者如果检索时出现问题则返回一个 `None` 对象。在 `getTitle`
    中，您检查了 `HTTPError`，就像前面的例子中一样，并将两行 BeautifulSoup 代码封装在一个 `try` 语句中。任何这些行都可能引发
    `AttributeError`（如果服务器不存在，`html` 将是一个 `None` 对象，`html.read()` 将引发 `AttributeError`）。实际上，您可以在一个
    `try` 语句中包含尽可能多的行或调用另一个可能在任何时候引发 `AttributeError` 的函数。
- en: When writing scrapers, it’s important to think about the overall pattern of
    your code in order to handle exceptions and make it readable at the same time.
    You’ll also likely want to heavily reuse code. Having generic functions such as
    `getSiteHTML` and `getTitle` (complete with thorough exception handling) makes
    it easy to quickly—and reliably—scrape the web.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当编写爬虫时，重要的是要考虑代码的整体结构，以便处理异常并同时保持可读性。您可能还希望大量重用代码。具有通用函数如 `getSiteHTML` 和 `getTitle`（完备的异常处理）使得能够快速且可靠地进行网页抓取。
