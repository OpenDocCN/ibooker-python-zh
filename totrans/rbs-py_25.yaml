- en: Chapter 21\. Testing Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tests are one of most important safety nets you can build around your codebase.
    It is incredibly comforting to make a change and see that all tests pass afterwards.
    However, it is challenging to gauge the best use of your time regarding testing.
    Too many tests and they become a burden; you spend more time maintaining tests
    than delivering features. Too few tests and you are letting potential catastrophes
    make it into production.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, I will ask you to focus on your testing strategy. I’ll break
    down the different types of tests and how to choose which tests to write. I’ll
    focus on Python best practices around test construction, and then I’ll end with
    some common testing strategies specific to Python.
  prefs: []
  type: TYPE_NORMAL
- en: Defining Your Test Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you write tests, you should decide what your *test strategy* will be.
    A test strategy is a plan for spending time and effort to test your software in
    order to mitigate risk. This strategy will influence what types of tests you write,
    how you write them, and how much time you spend writing (and maintaining) them.
    Everybody’s test strategy will be different, but they will all be in a similar
    form: a list of questions about your system and how you plan on answering them.
    For example, if I were writing a calorie-counting app, here would be a part of
    my test strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Do not treat your test strategy as a static document that is created once and
    never modified. As you develop your software, continue to ask questions as they
    come to mind, and discuss whether your strategy needs to evolve as you learn more.
  prefs: []
  type: TYPE_NORMAL
- en: This test strategy will govern where you put your focus for writing tests. As
    you start to fill it out, the first thing you need to do is understand what a
    test is and why you write them.
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Test?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should understand the *what* and the *why* you are writing the software.
    Answering these questions will frame your goals for writing tests. Tests serve
    as a way of verifying *what* the code is doing, and you write tests so that you
    don’t negatively impact the *why*. Software produces value. That’s it. Every piece
    of software has some value attached to it. Web apps provide important services
    for the general population. Data science pipelines may create prediction models
    that help us better understand the patterns in our world. Even malicious software
    has value; the people who are performing the exploit are using the software to
    achieve a goal (even if there is negative value to anyone affected).
  prefs: []
  type: TYPE_NORMAL
- en: That’s *what* software provides, but *why* does anyone write software? Most
    people answer “money,” and I don’t want to knock that, but there are other reasons
    too. Sometimes software is written for money, sometimes it’s written for self-fulfilment,
    and sometimes it’s written for advertising (such as contributing to an open source
    project to bolster a resume). Tests serve as validation for these systems. They
    go so much deeper than just catching errors or giving you confidence in shipping
    a product.
  prefs: []
  type: TYPE_NORMAL
- en: If I’m writing some code for learning purposes, my *why* is purely for self-fulfilment,
    and the value is derived from how much I learn. If I do things wrong, that is
    still a learning opportunity; I can get by if all my tests are just manual spot
    checks at the end of the project. However, a company that markets tools to other
    developers might have a completely different strategy. Developers at that company
    may choose to write tests to make sure they are not regressing any functionality
    so that the company does not lose customers (which would translate to a loss of
    profit). Each of these projects needs a different level of testing.
  prefs: []
  type: TYPE_NORMAL
- en: So, what is a test? Is it something that catches errors? Is it something that
    gives you confidence to ship your product? Yes, but the true answer goes a little
    deeper. Tests answer questions about your system. I want you to think about the
    software you write. What is its purpose? What do you want to always know about
    the things you build? The things that are important to you form your test strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you ask yourself questions, you really are asking yourself what tests
    you find valuable:'
  prefs: []
  type: TYPE_NORMAL
- en: Will my application handle a predicted load?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does my code meet the customer’s needs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is my application secure?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What happens when a customer inputs bad data into my system?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each one of these questions points to a different type of test that you might
    need to write. Check out [Table 21-1](part0027_split_002.html#testing_questions)
    for a list of common questions and the appropriate tests that answer those questions.
  prefs: []
  type: TYPE_NORMAL
- en: Table 21-1\. Types of tests and the questions they answer
  prefs: []
  type: TYPE_NORMAL
- en: '| Test type | Question the test answers |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Unit | Do units (functions and classes) act as developers expect? |'
  prefs: []
  type: TYPE_TB
- en: '| Integration | Are separate parts of the system stitched together properly?
    |'
  prefs: []
  type: TYPE_TB
- en: '| Acceptance | Does the system do what the end user expects? |'
  prefs: []
  type: TYPE_TB
- en: '| Load | Does the system stay operational under heavy duress? |'
  prefs: []
  type: TYPE_TB
- en: '| Security | Does the system resist specific attacks and exploits? |'
  prefs: []
  type: TYPE_TB
- en: '| Usability | Is the system intuitive to use? |'
  prefs: []
  type: TYPE_TB
- en: Notice that [Table 21-1](part0027_split_002.html#testing_questions) did not
    say anything about making sure your software is bug free. As Edsger Djikstra wrote,
    “Program testing can be used to show the presence of bugs, but never to show their
    absence!”^([1](part0027_split_007.html#idm45644727274344)) Tests answer questions
    regarding the *quality* of your software.
  prefs: []
  type: TYPE_NORMAL
- en: '*Quality* is this nebulous, ill-defined term that gets tossed around quite
    a bit. It’s a tough thing to pin down, but I prefer this quote from Gerald Weinberg:
    “Quality is value to some person.”^([2](part0027_split_007.html#idm45644727268952))
    I love how open-ended this quote is; you need to think of anyone who may receive
    some value from your system. It’s not just your direct customers, but your customers’
    customers, your operations team, your sales, your coworkers, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve identified who receives the value of your system, you need to measure
    the impact when something goes wrong. For every test that is not run, you lose
    a chance to learn whether you are delivering value. What is the impact if that
    value is not delivered? For core business needs, the impact is pretty high. For
    features that lie outside of an end user’s critical path, the impact may be low.
    Know your impact, and weigh that against the cost of testing. If the impact’s
    cost is higher than the test, write the test. If it’s lower, skip writing the
    test and spend your time doing something more impactful.
  prefs: []
  type: TYPE_NORMAL
- en: The testing pyramid
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In just about any testing book, you are bound to come across a figure similar
    to [Figure 21-1](part0027_split_002.html#testing_pyramid): a “testing pyramid.”^([3](part0027_split_007.html#idm45644727260312))'
  prefs: []
  type: TYPE_NORMAL
- en: '![ropy 2101](../images/00039.gif)'
  prefs: []
  type: TYPE_IMG
- en: Figure 21-1\. The testing pyramid
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The idea is that you want to write a lot of small, isolated unit tests. These
    are theoretically cheaper and should make up the bulk of your testing, hence they’re
    at the bottom. You have fewer integration tests, which are costly, and even fewer
    UI tests, which are very costly. Now, ever since its inception, developers have
    argued about the testing pyramid in a multitude of ways, including where the lines
    get drawn, the usefulness of unit tests, and even the shape of the triangle (I’ve
    even seen the triangle inverted).
  prefs: []
  type: TYPE_NORMAL
- en: The truth is, it doesn’t matter what the labels are or how you separate your
    tests. What you want is your triangle to look like [Figure 21-2](part0027_split_002.html#pat_testing_pyramid),
    which focuses on the ratio of value to cost.
  prefs: []
  type: TYPE_NORMAL
- en: '![ropy 2102](../images/00040.gif)'
  prefs: []
  type: TYPE_IMG
- en: Figure 21-2\. The testing pyramid focused on value-to-cost
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Write lots of tests that have a high value-to-cost ratio. It doesn’t matter
    if they are unit tests or acceptance tests. Find ways to run them often. Make
    tests fast so that developers run them multiple times between commits to verify
    that things are still working. Keep your less valuable, slower, or more costly
    tests for testing on each commit (or at least periodically).
  prefs: []
  type: TYPE_NORMAL
- en: The more tests you have, the fewer unknowns you have. The fewer unknowns you
    have, the more robust your codebase will be. With every change you make, you have
    a bigger safety net to check for any regression. But what if the tests are becoming
    too costly, far outweighing the cost of any impact? If you feel these tests are
    still worthwhile, you need to find a way to reduce their cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cost of a test is threefold: the initial cost of writing, the cost of running,
    and the cost for maintenance. Tests, at a minimum, will have to run for some amount
    of time, and that does cost money. However, reducing that cost often becomes an
    optimization exercise, where you look for ways of parallelizing your tests or
    running them more frequently on developer machines. You still need to reduce the
    initial cost of writing and ongoing cost of maintaining your tests. Fortunately,
    everything you’ve read in this book so far directly applies to reducing those
    costs. Your test code is just as much a part of your codebase as the rest of your
    code, and you need to make sure it is robust as well. Choose the right tools,
    organize your test cases properly, and make your tests clear to read and maintain.'
  prefs: []
  type: TYPE_NORMAL
- en: Discussion Topic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Measure the costs of tests in your system. Does time to write, time to run,
    or time spent maintaining dominate your costs? What can you do to reduce those
    costs?
  prefs: []
  type: TYPE_NORMAL
- en: Reducing Test Cost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you examine the value against the cost of a test, you are gathering information
    that will help you prioritize your testing strategy. Some tests may not be worth
    running, and some will stand out as the first tests you want to write to maximize
    value. However, sometimes you run into the case where there is a really important
    test that you want to write, but it is incredibly costly to write and/or maintain.
    In these cases, find a way to reduce the costs of that test. The way you write
    and organize your tests is paramount to making a test cheaper to write and understand.
  prefs: []
  type: TYPE_NORMAL
- en: AAA Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with production code, focus on readability and maintainability in your test
    code. Communicate your intent as clearly as possible. Future test readers will
    thank you if they can see exactly what you are trying to test. When writing a
    test, it helps for each test to follow the same basic pattern.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common patterns you’ll find in tests is the 3A, or AAA, test
    pattern.^([4](part0027_split_007.html#idm45644727210584)) AAA stands for *Arrange-Act-Assert*.
    You break up each test into three separate blocks of code, one for setting up
    your preconditions (arrange), one for performing the operations that are being
    tested (act), and then one for checking for any post-conditions (assert). You
    may also hear about a fourth A, for *annihilate*, or your clean-up code. I’ll
    cover each of these steps in detail to discuss how to make your tests easier to
    read and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Arrange
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *arrange* step is all about setting up the system in a state that is ready
    to test. These are called the *preconditions* of the test. You set up any dependencies
    or test data that are needed for the test to operate correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: First, I add ingredients to a database and associate a list of ingredients with
    a dish called “Bacon Cheeseburger w/ Fries.” Then I find out how many calories
    are in the burger, check this against a known value, and clean up the database.
  prefs: []
  type: TYPE_NORMAL
- en: Look how much code there is before I actually get to the test itself (the `get_calories`
    invocation). Large *arrange* blocks are a red flag. You will have many tests that
    look very similar, and you want readers to be able to know how they differ at
    a glance.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large *arrange* blocks may indicate a complicated setup of dependencies. Any
    user of this code will presumably have to set up the dependencies in a similar
    way. Take a step back and ask if there are simpler ways to handle dependencies,
    such as using the strategies described in [Part III](part0019.html#part_3).
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, if I have to add 15 ingredients in two separate tests
    but set an ingredient slightly differently to simulate substitutions, it will
    be difficult to eyeball how the tests differ. Giving the tests verbose names indicating
    their differences is a good step to make, but that only goes so far. Find a balance
    between keeping the test informative and making it easy to read at a glance.
  prefs: []
  type: TYPE_NORMAL
- en: Consistent preconditions versus changing preconditions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Look through your tests and ask yourself what preconditions are the same across
    sets of tests. Extract these through a function and reuse that function across
    each test. Look how much easier it is to compare the following two tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: By creating helper functions (in this case, `add_base_ingredients_to_database`
    and `setup_bacon_cheeseburger`), you take all the unimportant boilerplate of the
    tests and reduce it, allowing developers to hone in on differences between tests.
  prefs: []
  type: TYPE_NORMAL
- en: Use test framework features for boilerplate code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most test frameworks provide a way to run code automatically before tests. In
    the built-in `unittest` module, you can write a `setUp` function to run before
    every test. In `pytest`, you accomplish something similar with fixtures.
  prefs: []
  type: TYPE_NORMAL
- en: 'A *fixture* in `pytest` is a way of specifying initialization and teardown
    code for tests. Fixtures offer a ton of useful features, like defining dependencies
    on other fixtures (letting `pytest` control initialization order) and controlling
    initialization so that a fixture is only initialized once per module. In the previous
    example, we could have used a fixture for the `test_database`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the test has an argument for `test_database` now. This is the fixture
    at work; the function `test_database` (as well as `db_creation`) will get called
    before the test. Fixtures only become more useful as the number of tests grows.
    They are composable, allowing you to mix them together and reduce code duplication.
    I won’t generally use them to abstract code in a single file, but as soon as that
    initialization needs to be used in multiple files, fixtures are the way to go.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Python offers duck typing (first mentioned in [Chapter 2](part0005_split_000.html#types))
    as part of its type system, which means that you can easily substitute types for
    one another as long as they uphold the same contract (as discussed in [Chapter 12](part0016_split_000.html#subtyping)).
    This means that you can tackle complex dependencies in a completely different
    way: use a simple mocked object instead. A *mocked* object is something that looks
    identical to a production object as far as methods and fields go, but offers simplified
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Mocks are used a lot in unit tests, but you will see their usage decline the
    less granular the tests become. This is because you try to test more of the system
    at a higher level; the services you are mocking are often part of the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if the database in the previous example was quite complex to
    set up with multiple tables and schemas, it might not be worth setting up for
    every test, especially if tests share a database; you want to keep tests isolated
    from one another. (I’ll cover this more in a moment.) The class handling the database
    might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of using this class verbatim, create a mock class that just looks like
    a database handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With the mock, I’m just using a simple dictionary to store my data. How you
    mock your data will be different for each scenario, but if you can find a way
    to substitute the real object with a mock object, you can dramatically reduce
    the complexity of your setup.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Some people use [*monkeypatching*](https://oreil.ly/xBFHl), or swapping out
    methods at runtime to inject mocks. This is OK in moderation, but if you find
    your tests littered with monkeypatching, this is an antipattern. It means that
    you have far too rigid a physical dependency between different modules and should
    look at finding ways to make your system more modular. (Consult [Part III](part0019.html#part_3)
    for more ideas on making code extensible.)
  prefs: []
  type: TYPE_NORMAL
- en: Annihilate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Technically, the *annihilate* stage is the last thing you do in a test, but
    I’m covering it second. Why? Because it’s inherently tied to your *arrange* step.
    Whatever you set up in *arrange* needs to be torn down if it could influence other
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: You want your tests to be isolated from one another; it will make them easier
    to maintain. One of the biggest nightmares for a test automation writer is having
    tests fail depending on what order they run in (especially if you have thousands).
    This is a sure sign of tests having subtle dependencies on one another. Clean
    up your tests before you leave them and reduce the chances of tests interacting
    with one another. Here are some strategies for dealing with test cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t use shared resources
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you can get away with it, share nothing between tests. This isn’t always
    feasible, but it should be your goal. If no tests share any resources, then you
    don’t need to clean anything up. A shared resource can be in Python (global variable,
    class variables) or in the environment (database, file access, socket pools).
  prefs: []
  type: TYPE_NORMAL
- en: Use context managers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Use a context manager (discussed in [Chapter 11](part0015_split_000.html#api))
    to ensure that resources are always cleaned up. In my previous example, eagle-eyed
    readers may have noticed a bug:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If the assertion fails, an exception is raised and `cleanup_database` never
    executes. It would be much better to force usage through a context manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Put your cleanup code in the context manager so that your test writers never
    have to actively think about it; it’s just done for them.
  prefs: []
  type: TYPE_NORMAL
- en: Use fixtures
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you are using `pytest` fixtures, you can use them much like you could a
    context manager. You can *yield* values from a fixture, allowing you to return
    to the fixture’s execution after the test finishes. Observe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the `test_database` fixture now yields the database. When any test
    using this function finishes (whether it passes or fails), the database cleanup
    function will always execute.
  prefs: []
  type: TYPE_NORMAL
- en: Act
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *act* stage is the most important part of the test. It embodies the actual
    operation that you are testing. In the preceding examples, the *act* stage was
    getting the calories for a specific dish. You do not want an *act* stage to be
    much longer than one or two lines of code. Less is more; by keeping this stage
    small, you reduce the time it takes readers to understand the meat of the test.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, you want to reuse the same *act* stage across multiple tests. If
    you find yourself wanting to write the same test on the same action, but with
    slightly different input data and assertions, consider *parameterizing* your tests.
    Test *parameterization* is a way of running the same test on different parameters.
    This allows you to write *table-driven* tests, or a way of organizing your test
    data in a tabular form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the `get_calories` test with parameterization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You define your parameters as a list of tuples, one per test case. Each parameter
    is passed to the test case as an argument. `pytest` automatically will run this
    test, once per parameter set.
  prefs: []
  type: TYPE_NORMAL
- en: Parameterized tests have the benefit of condensing a lot of test cases into
    one function. Readers of the test can just go down through the table listed in
    the parameterization to understand what expected input and output is (Cobb salad
    should have 1,000 calories, mashed potatoes should have 400 calories, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Parameterization is a great way to separate the test data from the actual test
    (similar to separating policy and mechanisms, as discussed in [Chapter 17](part0022_split_000.html#composability)).
    However, be careful. If you make your tests too generic, it will be harder to
    ascertain what they are testing. Avoid using more than three or four parameters
    if you can.
  prefs: []
  type: TYPE_NORMAL
- en: Assert
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last step to do before cleaning up is *asserting* some property is true
    about the system. Preferably, there should be one logical assertion near the end
    of your test. If you find yourself jamming too many assertions into a test, you
    either have too many actions in your test or too many tests matched into one.
    When a test has too many responsibilities, it makes it harder for maintainers
    to debug software. If they make a change that produces a failed test, you want
    them to be able to quickly find out what the problem is. Ideally, they can figure
    out what’s wrong based on the test name, but at the very least, they should be
    able to open up the test, look for about 20 or 30 seconds, and realize what went
    wrong. If you have multiple assertions, you have multiple reasons a test can go
    wrong, and it will take maintainers time to sort through them.
  prefs: []
  type: TYPE_NORMAL
- en: This doesn’t mean that you should only have one *assert* statement; it is OK
    to have a few *assert* statements as long as they are all involved in testing
    the same property. Make your assertions verbose as well, so that developers get
    an informative message when things go wrong. In Python, you can supply a text
    message that gets passed along with the `AssertionError` to help with debugging.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`pytest` rewrites assertion statements, which also provides an extra level
    of debug messages. If the above test were to fail, the message returned to the
    test writer would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: For more complex assertions, build up an assertion library that makes it incredibly
    easy to define new tests. This is like building a vocabulary in your codebase;
    you want a diverse set of concepts to share in your test code as well. For this,
    I recommend using [Hamcrest matchers](http://hamcrest.org).^([5](part0027_split_007.html#idm45644726341656))
  prefs: []
  type: TYPE_NORMAL
- en: '*Hamcrest matchers* are a way of writing assertions to read similarly to natural
    language. The [`PyHamcrest`](https://github.com/hamcrest/PyHamcrest) library supplies
    common matchers to help you write your asserts. Take a look at how it uses custom
    assertion matchers to make tests more clear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The real strength of `PyHamcrest` is that you can define your own matchers.^([6](part0027_split_007.html#idm45644726260312))
    Here’s an example of a matcher for checking if a dish is vegan:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If the test fails, you get the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Discussion Topic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Where in your tests can you use custom matchers? Discuss what a shared testing
    vocabulary would be in your tests and how custom matchers would improve readability.
  prefs: []
  type: TYPE_NORMAL
- en: Closing Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like a tightrope walker’s safety net, tests give you comfort and confidence
    as you work. It’s not just about finding bugs. Tests verify that what you build
    is performing as you expect. They give future collaborators leeway to make more
    risky changes; they know that if they fall, the tests will catch them. You will
    find that regressions become more rare, and your codebase becomes easier to work
    in.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, tests are not free. There is a cost to writing, running, and maintaining
    them. You need to be careful how you spend your time and effort. Use well-known
    patterns in constructing tests to minimize the cost: follow the AAA pattern, keep
    each stage small, and make your tests clear and readable. Your tests are just
    as important as your codebase. Treat them with just as much respect and make them
    robust.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, I will focus on acceptance tests. Acceptance tests have
    a different purpose than unit or integration tests, and some of the patterns you
    use will differ.
  prefs: []
  type: TYPE_NORMAL
- en: You will learn about how acceptance tests create conversations, as well as how
    they make sure your codebase is doing the right thing for your customers. They
    are an invaluable tool for your codebase in delivering value.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](part0027_split_002.html#idm45644727274344-marker)) Edsger W. Dijkstra.
    “Notes on Structured Programming.” Technological University Eindhoven, The Netherlands,
    Department of Mathematics, 1970\. [*https://oreil.ly/NAhWf*](https://oreil.ly/NAhWf).
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](part0027_split_002.html#idm45644727268952-marker)) Gerald M. Weinberg.
    *Quality Software Management*. Vol. 1: *Systems Thinking*. New York, NY: Dorset
    House Publishing, 1992.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](part0027_split_002.html#idm45644727260312-marker)) This is known as the
    testing pyramid, introduced in *Succeeding with Agile* by Mike Cohn (Addison-Wesley
    Professional). Cohn originally has “Service” level tests in place of integration
    tests, but I’ve seen more iterations with “integration” tests as the middle layer.
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](part0027_split_005.html#idm45644727210584-marker)) The AAA pattern was
    first named by Bill Wake in 2001\. Check out [this blog post](https://oreil.ly/gdU4T)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](part0027_split_005.html#idm45644726341656-marker)) Hamcrest is an anagram
    of “matchers.”
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](part0027_split_005.html#idm45644726260312-marker)) Check out the [PyHamcrest
    documentation](https://oreil.ly/XWjOd) for more information, such as additional
    matchers or integrating with test frameworks.
  prefs: []
  type: TYPE_NORMAL
